for knowledge_type in gram gram gram ; do \
	for col_name in fine_log_cluster_template medium_log_cluster_template coarse_log_cluster_template ; do \
		~/miniconda3/envs/lena/bin/python main.py \
			--experimentconfig_sequence_type huawei_logs \
			--experimentconfig_model_type $knowledge_type \
			--huaweipreprocessorconfig_min_causality 0.01 \
			--experimentconfig_batch_size 128 \
			--no-modelconfig_base_feature_embeddings_trainable \
			--no-modelconfig_base_hidden_embeddings_trainable \
			--sequenceconfig_y_sequence_column_name attributes \
			--sequenceconfig_x_sequence_column_name $col_name \
			--huaweipreprocessorconfig_relevant_log_column $col_name \
			--sequenceconfig_max_window_size 10 \
			--sequenceconfig_min_window_size 10 \
			--experimentconfig_multilabel_classification \
			--sequenceconfig_flatten_y \
			--modelconfig_rnn_type gru \
			--modelconfig_rnn_dim 200 \
			--modelconfig_embedding_dim 300 \
			--modelconfig_attention_dim 100 \
			--huaweipreprocessorconfig_log_parser spell \
			 ; \
	done ; \
done ; \

2023-05-24 13:03:45.012707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:03:45.536509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:45.536568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:45.536574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 5249836641c743d7b6026aa5780aefd8
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:03:48.272067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.272266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.273122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.273277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.273419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.273558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.273906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:03:48.407035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.407256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.407415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.407553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.407690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:48.407825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.971397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.971596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.971769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.971905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.972035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.972153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:03:49.972579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:49.972687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.195471]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.128990]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.221269]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.189562]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126777]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094656]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:03:51.936188: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:03:52.449952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:52.450018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:52.450028: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 621f220048064ecc861c278a73e716a7
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:03:55.132561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.132765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.133552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.133710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.133854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.133991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.134333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:03:55.265761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.265978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.266133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.266271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.266401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:55.266677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.824418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.824613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.824770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.824904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.825037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.825153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:03:56.825516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:03:56.825623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.195975]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.128413]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.220566]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.190190]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126543]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094433]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:03:58.771271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:03:59.289958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:59.290019: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:03:59.290025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 5617fd745f8a47bbbecbb9a8b7eda249
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:01.980111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.980310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.981098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.981252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.981390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.981524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:01.981882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:02.110467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:02.110686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:02.110842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:02.110975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:02.111112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:02.111238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.660949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:03.661321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:03.661425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.195661]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.127979]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.223722]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.189324]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.125504]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094365]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:05.598318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:06.116117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:06.116181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:06.116186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run bdbca775ebf046b0b0561258c2a24e8c
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:08.808193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.808396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.809175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.809334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.809473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.809609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.809954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:08.936555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.936771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.936920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.937052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.937184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:08.937311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.500595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.500783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.500931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.501062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.501188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.501300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:10.501710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:10.501813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.196154]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.129142]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.219977]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.190047]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126126]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094993]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:12.427918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:12.946097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:12.946161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:12.946177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run a6391163b16646ab9db241f032ceebe3
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:15.655986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.656197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.656986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.657163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.657323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.657468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.657810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:15.789371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.789588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.789742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.789877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.790005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:15.790130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.359360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.359552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.359711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.359848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.359974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.360084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:17.360448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:17.360552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.197439]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.129056]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.229652]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.189581]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.125590]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.093885]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:19.305858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:19.828742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:19.828814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:19.828820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 27aa88f51e754a8bb091702aa0e00dc8
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:22.524433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.524645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.525424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.525590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.525744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.525889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.526235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:22.654129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.654339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.654490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.654622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.654753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:22.654883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.197374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.197565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.197716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.197851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.197979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.198089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:24.198506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:24.198611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.196591]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.128104]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.221794]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.189530]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.125628]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094210]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:26.125351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:26.644675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:26.644736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:26.644742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 7921e0323ab440d7a2b5a9379d8ac78f
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:29.355746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.355946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.356738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.356895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.357036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.357173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.357519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:29.489334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.489573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.489740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.489884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.490023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:29.490156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.048394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.048592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.048750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.048884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.049013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.049125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:31.049568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:31.049675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.198934]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.129517]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.226195]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.191267]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.127381]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.095959]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:33.012519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:33.540732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:33.540802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:33.540809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 78e35faebdae444891485464bb1f053a
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:36.276295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.276495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.277298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.277450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.277587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.277718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.278070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:36.413213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.413394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.413537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.413663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.413790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:36.413915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.979770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.979966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.980118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.980251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.980395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.980512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:37.980898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:37.981005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.198260]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.129240]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.228266]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.190636]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126050]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094422]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
2023-05-24 13:04:39.916781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:40.431450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:40.431512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 13:04:40.431517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 8db5494e8cc948b3a7f745dd152a1a92
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
DEBUG:root:Aggregating huawei data per grouper
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:198: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  merged_df["all_events"] = merged_df[self.relevant_columns].values.tolist()
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 13:04:43.132222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.132426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.133220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.133377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.133516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.133652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.133997: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 13:04:43.254457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.254664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.254813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.254943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.255073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:43.255202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.809295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.809489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.809649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.809785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.809914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.810028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 13:04:44.810423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 13:04:44.810527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:239: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['LineId'] = [i + 1 for i in range(len(self.df_log.index))]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:288: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventId'] = ids
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:289: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self.df_log['EventTemplate'] = templates
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py:735: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  hierarchy_df = hierarchy_df.append(
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.195129]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.129859]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.228260]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.190725]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126035]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094382]
Traceback (most recent call last):
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3803, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'coarse_log_cluster_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 33, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 43, in run
    (knowledge, model) = self._load_model(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 279, in _load_model
    hierarchy = self._load_hierarchy_knowledge(metadata)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 440, in _load_hierarchy_knowledge
    hierarchy_df = hierarchy_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 650, in load_data
    return self._load_log_only_hierarchy()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 661, in _load_log_only_hierarchy
    attribute_hierarchy = self._load_attribute_hierarchy(
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 747, in _load_attribute_hierarchy
    for x in huawei_df[column]
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py", line 3804, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    raise KeyError(key) from err
KeyError: 'coarse_log_cluster_path'
make: *** [Makefile:71: run_huawei] Error 1
for knowledge_type in gram gram gram ; do \
echo "Starting experiment for huawei_logs with knowledge type " $knowledge_type "....." ; \
	~/miniconda3/envs/lena/bin/python main.py \
		--experimentconfig_model_type $knowledge_type \
		--huaweipreprocessorconfig_min_causality 0.01 \
		--huaweipreprocessorconfig_relevant_log_column fine_log_cluster_template_drain \
		--no-modelconfig_base_feature_embeddings_trainable \
		--no-modelconfig_base_hidden_embeddings_trainable \
		--sequenceconfig_y_sequence_column_name attributes \
		--sequenceconfig_max_window_size 10 \
		--sequenceconfig_min_window_size 10 \
		--experimentconfig_multilabel_classification \
		--sequenceconfig_flatten_y \
		--sequenceconfig_flatten_x \
		--huaweipreprocessorconfig_log_parser all \
		 ; \
done ; \

Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 19:53:26.898896: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 19:53:27.416299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:53:27.416360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:53:27.416366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 380373d57e36484b97fedf83027fff47
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12234.43it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13306.26it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13167.86it/s]
Traceback (most recent call last):
  File "/home/i40/pacev/Domain-Guided-Monitoring/main.py", line 9, in <module>
    _main()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/main.py", line 34, in _main
    runner.run()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 30, in run
    sequence_df = self._load_sequences() # run preprocessor
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/runner.py", line 481, in _load_sequences
    return sequence_preprocessor.load_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 139, in load_data
    log_only_data = self._load_log_only_data()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 160, in _load_log_only_data
    log_df = self._read_log_df()
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 299, in _read_log_df
    rel_df = self._add_log_spell_clusters(rel_df)
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 486, in _add_log_spell_clusters
    log_result_df = self._add_log_spell_clusters_prefix(log_df=log_df, tau=0.9, prefix="fine_")
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/huawei.py", line 494, in _add_log_spell_clusters_prefix
    spell_result_df = spell.load_data().drop_duplicates().set_index("LineId")
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py", line 244, in load_data
    logmessageL = list(filter(lambda x: x != '', re.split(r'[\s=:,]', self.preprocess(line[self.data_df_column_name]))))
  File "/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/spell.py", line 348, in preprocess
    line = re.sub(currentRex, '*', line)
  File "/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/re.py", line 210, in sub
    return _compile(pattern, flags).sub(repl, string, count)
KeyboardInterrupt
make: *** [Makefile:50: run_attention] Interrupt
for knowledge_type in gram gram gram ; do \
echo "Starting experiment for huawei_logs with knowledge type " $knowledge_type "....." ; \
	~/miniconda3/envs/lena/bin/python main.py \
		--experimentconfig_model_type $knowledge_type \
		--huaweipreprocessorconfig_min_causality 0.01 \
		--huaweipreprocessorconfig_relevant_log_column fine_log_cluster_template_drain \
		--no-modelconfig_base_feature_embeddings_trainable \
		--no-modelconfig_base_hidden_embeddings_trainable \
		--sequenceconfig_y_sequence_column_name attributes \
		--sequenceconfig_max_window_size 10 \
		--sequenceconfig_min_window_size 10 \
		--experimentconfig_multilabel_classification \
		--sequenceconfig_flatten_y \
		--sequenceconfig_flatten_x \
		--huaweipreprocessorconfig_log_parser all \
		 ; \
done ; \

Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 19:53:33.560075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 19:53:34.072882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:53:34.072943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:53:34.072949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run ee70ed5b4d544010b53acaa5fb416763
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12196.18it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13193.08it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12964.04it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.203299]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.263237]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.098087]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11448.32it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.405516 Tokens per Sec: 1576.857056
Epoch Step: 11 / 173 Loss: 4.150618 Tokens per Sec: 4900.014648
Epoch Step: 21 / 173 Loss: 3.936595 Tokens per Sec: 5176.099121
Epoch Step: 31 / 173 Loss: 2.928795 Tokens per Sec: 5275.686035
Epoch Step: 41 / 173 Loss: 3.707602 Tokens per Sec: 5276.263672
Epoch Step: 51 / 173 Loss: 3.493975 Tokens per Sec: 5391.962402
Epoch Step: 61 / 173 Loss: 3.315748 Tokens per Sec: 5288.362305
Epoch Step: 71 / 173 Loss: 3.385040 Tokens per Sec: 5309.878906
Epoch Step: 81 / 173 Loss: 3.583582 Tokens per Sec: 5374.569824
Epoch Step: 91 / 173 Loss: 3.575059 Tokens per Sec: 5217.357422
Epoch Step: 101 / 173 Loss: 3.575830 Tokens per Sec: 5319.156738
Epoch Step: 111 / 173 Loss: 3.361500 Tokens per Sec: 5433.732910
Epoch Step: 121 / 173 Loss: 3.198306 Tokens per Sec: 5328.508301
Epoch Step: 131 / 173 Loss: 3.161098 Tokens per Sec: 5350.402832
Epoch Step: 141 / 173 Loss: 3.435710 Tokens per Sec: 5391.686523
Epoch Step: 151 / 173 Loss: 2.812113 Tokens per Sec: 5260.655762
Epoch Step: 161 / 173 Loss: 2.671366 Tokens per Sec: 5226.158691
Epoch Step: 171 / 173 Loss: 3.262629 Tokens per Sec: 5397.200684
Epoch 1
Epoch Step: 1 / 173 Loss: 2.394427 Tokens per Sec: 5106.274414
Epoch Step: 11 / 173 Loss: 3.069315 Tokens per Sec: 5346.768555
Epoch Step: 21 / 173 Loss: 3.321761 Tokens per Sec: 5431.281250
Epoch Step: 31 / 173 Loss: 2.348437 Tokens per Sec: 5362.889160
Epoch Step: 41 / 173 Loss: 2.873019 Tokens per Sec: 5366.178223
Epoch Step: 51 / 173 Loss: 2.427747 Tokens per Sec: 5278.119629
Epoch Step: 61 / 173 Loss: 2.918555 Tokens per Sec: 5380.523926
Epoch Step: 71 / 173 Loss: 2.986083 Tokens per Sec: 5356.767090
Epoch Step: 81 / 173 Loss: 2.250235 Tokens per Sec: 5305.140625
Epoch Step: 91 / 173 Loss: 2.866829 Tokens per Sec: 5258.894043
Epoch Step: 101 / 173 Loss: 2.277921 Tokens per Sec: 5282.462402
Epoch Step: 111 / 173 Loss: 3.309581 Tokens per Sec: 5193.096191
Epoch Step: 121 / 173 Loss: 3.169549 Tokens per Sec: 5448.710449
Epoch Step: 131 / 173 Loss: 2.671934 Tokens per Sec: 5369.684082
Epoch Step: 141 / 173 Loss: 3.422425 Tokens per Sec: 5367.872559
Epoch Step: 151 / 173 Loss: 3.150266 Tokens per Sec: 5394.453613
Epoch Step: 161 / 173 Loss: 2.766333 Tokens per Sec: 5405.073730
Epoch Step: 171 / 173 Loss: 2.708536 Tokens per Sec: 5405.786133
Epoch 2
Epoch Step: 1 / 173 Loss: 3.018076 Tokens per Sec: 5264.668945
Epoch Step: 11 / 173 Loss: 3.237447 Tokens per Sec: 5373.780273
Epoch Step: 21 / 173 Loss: 2.766343 Tokens per Sec: 5491.650879
Epoch Step: 31 / 173 Loss: 2.977556 Tokens per Sec: 5333.734863
Epoch Step: 41 / 173 Loss: 2.475492 Tokens per Sec: 5059.958984
Epoch Step: 51 / 173 Loss: 2.947932 Tokens per Sec: 5356.262207
Epoch Step: 61 / 173 Loss: 2.247127 Tokens per Sec: 5310.298340
Epoch Step: 71 / 173 Loss: 3.043987 Tokens per Sec: 5352.734375
Epoch Step: 81 / 173 Loss: 3.409763 Tokens per Sec: 5454.364746
Epoch Step: 91 / 173 Loss: 3.875849 Tokens per Sec: 5374.716309
Epoch Step: 101 / 173 Loss: 3.376150 Tokens per Sec: 5309.059082
Epoch Step: 111 / 173 Loss: 2.380769 Tokens per Sec: 5411.001465
Epoch Step: 121 / 173 Loss: 3.352524 Tokens per Sec: 5409.609863
Epoch Step: 131 / 173 Loss: 3.089583 Tokens per Sec: 5454.830566
Epoch Step: 141 / 173 Loss: 2.555509 Tokens per Sec: 5392.799805
Epoch Step: 151 / 173 Loss: 2.269805 Tokens per Sec: 5370.570312
Epoch Step: 161 / 173 Loss: 2.474103 Tokens per Sec: 5257.305664
Epoch Step: 171 / 173 Loss: 3.037297 Tokens per Sec: 5343.552734
Epoch 3
Epoch Step: 1 / 173 Loss: 2.734972 Tokens per Sec: 5496.533691
Epoch Step: 11 / 173 Loss: 2.617020 Tokens per Sec: 5364.239258
Epoch Step: 21 / 173 Loss: 3.308423 Tokens per Sec: 5372.288574
Epoch Step: 31 / 173 Loss: 2.127539 Tokens per Sec: 5409.996582
Epoch Step: 41 / 173 Loss: 2.079816 Tokens per Sec: 5314.622559
Epoch Step: 51 / 173 Loss: 3.100489 Tokens per Sec: 5459.759766
Epoch Step: 61 / 173 Loss: 3.284895 Tokens per Sec: 5408.475098
Epoch Step: 71 / 173 Loss: 3.172876 Tokens per Sec: 5457.186523
Epoch Step: 81 / 173 Loss: 2.603162 Tokens per Sec: 5392.490723
Epoch Step: 91 / 173 Loss: 3.351212 Tokens per Sec: 5412.542480
Epoch Step: 101 / 173 Loss: 2.338019 Tokens per Sec: 5449.838379
Epoch Step: 111 / 173 Loss: 3.509944 Tokens per Sec: 5363.966309
Epoch Step: 121 / 173 Loss: 3.059727 Tokens per Sec: 5118.455566
Epoch Step: 131 / 173 Loss: 2.688861 Tokens per Sec: 4794.623047
Epoch Step: 141 / 173 Loss: 3.141728 Tokens per Sec: 4690.532227
Epoch Step: 151 / 173 Loss: 2.334411 Tokens per Sec: 5167.193359
Epoch Step: 161 / 173 Loss: 2.932980 Tokens per Sec: 5318.041504
Epoch Step: 171 / 173 Loss: 2.207892 Tokens per Sec: 5281.761230
Epoch 4
Epoch Step: 1 / 173 Loss: 3.547127 Tokens per Sec: 5323.639648
Epoch Step: 11 / 173 Loss: 2.619299 Tokens per Sec: 5359.406250
Epoch Step: 21 / 173 Loss: 3.388177 Tokens per Sec: 5356.535645
Epoch Step: 31 / 173 Loss: 2.819444 Tokens per Sec: 5357.034668
Epoch Step: 41 / 173 Loss: 2.659663 Tokens per Sec: 5112.436523
Epoch Step: 51 / 173 Loss: 2.560369 Tokens per Sec: 5319.142578
Epoch Step: 61 / 173 Loss: 2.398175 Tokens per Sec: 5280.739746
Epoch Step: 71 / 173 Loss: 2.552380 Tokens per Sec: 5277.583496
Epoch Step: 81 / 173 Loss: 2.625142 Tokens per Sec: 5435.398438
Epoch Step: 91 / 173 Loss: 2.002555 Tokens per Sec: 5459.748047
Epoch Step: 101 / 173 Loss: 2.783194 Tokens per Sec: 5420.960938
Epoch Step: 111 / 173 Loss: 3.218866 Tokens per Sec: 5413.823242
Epoch Step: 121 / 173 Loss: 2.340512 Tokens per Sec: 5328.356934
Epoch Step: 131 / 173 Loss: 2.844262 Tokens per Sec: 5309.280762
Epoch Step: 141 / 173 Loss: 3.053900 Tokens per Sec: 4985.212891
Epoch Step: 151 / 173 Loss: 2.326790 Tokens per Sec: 5179.809082
Epoch Step: 161 / 173 Loss: 2.242233 Tokens per Sec: 5403.756836
Epoch Step: 171 / 173 Loss: 2.985776 Tokens per Sec: 5442.392090
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10899.91it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.140022 Tokens per Sec: 4996.839844
Epoch Step: 11 / 173 Loss: 4.074682 Tokens per Sec: 5136.355957
Epoch Step: 21 / 173 Loss: 3.061332 Tokens per Sec: 5350.906738
Epoch Step: 31 / 173 Loss: 3.443953 Tokens per Sec: 5513.407227
Epoch Step: 41 / 173 Loss: 3.661179 Tokens per Sec: 5328.523438
Epoch Step: 51 / 173 Loss: 3.142366 Tokens per Sec: 5387.509277
Epoch Step: 61 / 173 Loss: 3.547468 Tokens per Sec: 5331.697266
Epoch Step: 71 / 173 Loss: 3.652142 Tokens per Sec: 5324.585449
Epoch Step: 81 / 173 Loss: 2.654553 Tokens per Sec: 5390.858887
Epoch Step: 91 / 173 Loss: 2.753743 Tokens per Sec: 5446.662109
Epoch Step: 101 / 173 Loss: 3.002429 Tokens per Sec: 5378.639648
Epoch Step: 111 / 173 Loss: 3.642889 Tokens per Sec: 5353.944336
Epoch Step: 121 / 173 Loss: 3.299934 Tokens per Sec: 5257.635742
Epoch Step: 131 / 173 Loss: 2.682141 Tokens per Sec: 5314.729980
Epoch Step: 141 / 173 Loss: 2.757185 Tokens per Sec: 5354.692871
Epoch Step: 151 / 173 Loss: 2.492260 Tokens per Sec: 5426.668457
Epoch Step: 161 / 173 Loss: 3.377411 Tokens per Sec: 5402.789551
Epoch Step: 171 / 173 Loss: 3.154442 Tokens per Sec: 5495.090820
Epoch 1
Epoch Step: 1 / 173 Loss: 3.626061 Tokens per Sec: 5258.354980
Epoch Step: 11 / 173 Loss: 3.210566 Tokens per Sec: 5377.655273
Epoch Step: 21 / 173 Loss: 3.262713 Tokens per Sec: 5476.155762
Epoch Step: 31 / 173 Loss: 3.374504 Tokens per Sec: 5392.040527
Epoch Step: 41 / 173 Loss: 2.405659 Tokens per Sec: 5235.394531
Epoch Step: 51 / 173 Loss: 3.042424 Tokens per Sec: 5438.977051
Epoch Step: 61 / 173 Loss: 2.494295 Tokens per Sec: 5402.083008
Epoch Step: 71 / 173 Loss: 3.456644 Tokens per Sec: 5310.563965
Epoch Step: 81 / 173 Loss: 2.366578 Tokens per Sec: 5354.770020
Epoch Step: 91 / 173 Loss: 3.318631 Tokens per Sec: 5373.105957
Epoch Step: 101 / 173 Loss: 3.454778 Tokens per Sec: 5370.652832
Epoch Step: 111 / 173 Loss: 2.812992 Tokens per Sec: 5313.908203
Epoch Step: 121 / 173 Loss: 3.145530 Tokens per Sec: 5411.269043
Epoch Step: 131 / 173 Loss: 3.116588 Tokens per Sec: 5376.516602
Epoch Step: 141 / 173 Loss: 2.989764 Tokens per Sec: 5369.403809
Epoch Step: 151 / 173 Loss: 3.531586 Tokens per Sec: 5374.686035
Epoch Step: 161 / 173 Loss: 2.286673 Tokens per Sec: 5367.137695
Epoch Step: 171 / 173 Loss: 2.286959 Tokens per Sec: 5391.860352
Epoch 2
Epoch Step: 1 / 173 Loss: 2.558363 Tokens per Sec: 5064.102539
Epoch Step: 11 / 173 Loss: 2.795184 Tokens per Sec: 5422.697754
Epoch Step: 21 / 173 Loss: 3.014083 Tokens per Sec: 5402.184082
Epoch Step: 31 / 173 Loss: 3.007070 Tokens per Sec: 5326.984863
Epoch Step: 41 / 173 Loss: 2.803451 Tokens per Sec: 5421.133789
Epoch Step: 51 / 173 Loss: 2.500847 Tokens per Sec: 5402.978027
Epoch Step: 61 / 173 Loss: 2.641410 Tokens per Sec: 5294.633789
Epoch Step: 71 / 173 Loss: 2.805256 Tokens per Sec: 5276.715820
Epoch Step: 81 / 173 Loss: 2.815549 Tokens per Sec: 5325.812500
Epoch Step: 91 / 173 Loss: 2.893524 Tokens per Sec: 5385.877930
Epoch Step: 101 / 173 Loss: 2.958123 Tokens per Sec: 5383.647949
Epoch Step: 111 / 173 Loss: 3.251826 Tokens per Sec: 5407.565430
Epoch Step: 121 / 173 Loss: 3.157447 Tokens per Sec: 5412.149414
Epoch Step: 131 / 173 Loss: 3.329710 Tokens per Sec: 5381.416992
Epoch Step: 141 / 173 Loss: 3.280898 Tokens per Sec: 5425.879395
Epoch Step: 151 / 173 Loss: 3.242797 Tokens per Sec: 5365.975586
Epoch Step: 161 / 173 Loss: 3.031339 Tokens per Sec: 5388.820801
Epoch Step: 171 / 173 Loss: 2.516202 Tokens per Sec: 5362.577148
Epoch 3
Epoch Step: 1 / 173 Loss: 3.341591 Tokens per Sec: 5504.371094
Epoch Step: 11 / 173 Loss: 2.971089 Tokens per Sec: 5405.833496
Epoch Step: 21 / 173 Loss: 3.154899 Tokens per Sec: 5451.542969
Epoch Step: 31 / 173 Loss: 2.855009 Tokens per Sec: 5414.068848
Epoch Step: 41 / 173 Loss: 2.206493 Tokens per Sec: 5363.830078
Epoch Step: 51 / 173 Loss: 3.333107 Tokens per Sec: 5430.104492
Epoch Step: 61 / 173 Loss: 3.296485 Tokens per Sec: 5281.378418
Epoch Step: 71 / 173 Loss: 2.759118 Tokens per Sec: 5343.784180
Epoch Step: 81 / 173 Loss: 2.826972 Tokens per Sec: 5311.197266
Epoch Step: 91 / 173 Loss: 2.345584 Tokens per Sec: 5408.417480
Epoch Step: 101 / 173 Loss: 2.667205 Tokens per Sec: 5367.452148
Epoch Step: 111 / 173 Loss: 2.841089 Tokens per Sec: 5098.111816
Epoch Step: 121 / 173 Loss: 2.458083 Tokens per Sec: 5152.992188
Epoch Step: 131 / 173 Loss: 2.809174 Tokens per Sec: 4920.957031
Epoch Step: 141 / 173 Loss: 2.950120 Tokens per Sec: 5146.822266
Epoch Step: 151 / 173 Loss: 2.341714 Tokens per Sec: 5252.141113
Epoch Step: 161 / 173 Loss: 2.165370 Tokens per Sec: 5426.170898
Epoch Step: 171 / 173 Loss: 2.602476 Tokens per Sec: 5392.706543
Epoch 4
Epoch Step: 1 / 173 Loss: 2.861215 Tokens per Sec: 5153.470703
Epoch Step: 11 / 173 Loss: 2.348711 Tokens per Sec: 5357.446777
Epoch Step: 21 / 173 Loss: 2.430028 Tokens per Sec: 5347.036621
Epoch Step: 31 / 173 Loss: 2.478946 Tokens per Sec: 5319.427734
Epoch Step: 41 / 173 Loss: 3.440967 Tokens per Sec: 5459.643555
Epoch Step: 51 / 173 Loss: 3.035676 Tokens per Sec: 5407.827148
Epoch Step: 61 / 173 Loss: 2.119278 Tokens per Sec: 5258.984375
Epoch Step: 71 / 173 Loss: 2.789625 Tokens per Sec: 5110.173828
Epoch Step: 81 / 173 Loss: 3.588522 Tokens per Sec: 5079.835938
Epoch Step: 91 / 173 Loss: 2.748212 Tokens per Sec: 5053.544922
Epoch Step: 101 / 173 Loss: 2.237067 Tokens per Sec: 5129.912598
Epoch Step: 111 / 173 Loss: 2.198037 Tokens per Sec: 4985.573730
Epoch Step: 121 / 173 Loss: 2.218677 Tokens per Sec: 5252.185547
Epoch Step: 131 / 173 Loss: 2.996311 Tokens per Sec: 5169.912598
Epoch Step: 141 / 173 Loss: 3.112598 Tokens per Sec: 5227.829590
Epoch Step: 151 / 173 Loss: 2.461646 Tokens per Sec: 5213.068848
Epoch Step: 161 / 173 Loss: 3.197509 Tokens per Sec: 5213.555176
Epoch Step: 171 / 173 Loss: 2.901206 Tokens per Sec: 5107.973633
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10788.99it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 19:55:54.382837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.383094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.384122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.384305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.384460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.384607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.384985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 19:55:54.454150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.454336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.454479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.454609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.454737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.454864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.833840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11799 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 19:55:54.834229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 19:55:54.834343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22327 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Epoch 0
Epoch Step: 1 / 173 Loss: 6.478620 Tokens per Sec: 5197.431641
Epoch Step: 11 / 173 Loss: 3.709607 Tokens per Sec: 5265.742676
Epoch Step: 21 / 173 Loss: 3.869633 Tokens per Sec: 5376.879883
Epoch Step: 31 / 173 Loss: 3.565281 Tokens per Sec: 5378.214844
Epoch Step: 41 / 173 Loss: 3.620667 Tokens per Sec: 5347.125488
Epoch Step: 51 / 173 Loss: 4.100353 Tokens per Sec: 5409.351074
Epoch Step: 61 / 173 Loss: 3.709289 Tokens per Sec: 5175.416504
Epoch Step: 71 / 173 Loss: 3.309261 Tokens per Sec: 5337.324219
Epoch Step: 81 / 173 Loss: 3.394770 Tokens per Sec: 5231.016113
Epoch Step: 91 / 173 Loss: 3.537718 Tokens per Sec: 5432.292480
Epoch Step: 101 / 173 Loss: 3.369862 Tokens per Sec: 5412.687012
Epoch Step: 111 / 173 Loss: 2.857558 Tokens per Sec: 5408.840332
Epoch Step: 121 / 173 Loss: 3.343333 Tokens per Sec: 5406.978027
Epoch Step: 131 / 173 Loss: 3.308311 Tokens per Sec: 5345.204590
Epoch Step: 141 / 173 Loss: 4.007806 Tokens per Sec: 5292.411133
Epoch Step: 151 / 173 Loss: 3.764310 Tokens per Sec: 5372.145020
Epoch Step: 161 / 173 Loss: 2.756359 Tokens per Sec: 5317.616699
Epoch Step: 171 / 173 Loss: 3.080989 Tokens per Sec: 5348.811523
Epoch 1
Epoch Step: 1 / 173 Loss: 2.990770 Tokens per Sec: 5362.899902
Epoch Step: 11 / 173 Loss: 2.633706 Tokens per Sec: 5263.808594
Epoch Step: 21 / 173 Loss: 2.826633 Tokens per Sec: 5300.236816
Epoch Step: 31 / 173 Loss: 3.310023 Tokens per Sec: 5406.196777
Epoch Step: 41 / 173 Loss: 2.807665 Tokens per Sec: 5272.596680
Epoch Step: 51 / 173 Loss: 3.139883 Tokens per Sec: 5338.548828
Epoch Step: 61 / 173 Loss: 3.461204 Tokens per Sec: 5353.879395
Epoch Step: 71 / 173 Loss: 3.180307 Tokens per Sec: 5333.201660
Epoch Step: 81 / 173 Loss: 2.671724 Tokens per Sec: 5411.686523
Epoch Step: 91 / 173 Loss: 3.046331 Tokens per Sec: 5355.573730
Epoch Step: 101 / 173 Loss: 2.425619 Tokens per Sec: 5299.481445
Epoch Step: 111 / 173 Loss: 3.300850 Tokens per Sec: 5437.950195
Epoch Step: 121 / 173 Loss: 2.567358 Tokens per Sec: 5442.773438
Epoch Step: 131 / 173 Loss: 2.293204 Tokens per Sec: 5292.323730
Epoch Step: 141 / 173 Loss: 2.962118 Tokens per Sec: 5424.074219
Epoch Step: 151 / 173 Loss: 2.495908 Tokens per Sec: 5435.981445
Epoch Step: 161 / 173 Loss: 2.087163 Tokens per Sec: 5353.443848
Epoch Step: 171 / 173 Loss: 2.237099 Tokens per Sec: 5355.502930
Epoch 2
Epoch Step: 1 / 173 Loss: 2.299788 Tokens per Sec: 5075.895508
Epoch Step: 11 / 173 Loss: 2.626513 Tokens per Sec: 5296.144531
Epoch Step: 21 / 173 Loss: 1.587566 Tokens per Sec: 5358.895508
Epoch Step: 31 / 173 Loss: 1.582003 Tokens per Sec: 5349.430664
Epoch Step: 41 / 173 Loss: 2.952732 Tokens per Sec: 5301.206543
Epoch Step: 51 / 173 Loss: 3.517919 Tokens per Sec: 5400.235352
Epoch Step: 61 / 173 Loss: 2.359144 Tokens per Sec: 5335.419922
Epoch Step: 71 / 173 Loss: 3.145781 Tokens per Sec: 5386.363770
Epoch Step: 81 / 173 Loss: 1.883935 Tokens per Sec: 5317.691895
Epoch Step: 91 / 173 Loss: 3.181235 Tokens per Sec: 5411.205566
Epoch Step: 101 / 173 Loss: 2.921947 Tokens per Sec: 5387.783203
Epoch Step: 111 / 173 Loss: 2.558717 Tokens per Sec: 5405.703125
Epoch Step: 121 / 173 Loss: 1.836103 Tokens per Sec: 5462.127930
Epoch Step: 131 / 173 Loss: 2.884146 Tokens per Sec: 5354.571289
Epoch Step: 141 / 173 Loss: 1.795657 Tokens per Sec: 5370.790039
Epoch Step: 151 / 173 Loss: 1.461926 Tokens per Sec: 5436.837402
Epoch Step: 161 / 173 Loss: 2.720905 Tokens per Sec: 5367.774902
Epoch Step: 171 / 173 Loss: 1.953519 Tokens per Sec: 5474.238281
Epoch 3
Epoch Step: 1 / 173 Loss: 2.674917 Tokens per Sec: 5426.518066
Epoch Step: 11 / 173 Loss: 2.346650 Tokens per Sec: 5326.454590
Epoch Step: 21 / 173 Loss: 1.597998 Tokens per Sec: 5289.492676
Epoch Step: 31 / 173 Loss: 1.502074 Tokens per Sec: 5411.546875
Epoch Step: 41 / 173 Loss: 2.572282 Tokens per Sec: 5352.182129
Epoch Step: 51 / 173 Loss: 2.620924 Tokens per Sec: 5428.638184
Epoch Step: 61 / 173 Loss: 2.455630 Tokens per Sec: 5439.603027
Epoch Step: 71 / 173 Loss: 1.555032 Tokens per Sec: 5344.290039
Epoch Step: 81 / 173 Loss: 1.607321 Tokens per Sec: 5238.336914
Epoch Step: 91 / 173 Loss: 2.431110 Tokens per Sec: 5298.276367
Epoch Step: 101 / 173 Loss: 2.507153 Tokens per Sec: 5341.246582
Epoch Step: 111 / 173 Loss: 2.573786 Tokens per Sec: 5339.410645
Epoch Step: 121 / 173 Loss: 1.466085 Tokens per Sec: 5319.438965
Epoch Step: 131 / 173 Loss: 1.077516 Tokens per Sec: 5323.218262
Epoch Step: 141 / 173 Loss: 1.845584 Tokens per Sec: 5304.897949
Epoch Step: 151 / 173 Loss: 2.047233 Tokens per Sec: 5400.392090
Epoch Step: 161 / 173 Loss: 0.969979 Tokens per Sec: 5414.342285
Epoch Step: 171 / 173 Loss: 1.824639 Tokens per Sec: 5278.734375
Epoch 4
Epoch Step: 1 / 173 Loss: 1.175699 Tokens per Sec: 5289.004395
Epoch Step: 11 / 173 Loss: 1.830208 Tokens per Sec: 5433.589355
Epoch Step: 21 / 173 Loss: 2.476010 Tokens per Sec: 5308.205078
Epoch Step: 31 / 173 Loss: 2.470863 Tokens per Sec: 5427.824219
Epoch Step: 41 / 173 Loss: 1.117099 Tokens per Sec: 5357.717285
Epoch Step: 51 / 173 Loss: 1.489830 Tokens per Sec: 5250.045898
Epoch Step: 61 / 173 Loss: 2.293046 Tokens per Sec: 5340.916992
Epoch Step: 71 / 173 Loss: 2.101823 Tokens per Sec: 5158.100586
Epoch Step: 81 / 173 Loss: 2.494408 Tokens per Sec: 5431.307617
Epoch Step: 91 / 173 Loss: 1.356225 Tokens per Sec: 5286.634277
Epoch Step: 101 / 173 Loss: 2.433267 Tokens per Sec: 5364.264648
Epoch Step: 111 / 173 Loss: 1.342797 Tokens per Sec: 5228.095703
Epoch Step: 121 / 173 Loss: 2.440273 Tokens per Sec: 5325.140625
Epoch Step: 131 / 173 Loss: 2.005505 Tokens per Sec: 5290.407715
Epoch Step: 141 / 173 Loss: 2.159871 Tokens per Sec: 5348.011719
Epoch Step: 151 / 173 Loss: 2.313246 Tokens per Sec: 5307.451172
Epoch Step: 161 / 173 Loss: 1.796152 Tokens per Sec: 5379.946289
Epoch Step: 171 / 173 Loss: 2.647519 Tokens per Sec: 5388.390625
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12644.29it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13419.86it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13125.94it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.193112]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.127490]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.095857]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11760.20it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.522120 Tokens per Sec: 5374.309570
Epoch Step: 11 / 173 Loss: 4.236501 Tokens per Sec: 5303.029785
Epoch Step: 21 / 173 Loss: 3.955371 Tokens per Sec: 5362.566406
Epoch Step: 31 / 173 Loss: 3.139581 Tokens per Sec: 5383.773438
Epoch Step: 41 / 173 Loss: 3.607996 Tokens per Sec: 5393.529297
Epoch Step: 51 / 173 Loss: 3.298896 Tokens per Sec: 5189.425781
Epoch Step: 61 / 173 Loss: 3.178228 Tokens per Sec: 5199.820312
Epoch Step: 71 / 173 Loss: 3.004368 Tokens per Sec: 5271.887207
Epoch Step: 81 / 173 Loss: 3.200791 Tokens per Sec: 5400.436523
Epoch Step: 91 / 173 Loss: 3.080163 Tokens per Sec: 5371.571289
Epoch Step: 101 / 173 Loss: 2.991105 Tokens per Sec: 5383.166504
Epoch Step: 111 / 173 Loss: 3.255289 Tokens per Sec: 5289.755371
Epoch Step: 121 / 173 Loss: 2.923741 Tokens per Sec: 5257.433105
Epoch Step: 131 / 173 Loss: 2.371634 Tokens per Sec: 5385.559570
Epoch Step: 141 / 173 Loss: 2.503484 Tokens per Sec: 5330.585449
Epoch Step: 151 / 173 Loss: 3.337396 Tokens per Sec: 5444.886230
Epoch Step: 161 / 173 Loss: 2.944318 Tokens per Sec: 5465.897949
Epoch Step: 171 / 173 Loss: 3.616162 Tokens per Sec: 5325.315918
Epoch 1
Epoch Step: 1 / 173 Loss: 3.308990 Tokens per Sec: 5445.125977
Epoch Step: 11 / 173 Loss: 2.722789 Tokens per Sec: 5359.715332
Epoch Step: 21 / 173 Loss: 3.015966 Tokens per Sec: 5108.338867
Epoch Step: 31 / 173 Loss: 2.161490 Tokens per Sec: 5142.562988
Epoch Step: 41 / 173 Loss: 2.340763 Tokens per Sec: 5069.717773
Epoch Step: 51 / 173 Loss: 2.672184 Tokens per Sec: 5155.625000
Epoch Step: 61 / 173 Loss: 2.641525 Tokens per Sec: 5112.816895
Epoch Step: 71 / 173 Loss: 2.340884 Tokens per Sec: 5452.742676
Epoch Step: 81 / 173 Loss: 1.590991 Tokens per Sec: 5387.493652
Epoch Step: 91 / 173 Loss: 1.533351 Tokens per Sec: 5294.815430
Epoch Step: 101 / 173 Loss: 2.610544 Tokens per Sec: 5181.051270
Epoch Step: 111 / 173 Loss: 2.129437 Tokens per Sec: 5389.990723
Epoch Step: 121 / 173 Loss: 3.274095 Tokens per Sec: 5361.972656
Epoch Step: 131 / 173 Loss: 1.601593 Tokens per Sec: 5293.621582
Epoch Step: 141 / 173 Loss: 1.749479 Tokens per Sec: 5425.300781
Epoch Step: 151 / 173 Loss: 1.875777 Tokens per Sec: 5346.137207
Epoch Step: 161 / 173 Loss: 2.917012 Tokens per Sec: 5325.952637
Epoch Step: 171 / 173 Loss: 2.862292 Tokens per Sec: 5372.395020
Epoch 2
Epoch Step: 1 / 173 Loss: 2.793345 Tokens per Sec: 5323.139160
Epoch Step: 11 / 173 Loss: 2.404911 Tokens per Sec: 5265.335449
Epoch Step: 21 / 173 Loss: 1.684493 Tokens per Sec: 5373.157715
Epoch Step: 31 / 173 Loss: 1.206377 Tokens per Sec: 5410.144043
Epoch Step: 41 / 173 Loss: 1.445770 Tokens per Sec: 5265.567383
Epoch Step: 51 / 173 Loss: 2.708381 Tokens per Sec: 5460.760254
Epoch Step: 61 / 173 Loss: 1.383528 Tokens per Sec: 5331.673828
Epoch Step: 71 / 173 Loss: 1.931371 Tokens per Sec: 5359.059570
Epoch Step: 81 / 173 Loss: 2.373226 Tokens per Sec: 5408.925781
Epoch Step: 91 / 173 Loss: 1.215758 Tokens per Sec: 5369.528320
Epoch Step: 101 / 173 Loss: 2.995501 Tokens per Sec: 5288.104004
Epoch Step: 111 / 173 Loss: 2.478697 Tokens per Sec: 5373.093750
Epoch Step: 121 / 173 Loss: 2.564624 Tokens per Sec: 5327.510742
Epoch Step: 131 / 173 Loss: 3.390823 Tokens per Sec: 5407.709961
Epoch Step: 141 / 173 Loss: 2.154913 Tokens per Sec: 5299.428711
Epoch Step: 151 / 173 Loss: 1.418235 Tokens per Sec: 5381.559570
Epoch Step: 161 / 173 Loss: 2.140360 Tokens per Sec: 5367.182617
Epoch Step: 171 / 173 Loss: 2.297701 Tokens per Sec: 5304.458496
Epoch 3
Epoch Step: 1 / 173 Loss: 1.887536 Tokens per Sec: 5419.568359
Epoch Step: 11 / 173 Loss: 1.394155 Tokens per Sec: 5302.953125
Epoch Step: 21 / 173 Loss: 1.997410 Tokens per Sec: 5379.282715
Epoch Step: 31 / 173 Loss: 1.952792 Tokens per Sec: 5326.673340
Epoch Step: 41 / 173 Loss: 2.030929 Tokens per Sec: 5443.897461
Epoch Step: 51 / 173 Loss: 1.136300 Tokens per Sec: 5390.528809
Epoch Step: 61 / 173 Loss: 2.576167 Tokens per Sec: 5386.423340
Epoch Step: 71 / 173 Loss: 2.220917 Tokens per Sec: 5328.374512
Epoch Step: 81 / 173 Loss: 0.946109 Tokens per Sec: 5410.395996
Epoch Step: 91 / 173 Loss: 1.533854 Tokens per Sec: 5267.243652
Epoch Step: 101 / 173 Loss: 1.335641 Tokens per Sec: 5274.501465
Epoch Step: 111 / 173 Loss: 2.625299 Tokens per Sec: 5373.269043
Epoch Step: 121 / 173 Loss: 2.696965 Tokens per Sec: 5442.704102
Epoch Step: 131 / 173 Loss: 1.428128 Tokens per Sec: 5197.104004
Epoch Step: 141 / 173 Loss: 1.129411 Tokens per Sec: 5404.014648
Epoch Step: 151 / 173 Loss: 2.554277 Tokens per Sec: 5321.003906
Epoch Step: 161 / 173 Loss: 1.469206 Tokens per Sec: 5289.653809
Epoch Step: 171 / 173 Loss: 1.063350 Tokens per Sec: 5350.432617
Epoch 4
Epoch Step: 1 / 173 Loss: 3.110556 Tokens per Sec: 5433.705078
Epoch Step: 11 / 173 Loss: 1.795277 Tokens per Sec: 5392.380859
Epoch Step: 21 / 173 Loss: 1.687275 Tokens per Sec: 5098.430176
Epoch Step: 31 / 173 Loss: 2.112998 Tokens per Sec: 5281.394043
Epoch Step: 41 / 173 Loss: 2.449067 Tokens per Sec: 5430.855957
Epoch Step: 51 / 173 Loss: 2.768036 Tokens per Sec: 5316.172363
Epoch Step: 61 / 173 Loss: 2.286389 Tokens per Sec: 5368.068359
Epoch Step: 71 / 173 Loss: 1.260898 Tokens per Sec: 5333.648438
Epoch Step: 81 / 173 Loss: 1.812203 Tokens per Sec: 5352.926758
Epoch Step: 91 / 173 Loss: 1.516426 Tokens per Sec: 5363.520508
Epoch Step: 101 / 173 Loss: 1.808406 Tokens per Sec: 5412.288574
Epoch Step: 111 / 173 Loss: 1.502362 Tokens per Sec: 5277.050781
Epoch Step: 121 / 173 Loss: 1.391245 Tokens per Sec: 5287.429688
Epoch Step: 131 / 173 Loss: 3.106317 Tokens per Sec: 5327.125977
Epoch Step: 141 / 173 Loss: 2.118413 Tokens per Sec: 5366.969238
Epoch Step: 151 / 173 Loss: 3.117063 Tokens per Sec: 5262.540039
Epoch Step: 161 / 173 Loss: 1.430783 Tokens per Sec: 5392.393555
Epoch Step: 171 / 173 Loss: 1.737974 Tokens per Sec: 5321.697754
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10887.41it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.163312 Tokens per Sec: 5351.973633
Epoch Step: 11 / 173 Loss: 3.891654 Tokens per Sec: 5393.718262
Epoch Step: 21 / 173 Loss: 3.340985 Tokens per Sec: 5313.870605
Epoch Step: 31 / 173 Loss: 3.973598 Tokens per Sec: 5456.083984
Epoch Step: 41 / 173 Loss: 3.619210 Tokens per Sec: 4813.990234
Epoch Step: 51 / 173 Loss: 3.645101 Tokens per Sec: 5056.796875
Epoch Step: 61 / 173 Loss: 3.511043 Tokens per Sec: 5389.731934
Epoch Step: 71 / 173 Loss: 3.187378 Tokens per Sec: 5293.776367
Epoch Step: 81 / 173 Loss: 2.863080 Tokens per Sec: 5318.448730
Epoch Step: 91 / 173 Loss: 3.285658 Tokens per Sec: 5319.156738
Epoch Step: 101 / 173 Loss: 2.608625 Tokens per Sec: 5391.308594
Epoch Step: 111 / 173 Loss: 2.703587 Tokens per Sec: 5528.057617
Epoch Step: 121 / 173 Loss: 3.175656 Tokens per Sec: 5398.315430
Epoch Step: 131 / 173 Loss: 3.223944 Tokens per Sec: 5266.662598
Epoch Step: 141 / 173 Loss: 2.948371 Tokens per Sec: 5310.089844
Epoch Step: 151 / 173 Loss: 2.837594 Tokens per Sec: 5410.729004
Epoch Step: 161 / 173 Loss: 3.526894 Tokens per Sec: 5362.213867
Epoch Step: 171 / 173 Loss: 3.229080 Tokens per Sec: 5508.764648
Epoch 1
Epoch Step: 1 / 173 Loss: 3.288765 Tokens per Sec: 5399.946777
Epoch Step: 11 / 173 Loss: 3.260861 Tokens per Sec: 5336.975586
Epoch Step: 21 / 173 Loss: 2.880430 Tokens per Sec: 5377.098633
Epoch Step: 31 / 173 Loss: 2.454669 Tokens per Sec: 5417.854004
Epoch Step: 41 / 173 Loss: 3.319271 Tokens per Sec: 5398.191895
Epoch Step: 51 / 173 Loss: 2.720552 Tokens per Sec: 5404.820801
Epoch Step: 61 / 173 Loss: 2.393676 Tokens per Sec: 5381.555176
Epoch Step: 71 / 173 Loss: 3.488531 Tokens per Sec: 5310.320312
Epoch Step: 81 / 173 Loss: 2.698142 Tokens per Sec: 5300.463379
Epoch Step: 91 / 173 Loss: 2.858494 Tokens per Sec: 5383.992188
Epoch Step: 101 / 173 Loss: 2.640072 Tokens per Sec: 5304.226074
Epoch Step: 111 / 173 Loss: 2.950265 Tokens per Sec: 5370.384766
Epoch Step: 121 / 173 Loss: 2.692803 Tokens per Sec: 5339.563965
Epoch Step: 131 / 173 Loss: 3.625345 Tokens per Sec: 5293.741699
Epoch Step: 141 / 173 Loss: 2.228989 Tokens per Sec: 5451.112793
Epoch Step: 151 / 173 Loss: 2.385919 Tokens per Sec: 5351.125000
Epoch Step: 161 / 173 Loss: 2.882380 Tokens per Sec: 5445.475586
Epoch Step: 171 / 173 Loss: 2.454980 Tokens per Sec: 5461.923828
Epoch 2
Epoch Step: 1 / 173 Loss: 2.437947 Tokens per Sec: 4995.870117
Epoch Step: 11 / 173 Loss: 3.245078 Tokens per Sec: 5373.808105
Epoch Step: 21 / 173 Loss: 2.793113 Tokens per Sec: 5317.597168
Epoch Step: 31 / 173 Loss: 2.488728 Tokens per Sec: 5175.015625
Epoch Step: 41 / 173 Loss: 2.773388 Tokens per Sec: 5439.998535
Epoch Step: 51 / 173 Loss: 3.636965 Tokens per Sec: 5423.989258
Epoch Step: 61 / 173 Loss: 3.332530 Tokens per Sec: 5486.742676
Epoch Step: 71 / 173 Loss: 2.576520 Tokens per Sec: 5266.450684
Epoch Step: 81 / 173 Loss: 2.311344 Tokens per Sec: 5400.713379
Epoch Step: 91 / 173 Loss: 3.041704 Tokens per Sec: 5412.752930
Epoch Step: 101 / 173 Loss: 3.304473 Tokens per Sec: 5293.682617
Epoch Step: 111 / 173 Loss: 2.978332 Tokens per Sec: 5402.733887
Epoch Step: 121 / 173 Loss: 3.518331 Tokens per Sec: 5334.623535
Epoch Step: 131 / 173 Loss: 2.856688 Tokens per Sec: 5362.291016
Epoch Step: 141 / 173 Loss: 3.657433 Tokens per Sec: 5426.985352
Epoch Step: 151 / 173 Loss: 3.931428 Tokens per Sec: 5345.585938
Epoch Step: 161 / 173 Loss: 2.433865 Tokens per Sec: 5414.374023
Epoch Step: 171 / 173 Loss: 3.126077 Tokens per Sec: 5454.744141
Epoch 3
Epoch Step: 1 / 173 Loss: 2.231236 Tokens per Sec: 5480.787598
Epoch Step: 11 / 173 Loss: 2.966776 Tokens per Sec: 5355.324219
Epoch Step: 21 / 173 Loss: 2.681882 Tokens per Sec: 5318.804199
Epoch Step: 31 / 173 Loss: 2.273843 Tokens per Sec: 4197.692383
Epoch Step: 41 / 173 Loss: 3.043911 Tokens per Sec: 5344.032715
Epoch Step: 51 / 173 Loss: 2.850984 Tokens per Sec: 5348.823730
Epoch Step: 61 / 173 Loss: 2.263961 Tokens per Sec: 5400.149414
Epoch Step: 71 / 173 Loss: 2.999577 Tokens per Sec: 5401.147949
Epoch Step: 81 / 173 Loss: 3.167065 Tokens per Sec: 5455.784180
Epoch Step: 91 / 173 Loss: 2.118173 Tokens per Sec: 5371.665527
Epoch Step: 101 / 173 Loss: 3.325565 Tokens per Sec: 5381.298828
Epoch Step: 111 / 173 Loss: 3.442950 Tokens per Sec: 5445.586914
Epoch Step: 121 / 173 Loss: 2.608701 Tokens per Sec: 5424.933105
Epoch Step: 131 / 173 Loss: 2.181441 Tokens per Sec: 5288.099609
Epoch Step: 141 / 173 Loss: 2.019335 Tokens per Sec: 5267.176758
Epoch Step: 151 / 173 Loss: 2.918769 Tokens per Sec: 5276.992188
Epoch Step: 161 / 173 Loss: 2.404537 Tokens per Sec: 5310.383789
Epoch Step: 171 / 173 Loss: 3.171136 Tokens per Sec: 5432.484863
Epoch 4
Epoch Step: 1 / 173 Loss: 2.757430 Tokens per Sec: 5445.329590
Epoch Step: 11 / 173 Loss: 3.485754 Tokens per Sec: 5425.830566
Epoch Step: 21 / 173 Loss: 2.432833 Tokens per Sec: 5346.779297
Epoch Step: 31 / 173 Loss: 2.740495 Tokens per Sec: 5416.104980
Epoch Step: 41 / 173 Loss: 2.300935 Tokens per Sec: 5321.710938
Epoch Step: 51 / 173 Loss: 3.120520 Tokens per Sec: 5424.500000
Epoch Step: 61 / 173 Loss: 2.702376 Tokens per Sec: 5339.796387
Epoch Step: 71 / 173 Loss: 3.491594 Tokens per Sec: 5373.089844
Epoch Step: 81 / 173 Loss: 3.018936 Tokens per Sec: 5426.523926
Epoch Step: 91 / 173 Loss: 2.719368 Tokens per Sec: 5348.027832
Epoch Step: 101 / 173 Loss: 2.750379 Tokens per Sec: 5354.099609
Epoch Step: 111 / 173 Loss: 2.790795 Tokens per Sec: 5371.240234
Epoch Step: 121 / 173 Loss: 3.144665 Tokens per Sec: 5390.219727
Epoch Step: 131 / 173 Loss: 2.159345 Tokens per Sec: 5271.673340
Epoch Step: 141 / 173 Loss: 3.443600 Tokens per Sec: 5315.864258
Epoch Step: 151 / 173 Loss: 2.217108 Tokens per Sec: 5233.603027
Epoch Step: 161 / 173 Loss: 2.341400 Tokens per Sec: 5355.707031
Epoch Step: 171 / 173 Loss: 2.798831 Tokens per Sec: 5404.666016
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10931.11it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.468849 Tokens per Sec: 5096.253418
Epoch Step: 11 / 173 Loss: 3.954091 Tokens per Sec: 4980.252441
Epoch Step: 21 / 173 Loss: 3.520875 Tokens per Sec: 5335.145020
Epoch Step: 31 / 173 Loss: 3.609675 Tokens per Sec: 5425.231445
Epoch Step: 41 / 173 Loss: 3.205271 Tokens per Sec: 5431.614746
Epoch Step: 51 / 173 Loss: 3.126133 Tokens per Sec: 5317.612793
Epoch Step: 61 / 173 Loss: 2.981892 Tokens per Sec: 5277.476074
Epoch Step: 71 / 173 Loss: 3.750581 Tokens per Sec: 5394.762207
Epoch Step: 81 / 173 Loss: 2.815759 Tokens per Sec: 5422.419434
Epoch Step: 91 / 173 Loss: 3.322722 Tokens per Sec: 5403.870605
Epoch Step: 101 / 173 Loss: 3.150580 Tokens per Sec: 5389.854004
Epoch Step: 111 / 173 Loss: 3.526043 Tokens per Sec: 5414.722656
Epoch Step: 121 / 173 Loss: 3.605434 Tokens per Sec: 5429.241211
Epoch Step: 131 / 173 Loss: 4.151502 Tokens per Sec: 5457.820801
Epoch Step: 141 / 173 Loss: 3.587976 Tokens per Sec: 5390.495117
Epoch Step: 151 / 173 Loss: 2.241386 Tokens per Sec: 5339.229004
Epoch Step: 161 / 173 Loss: 2.673714 Tokens per Sec: 5398.011230
Epoch Step: 171 / 173 Loss: 2.587828 Tokens per Sec: 5370.259766
Epoch 1
Epoch Step: 1 / 173 Loss: 2.039580 Tokens per Sec: 5387.788574
Epoch Step: 11 / 173 Loss: 2.842444 Tokens per Sec: 5359.584961
Epoch Step: 21 / 173 Loss: 2.978715 Tokens per Sec: 5311.418945
Epoch Step: 31 / 173 Loss: 2.808809 Tokens per Sec: 5254.440430
Epoch Step: 41 / 173 Loss: 3.190780 Tokens per Sec: 5423.497559
Epoch Step: 51 / 173 Loss: 2.881022 Tokens per Sec: 5430.357910
Epoch Step: 61 / 173 Loss: 1.986977 Tokens per Sec: 5386.107422
Epoch Step: 71 / 173 Loss: 2.693856 Tokens per Sec: 5398.191406
Epoch Step: 81 / 173 Loss: 2.738903 Tokens per Sec: 5395.754883
Epoch Step: 91 / 173 Loss: 2.839106 Tokens per Sec: 5455.786133
Epoch Step: 101 / 173 Loss: 2.846610 Tokens per Sec: 5371.733887
Epoch Step: 111 / 173 Loss: 2.346254 Tokens per Sec: 5432.268066
Epoch Step: 121 / 173 Loss: 2.281289 Tokens per Sec: 5432.841309
Epoch Step: 131 / 173 Loss: 2.434247 Tokens per Sec: 5317.650391
Epoch Step: 141 / 173 Loss: 2.717577 Tokens per Sec: 5421.651855
Epoch Step: 151 / 173 Loss: 3.602275 Tokens per Sec: 5386.993652
Epoch Step: 161 / 173 Loss: 2.640581 Tokens per Sec: 5372.257324
Epoch Step: 171 / 173 Loss: 3.067277 Tokens per Sec: 5390.877441
Epoch 2
Epoch Step: 1 / 173 Loss: 2.852024 Tokens per Sec: 5416.541016
Epoch Step: 11 / 173 Loss: 3.102726 Tokens per Sec: 5425.208008
Epoch Step: 21 / 173 Loss: 2.361627 Tokens per Sec: 5428.161133
Epoch Step: 31 / 173 Loss: 1.832650 Tokens per Sec: 5333.326172
Epoch Step: 41 / 173 Loss: 1.664932 Tokens per Sec: 5466.213867
Epoch Step: 51 / 173 Loss: 2.694702 Tokens per Sec: 5356.614258
Epoch Step: 61 / 173 Loss: 3.319945 Tokens per Sec: 5428.027344
Epoch Step: 71 / 173 Loss: 2.144547 Tokens per Sec: 5446.247559
Epoch Step: 81 / 173 Loss: 2.510421 Tokens per Sec: 5385.217285
Epoch Step: 91 / 173 Loss: 2.806384 Tokens per Sec: 5263.982422
Epoch Step: 101 / 173 Loss: 2.825364 Tokens per Sec: 5419.655273
Epoch Step: 111 / 173 Loss: 2.104415 Tokens per Sec: 5331.618164
Epoch Step: 121 / 173 Loss: 2.369097 Tokens per Sec: 5319.238770
Epoch Step: 131 / 173 Loss: 2.553416 Tokens per Sec: 5430.288574
Epoch Step: 141 / 173 Loss: 2.430435 Tokens per Sec: 5510.264160
Epoch Step: 151 / 173 Loss: 2.503248 Tokens per Sec: 5273.233398
Epoch Step: 161 / 173 Loss: 1.517472 Tokens per Sec: 5365.036133
Epoch Step: 171 / 173 Loss: 2.092046 Tokens per Sec: 5308.365723
Epoch 3
Epoch Step: 1 / 173 Loss: 1.007862 Tokens per Sec: 5179.761719
Epoch Step: 11 / 173 Loss: 2.987474 Tokens per Sec: 5361.839844
Epoch Step: 21 / 173 Loss: 1.638320 Tokens per Sec: 5221.996094
Epoch Step: 31 / 173 Loss: 2.895084 Tokens per Sec: 5420.960938
Epoch Step: 41 / 173 Loss: 1.217561 Tokens per Sec: 5426.139160
Epoch Step: 51 / 173 Loss: 2.575652 Tokens per Sec: 5403.356934
Epoch Step: 61 / 173 Loss: 2.033468 Tokens per Sec: 5413.535645
Epoch Step: 71 / 173 Loss: 2.020175 Tokens per Sec: 5393.985352
Epoch Step: 81 / 173 Loss: 1.240477 Tokens per Sec: 5467.500488
Epoch Step: 91 / 173 Loss: 2.039902 Tokens per Sec: 5363.745605
Epoch Step: 101 / 173 Loss: 2.619211 Tokens per Sec: 5299.666016
Epoch Step: 111 / 173 Loss: 2.369279 Tokens per Sec: 5235.425293
Epoch Step: 121 / 173 Loss: 2.496354 Tokens per Sec: 5465.589355
Epoch Step: 131 / 173 Loss: 2.618243 Tokens per Sec: 5445.953613
Epoch Step: 141 / 173 Loss: 1.243021 Tokens per Sec: 5290.190918
Epoch Step: 151 / 173 Loss: 2.210308 Tokens per Sec: 5445.353516
Epoch Step: 161 / 173 Loss: 1.403222 Tokens per Sec: 5414.358887
Epoch Step: 171 / 173 Loss: 0.950170 Tokens per Sec: 5418.950195
Epoch 4
Epoch Step: 1 / 173 Loss: 2.176540 Tokens per Sec: 5482.176270
Epoch Step: 11 / 173 Loss: 1.756490 Tokens per Sec: 5166.169922
Epoch Step: 21 / 173 Loss: 2.264447 Tokens per Sec: 5344.216797
Epoch Step: 31 / 173 Loss: 2.123966 Tokens per Sec: 5400.517578
Epoch Step: 41 / 173 Loss: 1.565443 Tokens per Sec: 5475.445801
Epoch Step: 51 / 173 Loss: 1.067783 Tokens per Sec: 5477.575684
Epoch Step: 61 / 173 Loss: 2.659255 Tokens per Sec: 5417.903809
Epoch Step: 71 / 173 Loss: 2.068690 Tokens per Sec: 5441.018066
Epoch Step: 81 / 173 Loss: 2.469478 Tokens per Sec: 5296.313965
Epoch Step: 91 / 173 Loss: 2.330210 Tokens per Sec: 5279.746582
Epoch Step: 101 / 173 Loss: 2.482354 Tokens per Sec: 5391.796387
Epoch Step: 111 / 173 Loss: 2.323958 Tokens per Sec: 5374.153809
Epoch Step: 121 / 173 Loss: 2.300538 Tokens per Sec: 5451.206543
Epoch Step: 131 / 173 Loss: 1.654357 Tokens per Sec: 5375.240234
Epoch Step: 141 / 173 Loss: 1.458899 Tokens per Sec: 5335.517090
Epoch Step: 151 / 173 Loss: 2.453601 Tokens per Sec: 5375.854004
Epoch Step: 161 / 173 Loss: 1.041148 Tokens per Sec: 5410.212891
Epoch Step: 171 / 173 Loss: 1.854471 Tokens per Sec: 5333.511230
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  18%|█▊        | 28/154 [00:00<00:00, 272.39it/s]Loading hierarchy for column coarse_log_cluster_path:  37%|███▋      | 57/154 [00:00<00:00, 280.47it/s]Loading hierarchy for column coarse_log_cluster_path:  56%|█████▌    | 86/154 [00:00<00:00, 284.17it/s]Loading hierarchy for column coarse_log_cluster_path:  76%|███████▌  | 117/154 [00:00<00:00, 290.81it/s]Loading hierarchy for column coarse_log_cluster_path:  95%|█████████▌| 147/154 [00:00<00:00, 292.46it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 288.92it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 14630.01it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 3070it [00:00, 39383.14it/s]
INFO:root:Built hierarchy with 2100 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/1266 [00:00<?, ?it/s]Initializing gram_embedding connections:  10%|█         | 127/1266 [00:00<00:00, 1268.05it/s]Initializing gram_embedding connections:  20%|██        | 254/1266 [00:00<00:01, 623.69it/s] Initializing gram_embedding connections:  26%|██▋       | 334/1266 [00:00<00:01, 476.91it/s]Initializing gram_embedding connections:  31%|███       | 393/1266 [00:00<00:02, 404.53it/s]Initializing gram_embedding connections:  35%|███▍      | 440/1266 [00:01<00:02, 355.68it/s]Initializing gram_embedding connections:  38%|███▊      | 479/1266 [00:01<00:02, 318.28it/s]Initializing gram_embedding connections:  41%|████      | 513/1266 [00:01<00:02, 286.54it/s]Initializing gram_embedding connections:  43%|████▎     | 543/1266 [00:01<00:02, 262.58it/s]Initializing gram_embedding connections:  45%|████▌     | 570/1266 [00:01<00:02, 243.34it/s]Initializing gram_embedding connections:  47%|████▋     | 595/1266 [00:01<00:02, 227.11it/s]Initializing gram_embedding connections:  49%|████▉     | 618/1266 [00:01<00:03, 212.40it/s]Initializing gram_embedding connections:  50%|█████     | 639/1266 [00:02<00:03, 201.29it/s]Initializing gram_embedding connections:  52%|█████▏    | 659/1266 [00:02<00:03, 190.96it/s]Initializing gram_embedding connections:  54%|█████▎    | 678/1266 [00:02<00:03, 180.83it/s]Initializing gram_embedding connections:  55%|█████▍    | 696/1266 [00:02<00:03, 172.37it/s]Initializing gram_embedding connections:  56%|█████▋    | 713/1266 [00:02<00:03, 164.99it/s]Initializing gram_embedding connections:  58%|█████▊    | 730/1266 [00:02<00:03, 158.21it/s]Initializing gram_embedding connections:  59%|█████▉    | 746/1266 [00:02<00:03, 152.05it/s]Initializing gram_embedding connections:  60%|██████    | 762/1266 [00:02<00:03, 146.33it/s]Initializing gram_embedding connections:  61%|██████▏   | 777/1266 [00:02<00:03, 141.56it/s]Initializing gram_embedding connections:  63%|██████▎   | 792/1266 [00:03<00:03, 137.20it/s]Initializing gram_embedding connections:  64%|██████▎   | 806/1266 [00:03<00:03, 133.89it/s]Initializing gram_embedding connections:  65%|██████▍   | 820/1266 [00:03<00:03, 130.71it/s]Initializing gram_embedding connections:  66%|██████▌   | 834/1266 [00:03<00:03, 127.36it/s]Initializing gram_embedding connections:  67%|██████▋   | 847/1266 [00:03<00:03, 124.99it/s]Initializing gram_embedding connections:  68%|██████▊   | 860/1266 [00:03<00:03, 122.91it/s]Initializing gram_embedding connections:  69%|██████▉   | 873/1266 [00:03<00:03, 121.02it/s]Initializing gram_embedding connections:  70%|██████▉   | 886/1266 [00:03<00:03, 119.08it/s]Initializing gram_embedding connections:  71%|███████   | 898/1266 [00:03<00:03, 117.34it/s]Initializing gram_embedding connections:  72%|███████▏  | 910/1266 [00:04<00:03, 115.77it/s]Initializing gram_embedding connections:  73%|███████▎  | 922/1266 [00:04<00:03, 113.97it/s]Initializing gram_embedding connections:  74%|███████▍  | 934/1266 [00:04<00:02, 112.27it/s]Initializing gram_embedding connections:  75%|███████▍  | 946/1266 [00:04<00:02, 110.73it/s]Initializing gram_embedding connections:  76%|███████▌  | 958/1266 [00:04<00:02, 109.21it/s]Initializing gram_embedding connections:  77%|███████▋  | 969/1266 [00:04<00:02, 107.59it/s]Initializing gram_embedding connections:  77%|███████▋  | 980/1266 [00:04<00:02, 106.16it/s]Initializing gram_embedding connections:  78%|███████▊  | 991/1266 [00:04<00:02, 105.10it/s]Initializing gram_embedding connections:  79%|███████▉  | 1002/1266 [00:04<00:02, 103.72it/s]Initializing gram_embedding connections:  80%|████████  | 1013/1266 [00:05<00:02, 102.22it/s]Initializing gram_embedding connections:  81%|████████  | 1024/1266 [00:05<00:02, 100.80it/s]Initializing gram_embedding connections:  82%|████████▏ | 1035/1266 [00:05<00:02, 99.80it/s] Initializing gram_embedding connections:  83%|████████▎ | 1045/1266 [00:05<00:02, 99.04it/s]Initializing gram_embedding connections:  83%|████████▎ | 1055/1266 [00:05<00:02, 98.16it/s]Initializing gram_embedding connections:  84%|████████▍ | 1065/1266 [00:05<00:02, 97.41it/s]Initializing gram_embedding connections:  85%|████████▍ | 1075/1266 [00:05<00:01, 96.73it/s]Initializing gram_embedding connections:  86%|████████▌ | 1085/1266 [00:05<00:01, 95.79it/s]Initializing gram_embedding connections:  86%|████████▋ | 1095/1266 [00:05<00:01, 94.92it/s]Initializing gram_embedding connections:  87%|████████▋ | 1105/1266 [00:06<00:01, 93.50it/s]Initializing gram_embedding connections:  88%|████████▊ | 1115/1266 [00:06<00:01, 92.32it/s]Initializing gram_embedding connections:  89%|████████▉ | 1125/1266 [00:06<00:01, 91.19it/s]Initializing gram_embedding connections:  90%|████████▉ | 1135/1266 [00:06<00:01, 90.03it/s]Initializing gram_embedding connections:  90%|█████████ | 1145/1266 [00:06<00:01, 89.10it/s]Initializing gram_embedding connections:  91%|█████████ | 1154/1266 [00:06<00:01, 87.93it/s]Initializing gram_embedding connections:  92%|█████████▏| 1163/1266 [00:06<00:01, 86.92it/s]Initializing gram_embedding connections:  93%|█████████▎| 1172/1266 [00:06<00:01, 85.85it/s]Initializing gram_embedding connections:  93%|█████████▎| 1181/1266 [00:06<00:00, 85.17it/s]Initializing gram_embedding connections:  94%|█████████▍| 1190/1266 [00:07<00:00, 84.41it/s]Initializing gram_embedding connections:  95%|█████████▍| 1199/1266 [00:07<00:00, 83.76it/s]Initializing gram_embedding connections:  95%|█████████▌| 1208/1266 [00:07<00:00, 82.69it/s]Initializing gram_embedding connections:  96%|█████████▌| 1217/1266 [00:07<00:00, 82.08it/s]Initializing gram_embedding connections:  97%|█████████▋| 1226/1266 [00:07<00:00, 81.24it/s]Initializing gram_embedding connections:  98%|█████████▊| 1235/1266 [00:07<00:00, 80.66it/s]Initializing gram_embedding connections:  98%|█████████▊| 1244/1266 [00:07<00:00, 79.85it/s]Initializing gram_embedding connections:  99%|█████████▉| 1252/1266 [00:07<00:00, 79.11it/s]Initializing gram_embedding connections: 100%|█████████▉| 1260/1266 [00:07<00:00, 78.59it/s]Initializing gram_embedding connections: 100%|██████████| 1266/1266 [00:08<00:00, 158.24it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.08it/s]Calculating percentile frequencies...: 7it [00:00,  7.48it/s]
2023-05-24 19:58:24.451076: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 19:58:56.390074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 19:58:56.608700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 19:58:56.678913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 19:58:56.949904: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fcea400c600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 19:58:56.949948: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 19:58:56.949960: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 19:58:56.957896: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 19:58:57.067500: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 33s 33s/step - loss: 0.2146 - categorical_accuracy: 0.0117 - top_5_categorical_accuracy: 0.0664 - top_10_categorical_accuracy: 0.1230 - top_20_categorical_accuracy: 0.2656 - top_5_categorical_accuracy_cp0: 0.0865 - top_5_categorical_accuracy_cp1: 0.0714 - top_5_categorical_accuracy_cp2: 0.0897 - top_5_categorical_accuracy_cp3: 0.1053 - top_5_categorical_accuracy_cp4: 0.0000e+00 - top_5_categorical_accuracy_p0: 1.0000 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1163 - top_5_categorical_accuracy_p4: 0.0635 - top_10_categorical_accuracy_cp0: 0.1250 - top_10_categorical_accuracy_cp1: 0.1429 - top_10_categorical_accuracy_cp2: 0.1793 - top_10_categorical_accuracy_cp3: 0.1754 - top_10_categorical_accuracy_cp4: 0.0164 - top_10_categorical_accuracy_p0: 1.0000 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0500 - top_10_categorical_accuracy_p3: 0.1395 - top_10_categorical_accuracy_p4: 0.1247 - top_20_categorical_accuracy_cp0: 0.2788 - top_20_categorical_accuracy_cp1: 0.3333 - top_20_categorical_accuracy_cp2: 0.3448 - top_20_categorical_accuracy_cp3: 0.3509 - top_20_categorical_accuracy_cp4: 0.0738 - top_20_categorical_accuracy_p0: 1.0000 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.2500 - top_20_categorical_accuracy_p3: 0.3023 - top_20_categorical_accuracy_p4: 0.2630      3/Unknown - 33s 50ms/step - loss: 0.2106 - categorical_accuracy: 0.0684 - top_5_categorical_accuracy: 0.2318 - top_10_categorical_accuracy: 0.3275 - top_20_categorical_accuracy: 0.4701 - top_5_categorical_accuracy_cp0: 0.0814 - top_5_categorical_accuracy_cp1: 0.1679 - top_5_categorical_accuracy_cp2: 0.3260 - top_5_categorical_accuracy_cp3: 0.1852 - top_5_categorical_accuracy_cp4: 0.3169 - top_5_categorical_accuracy_p0: 0.3333 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0204 - top_5_categorical_accuracy_p3: 0.1203 - top_5_categorical_accuracy_p4: 0.2538 - top_10_categorical_accuracy_cp0: 0.1238 - top_10_categorical_accuracy_cp1: 0.2701 - top_10_categorical_accuracy_cp2: 0.4216 - top_10_categorical_accuracy_cp3: 0.2654 - top_10_categorical_accuracy_cp4: 0.4571 - top_10_categorical_accuracy_p0: 0.3333 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0408 - top_10_categorical_accuracy_p3: 0.1654 - top_10_categorical_accuracy_p4: 0.3589 - top_20_categorical_accuracy_cp0: 0.2671 - top_20_categorical_accuracy_cp1: 0.4526 - top_20_categorical_accuracy_cp2: 0.5564 - top_20_categorical_accuracy_cp3: 0.4259 - top_20_categorical_accuracy_cp4: 0.5714 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.0526 - top_20_categorical_accuracy_p2: 0.1633 - top_20_categorical_accuracy_p3: 0.3083 - top_20_categorical_accuracy_p4: 0.5038             5/Unknown - 33s 48ms/step - loss: 0.2066 - categorical_accuracy: 0.1016 - top_5_categorical_accuracy: 0.3293 - top_10_categorical_accuracy: 0.4223 - top_20_categorical_accuracy: 0.5465 - top_5_categorical_accuracy_cp0: 0.0921 - top_5_categorical_accuracy_cp1: 0.1855 - top_5_categorical_accuracy_cp2: 0.4190 - top_5_categorical_accuracy_cp3: 0.3333 - top_5_categorical_accuracy_cp4: 0.5452 - top_5_categorical_accuracy_p0: 0.0909 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0260 - top_5_categorical_accuracy_p3: 0.1000 - top_5_categorical_accuracy_p4: 0.3702 - top_10_categorical_accuracy_cp0: 0.1447 - top_10_categorical_accuracy_cp1: 0.3284 - top_10_categorical_accuracy_cp2: 0.5138 - top_10_categorical_accuracy_cp3: 0.4000 - top_10_categorical_accuracy_cp4: 0.6452 - top_10_categorical_accuracy_p0: 0.0909 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0390 - top_10_categorical_accuracy_p3: 0.1500 - top_10_categorical_accuracy_p4: 0.4723 - top_20_categorical_accuracy_cp0: 0.2820 - top_20_categorical_accuracy_cp1: 0.5011 - top_20_categorical_accuracy_cp2: 0.6315 - top_20_categorical_accuracy_cp3: 0.5439 - top_20_categorical_accuracy_cp4: 0.7194 - top_20_categorical_accuracy_p0: 0.1818 - top_20_categorical_accuracy_p1: 0.0357 - top_20_categorical_accuracy_p2: 0.1299 - top_20_categorical_accuracy_p3: 0.2875 - top_20_categorical_accuracy_p4: 0.5975      7/Unknown - 33s 47ms/step - loss: 0.2040 - categorical_accuracy: 0.1134 - top_5_categorical_accuracy: 0.3715 - top_10_categorical_accuracy: 0.4604 - top_20_categorical_accuracy: 0.5786 - top_5_categorical_accuracy_cp0: 0.0887 - top_5_categorical_accuracy_cp1: 0.2133 - top_5_categorical_accuracy_cp2: 0.4659 - top_5_categorical_accuracy_cp3: 0.3765 - top_5_categorical_accuracy_cp4: 0.6202 - top_5_categorical_accuracy_p0: 0.0714 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0233 - top_5_categorical_accuracy_p3: 0.0972 - top_5_categorical_accuracy_p4: 0.4182 - top_10_categorical_accuracy_cp0: 0.1426 - top_10_categorical_accuracy_cp1: 0.3584 - top_10_categorical_accuracy_cp2: 0.5560 - top_10_categorical_accuracy_cp3: 0.4471 - top_10_categorical_accuracy_cp4: 0.7039 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0465 - top_10_categorical_accuracy_p3: 0.1493 - top_10_categorical_accuracy_p4: 0.5147 - top_20_categorical_accuracy_cp0: 0.2868 - top_20_categorical_accuracy_cp1: 0.5305 - top_20_categorical_accuracy_cp2: 0.6655 - top_20_categorical_accuracy_cp3: 0.5735 - top_20_categorical_accuracy_cp4: 0.7663 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.2882 - top_20_categorical_accuracy_p4: 0.63292023-05-24 19:58:58.160445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.211081
7/7 [==============================] - 52s 3s/step - loss: 0.2040 - categorical_accuracy: 0.1134 - top_5_categorical_accuracy: 0.3715 - top_10_categorical_accuracy: 0.4604 - top_20_categorical_accuracy: 0.5786 - top_5_categorical_accuracy_cp0: 0.0887 - top_5_categorical_accuracy_cp1: 0.2133 - top_5_categorical_accuracy_cp2: 0.4659 - top_5_categorical_accuracy_cp3: 0.3765 - top_5_categorical_accuracy_cp4: 0.6202 - top_5_categorical_accuracy_p0: 0.0714 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0233 - top_5_categorical_accuracy_p3: 0.0972 - top_5_categorical_accuracy_p4: 0.4182 - top_10_categorical_accuracy_cp0: 0.1426 - top_10_categorical_accuracy_cp1: 0.3584 - top_10_categorical_accuracy_cp2: 0.5560 - top_10_categorical_accuracy_cp3: 0.4471 - top_10_categorical_accuracy_cp4: 0.7039 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0465 - top_10_categorical_accuracy_p3: 0.1493 - top_10_categorical_accuracy_p4: 0.5147 - top_20_categorical_accuracy_cp0: 0.2868 - top_20_categorical_accuracy_cp1: 0.5305 - top_20_categorical_accuracy_cp2: 0.6655 - top_20_categorical_accuracy_cp3: 0.5735 - top_20_categorical_accuracy_cp4: 0.7663 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.2882 - top_20_categorical_accuracy_p4: 0.6329 - val_loss: 0.2111 - val_categorical_accuracy: 0.1529 - val_top_5_categorical_accuracy: 0.2912 - val_top_10_categorical_accuracy: 0.3824 - val_top_20_categorical_accuracy: 0.4824 - val_top_5_categorical_accuracy_cp0: 0.1963 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2308 - val_top_5_categorical_accuracy_cp3: 0.7349 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2540 - val_top_5_categorical_accuracy_p4: 0.3785 - val_top_10_categorical_accuracy_cp0: 0.2761 - val_top_10_categorical_accuracy_cp1: 0.1642 - val_top_10_categorical_accuracy_cp2: 0.3077 - val_top_10_categorical_accuracy_cp3: 0.7952 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.1111 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.3413 - val_top_10_categorical_accuracy_p4: 0.4802 - val_top_20_categorical_accuracy_cp0: 0.4479 - val_top_20_categorical_accuracy_cp1: 0.1642 - val_top_20_categorical_accuracy_cp2: 0.3846 - val_top_20_categorical_accuracy_cp3: 0.8434 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.1667 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0556 - val_top_20_categorical_accuracy_p3: 0.5476 - val_top_20_categorical_accuracy_p4: 0.5141
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1790 - categorical_accuracy: 0.1855 - top_5_categorical_accuracy: 0.6035 - top_10_categorical_accuracy: 0.7012 - top_20_categorical_accuracy: 0.7812 - top_5_categorical_accuracy_cp0: 0.1300 - top_5_categorical_accuracy_cp1: 0.3763 - top_5_categorical_accuracy_cp2: 0.7826 - top_5_categorical_accuracy_cp3: 0.5536 - top_5_categorical_accuracy_cp4: 0.9760 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2045 - top_5_categorical_accuracy_p4: 0.6726 - top_10_categorical_accuracy_cp0: 0.2300 - top_10_categorical_accuracy_cp1: 0.5806 - top_10_categorical_accuracy_cp2: 0.8913 - top_10_categorical_accuracy_cp3: 0.6071 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0667 - top_10_categorical_accuracy_p3: 0.2045 - top_10_categorical_accuracy_p4: 0.7825 - top_20_categorical_accuracy_cp0: 0.3500 - top_20_categorical_accuracy_cp1: 0.7634 - top_20_categorical_accuracy_cp2: 0.9348 - top_20_categorical_accuracy_cp3: 0.7143 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2000 - top_20_categorical_accuracy_p2: 0.2667 - top_20_categorical_accuracy_p3: 0.3182 - top_20_categorical_accuracy_p4: 0.85433/7 [===========>..................] - ETA: 0s - loss: 0.1747 - categorical_accuracy: 0.1732 - top_5_categorical_accuracy: 0.5749 - top_10_categorical_accuracy: 0.6712 - top_20_categorical_accuracy: 0.7708 - top_5_categorical_accuracy_cp0: 0.0831 - top_5_categorical_accuracy_cp1: 0.3654 - top_5_categorical_accuracy_cp2: 0.7836 - top_5_categorical_accuracy_cp3: 0.5140 - top_5_categorical_accuracy_cp4: 0.9860 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1074 - top_5_categorical_accuracy_p4: 0.6654 - top_10_categorical_accuracy_cp0: 0.1869 - top_10_categorical_accuracy_cp1: 0.5769 - top_10_categorical_accuracy_cp2: 0.8756 - top_10_categorical_accuracy_cp3: 0.6145 - top_10_categorical_accuracy_cp4: 0.9944 - top_10_categorical_accuracy_p0: 0.1250 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0345 - top_10_categorical_accuracy_p3: 0.1946 - top_10_categorical_accuracy_p4: 0.7667 - top_20_categorical_accuracy_cp0: 0.3591 - top_20_categorical_accuracy_cp1: 0.7538 - top_20_categorical_accuracy_cp2: 0.9453 - top_20_categorical_accuracy_cp3: 0.7318 - top_20_categorical_accuracy_cp4: 0.9944 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1667 - top_20_categorical_accuracy_p2: 0.1724 - top_20_categorical_accuracy_p3: 0.3557 - top_20_categorical_accuracy_p4: 0.8573        5/7 [====================>.........] - ETA: 0s - loss: 0.1667 - categorical_accuracy: 0.1734 - top_5_categorical_accuracy: 0.5969 - top_10_categorical_accuracy: 0.7031 - top_20_categorical_accuracy: 0.8027 - top_5_categorical_accuracy_cp0: 0.0727 - top_5_categorical_accuracy_cp1: 0.3728 - top_5_categorical_accuracy_cp2: 0.8061 - top_5_categorical_accuracy_cp3: 0.5516 - top_5_categorical_accuracy_cp4: 0.9887 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0847 - top_5_categorical_accuracy_p4: 0.6833 - top_10_categorical_accuracy_cp0: 0.1950 - top_10_categorical_accuracy_cp1: 0.6183 - top_10_categorical_accuracy_cp2: 0.8994 - top_10_categorical_accuracy_cp3: 0.6584 - top_10_categorical_accuracy_cp4: 0.9952 - top_10_categorical_accuracy_p0: 0.0769 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0263 - top_10_categorical_accuracy_p3: 0.2034 - top_10_categorical_accuracy_p4: 0.7925 - top_20_categorical_accuracy_cp0: 0.3748 - top_20_categorical_accuracy_cp1: 0.8058 - top_20_categorical_accuracy_cp2: 0.9577 - top_20_categorical_accuracy_cp3: 0.7865 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.1071 - top_20_categorical_accuracy_p2: 0.1579 - top_20_categorical_accuracy_p3: 0.3898 - top_20_categorical_accuracy_p4: 0.88227/7 [==============================] - ETA: 0s - loss: 0.1652 - categorical_accuracy: 0.1714 - top_5_categorical_accuracy: 0.5979 - top_10_categorical_accuracy: 0.7133 - top_20_categorical_accuracy: 0.8102 - top_5_categorical_accuracy_cp0: 0.0666 - top_5_categorical_accuracy_cp1: 0.3656 - top_5_categorical_accuracy_cp2: 0.8139 - top_5_categorical_accuracy_cp3: 0.5765 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0764 - top_5_categorical_accuracy_p4: 0.6836 - top_10_categorical_accuracy_cp0: 0.1981 - top_10_categorical_accuracy_cp1: 0.6398 - top_10_categorical_accuracy_cp2: 0.9075 - top_10_categorical_accuracy_cp3: 0.6941 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.1979 - top_10_categorical_accuracy_p4: 0.8028 - top_20_categorical_accuracy_cp0: 0.3756 - top_20_categorical_accuracy_cp1: 0.8226 - top_20_categorical_accuracy_cp2: 0.9611 - top_20_categorical_accuracy_cp3: 0.8176 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1512 - top_20_categorical_accuracy_p3: 0.3785 - top_20_categorical_accuracy_p4: 0.8900DEBUG:root:Model metric val_loss improved from 0.211081 to 0.207820
7/7 [==============================] - 1s 121ms/step - loss: 0.1652 - categorical_accuracy: 0.1714 - top_5_categorical_accuracy: 0.5979 - top_10_categorical_accuracy: 0.7133 - top_20_categorical_accuracy: 0.8102 - top_5_categorical_accuracy_cp0: 0.0666 - top_5_categorical_accuracy_cp1: 0.3656 - top_5_categorical_accuracy_cp2: 0.8139 - top_5_categorical_accuracy_cp3: 0.5765 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0764 - top_5_categorical_accuracy_p4: 0.6836 - top_10_categorical_accuracy_cp0: 0.1981 - top_10_categorical_accuracy_cp1: 0.6398 - top_10_categorical_accuracy_cp2: 0.9075 - top_10_categorical_accuracy_cp3: 0.6941 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.1979 - top_10_categorical_accuracy_p4: 0.8028 - top_20_categorical_accuracy_cp0: 0.3756 - top_20_categorical_accuracy_cp1: 0.8226 - top_20_categorical_accuracy_cp2: 0.9611 - top_20_categorical_accuracy_cp3: 0.8176 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1512 - top_20_categorical_accuracy_p3: 0.3785 - top_20_categorical_accuracy_p4: 0.8900 - val_loss: 0.2078 - val_categorical_accuracy: 0.1647 - val_top_5_categorical_accuracy: 0.3088 - val_top_10_categorical_accuracy: 0.4500 - val_top_20_categorical_accuracy: 0.6647 - val_top_5_categorical_accuracy_cp0: 0.1902 - val_top_5_categorical_accuracy_cp1: 0.0149 - val_top_5_categorical_accuracy_cp2: 0.2308 - val_top_5_categorical_accuracy_cp3: 0.8072 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2460 - val_top_5_categorical_accuracy_p4: 0.4181 - val_top_10_categorical_accuracy_cp0: 0.2822 - val_top_10_categorical_accuracy_cp1: 0.2239 - val_top_10_categorical_accuracy_cp2: 0.5000 - val_top_10_categorical_accuracy_cp3: 0.9518 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.3651 - val_top_10_categorical_accuracy_p4: 0.6045 - val_top_20_categorical_accuracy_cp0: 0.6012 - val_top_20_categorical_accuracy_cp1: 0.4776 - val_top_20_categorical_accuracy_cp2: 0.5769 - val_top_20_categorical_accuracy_cp3: 0.9759 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.1667 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.2778 - val_top_20_categorical_accuracy_p3: 0.7143 - val_top_20_categorical_accuracy_p4: 0.7232
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1504 - categorical_accuracy: 0.1621 - top_5_categorical_accuracy: 0.6191 - top_10_categorical_accuracy: 0.7812 - top_20_categorical_accuracy: 0.8672 - top_5_categorical_accuracy_cp0: 0.0396 - top_5_categorical_accuracy_cp1: 0.2927 - top_5_categorical_accuracy_cp2: 0.8844 - top_5_categorical_accuracy_cp3: 0.5849 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0638 - top_5_categorical_accuracy_p4: 0.7009 - top_10_categorical_accuracy_cp0: 0.1386 - top_10_categorical_accuracy_cp1: 0.8171 - top_10_categorical_accuracy_cp2: 0.9796 - top_10_categorical_accuracy_cp3: 0.8679 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1489 - top_10_categorical_accuracy_p4: 0.8772 - top_20_categorical_accuracy_cp0: 0.4059 - top_20_categorical_accuracy_cp1: 0.9512 - top_20_categorical_accuracy_cp2: 0.9932 - top_20_categorical_accuracy_cp3: 0.9434 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.1429 - top_20_categorical_accuracy_p3: 0.4255 - top_20_categorical_accuracy_p4: 0.93973/7 [===========>..................] - ETA: 0s - loss: 0.1554 - categorical_accuracy: 0.1582 - top_5_categorical_accuracy: 0.5885 - top_10_categorical_accuracy: 0.7572 - top_20_categorical_accuracy: 0.8464 - top_5_categorical_accuracy_cp0: 0.0542 - top_5_categorical_accuracy_cp1: 0.3146 - top_5_categorical_accuracy_cp2: 0.8621 - top_5_categorical_accuracy_cp3: 0.5632 - top_5_categorical_accuracy_cp4: 0.9916 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0592 - top_5_categorical_accuracy_p4: 0.6796 - top_10_categorical_accuracy_cp0: 0.1596 - top_10_categorical_accuracy_cp1: 0.7828 - top_10_categorical_accuracy_cp2: 0.9828 - top_10_categorical_accuracy_cp3: 0.8333 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1908 - top_10_categorical_accuracy_p4: 0.8610 - top_20_categorical_accuracy_cp0: 0.3705 - top_20_categorical_accuracy_cp1: 0.9326 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9540 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0952 - top_20_categorical_accuracy_p2: 0.0256 - top_20_categorical_accuracy_p3: 0.4079 - top_20_categorical_accuracy_p4: 0.93775/7 [====================>.........] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.1621 - top_5_categorical_accuracy: 0.6074 - top_10_categorical_accuracy: 0.7785 - top_20_categorical_accuracy: 0.8641 - top_5_categorical_accuracy_cp0: 0.0594 - top_5_categorical_accuracy_cp1: 0.3355 - top_5_categorical_accuracy_cp2: 0.8692 - top_5_categorical_accuracy_cp3: 0.6121 - top_5_categorical_accuracy_cp4: 0.9839 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0601 - top_5_categorical_accuracy_p4: 0.6954 - top_10_categorical_accuracy_cp0: 0.1705 - top_10_categorical_accuracy_cp1: 0.8095 - top_10_categorical_accuracy_cp2: 0.9881 - top_10_categorical_accuracy_cp3: 0.8648 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1931 - top_10_categorical_accuracy_p4: 0.8791 - top_20_categorical_accuracy_cp0: 0.4023 - top_20_categorical_accuracy_cp1: 0.9416 - top_20_categorical_accuracy_cp2: 0.9985 - top_20_categorical_accuracy_cp3: 0.9715 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0690 - top_20_categorical_accuracy_p2: 0.0556 - top_20_categorical_accuracy_p3: 0.4378 - top_20_categorical_accuracy_p4: 0.94957/7 [==============================] - ETA: 0s - loss: 0.1509 - categorical_accuracy: 0.1675 - top_5_categorical_accuracy: 0.6147 - top_10_categorical_accuracy: 0.7816 - top_20_categorical_accuracy: 0.8637 - top_5_categorical_accuracy_cp0: 0.0602 - top_5_categorical_accuracy_cp1: 0.3530 - top_5_categorical_accuracy_cp2: 0.8662 - top_5_categorical_accuracy_cp3: 0.6588 - top_5_categorical_accuracy_cp4: 0.9788 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0556 - top_5_categorical_accuracy_p4: 0.7052 - top_10_categorical_accuracy_cp0: 0.1743 - top_10_categorical_accuracy_cp1: 0.8100 - top_10_categorical_accuracy_cp2: 0.9878 - top_10_categorical_accuracy_cp3: 0.8824 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1875 - top_10_categorical_accuracy_p4: 0.8841 - top_20_categorical_accuracy_cp0: 0.3930 - top_20_categorical_accuracy_cp1: 0.9498 - top_20_categorical_accuracy_cp2: 0.9964 - top_20_categorical_accuracy_cp3: 0.9765 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.4271 - top_20_categorical_accuracy_p4: 0.9512DEBUG:root:Model metric val_loss improved from 0.207820 to 0.201343
7/7 [==============================] - 1s 121ms/step - loss: 0.1509 - categorical_accuracy: 0.1675 - top_5_categorical_accuracy: 0.6147 - top_10_categorical_accuracy: 0.7816 - top_20_categorical_accuracy: 0.8637 - top_5_categorical_accuracy_cp0: 0.0602 - top_5_categorical_accuracy_cp1: 0.3530 - top_5_categorical_accuracy_cp2: 0.8662 - top_5_categorical_accuracy_cp3: 0.6588 - top_5_categorical_accuracy_cp4: 0.9788 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0556 - top_5_categorical_accuracy_p4: 0.7052 - top_10_categorical_accuracy_cp0: 0.1743 - top_10_categorical_accuracy_cp1: 0.8100 - top_10_categorical_accuracy_cp2: 0.9878 - top_10_categorical_accuracy_cp3: 0.8824 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1875 - top_10_categorical_accuracy_p4: 0.8841 - top_20_categorical_accuracy_cp0: 0.3930 - top_20_categorical_accuracy_cp1: 0.9498 - top_20_categorical_accuracy_cp2: 0.9964 - top_20_categorical_accuracy_cp3: 0.9765 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.4271 - top_20_categorical_accuracy_p4: 0.9512 - val_loss: 0.2013 - val_categorical_accuracy: 0.2029 - val_top_5_categorical_accuracy: 0.3882 - val_top_10_categorical_accuracy: 0.5824 - val_top_20_categorical_accuracy: 0.8029 - val_top_5_categorical_accuracy_cp0: 0.1595 - val_top_5_categorical_accuracy_cp1: 0.1940 - val_top_5_categorical_accuracy_cp2: 0.5000 - val_top_5_categorical_accuracy_cp3: 0.9639 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2063 - val_top_5_categorical_accuracy_p4: 0.5989 - val_top_10_categorical_accuracy_cp0: 0.3865 - val_top_10_categorical_accuracy_cp1: 0.4925 - val_top_10_categorical_accuracy_cp2: 0.7308 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.5000 - val_top_10_categorical_accuracy_p4: 0.7627 - val_top_20_categorical_accuracy_cp0: 0.6564 - val_top_20_categorical_accuracy_cp1: 0.8955 - val_top_20_categorical_accuracy_cp2: 0.8846 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.0556 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.2778 - val_top_20_categorical_accuracy_p3: 0.8016 - val_top_20_categorical_accuracy_p4: 0.9379
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1393 - categorical_accuracy: 0.2051 - top_5_categorical_accuracy: 0.6738 - top_10_categorical_accuracy: 0.8223 - top_20_categorical_accuracy: 0.8887 - top_5_categorical_accuracy_cp0: 0.0309 - top_5_categorical_accuracy_cp1: 0.4247 - top_5_categorical_accuracy_cp2: 0.8805 - top_5_categorical_accuracy_cp3: 0.8364 - top_5_categorical_accuracy_cp4: 0.9766 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0204 - top_5_categorical_accuracy_p4: 0.7713 - top_10_categorical_accuracy_cp0: 0.2062 - top_10_categorical_accuracy_cp1: 0.8767 - top_10_categorical_accuracy_cp2: 0.9874 - top_10_categorical_accuracy_cp3: 0.9636 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1837 - top_10_categorical_accuracy_p4: 0.9238 - top_20_categorical_accuracy_cp0: 0.4433 - top_20_categorical_accuracy_cp1: 0.9863 - top_20_categorical_accuracy_cp2: 0.9937 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9922 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.3878 - top_20_categorical_accuracy_p4: 0.97533/7 [===========>..................] - ETA: 0s - loss: 0.1415 - categorical_accuracy: 0.2038 - top_5_categorical_accuracy: 0.6491 - top_10_categorical_accuracy: 0.8053 - top_20_categorical_accuracy: 0.8880 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.4516 - top_5_categorical_accuracy_cp2: 0.8642 - top_5_categorical_accuracy_cp3: 0.8436 - top_5_categorical_accuracy_cp4: 0.9778 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0284 - top_5_categorical_accuracy_p4: 0.7477 - top_10_categorical_accuracy_cp0: 0.1863 - top_10_categorical_accuracy_cp1: 0.8992 - top_10_categorical_accuracy_cp2: 0.9930 - top_10_categorical_accuracy_cp3: 0.9553 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1773 - top_10_categorical_accuracy_p4: 0.9127 - top_20_categorical_accuracy_cp0: 0.4814 - top_20_categorical_accuracy_cp1: 0.9879 - top_20_categorical_accuracy_cp2: 0.9977 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0714 - top_20_categorical_accuracy_p2: 0.1667 - top_20_categorical_accuracy_p3: 0.4681 - top_20_categorical_accuracy_p4: 0.9714    5/7 [====================>.........] - ETA: 0s - loss: 0.1399 - categorical_accuracy: 0.2047 - top_5_categorical_accuracy: 0.6520 - top_10_categorical_accuracy: 0.8098 - top_20_categorical_accuracy: 0.8906 - top_5_categorical_accuracy_cp0: 0.0422 - top_5_categorical_accuracy_cp1: 0.4365 - top_5_categorical_accuracy_cp2: 0.8725 - top_5_categorical_accuracy_cp3: 0.8777 - top_5_categorical_accuracy_cp4: 0.9727 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0251 - top_5_categorical_accuracy_p4: 0.7528 - top_10_categorical_accuracy_cp0: 0.1939 - top_10_categorical_accuracy_cp1: 0.8842 - top_10_categorical_accuracy_cp2: 0.9928 - top_10_categorical_accuracy_cp3: 0.9712 - top_10_categorical_accuracy_cp4: 0.9968 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1841 - top_10_categorical_accuracy_p4: 0.9185 - top_20_categorical_accuracy_cp0: 0.4837 - top_20_categorical_accuracy_cp1: 0.9800 - top_20_categorical_accuracy_cp2: 0.9986 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0370 - top_20_categorical_accuracy_p2: 0.1111 - top_20_categorical_accuracy_p3: 0.5021 - top_20_categorical_accuracy_p4: 0.97377/7 [==============================] - ETA: 0s - loss: 0.1386 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6579 - top_10_categorical_accuracy: 0.8148 - top_20_categorical_accuracy: 0.8927 - top_5_categorical_accuracy_cp0: 0.0491 - top_5_categorical_accuracy_cp1: 0.4642 - top_5_categorical_accuracy_cp2: 0.8723 - top_5_categorical_accuracy_cp3: 0.9000 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0208 - top_5_categorical_accuracy_p4: 0.7589 - top_10_categorical_accuracy_cp0: 0.2139 - top_10_categorical_accuracy_cp1: 0.8871 - top_10_categorical_accuracy_cp2: 0.9939 - top_10_categorical_accuracy_cp3: 0.9765 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1944 - top_10_categorical_accuracy_p4: 0.9217 - top_20_categorical_accuracy_cp0: 0.4929 - top_20_categorical_accuracy_cp1: 0.9803 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.1047 - top_20_categorical_accuracy_p3: 0.4965 - top_20_categorical_accuracy_p4: 0.9754DEBUG:root:Model metric val_loss improved from 0.201343 to 0.188523
7/7 [==============================] - 1s 123ms/step - loss: 0.1386 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6579 - top_10_categorical_accuracy: 0.8148 - top_20_categorical_accuracy: 0.8927 - top_5_categorical_accuracy_cp0: 0.0491 - top_5_categorical_accuracy_cp1: 0.4642 - top_5_categorical_accuracy_cp2: 0.8723 - top_5_categorical_accuracy_cp3: 0.9000 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0208 - top_5_categorical_accuracy_p4: 0.7589 - top_10_categorical_accuracy_cp0: 0.2139 - top_10_categorical_accuracy_cp1: 0.8871 - top_10_categorical_accuracy_cp2: 0.9939 - top_10_categorical_accuracy_cp3: 0.9765 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1944 - top_10_categorical_accuracy_p4: 0.9217 - top_20_categorical_accuracy_cp0: 0.4929 - top_20_categorical_accuracy_cp1: 0.9803 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.1047 - top_20_categorical_accuracy_p3: 0.4965 - top_20_categorical_accuracy_p4: 0.9754 - val_loss: 0.1885 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.3441 - val_top_10_categorical_accuracy: 0.5265 - val_top_20_categorical_accuracy: 0.7265 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1791 - val_top_5_categorical_accuracy_cp2: 0.8462 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6610 - val_top_10_categorical_accuracy_cp0: 0.0859 - val_top_10_categorical_accuracy_cp1: 0.8209 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1111 - val_top_10_categorical_accuracy_p4: 0.9322 - val_top_20_categorical_accuracy_cp0: 0.4294 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.5556 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6758 - top_10_categorical_accuracy: 0.8379 - top_20_categorical_accuracy: 0.8984 - top_5_categorical_accuracy_cp0: 0.0594 - top_5_categorical_accuracy_cp1: 0.5102 - top_5_categorical_accuracy_cp2: 0.9141 - top_5_categorical_accuracy_cp3: 0.9825 - top_5_categorical_accuracy_cp4: 0.9141 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0233 - top_5_categorical_accuracy_p4: 0.7667 - top_10_categorical_accuracy_cp0: 0.2772 - top_10_categorical_accuracy_cp1: 0.9082 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2093 - top_10_categorical_accuracy_p4: 0.9333 - top_20_categorical_accuracy_cp0: 0.4851 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4419 - top_20_categorical_accuracy_p4: 0.98003/7 [===========>..................] - ETA: 0s - loss: 0.1362 - categorical_accuracy: 0.2129 - top_5_categorical_accuracy: 0.6595 - top_10_categorical_accuracy: 0.8099 - top_20_categorical_accuracy: 0.8893 - top_5_categorical_accuracy_cp0: 0.0557 - top_5_categorical_accuracy_cp1: 0.5130 - top_5_categorical_accuracy_cp2: 0.9046 - top_5_categorical_accuracy_cp3: 0.9778 - top_5_categorical_accuracy_cp4: 0.9190 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0127 - top_5_categorical_accuracy_p4: 0.7723 - top_10_categorical_accuracy_cp0: 0.2463 - top_10_categorical_accuracy_cp1: 0.8922 - top_10_categorical_accuracy_cp2: 0.9948 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9888 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1962 - top_10_categorical_accuracy_p4: 0.9267 - top_20_categorical_accuracy_cp0: 0.5073 - top_20_categorical_accuracy_cp1: 0.9926 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0204 - top_20_categorical_accuracy_p3: 0.5316 - top_20_categorical_accuracy_p4: 0.9786    5/7 [====================>.........] - ETA: 0s - loss: 0.1340 - categorical_accuracy: 0.2176 - top_5_categorical_accuracy: 0.6723 - top_10_categorical_accuracy: 0.8172 - top_20_categorical_accuracy: 0.8977 - top_5_categorical_accuracy_cp0: 0.0596 - top_5_categorical_accuracy_cp1: 0.5152 - top_5_categorical_accuracy_cp2: 0.9010 - top_5_categorical_accuracy_cp3: 0.9724 - top_5_categorical_accuracy_cp4: 0.9389 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0123 - top_5_categorical_accuracy_p4: 0.7806 - top_10_categorical_accuracy_cp0: 0.2421 - top_10_categorical_accuracy_cp1: 0.8935 - top_10_categorical_accuracy_cp2: 0.9925 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9884 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1721 - top_10_categorical_accuracy_p4: 0.9314 - top_20_categorical_accuracy_cp0: 0.5158 - top_20_categorical_accuracy_cp1: 0.9957 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0253 - top_20_categorical_accuracy_p3: 0.5246 - top_20_categorical_accuracy_p4: 0.98507/7 [==============================] - ETA: 0s - loss: 0.1332 - categorical_accuracy: 0.2146 - top_5_categorical_accuracy: 0.6756 - top_10_categorical_accuracy: 0.8251 - top_20_categorical_accuracy: 0.9008 - top_5_categorical_accuracy_cp0: 0.0602 - top_5_categorical_accuracy_cp1: 0.5036 - top_5_categorical_accuracy_cp2: 0.9002 - top_5_categorical_accuracy_cp3: 0.9647 - top_5_categorical_accuracy_cp4: 0.9429 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0104 - top_5_categorical_accuracy_p4: 0.7805 - top_10_categorical_accuracy_cp0: 0.2567 - top_10_categorical_accuracy_cp1: 0.8978 - top_10_categorical_accuracy_cp2: 0.9915 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1736 - top_10_categorical_accuracy_p4: 0.9359 - top_20_categorical_accuracy_cp0: 0.5182 - top_20_categorical_accuracy_cp1: 0.9928 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.0233 - top_20_categorical_accuracy_p3: 0.5104 - top_20_categorical_accuracy_p4: 0.9862    DEBUG:root:Model metric val_loss improved from 0.188523 to 0.182065
7/7 [==============================] - 1s 123ms/step - loss: 0.1332 - categorical_accuracy: 0.2146 - top_5_categorical_accuracy: 0.6756 - top_10_categorical_accuracy: 0.8251 - top_20_categorical_accuracy: 0.9008 - top_5_categorical_accuracy_cp0: 0.0602 - top_5_categorical_accuracy_cp1: 0.5036 - top_5_categorical_accuracy_cp2: 0.9002 - top_5_categorical_accuracy_cp3: 0.9647 - top_5_categorical_accuracy_cp4: 0.9429 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0104 - top_5_categorical_accuracy_p4: 0.7805 - top_10_categorical_accuracy_cp0: 0.2567 - top_10_categorical_accuracy_cp1: 0.8978 - top_10_categorical_accuracy_cp2: 0.9915 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1736 - top_10_categorical_accuracy_p4: 0.9359 - top_20_categorical_accuracy_cp0: 0.5182 - top_20_categorical_accuracy_cp1: 0.9928 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.0233 - top_20_categorical_accuracy_p3: 0.5104 - top_20_categorical_accuracy_p4: 0.9862 - val_loss: 0.1821 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.3471 - val_top_10_categorical_accuracy: 0.5265 - val_top_20_categorical_accuracy: 0.6618 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1791 - val_top_5_categorical_accuracy_cp2: 0.8846 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6667 - val_top_10_categorical_accuracy_cp0: 0.0491 - val_top_10_categorical_accuracy_cp1: 0.9254 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0635 - val_top_10_categorical_accuracy_p4: 0.9661 - val_top_20_categorical_accuracy_cp0: 0.2945 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3810 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1299 - categorical_accuracy: 0.2031 - top_5_categorical_accuracy: 0.6895 - top_10_categorical_accuracy: 0.8379 - top_20_categorical_accuracy: 0.9199 - top_5_categorical_accuracy_cp0: 0.1092 - top_5_categorical_accuracy_cp1: 0.6214 - top_5_categorical_accuracy_cp2: 0.9455 - top_5_categorical_accuracy_cp3: 0.9545 - top_5_categorical_accuracy_cp4: 0.9561 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0755 - top_5_categorical_accuracy_p4: 0.7950 - top_10_categorical_accuracy_cp0: 0.3529 - top_10_categorical_accuracy_cp1: 0.9709 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9737 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2264 - top_10_categorical_accuracy_p4: 0.9499 - top_20_categorical_accuracy_cp0: 0.6555 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6604 - top_20_categorical_accuracy_p4: 0.99323/7 [===========>..................] - ETA: 0s - loss: 0.1279 - categorical_accuracy: 0.2070 - top_5_categorical_accuracy: 0.6973 - top_10_categorical_accuracy: 0.8431 - top_20_categorical_accuracy: 0.9141 - top_5_categorical_accuracy_cp0: 0.0883 - top_5_categorical_accuracy_cp1: 0.5868 - top_5_categorical_accuracy_cp2: 0.9184 - top_5_categorical_accuracy_cp3: 0.9598 - top_5_categorical_accuracy_cp4: 0.9507 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0455 - top_5_categorical_accuracy_p4: 0.7966 - top_10_categorical_accuracy_cp0: 0.3470 - top_10_categorical_accuracy_cp1: 0.9306 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9753 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2652 - top_10_categorical_accuracy_p4: 0.9424 - top_20_categorical_accuracy_cp0: 0.5962 - top_20_categorical_accuracy_cp1: 0.9861 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.5985 - top_20_categorical_accuracy_p4: 0.99105/7 [====================>.........] - ETA: 0s - loss: 0.1283 - categorical_accuracy: 0.2051 - top_5_categorical_accuracy: 0.6980 - top_10_categorical_accuracy: 0.8398 - top_20_categorical_accuracy: 0.9164 - top_5_categorical_accuracy_cp0: 0.0853 - top_5_categorical_accuracy_cp1: 0.5558 - top_5_categorical_accuracy_cp2: 0.9141 - top_5_categorical_accuracy_cp3: 0.9564 - top_5_categorical_accuracy_cp4: 0.9618 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0472 - top_5_categorical_accuracy_p4: 0.8007 - top_10_categorical_accuracy_cp0: 0.3372 - top_10_categorical_accuracy_cp1: 0.9034 - top_10_categorical_accuracy_cp2: 0.9881 - top_10_categorical_accuracy_cp3: 0.9927 - top_10_categorical_accuracy_cp4: 0.9793 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2575 - top_10_categorical_accuracy_p4: 0.9423 - top_20_categorical_accuracy_cp0: 0.5988 - top_20_categorical_accuracy_cp1: 0.9850 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0400 - top_20_categorical_accuracy_p3: 0.6052 - top_20_categorical_accuracy_p4: 0.9928    7/7 [==============================] - ETA: 0s - loss: 0.1280 - categorical_accuracy: 0.2062 - top_5_categorical_accuracy: 0.7017 - top_10_categorical_accuracy: 0.8431 - top_20_categorical_accuracy: 0.9175 - top_5_categorical_accuracy_cp0: 0.0935 - top_5_categorical_accuracy_cp1: 0.5627 - top_5_categorical_accuracy_cp2: 0.9161 - top_5_categorical_accuracy_cp3: 0.9500 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0660 - top_5_categorical_accuracy_p4: 0.8047 - top_10_categorical_accuracy_cp0: 0.3502 - top_10_categorical_accuracy_cp1: 0.9050 - top_10_categorical_accuracy_cp2: 0.9891 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2708 - top_10_categorical_accuracy_p4: 0.9463 - top_20_categorical_accuracy_cp0: 0.6070 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.6250 - top_20_categorical_accuracy_p4: 0.9925DEBUG:root:Model metric val_loss improved from 0.182065 to 0.177785
7/7 [==============================] - 1s 121ms/step - loss: 0.1280 - categorical_accuracy: 0.2062 - top_5_categorical_accuracy: 0.7017 - top_10_categorical_accuracy: 0.8431 - top_20_categorical_accuracy: 0.9175 - top_5_categorical_accuracy_cp0: 0.0935 - top_5_categorical_accuracy_cp1: 0.5627 - top_5_categorical_accuracy_cp2: 0.9161 - top_5_categorical_accuracy_cp3: 0.9500 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0660 - top_5_categorical_accuracy_p4: 0.8047 - top_10_categorical_accuracy_cp0: 0.3502 - top_10_categorical_accuracy_cp1: 0.9050 - top_10_categorical_accuracy_cp2: 0.9891 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2708 - top_10_categorical_accuracy_p4: 0.9463 - top_20_categorical_accuracy_cp0: 0.6070 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.6250 - top_20_categorical_accuracy_p4: 0.9925 - val_loss: 0.1778 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.3441 - val_top_10_categorical_accuracy: 0.5235 - val_top_20_categorical_accuracy: 0.6824 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1493 - val_top_5_categorical_accuracy_cp2: 0.9231 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6610 - val_top_10_categorical_accuracy_cp0: 0.0613 - val_top_10_categorical_accuracy_cp1: 0.9104 - val_top_10_categorical_accuracy_cp2: 0.9231 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0794 - val_top_10_categorical_accuracy_p4: 0.9492 - val_top_20_categorical_accuracy_cp0: 0.3436 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4444 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1215 - categorical_accuracy: 0.2305 - top_5_categorical_accuracy: 0.7227 - top_10_categorical_accuracy: 0.8574 - top_20_categorical_accuracy: 0.9375 - top_5_categorical_accuracy_cp0: 0.1042 - top_5_categorical_accuracy_cp1: 0.5056 - top_5_categorical_accuracy_cp2: 0.9463 - top_5_categorical_accuracy_cp3: 0.9796 - top_5_categorical_accuracy_cp4: 0.9767 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0556 - top_5_categorical_accuracy_p4: 0.8266 - top_10_categorical_accuracy_cp0: 0.3646 - top_10_categorical_accuracy_cp1: 0.8989 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2593 - top_10_categorical_accuracy_p4: 0.9572 - top_20_categorical_accuracy_cp0: 0.6771 - top_20_categorical_accuracy_cp1: 0.9888 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.7037 - top_20_categorical_accuracy_p4: 0.99553/7 [===========>..................] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2220 - top_5_categorical_accuracy: 0.7207 - top_10_categorical_accuracy: 0.8535 - top_20_categorical_accuracy: 0.9206 - top_5_categorical_accuracy_cp0: 0.0936 - top_5_categorical_accuracy_cp1: 0.5299 - top_5_categorical_accuracy_cp2: 0.9521 - top_5_categorical_accuracy_cp3: 0.9560 - top_5_categorical_accuracy_cp4: 0.9692 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0523 - top_5_categorical_accuracy_p4: 0.8307 - top_10_categorical_accuracy_cp0: 0.3545 - top_10_categorical_accuracy_cp1: 0.9243 - top_10_categorical_accuracy_cp2: 0.9863 - top_10_categorical_accuracy_cp3: 0.9874 - top_10_categorical_accuracy_cp4: 0.9871 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2745 - top_10_categorical_accuracy_p4: 0.9592 - top_20_categorical_accuracy_cp0: 0.5987 - top_20_categorical_accuracy_cp1: 0.9920 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0238 - top_20_categorical_accuracy_p3: 0.6078 - top_20_categorical_accuracy_p4: 0.9977    5/7 [====================>.........] - ETA: 0s - loss: 0.1251 - categorical_accuracy: 0.2148 - top_5_categorical_accuracy: 0.7082 - top_10_categorical_accuracy: 0.8598 - top_20_categorical_accuracy: 0.9215 - top_5_categorical_accuracy_cp0: 0.1214 - top_5_categorical_accuracy_cp1: 0.5099 - top_5_categorical_accuracy_cp2: 0.9478 - top_5_categorical_accuracy_cp3: 0.9568 - top_5_categorical_accuracy_cp4: 0.9662 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0792 - top_5_categorical_accuracy_p4: 0.8132 - top_10_categorical_accuracy_cp0: 0.4104 - top_10_categorical_accuracy_cp1: 0.9272 - top_10_categorical_accuracy_cp2: 0.9855 - top_10_categorical_accuracy_cp3: 0.9892 - top_10_categorical_accuracy_cp4: 0.9887 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3333 - top_10_categorical_accuracy_p4: 0.9615 - top_20_categorical_accuracy_cp0: 0.6204 - top_20_categorical_accuracy_cp1: 0.9934 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0411 - top_20_categorical_accuracy_p3: 0.6500 - top_20_categorical_accuracy_p4: 0.99737/7 [==============================] - ETA: 0s - loss: 0.1251 - categorical_accuracy: 0.2152 - top_5_categorical_accuracy: 0.7091 - top_10_categorical_accuracy: 0.8582 - top_20_categorical_accuracy: 0.9220 - top_5_categorical_accuracy_cp0: 0.1347 - top_5_categorical_accuracy_cp1: 0.5054 - top_5_categorical_accuracy_cp2: 0.9489 - top_5_categorical_accuracy_cp3: 0.9588 - top_5_categorical_accuracy_cp4: 0.9668 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0833 - top_5_categorical_accuracy_p4: 0.8114 - top_10_categorical_accuracy_cp0: 0.4120 - top_10_categorical_accuracy_cp1: 0.9229 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3229 - top_10_categorical_accuracy_p4: 0.9583 - top_20_categorical_accuracy_cp0: 0.6292 - top_20_categorical_accuracy_cp1: 0.9892 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.6424 - top_20_categorical_accuracy_p4: 0.9963DEBUG:root:Model metric val_loss improved from 0.177785 to 0.170639
7/7 [==============================] - 1s 124ms/step - loss: 0.1251 - categorical_accuracy: 0.2152 - top_5_categorical_accuracy: 0.7091 - top_10_categorical_accuracy: 0.8582 - top_20_categorical_accuracy: 0.9220 - top_5_categorical_accuracy_cp0: 0.1347 - top_5_categorical_accuracy_cp1: 0.5054 - top_5_categorical_accuracy_cp2: 0.9489 - top_5_categorical_accuracy_cp3: 0.9588 - top_5_categorical_accuracy_cp4: 0.9668 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0833 - top_5_categorical_accuracy_p4: 0.8114 - top_10_categorical_accuracy_cp0: 0.4120 - top_10_categorical_accuracy_cp1: 0.9229 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3229 - top_10_categorical_accuracy_p4: 0.9583 - top_20_categorical_accuracy_cp0: 0.6292 - top_20_categorical_accuracy_cp1: 0.9892 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.6424 - top_20_categorical_accuracy_p4: 0.9963 - val_loss: 0.1706 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.3765 - val_top_10_categorical_accuracy: 0.5147 - val_top_20_categorical_accuracy: 0.7088 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.3134 - val_top_5_categorical_accuracy_cp2: 0.9231 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7232 - val_top_10_categorical_accuracy_cp0: 0.0552 - val_top_10_categorical_accuracy_cp1: 0.8806 - val_top_10_categorical_accuracy_cp2: 0.9231 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0714 - val_top_10_categorical_accuracy_p4: 0.9379 - val_top_20_categorical_accuracy_cp0: 0.3988 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.5159 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6582 - top_10_categorical_accuracy: 0.8164 - top_20_categorical_accuracy: 0.9121 - top_5_categorical_accuracy_cp0: 0.0877 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.9244 - top_5_categorical_accuracy_cp3: 0.9692 - top_5_categorical_accuracy_cp4: 0.9352 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0392 - top_5_categorical_accuracy_p4: 0.7648 - top_10_categorical_accuracy_cp0: 0.3947 - top_10_categorical_accuracy_cp1: 0.8491 - top_10_categorical_accuracy_cp2: 0.9748 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9444 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2745 - top_10_categorical_accuracy_p4: 0.9224 - top_20_categorical_accuracy_cp0: 0.6491 - top_20_categorical_accuracy_cp1: 0.9623 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.6471 - top_20_categorical_accuracy_p4: 0.98863/7 [===========>..................] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.2174 - top_5_categorical_accuracy: 0.7096 - top_10_categorical_accuracy: 0.8548 - top_20_categorical_accuracy: 0.9199 - top_5_categorical_accuracy_cp0: 0.1667 - top_5_categorical_accuracy_cp1: 0.5124 - top_5_categorical_accuracy_cp2: 0.9646 - top_5_categorical_accuracy_cp3: 0.9775 - top_5_categorical_accuracy_cp4: 0.9438 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1583 - top_5_categorical_accuracy_p4: 0.8079 - top_10_categorical_accuracy_cp0: 0.4444 - top_10_categorical_accuracy_cp1: 0.9046 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9691 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3957 - top_10_categorical_accuracy_p4: 0.9516 - top_20_categorical_accuracy_cp0: 0.6543 - top_20_categorical_accuracy_cp1: 0.9753 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9888 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1020 - top_20_categorical_accuracy_p3: 0.6978 - top_20_categorical_accuracy_p4: 0.99175/7 [====================>.........] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.2195 - top_5_categorical_accuracy: 0.7242 - top_10_categorical_accuracy: 0.8680 - top_20_categorical_accuracy: 0.9242 - top_5_categorical_accuracy_cp0: 0.1853 - top_5_categorical_accuracy_cp1: 0.5597 - top_5_categorical_accuracy_cp2: 0.9495 - top_5_categorical_accuracy_cp3: 0.9719 - top_5_categorical_accuracy_cp4: 0.9510 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1542 - top_5_categorical_accuracy_p4: 0.8237 - top_10_categorical_accuracy_cp0: 0.4669 - top_10_categorical_accuracy_cp1: 0.9284 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 0.9965 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4042 - top_10_categorical_accuracy_p4: 0.9633 - top_20_categorical_accuracy_cp0: 0.6597 - top_20_categorical_accuracy_cp1: 0.9826 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9902 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0986 - top_20_categorical_accuracy_p3: 0.6958 - top_20_categorical_accuracy_p4: 0.99377/7 [==============================] - ETA: 0s - loss: 0.1223 - categorical_accuracy: 0.2210 - top_5_categorical_accuracy: 0.7271 - top_10_categorical_accuracy: 0.8686 - top_20_categorical_accuracy: 0.9269 - top_5_categorical_accuracy_cp0: 0.1838 - top_5_categorical_accuracy_cp1: 0.5591 - top_5_categorical_accuracy_cp2: 0.9465 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1424 - top_5_categorical_accuracy_p4: 0.8259 - top_10_categorical_accuracy_cp0: 0.4691 - top_10_categorical_accuracy_cp1: 0.9194 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3889 - top_10_categorical_accuracy_p4: 0.9631 - top_20_categorical_accuracy_cp0: 0.6640 - top_20_categorical_accuracy_cp1: 0.9839 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.6979 - top_20_categorical_accuracy_p4: 0.9944DEBUG:root:Model metric val_loss improved from 0.170639 to 0.165559
7/7 [==============================] - 1s 124ms/step - loss: 0.1223 - categorical_accuracy: 0.2210 - top_5_categorical_accuracy: 0.7271 - top_10_categorical_accuracy: 0.8686 - top_20_categorical_accuracy: 0.9269 - top_5_categorical_accuracy_cp0: 0.1838 - top_5_categorical_accuracy_cp1: 0.5591 - top_5_categorical_accuracy_cp2: 0.9465 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1424 - top_5_categorical_accuracy_p4: 0.8259 - top_10_categorical_accuracy_cp0: 0.4691 - top_10_categorical_accuracy_cp1: 0.9194 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3889 - top_10_categorical_accuracy_p4: 0.9631 - top_20_categorical_accuracy_cp0: 0.6640 - top_20_categorical_accuracy_cp1: 0.9839 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.6979 - top_20_categorical_accuracy_p4: 0.9944 - val_loss: 0.1656 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.4412 - val_top_10_categorical_accuracy: 0.5588 - val_top_20_categorical_accuracy: 0.8235 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.6567 - val_top_5_categorical_accuracy_cp2: 0.8846 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8475 - val_top_10_categorical_accuracy_cp0: 0.1472 - val_top_10_categorical_accuracy_cp1: 0.8806 - val_top_10_categorical_accuracy_cp2: 0.9231 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1905 - val_top_10_categorical_accuracy_p4: 0.9379 - val_top_20_categorical_accuracy_cp0: 0.6380 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8254 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1222 - categorical_accuracy: 0.2246 - top_5_categorical_accuracy: 0.7344 - top_10_categorical_accuracy: 0.8594 - top_20_categorical_accuracy: 0.9238 - top_5_categorical_accuracy_cp0: 0.2920 - top_5_categorical_accuracy_cp1: 0.6022 - top_5_categorical_accuracy_cp2: 0.9051 - top_5_categorical_accuracy_cp3: 0.9825 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1667 - top_5_categorical_accuracy_p4: 0.8364 - top_10_categorical_accuracy_cp0: 0.5221 - top_10_categorical_accuracy_cp1: 0.9247 - top_10_categorical_accuracy_cp2: 0.9562 - top_10_categorical_accuracy_cp3: 0.9825 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4583 - top_10_categorical_accuracy_p4: 0.9500 - top_20_categorical_accuracy_cp0: 0.6903 - top_20_categorical_accuracy_cp1: 0.9785 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9821 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.7292 - top_20_categorical_accuracy_p4: 0.99093/7 [===========>..................] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.2220 - top_5_categorical_accuracy: 0.7318 - top_10_categorical_accuracy: 0.8691 - top_20_categorical_accuracy: 0.9310 - top_5_categorical_accuracy_cp0: 0.2462 - top_5_categorical_accuracy_cp1: 0.5882 - top_5_categorical_accuracy_cp2: 0.9239 - top_5_categorical_accuracy_cp3: 0.9943 - top_5_categorical_accuracy_cp4: 0.9501 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1438 - top_5_categorical_accuracy_p4: 0.8343 - top_10_categorical_accuracy_cp0: 0.5075 - top_10_categorical_accuracy_cp1: 0.9412 - top_10_categorical_accuracy_cp2: 0.9772 - top_10_categorical_accuracy_cp3: 0.9943 - top_10_categorical_accuracy_cp4: 0.9695 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4110 - top_10_categorical_accuracy_p4: 0.9644 - top_20_categorical_accuracy_cp0: 0.7117 - top_20_categorical_accuracy_cp1: 0.9816 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9861 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1333 - top_20_categorical_accuracy_p3: 0.7671 - top_20_categorical_accuracy_p4: 0.99245/7 [====================>.........] - ETA: 0s - loss: 0.1202 - categorical_accuracy: 0.2215 - top_5_categorical_accuracy: 0.7395 - top_10_categorical_accuracy: 0.8742 - top_20_categorical_accuracy: 0.9336 - top_5_categorical_accuracy_cp0: 0.2433 - top_5_categorical_accuracy_cp1: 0.5708 - top_5_categorical_accuracy_cp2: 0.9345 - top_5_categorical_accuracy_cp3: 0.9892 - top_5_categorical_accuracy_cp4: 0.9597 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1632 - top_5_categorical_accuracy_p4: 0.8393 - top_10_categorical_accuracy_cp0: 0.4943 - top_10_categorical_accuracy_cp1: 0.9378 - top_10_categorical_accuracy_cp2: 0.9807 - top_10_categorical_accuracy_cp3: 0.9928 - top_10_categorical_accuracy_cp4: 0.9775 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4310 - top_10_categorical_accuracy_p4: 0.9665 - top_20_categorical_accuracy_cp0: 0.7031 - top_20_categorical_accuracy_cp1: 0.9828 - top_20_categorical_accuracy_cp2: 0.9985 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9903 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1233 - top_20_categorical_accuracy_p3: 0.7866 - top_20_categorical_accuracy_p4: 0.99287/7 [==============================] - ETA: 0s - loss: 0.1200 - categorical_accuracy: 0.2223 - top_5_categorical_accuracy: 0.7403 - top_10_categorical_accuracy: 0.8747 - top_20_categorical_accuracy: 0.9346 - top_5_categorical_accuracy_cp0: 0.2456 - top_5_categorical_accuracy_cp1: 0.5645 - top_5_categorical_accuracy_cp2: 0.9343 - top_5_categorical_accuracy_cp3: 0.9853 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1701 - top_5_categorical_accuracy_p4: 0.8382 - top_10_categorical_accuracy_cp0: 0.4960 - top_10_categorical_accuracy_cp1: 0.9355 - top_10_categorical_accuracy_cp2: 0.9818 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4306 - top_10_categorical_accuracy_p4: 0.9657 - top_20_categorical_accuracy_cp0: 0.7084 - top_20_categorical_accuracy_cp1: 0.9803 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1163 - top_20_categorical_accuracy_p3: 0.7917 - top_20_categorical_accuracy_p4: 0.9925DEBUG:root:Model metric val_loss improved from 0.165559 to 0.161417
7/7 [==============================] - 1s 118ms/step - loss: 0.1200 - categorical_accuracy: 0.2223 - top_5_categorical_accuracy: 0.7403 - top_10_categorical_accuracy: 0.8747 - top_20_categorical_accuracy: 0.9346 - top_5_categorical_accuracy_cp0: 0.2456 - top_5_categorical_accuracy_cp1: 0.5645 - top_5_categorical_accuracy_cp2: 0.9343 - top_5_categorical_accuracy_cp3: 0.9853 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1701 - top_5_categorical_accuracy_p4: 0.8382 - top_10_categorical_accuracy_cp0: 0.4960 - top_10_categorical_accuracy_cp1: 0.9355 - top_10_categorical_accuracy_cp2: 0.9818 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4306 - top_10_categorical_accuracy_p4: 0.9657 - top_20_categorical_accuracy_cp0: 0.7084 - top_20_categorical_accuracy_cp1: 0.9803 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1163 - top_20_categorical_accuracy_p3: 0.7917 - top_20_categorical_accuracy_p4: 0.9925 - val_loss: 0.1614 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.4971 - val_top_10_categorical_accuracy: 0.6176 - val_top_20_categorical_accuracy: 0.8412 - val_top_5_categorical_accuracy_cp0: 0.0920 - val_top_5_categorical_accuracy_cp1: 0.7164 - val_top_5_categorical_accuracy_cp2: 0.8846 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.1190 - val_top_5_categorical_accuracy_p4: 0.8701 - val_top_10_categorical_accuracy_cp0: 0.2638 - val_top_10_categorical_accuracy_cp1: 0.8955 - val_top_10_categorical_accuracy_cp2: 0.9231 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.3413 - val_top_10_categorical_accuracy_p4: 0.9435 - val_top_20_categorical_accuracy_cp0: 0.6748 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8730 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1119 - categorical_accuracy: 0.2227 - top_5_categorical_accuracy: 0.7871 - top_10_categorical_accuracy: 0.9082 - top_20_categorical_accuracy: 0.9590 - top_5_categorical_accuracy_cp0: 0.2976 - top_5_categorical_accuracy_cp1: 0.6300 - top_5_categorical_accuracy_cp2: 0.9514 - top_5_categorical_accuracy_cp3: 0.9787 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2381 - top_5_categorical_accuracy_p4: 0.8618 - top_10_categorical_accuracy_cp0: 0.5952 - top_10_categorical_accuracy_cp1: 0.9500 - top_10_categorical_accuracy_cp2: 0.9722 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9708 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5714 - top_10_categorical_accuracy_p4: 0.9671 - top_20_categorical_accuracy_cp0: 0.7857 - top_20_categorical_accuracy_cp1: 0.9800 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2000 - top_20_categorical_accuracy_p3: 0.8571 - top_20_categorical_accuracy_p4: 0.99343/7 [===========>..................] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.2214 - top_5_categorical_accuracy: 0.7572 - top_10_categorical_accuracy: 0.8835 - top_20_categorical_accuracy: 0.9401 - top_5_categorical_accuracy_cp0: 0.2444 - top_5_categorical_accuracy_cp1: 0.6426 - top_5_categorical_accuracy_cp2: 0.9529 - top_5_categorical_accuracy_cp3: 0.9701 - top_5_categorical_accuracy_cp4: 0.9679 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1622 - top_5_categorical_accuracy_p4: 0.8596 - top_10_categorical_accuracy_cp0: 0.5460 - top_10_categorical_accuracy_cp1: 0.9350 - top_10_categorical_accuracy_cp2: 0.9752 - top_10_categorical_accuracy_cp3: 0.9940 - top_10_categorical_accuracy_cp4: 0.9813 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0500 - top_10_categorical_accuracy_p3: 0.5068 - top_10_categorical_accuracy_p4: 0.9660 - top_20_categorical_accuracy_cp0: 0.7397 - top_20_categorical_accuracy_cp1: 0.9783 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1750 - top_20_categorical_accuracy_p3: 0.8243 - top_20_categorical_accuracy_p4: 0.9925    5/7 [====================>.........] - ETA: 0s - loss: 0.1181 - categorical_accuracy: 0.2180 - top_5_categorical_accuracy: 0.7527 - top_10_categorical_accuracy: 0.8813 - top_20_categorical_accuracy: 0.9379 - top_5_categorical_accuracy_cp0: 0.2447 - top_5_categorical_accuracy_cp1: 0.6112 - top_5_categorical_accuracy_cp2: 0.9485 - top_5_categorical_accuracy_cp3: 0.9708 - top_5_categorical_accuracy_cp4: 0.9666 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1610 - top_5_categorical_accuracy_p4: 0.8521 - top_10_categorical_accuracy_cp0: 0.5359 - top_10_categorical_accuracy_cp1: 0.9222 - top_10_categorical_accuracy_cp2: 0.9779 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9793 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0290 - top_10_categorical_accuracy_p3: 0.4873 - top_10_categorical_accuracy_p4: 0.9648 - top_20_categorical_accuracy_cp0: 0.7243 - top_20_categorical_accuracy_cp1: 0.9762 - top_20_categorical_accuracy_cp2: 0.9985 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1739 - top_20_categorical_accuracy_p3: 0.8008 - top_20_categorical_accuracy_p4: 0.99237/7 [==============================] - ETA: 0s - loss: 0.1183 - categorical_accuracy: 0.2175 - top_5_categorical_accuracy: 0.7500 - top_10_categorical_accuracy: 0.8792 - top_20_categorical_accuracy: 0.9372 - top_5_categorical_accuracy_cp0: 0.2488 - top_5_categorical_accuracy_cp1: 0.6039 - top_5_categorical_accuracy_cp2: 0.9440 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1667 - top_5_categorical_accuracy_p4: 0.8498 - top_10_categorical_accuracy_cp0: 0.5277 - top_10_categorical_accuracy_cp1: 0.9283 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.4826 - top_10_categorical_accuracy_p4: 0.9646 - top_20_categorical_accuracy_cp0: 0.7242 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1628 - top_20_categorical_accuracy_p3: 0.8090 - top_20_categorical_accuracy_p4: 0.9922DEBUG:root:Model metric val_loss improved from 0.161417 to 0.156929
7/7 [==============================] - 1s 112ms/step - loss: 0.1183 - categorical_accuracy: 0.2175 - top_5_categorical_accuracy: 0.7500 - top_10_categorical_accuracy: 0.8792 - top_20_categorical_accuracy: 0.9372 - top_5_categorical_accuracy_cp0: 0.2488 - top_5_categorical_accuracy_cp1: 0.6039 - top_5_categorical_accuracy_cp2: 0.9440 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1667 - top_5_categorical_accuracy_p4: 0.8498 - top_10_categorical_accuracy_cp0: 0.5277 - top_10_categorical_accuracy_cp1: 0.9283 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.4826 - top_10_categorical_accuracy_p4: 0.9646 - top_20_categorical_accuracy_cp0: 0.7242 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1628 - top_20_categorical_accuracy_p3: 0.8090 - top_20_categorical_accuracy_p4: 0.9922 - val_loss: 0.1569 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.5441 - val_top_10_categorical_accuracy: 0.6971 - val_top_20_categorical_accuracy: 0.8441 - val_top_5_categorical_accuracy_cp0: 0.1902 - val_top_5_categorical_accuracy_cp1: 0.7164 - val_top_5_categorical_accuracy_cp2: 0.8846 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2460 - val_top_5_categorical_accuracy_p4: 0.8701 - val_top_10_categorical_accuracy_cp0: 0.4663 - val_top_10_categorical_accuracy_cp1: 0.8060 - val_top_10_categorical_accuracy_cp2: 0.9231 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.6032 - val_top_10_categorical_accuracy_p4: 0.9096 - val_top_20_categorical_accuracy_cp0: 0.6810 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8810 - val_top_20_categorical_accuracy_p4: 0.9944
INFO:root:Restoring best model weights with val_loss: 0.156929 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  7.18it/s]Calculating prediction outputs...: 1it [00:00,  7.16it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 967.32it/s]
INFO:root:Finished run ee70ed5b4d544010b53acaa5fb416763
Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 19:59:34.140285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 19:59:34.664774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:59:34.664837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 19:59:34.664842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run efc242213f484be2bc80233eb2609214
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 11978.91it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13264.05it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13241.70it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.196631]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.254263]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.095517]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11580.40it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.104476 Tokens per Sec: 1095.330200
Epoch Step: 11 / 173 Loss: 3.941206 Tokens per Sec: 5460.411133
Epoch Step: 21 / 173 Loss: 3.229469 Tokens per Sec: 5104.436523
Epoch Step: 31 / 173 Loss: 3.741095 Tokens per Sec: 5403.139648
Epoch Step: 41 / 173 Loss: 3.690719 Tokens per Sec: 5447.235840
Epoch Step: 51 / 173 Loss: 3.372973 Tokens per Sec: 5441.398438
Epoch Step: 61 / 173 Loss: 3.213740 Tokens per Sec: 5448.455566
Epoch Step: 71 / 173 Loss: 3.783741 Tokens per Sec: 5462.797852
Epoch Step: 81 / 173 Loss: 3.783890 Tokens per Sec: 5429.638672
Epoch Step: 91 / 173 Loss: 3.255566 Tokens per Sec: 5515.907227
Epoch Step: 101 / 173 Loss: 3.357334 Tokens per Sec: 5382.396973
Epoch Step: 111 / 173 Loss: 2.810310 Tokens per Sec: 5307.108887
Epoch Step: 121 / 173 Loss: 2.687805 Tokens per Sec: 5385.784668
Epoch Step: 131 / 173 Loss: 3.146715 Tokens per Sec: 5444.627930
Epoch Step: 141 / 173 Loss: 3.405338 Tokens per Sec: 5293.925293
Epoch Step: 151 / 173 Loss: 3.287899 Tokens per Sec: 5400.466797
Epoch Step: 161 / 173 Loss: 2.849882 Tokens per Sec: 5408.057617
Epoch Step: 171 / 173 Loss: 2.638711 Tokens per Sec: 5320.798340
Epoch 1
Epoch Step: 1 / 173 Loss: 2.631676 Tokens per Sec: 5203.176758
Epoch Step: 11 / 173 Loss: 3.372947 Tokens per Sec: 5359.256836
Epoch Step: 21 / 173 Loss: 2.633129 Tokens per Sec: 5318.916992
Epoch Step: 31 / 173 Loss: 2.875039 Tokens per Sec: 5477.734863
Epoch Step: 41 / 173 Loss: 3.358888 Tokens per Sec: 5463.418945
Epoch Step: 51 / 173 Loss: 2.920820 Tokens per Sec: 5440.692871
Epoch Step: 61 / 173 Loss: 2.829366 Tokens per Sec: 5358.924805
Epoch Step: 71 / 173 Loss: 2.393480 Tokens per Sec: 5490.411621
Epoch Step: 81 / 173 Loss: 2.876429 Tokens per Sec: 5452.341797
Epoch Step: 91 / 173 Loss: 3.191180 Tokens per Sec: 5357.500977
Epoch Step: 101 / 173 Loss: 2.627088 Tokens per Sec: 5419.409668
Epoch Step: 111 / 173 Loss: 3.474332 Tokens per Sec: 5480.144043
Epoch Step: 121 / 173 Loss: 3.813658 Tokens per Sec: 5276.925781
Epoch Step: 131 / 173 Loss: 3.260124 Tokens per Sec: 5414.817871
Epoch Step: 141 / 173 Loss: 2.901454 Tokens per Sec: 5495.541016
Epoch Step: 151 / 173 Loss: 2.956270 Tokens per Sec: 5284.727051
Epoch Step: 161 / 173 Loss: 3.669696 Tokens per Sec: 5443.873047
Epoch Step: 171 / 173 Loss: 2.963584 Tokens per Sec: 5379.385742
Epoch 2
Epoch Step: 1 / 173 Loss: 2.452572 Tokens per Sec: 5228.490234
Epoch Step: 11 / 173 Loss: 3.244450 Tokens per Sec: 5493.594238
Epoch Step: 21 / 173 Loss: 2.834868 Tokens per Sec: 5481.534180
Epoch Step: 31 / 173 Loss: 2.486761 Tokens per Sec: 5510.340820
Epoch Step: 41 / 173 Loss: 2.251598 Tokens per Sec: 5362.619141
Epoch Step: 51 / 173 Loss: 3.338768 Tokens per Sec: 5303.365234
Epoch Step: 61 / 173 Loss: 3.027514 Tokens per Sec: 5442.440918
Epoch Step: 71 / 173 Loss: 2.385700 Tokens per Sec: 5449.890137
Epoch Step: 81 / 173 Loss: 2.623504 Tokens per Sec: 5323.217285
Epoch Step: 91 / 173 Loss: 2.761467 Tokens per Sec: 5366.988281
Epoch Step: 101 / 173 Loss: 2.331984 Tokens per Sec: 5416.715820
Epoch Step: 111 / 173 Loss: 3.584982 Tokens per Sec: 5392.250488
Epoch Step: 121 / 173 Loss: 3.252229 Tokens per Sec: 5389.940430
Epoch Step: 131 / 173 Loss: 3.052106 Tokens per Sec: 5430.899902
Epoch Step: 141 / 173 Loss: 3.218897 Tokens per Sec: 5410.052246
Epoch Step: 151 / 173 Loss: 3.125333 Tokens per Sec: 5373.722168
Epoch Step: 161 / 173 Loss: 2.317762 Tokens per Sec: 5435.719238
Epoch Step: 171 / 173 Loss: 2.709084 Tokens per Sec: 5350.332520
Epoch 3
Epoch Step: 1 / 173 Loss: 2.346895 Tokens per Sec: 5322.602539
Epoch Step: 11 / 173 Loss: 3.242781 Tokens per Sec: 5423.505371
Epoch Step: 21 / 173 Loss: 3.185692 Tokens per Sec: 5455.123535
Epoch Step: 31 / 173 Loss: 2.831693 Tokens per Sec: 5417.871582
Epoch Step: 41 / 173 Loss: 2.857476 Tokens per Sec: 5360.481934
Epoch Step: 51 / 173 Loss: 2.605969 Tokens per Sec: 5435.182617
Epoch Step: 61 / 173 Loss: 2.891316 Tokens per Sec: 5440.774902
Epoch Step: 71 / 173 Loss: 2.542902 Tokens per Sec: 5435.033203
Epoch Step: 81 / 173 Loss: 2.959050 Tokens per Sec: 5353.300293
Epoch Step: 91 / 173 Loss: 2.185071 Tokens per Sec: 5294.858398
Epoch Step: 101 / 173 Loss: 3.009549 Tokens per Sec: 5233.156250
Epoch Step: 111 / 173 Loss: 3.499176 Tokens per Sec: 5305.835938
Epoch Step: 121 / 173 Loss: 2.341430 Tokens per Sec: 5377.699219
Epoch Step: 131 / 173 Loss: 3.105691 Tokens per Sec: 5521.186523
Epoch Step: 141 / 173 Loss: 3.006846 Tokens per Sec: 5444.953613
Epoch Step: 151 / 173 Loss: 2.771505 Tokens per Sec: 5424.302246
Epoch Step: 161 / 173 Loss: 2.866782 Tokens per Sec: 5470.225586
Epoch Step: 171 / 173 Loss: 2.656868 Tokens per Sec: 5433.270508
Epoch 4
Epoch Step: 1 / 173 Loss: 2.287128 Tokens per Sec: 5411.375977
Epoch Step: 11 / 173 Loss: 2.472435 Tokens per Sec: 5218.238770
Epoch Step: 21 / 173 Loss: 3.129049 Tokens per Sec: 5505.718262
Epoch Step: 31 / 173 Loss: 2.534652 Tokens per Sec: 5350.298828
Epoch Step: 41 / 173 Loss: 2.240909 Tokens per Sec: 5445.382324
Epoch Step: 51 / 173 Loss: 2.732074 Tokens per Sec: 5376.045410
Epoch Step: 61 / 173 Loss: 2.787297 Tokens per Sec: 5448.108398
Epoch Step: 71 / 173 Loss: 2.723943 Tokens per Sec: 5398.241211
Epoch Step: 81 / 173 Loss: 2.753395 Tokens per Sec: 5461.560059
Epoch Step: 91 / 173 Loss: 2.172196 Tokens per Sec: 5396.846680
Epoch Step: 101 / 173 Loss: 2.255925 Tokens per Sec: 5334.593750
Epoch Step: 111 / 173 Loss: 2.594784 Tokens per Sec: 5260.059082
Epoch Step: 121 / 173 Loss: 3.023197 Tokens per Sec: 5469.231445
Epoch Step: 131 / 173 Loss: 2.490278 Tokens per Sec: 5411.557129
Epoch Step: 141 / 173 Loss: 3.235398 Tokens per Sec: 5534.054199
Epoch Step: 151 / 173 Loss: 3.032833 Tokens per Sec: 5432.797363
Epoch Step: 161 / 173 Loss: 2.231025 Tokens per Sec: 5383.583496
Epoch Step: 171 / 173 Loss: 2.037578 Tokens per Sec: 5470.940430
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11080.82it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.107027 Tokens per Sec: 5083.904785
Epoch Step: 11 / 173 Loss: 3.498186 Tokens per Sec: 5351.288086
Epoch Step: 21 / 173 Loss: 3.115049 Tokens per Sec: 5318.921875
Epoch Step: 31 / 173 Loss: 3.580116 Tokens per Sec: 5373.514160
Epoch Step: 41 / 173 Loss: 3.521970 Tokens per Sec: 5467.453125
Epoch Step: 51 / 173 Loss: 3.180259 Tokens per Sec: 5297.417969
Epoch Step: 61 / 173 Loss: 2.932652 Tokens per Sec: 5305.037109
Epoch Step: 71 / 173 Loss: 4.197069 Tokens per Sec: 5363.715332
Epoch Step: 81 / 173 Loss: 3.743780 Tokens per Sec: 5333.653809
Epoch Step: 91 / 173 Loss: 3.888436 Tokens per Sec: 5373.218262
Epoch Step: 101 / 173 Loss: 2.566321 Tokens per Sec: 5358.341309
Epoch Step: 111 / 173 Loss: 3.043370 Tokens per Sec: 5374.958496
Epoch Step: 121 / 173 Loss: 3.149113 Tokens per Sec: 5364.014648
Epoch Step: 131 / 173 Loss: 3.729640 Tokens per Sec: 5510.471680
Epoch Step: 141 / 173 Loss: 3.164769 Tokens per Sec: 5415.773438
Epoch Step: 151 / 173 Loss: 3.468707 Tokens per Sec: 5480.418457
Epoch Step: 161 / 173 Loss: 2.913666 Tokens per Sec: 5450.328613
Epoch Step: 171 / 173 Loss: 3.467000 Tokens per Sec: 5426.067383
Epoch 1
Epoch Step: 1 / 173 Loss: 3.383875 Tokens per Sec: 5336.835938
Epoch Step: 11 / 173 Loss: 2.474276 Tokens per Sec: 5300.319824
Epoch Step: 21 / 173 Loss: 3.204227 Tokens per Sec: 5405.428223
Epoch Step: 31 / 173 Loss: 2.321528 Tokens per Sec: 5199.973633
Epoch Step: 41 / 173 Loss: 3.128298 Tokens per Sec: 5447.480469
Epoch Step: 51 / 173 Loss: 3.161034 Tokens per Sec: 5404.766602
Epoch Step: 61 / 173 Loss: 3.280000 Tokens per Sec: 5284.234375
Epoch Step: 71 / 173 Loss: 3.234724 Tokens per Sec: 5374.551758
Epoch Step: 81 / 173 Loss: 2.238350 Tokens per Sec: 5450.276855
Epoch Step: 91 / 173 Loss: 2.862528 Tokens per Sec: 5396.043457
Epoch Step: 101 / 173 Loss: 3.171342 Tokens per Sec: 5469.871094
Epoch Step: 111 / 173 Loss: 1.824639 Tokens per Sec: 5373.926758
Epoch Step: 121 / 173 Loss: 2.360217 Tokens per Sec: 5327.778809
Epoch Step: 131 / 173 Loss: 2.160240 Tokens per Sec: 5427.540039
Epoch Step: 141 / 173 Loss: 2.224779 Tokens per Sec: 5459.028809
Epoch Step: 151 / 173 Loss: 2.835309 Tokens per Sec: 5472.290527
Epoch Step: 161 / 173 Loss: 2.552820 Tokens per Sec: 5414.916504
Epoch Step: 171 / 173 Loss: 1.945245 Tokens per Sec: 5395.633789
Epoch 2
Epoch Step: 1 / 173 Loss: 1.743074 Tokens per Sec: 5189.906738
Epoch Step: 11 / 173 Loss: 1.899928 Tokens per Sec: 5355.462891
Epoch Step: 21 / 173 Loss: 2.478833 Tokens per Sec: 5459.714844
Epoch Step: 31 / 173 Loss: 2.242940 Tokens per Sec: 5441.428711
Epoch Step: 41 / 173 Loss: 1.415065 Tokens per Sec: 5372.852539
Epoch Step: 51 / 173 Loss: 2.208943 Tokens per Sec: 5400.370605
Epoch Step: 61 / 173 Loss: 1.717420 Tokens per Sec: 5362.940430
Epoch Step: 71 / 173 Loss: 2.874837 Tokens per Sec: 5330.147461
Epoch Step: 81 / 173 Loss: 2.826789 Tokens per Sec: 5458.608887
Epoch Step: 91 / 173 Loss: 1.904597 Tokens per Sec: 5427.340820
Epoch Step: 101 / 173 Loss: 2.721125 Tokens per Sec: 5282.302734
Epoch Step: 111 / 173 Loss: 3.197954 Tokens per Sec: 5495.599609
Epoch Step: 121 / 173 Loss: 2.282288 Tokens per Sec: 5244.301270
Epoch Step: 131 / 173 Loss: 1.487534 Tokens per Sec: 5435.925781
Epoch Step: 141 / 173 Loss: 2.881550 Tokens per Sec: 5415.291016
Epoch Step: 151 / 173 Loss: 2.574406 Tokens per Sec: 5394.448730
Epoch Step: 161 / 173 Loss: 2.369037 Tokens per Sec: 5350.932617
Epoch Step: 171 / 173 Loss: 2.429002 Tokens per Sec: 5442.359863
Epoch 3
Epoch Step: 1 / 173 Loss: 2.225422 Tokens per Sec: 4974.029785
Epoch Step: 11 / 173 Loss: 2.286040 Tokens per Sec: 5365.556641
Epoch Step: 21 / 173 Loss: 2.722595 Tokens per Sec: 5465.461426
Epoch Step: 31 / 173 Loss: 2.361223 Tokens per Sec: 5344.042969
Epoch Step: 41 / 173 Loss: 2.808571 Tokens per Sec: 5436.915527
Epoch Step: 51 / 173 Loss: 1.406572 Tokens per Sec: 5416.699707
Epoch Step: 61 / 173 Loss: 3.703350 Tokens per Sec: 5441.596680
Epoch Step: 71 / 173 Loss: 2.487757 Tokens per Sec: 5427.758789
Epoch Step: 81 / 173 Loss: 2.375580 Tokens per Sec: 5355.238770
Epoch Step: 91 / 173 Loss: 2.809312 Tokens per Sec: 5462.673828
Epoch Step: 101 / 173 Loss: 1.746485 Tokens per Sec: 5352.752441
Epoch Step: 111 / 173 Loss: 2.686781 Tokens per Sec: 5379.679199
Epoch Step: 121 / 173 Loss: 1.122386 Tokens per Sec: 5352.234375
Epoch Step: 131 / 173 Loss: 2.097300 Tokens per Sec: 5416.088867
Epoch Step: 141 / 173 Loss: 1.776697 Tokens per Sec: 5337.276855
Epoch Step: 151 / 173 Loss: 1.615894 Tokens per Sec: 5451.067871
Epoch Step: 161 / 173 Loss: 2.124141 Tokens per Sec: 5401.506348
Epoch Step: 171 / 173 Loss: 2.145218 Tokens per Sec: 5329.412598
Epoch 4
Epoch Step: 1 / 173 Loss: 2.969940 Tokens per Sec: 5569.331543
Epoch Step: 11 / 173 Loss: 2.212295 Tokens per Sec: 5360.231445
Epoch Step: 21 / 173 Loss: 2.397219 Tokens per Sec: 5368.205078
Epoch Step: 31 / 173 Loss: 2.987319 Tokens per Sec: 5395.050293
Epoch Step: 41 / 173 Loss: 2.319506 Tokens per Sec: 5346.267090
Epoch Step: 51 / 173 Loss: 2.360358 Tokens per Sec: 5325.413574
Epoch Step: 61 / 173 Loss: 2.095196 Tokens per Sec: 5479.789551
Epoch Step: 71 / 173 Loss: 0.984736 Tokens per Sec: 5395.510254
Epoch Step: 81 / 173 Loss: 2.087147 Tokens per Sec: 5384.987793
Epoch Step: 91 / 173 Loss: 2.950095 Tokens per Sec: 5354.361328
Epoch Step: 101 / 173 Loss: 3.206003 Tokens per Sec: 5401.659668
Epoch Step: 111 / 173 Loss: 0.660317 Tokens per Sec: 5463.905762
Epoch Step: 121 / 173 Loss: 2.518014 Tokens per Sec: 5449.060547
Epoch Step: 131 / 173 Loss: 2.121259 Tokens per Sec: 5451.890137
Epoch Step: 141 / 173 Loss: 2.131519 Tokens per Sec: 5348.428711
Epoch Step: 151 / 173 Loss: 1.021847 Tokens per Sec: 5384.269531
Epoch Step: 161 / 173 Loss: 1.472764 Tokens per Sec: 5356.709961
Epoch Step: 171 / 173 Loss: 2.424400 Tokens per Sec: 5333.917480
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11015.91it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 20:01:53.554374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.554621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.555654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.555835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.555990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.556137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.556515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:01:53.627255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.627473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.627633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.627783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.627919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:53.628052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.010786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9333 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:01:54.011258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:01:54.011364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22327 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Epoch 0
Epoch Step: 1 / 173 Loss: 6.350638 Tokens per Sec: 5233.570801
Epoch Step: 11 / 173 Loss: 3.805209 Tokens per Sec: 5421.278320
Epoch Step: 21 / 173 Loss: 3.653437 Tokens per Sec: 5378.449707
Epoch Step: 31 / 173 Loss: 3.417812 Tokens per Sec: 5319.367676
Epoch Step: 41 / 173 Loss: 3.498106 Tokens per Sec: 5373.923340
Epoch Step: 51 / 173 Loss: 3.965777 Tokens per Sec: 5395.960449
Epoch Step: 61 / 173 Loss: 3.804191 Tokens per Sec: 5481.293945
Epoch Step: 71 / 173 Loss: 3.612789 Tokens per Sec: 5436.716797
Epoch Step: 81 / 173 Loss: 3.822546 Tokens per Sec: 5429.912109
Epoch Step: 91 / 173 Loss: 3.614462 Tokens per Sec: 5412.586426
Epoch Step: 101 / 173 Loss: 3.029727 Tokens per Sec: 5218.297363
Epoch Step: 111 / 173 Loss: 3.167490 Tokens per Sec: 5244.750488
Epoch Step: 121 / 173 Loss: 3.739619 Tokens per Sec: 5409.779785
Epoch Step: 131 / 173 Loss: 3.338500 Tokens per Sec: 5412.987305
Epoch Step: 141 / 173 Loss: 3.398198 Tokens per Sec: 5383.187500
Epoch Step: 151 / 173 Loss: 2.549468 Tokens per Sec: 5375.030273
Epoch Step: 161 / 173 Loss: 2.418610 Tokens per Sec: 5332.044922
Epoch Step: 171 / 173 Loss: 2.738237 Tokens per Sec: 5440.410645
Epoch 1
Epoch Step: 1 / 173 Loss: 3.995856 Tokens per Sec: 5334.742188
Epoch Step: 11 / 173 Loss: 2.922170 Tokens per Sec: 5341.900879
Epoch Step: 21 / 173 Loss: 3.427713 Tokens per Sec: 5270.493652
Epoch Step: 31 / 173 Loss: 4.063941 Tokens per Sec: 5362.547852
Epoch Step: 41 / 173 Loss: 2.432935 Tokens per Sec: 5432.903320
Epoch Step: 51 / 173 Loss: 3.187466 Tokens per Sec: 5481.410645
Epoch Step: 61 / 173 Loss: 3.147853 Tokens per Sec: 5541.918457
Epoch Step: 71 / 173 Loss: 3.102927 Tokens per Sec: 5388.011230
Epoch Step: 81 / 173 Loss: 3.113862 Tokens per Sec: 5386.969238
Epoch Step: 91 / 173 Loss: 2.915063 Tokens per Sec: 5318.616211
Epoch Step: 101 / 173 Loss: 4.190161 Tokens per Sec: 5315.971191
Epoch Step: 111 / 173 Loss: 3.609815 Tokens per Sec: 5477.299805
Epoch Step: 121 / 173 Loss: 2.461349 Tokens per Sec: 5347.953125
Epoch Step: 131 / 173 Loss: 2.484959 Tokens per Sec: 5313.896973
Epoch Step: 141 / 173 Loss: 2.274429 Tokens per Sec: 5277.536621
Epoch Step: 151 / 173 Loss: 2.589112 Tokens per Sec: 5318.695312
Epoch Step: 161 / 173 Loss: 2.432917 Tokens per Sec: 5407.388184
Epoch Step: 171 / 173 Loss: 2.931765 Tokens per Sec: 5471.189941
Epoch 2
Epoch Step: 1 / 173 Loss: 3.001752 Tokens per Sec: 5431.191895
Epoch Step: 11 / 173 Loss: 3.437891 Tokens per Sec: 5291.252441
Epoch Step: 21 / 173 Loss: 2.874093 Tokens per Sec: 5282.597168
Epoch Step: 31 / 173 Loss: 3.035685 Tokens per Sec: 5399.142090
Epoch Step: 41 / 173 Loss: 3.057106 Tokens per Sec: 5441.437012
Epoch Step: 51 / 173 Loss: 2.569376 Tokens per Sec: 5477.033203
Epoch Step: 61 / 173 Loss: 3.066669 Tokens per Sec: 5416.052246
Epoch Step: 71 / 173 Loss: 2.793142 Tokens per Sec: 5325.273438
Epoch Step: 81 / 173 Loss: 3.099593 Tokens per Sec: 5346.737793
Epoch Step: 91 / 173 Loss: 3.229760 Tokens per Sec: 5498.173828
Epoch Step: 101 / 173 Loss: 2.760223 Tokens per Sec: 5433.731445
Epoch Step: 111 / 173 Loss: 3.200732 Tokens per Sec: 5402.245605
Epoch Step: 121 / 173 Loss: 2.566461 Tokens per Sec: 5353.010742
Epoch Step: 131 / 173 Loss: 2.799146 Tokens per Sec: 5337.849609
Epoch Step: 141 / 173 Loss: 2.755983 Tokens per Sec: 5474.713379
Epoch Step: 151 / 173 Loss: 3.572114 Tokens per Sec: 5373.425293
Epoch Step: 161 / 173 Loss: 2.935450 Tokens per Sec: 5330.080078
Epoch Step: 171 / 173 Loss: 3.470393 Tokens per Sec: 5349.392578
Epoch 3
Epoch Step: 1 / 173 Loss: 3.106128 Tokens per Sec: 5364.112305
Epoch Step: 11 / 173 Loss: 2.489479 Tokens per Sec: 5313.138672
Epoch Step: 21 / 173 Loss: 2.815088 Tokens per Sec: 5382.172852
Epoch Step: 31 / 173 Loss: 3.640574 Tokens per Sec: 5323.987305
Epoch Step: 41 / 173 Loss: 3.579491 Tokens per Sec: 5417.521973
Epoch Step: 51 / 173 Loss: 2.958503 Tokens per Sec: 5405.739258
Epoch Step: 61 / 173 Loss: 2.275253 Tokens per Sec: 5391.618164
Epoch Step: 71 / 173 Loss: 2.261150 Tokens per Sec: 5385.317383
Epoch Step: 81 / 173 Loss: 2.438228 Tokens per Sec: 5322.607910
Epoch Step: 91 / 173 Loss: 2.779961 Tokens per Sec: 5388.869629
Epoch Step: 101 / 173 Loss: 2.437076 Tokens per Sec: 5312.256836
Epoch Step: 111 / 173 Loss: 2.728282 Tokens per Sec: 5486.087402
Epoch Step: 121 / 173 Loss: 3.075371 Tokens per Sec: 5360.117188
Epoch Step: 131 / 173 Loss: 2.774452 Tokens per Sec: 5383.701172
Epoch Step: 141 / 173 Loss: 2.222190 Tokens per Sec: 5316.256836
Epoch Step: 151 / 173 Loss: 3.320336 Tokens per Sec: 5434.958008
Epoch Step: 161 / 173 Loss: 2.822329 Tokens per Sec: 5306.376465
Epoch Step: 171 / 173 Loss: 2.274115 Tokens per Sec: 5358.600586
Epoch 4
Epoch Step: 1 / 173 Loss: 2.081187 Tokens per Sec: 5253.582520
Epoch Step: 11 / 173 Loss: 3.071456 Tokens per Sec: 5316.674316
Epoch Step: 21 / 173 Loss: 2.747810 Tokens per Sec: 5400.761230
Epoch Step: 31 / 173 Loss: 3.042560 Tokens per Sec: 5329.080566
Epoch Step: 41 / 173 Loss: 3.375069 Tokens per Sec: 5318.199707
Epoch Step: 51 / 173 Loss: 2.256671 Tokens per Sec: 5282.388672
Epoch Step: 61 / 173 Loss: 2.501380 Tokens per Sec: 5426.004883
Epoch Step: 71 / 173 Loss: 2.560084 Tokens per Sec: 5412.438965
Epoch Step: 81 / 173 Loss: 2.959790 Tokens per Sec: 5446.361816
Epoch Step: 91 / 173 Loss: 2.687742 Tokens per Sec: 5478.850586
Epoch Step: 101 / 173 Loss: 2.731954 Tokens per Sec: 5458.034180
Epoch Step: 111 / 173 Loss: 2.448147 Tokens per Sec: 5344.367676
Epoch Step: 121 / 173 Loss: 2.907391 Tokens per Sec: 5330.724121
Epoch Step: 131 / 173 Loss: 2.197289 Tokens per Sec: 5259.820312
Epoch Step: 141 / 173 Loss: 3.097444 Tokens per Sec: 5414.946289
Epoch Step: 151 / 173 Loss: 3.085790 Tokens per Sec: 5343.802246
Epoch Step: 161 / 173 Loss: 2.896533 Tokens per Sec: 5442.219727
Epoch Step: 171 / 173 Loss: 2.444685 Tokens per Sec: 5375.325684
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12715.62it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13821.96it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13423.82it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.189139]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.125761]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.094656]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11828.76it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.073981 Tokens per Sec: 5261.392090
Epoch Step: 11 / 173 Loss: 3.562559 Tokens per Sec: 5370.080566
Epoch Step: 21 / 173 Loss: 3.686527 Tokens per Sec: 5468.155273
Epoch Step: 31 / 173 Loss: 3.708297 Tokens per Sec: 5346.100586
Epoch Step: 41 / 173 Loss: 3.405727 Tokens per Sec: 5420.055664
Epoch Step: 51 / 173 Loss: 3.068761 Tokens per Sec: 5278.945801
Epoch Step: 61 / 173 Loss: 2.815498 Tokens per Sec: 5433.312500
Epoch Step: 71 / 173 Loss: 4.055773 Tokens per Sec: 5327.145020
Epoch Step: 81 / 173 Loss: 3.527707 Tokens per Sec: 5469.660156
Epoch Step: 91 / 173 Loss: 3.027224 Tokens per Sec: 5341.809082
Epoch Step: 101 / 173 Loss: 3.340235 Tokens per Sec: 5485.291504
Epoch Step: 111 / 173 Loss: 3.388379 Tokens per Sec: 5412.049316
Epoch Step: 121 / 173 Loss: 3.011303 Tokens per Sec: 5383.011230
Epoch Step: 131 / 173 Loss: 3.445818 Tokens per Sec: 5422.007324
Epoch Step: 141 / 173 Loss: 2.526144 Tokens per Sec: 5361.190430
Epoch Step: 151 / 173 Loss: 3.088406 Tokens per Sec: 5316.824707
Epoch Step: 161 / 173 Loss: 3.430314 Tokens per Sec: 5437.044922
Epoch Step: 171 / 173 Loss: 2.936606 Tokens per Sec: 5427.388672
Epoch 1
Epoch Step: 1 / 173 Loss: 2.418919 Tokens per Sec: 5370.054199
Epoch Step: 11 / 173 Loss: 2.542800 Tokens per Sec: 5381.977051
Epoch Step: 21 / 173 Loss: 2.735591 Tokens per Sec: 5324.647949
Epoch Step: 31 / 173 Loss: 2.803797 Tokens per Sec: 5360.099609
Epoch Step: 41 / 173 Loss: 3.504609 Tokens per Sec: 5363.928711
Epoch Step: 51 / 173 Loss: 3.169468 Tokens per Sec: 5374.200195
Epoch Step: 61 / 173 Loss: 2.819545 Tokens per Sec: 5196.319824
Epoch Step: 71 / 173 Loss: 2.270027 Tokens per Sec: 5169.329102
Epoch Step: 81 / 173 Loss: 3.604080 Tokens per Sec: 5166.849609
Epoch Step: 91 / 173 Loss: 2.291704 Tokens per Sec: 5243.995605
Epoch Step: 101 / 173 Loss: 2.844262 Tokens per Sec: 5491.771973
Epoch Step: 111 / 173 Loss: 3.187993 Tokens per Sec: 5378.752930
Epoch Step: 121 / 173 Loss: 2.567594 Tokens per Sec: 5457.518066
Epoch Step: 131 / 173 Loss: 3.105230 Tokens per Sec: 5402.110840
Epoch Step: 141 / 173 Loss: 2.430011 Tokens per Sec: 5413.400879
Epoch Step: 151 / 173 Loss: 2.774643 Tokens per Sec: 5432.495117
Epoch Step: 161 / 173 Loss: 2.634814 Tokens per Sec: 5452.828613
Epoch Step: 171 / 173 Loss: 2.340947 Tokens per Sec: 5372.629883
Epoch 2
Epoch Step: 1 / 173 Loss: 3.046906 Tokens per Sec: 5383.201660
Epoch Step: 11 / 173 Loss: 2.775030 Tokens per Sec: 5289.302734
Epoch Step: 21 / 173 Loss: 3.145091 Tokens per Sec: 5464.439941
Epoch Step: 31 / 173 Loss: 3.262999 Tokens per Sec: 5299.588867
Epoch Step: 41 / 173 Loss: 2.692098 Tokens per Sec: 5253.463379
Epoch Step: 51 / 173 Loss: 2.493791 Tokens per Sec: 5355.844238
Epoch Step: 61 / 173 Loss: 2.373428 Tokens per Sec: 5366.833008
Epoch Step: 71 / 173 Loss: 2.382231 Tokens per Sec: 5321.385254
Epoch Step: 81 / 173 Loss: 2.165776 Tokens per Sec: 5320.414551
Epoch Step: 91 / 173 Loss: 2.398974 Tokens per Sec: 5415.248047
Epoch Step: 101 / 173 Loss: 3.108180 Tokens per Sec: 5418.879883
Epoch Step: 111 / 173 Loss: 2.970343 Tokens per Sec: 5426.113281
Epoch Step: 121 / 173 Loss: 3.041297 Tokens per Sec: 5489.837891
Epoch Step: 131 / 173 Loss: 2.730721 Tokens per Sec: 5499.906250
Epoch Step: 141 / 173 Loss: 3.092759 Tokens per Sec: 5386.644043
Epoch Step: 151 / 173 Loss: 3.347204 Tokens per Sec: 5446.232422
Epoch Step: 161 / 173 Loss: 3.135784 Tokens per Sec: 5486.900879
Epoch Step: 171 / 173 Loss: 2.200839 Tokens per Sec: 5430.925293
Epoch 3
Epoch Step: 1 / 173 Loss: 2.537065 Tokens per Sec: 5241.549316
Epoch Step: 11 / 173 Loss: 2.885348 Tokens per Sec: 5491.631836
Epoch Step: 21 / 173 Loss: 2.715261 Tokens per Sec: 5353.198242
Epoch Step: 31 / 173 Loss: 1.993968 Tokens per Sec: 5359.183594
Epoch Step: 41 / 173 Loss: 2.486366 Tokens per Sec: 5458.512695
Epoch Step: 51 / 173 Loss: 2.723610 Tokens per Sec: 5407.548828
Epoch Step: 61 / 173 Loss: 3.024242 Tokens per Sec: 5499.667969
Epoch Step: 71 / 173 Loss: 2.699727 Tokens per Sec: 5387.740234
Epoch Step: 81 / 173 Loss: 2.592921 Tokens per Sec: 5308.607910
Epoch Step: 91 / 173 Loss: 2.168582 Tokens per Sec: 5406.238281
Epoch Step: 101 / 173 Loss: 2.012131 Tokens per Sec: 5450.827637
Epoch Step: 111 / 173 Loss: 2.268087 Tokens per Sec: 5396.712891
Epoch Step: 121 / 173 Loss: 2.944790 Tokens per Sec: 5334.501953
Epoch Step: 131 / 173 Loss: 3.085494 Tokens per Sec: 5523.512207
Epoch Step: 141 / 173 Loss: 2.738320 Tokens per Sec: 5493.252441
Epoch Step: 151 / 173 Loss: 2.035104 Tokens per Sec: 5382.040039
Epoch Step: 161 / 173 Loss: 1.974277 Tokens per Sec: 5341.271484
Epoch Step: 171 / 173 Loss: 3.193067 Tokens per Sec: 5410.271973
Epoch 4
Epoch Step: 1 / 173 Loss: 1.825540 Tokens per Sec: 5217.999512
Epoch Step: 11 / 173 Loss: 3.421520 Tokens per Sec: 5393.149902
Epoch Step: 21 / 173 Loss: 2.215266 Tokens per Sec: 5350.408691
Epoch Step: 31 / 173 Loss: 2.951344 Tokens per Sec: 5438.401367
Epoch Step: 41 / 173 Loss: 2.082502 Tokens per Sec: 5392.200684
Epoch Step: 51 / 173 Loss: 2.186183 Tokens per Sec: 5388.921387
Epoch Step: 61 / 173 Loss: 2.657216 Tokens per Sec: 5418.250488
Epoch Step: 71 / 173 Loss: 2.987367 Tokens per Sec: 5440.932617
Epoch Step: 81 / 173 Loss: 2.509319 Tokens per Sec: 5448.625488
Epoch Step: 91 / 173 Loss: 1.797244 Tokens per Sec: 5336.614258
Epoch Step: 101 / 173 Loss: 1.732344 Tokens per Sec: 5314.483887
Epoch Step: 111 / 173 Loss: 2.998458 Tokens per Sec: 5475.841309
Epoch Step: 121 / 173 Loss: 2.282768 Tokens per Sec: 5438.596680
Epoch Step: 131 / 173 Loss: 2.918750 Tokens per Sec: 5439.017090
Epoch Step: 141 / 173 Loss: 3.526049 Tokens per Sec: 5380.893555
Epoch Step: 151 / 173 Loss: 3.005952 Tokens per Sec: 5475.314941
Epoch Step: 161 / 173 Loss: 1.661716 Tokens per Sec: 5400.414062
Epoch Step: 171 / 173 Loss: 2.433740 Tokens per Sec: 5465.196777
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10938.54it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.034221 Tokens per Sec: 5177.467285
Epoch Step: 11 / 173 Loss: 3.762698 Tokens per Sec: 5371.900391
Epoch Step: 21 / 173 Loss: 3.408211 Tokens per Sec: 5511.871094
Epoch Step: 31 / 173 Loss: 3.609703 Tokens per Sec: 5388.807129
Epoch Step: 41 / 173 Loss: 4.171097 Tokens per Sec: 5379.308105
Epoch Step: 51 / 173 Loss: 3.243740 Tokens per Sec: 5416.137207
Epoch Step: 61 / 173 Loss: 3.341512 Tokens per Sec: 5437.969238
Epoch Step: 71 / 173 Loss: 3.579024 Tokens per Sec: 5559.083984
Epoch Step: 81 / 173 Loss: 3.331212 Tokens per Sec: 5455.457520
Epoch Step: 91 / 173 Loss: 3.166682 Tokens per Sec: 5303.231934
Epoch Step: 101 / 173 Loss: 3.132595 Tokens per Sec: 5401.235352
Epoch Step: 111 / 173 Loss: 3.255707 Tokens per Sec: 5416.809570
Epoch Step: 121 / 173 Loss: 3.082389 Tokens per Sec: 5347.075684
Epoch Step: 131 / 173 Loss: 3.402941 Tokens per Sec: 5376.323242
Epoch Step: 141 / 173 Loss: 3.598588 Tokens per Sec: 5368.472656
Epoch Step: 151 / 173 Loss: 3.200123 Tokens per Sec: 5374.433594
Epoch Step: 161 / 173 Loss: 3.559597 Tokens per Sec: 5407.622559
Epoch Step: 171 / 173 Loss: 2.487004 Tokens per Sec: 5461.582520
Epoch 1
Epoch Step: 1 / 173 Loss: 3.213576 Tokens per Sec: 5431.733398
Epoch Step: 11 / 173 Loss: 2.699816 Tokens per Sec: 5336.796387
Epoch Step: 21 / 173 Loss: 3.691590 Tokens per Sec: 5399.144043
Epoch Step: 31 / 173 Loss: 3.300811 Tokens per Sec: 5342.420410
Epoch Step: 41 / 173 Loss: 3.045449 Tokens per Sec: 5402.368652
Epoch Step: 51 / 173 Loss: 2.606151 Tokens per Sec: 5371.542969
Epoch Step: 61 / 173 Loss: 2.814227 Tokens per Sec: 5388.312988
Epoch Step: 71 / 173 Loss: 2.558270 Tokens per Sec: 5389.947266
Epoch Step: 81 / 173 Loss: 2.936657 Tokens per Sec: 5435.102051
Epoch Step: 91 / 173 Loss: 2.585315 Tokens per Sec: 5468.724121
Epoch Step: 101 / 173 Loss: 3.051535 Tokens per Sec: 5362.409180
Epoch Step: 111 / 173 Loss: 3.477197 Tokens per Sec: 5391.808594
Epoch Step: 121 / 173 Loss: 3.367751 Tokens per Sec: 5514.325684
Epoch Step: 131 / 173 Loss: 3.225713 Tokens per Sec: 5416.224121
Epoch Step: 141 / 173 Loss: 2.920379 Tokens per Sec: 5435.454102
Epoch Step: 151 / 173 Loss: 3.267527 Tokens per Sec: 5471.558594
Epoch Step: 161 / 173 Loss: 3.414532 Tokens per Sec: 5495.719238
Epoch Step: 171 / 173 Loss: 2.273362 Tokens per Sec: 5357.411621
Epoch 2
Epoch Step: 1 / 173 Loss: 2.057702 Tokens per Sec: 5384.655273
Epoch Step: 11 / 173 Loss: 2.909229 Tokens per Sec: 5385.542969
Epoch Step: 21 / 173 Loss: 2.224143 Tokens per Sec: 5384.218750
Epoch Step: 31 / 173 Loss: 2.054407 Tokens per Sec: 5442.023438
Epoch Step: 41 / 173 Loss: 2.738641 Tokens per Sec: 5296.044922
Epoch Step: 51 / 173 Loss: 1.869595 Tokens per Sec: 5420.315918
Epoch Step: 61 / 173 Loss: 2.370484 Tokens per Sec: 5297.414062
Epoch Step: 71 / 173 Loss: 1.818953 Tokens per Sec: 5412.101074
Epoch Step: 81 / 173 Loss: 3.383067 Tokens per Sec: 5431.486816
Epoch Step: 91 / 173 Loss: 2.180704 Tokens per Sec: 5456.510742
Epoch Step: 101 / 173 Loss: 2.503569 Tokens per Sec: 5447.418457
Epoch Step: 111 / 173 Loss: 2.618477 Tokens per Sec: 5391.789551
Epoch Step: 121 / 173 Loss: 3.253407 Tokens per Sec: 5489.052734
Epoch Step: 131 / 173 Loss: 2.734242 Tokens per Sec: 5488.537598
Epoch Step: 141 / 173 Loss: 2.465564 Tokens per Sec: 4070.244629
Epoch Step: 151 / 173 Loss: 2.215356 Tokens per Sec: 5506.458496
Epoch Step: 161 / 173 Loss: 2.404200 Tokens per Sec: 5438.701660
Epoch Step: 171 / 173 Loss: 2.631576 Tokens per Sec: 5382.982910
Epoch 3
Epoch Step: 1 / 173 Loss: 2.185058 Tokens per Sec: 5455.574219
Epoch Step: 11 / 173 Loss: 2.772034 Tokens per Sec: 5498.979980
Epoch Step: 21 / 173 Loss: 1.296544 Tokens per Sec: 5373.786621
Epoch Step: 31 / 173 Loss: 2.013467 Tokens per Sec: 5484.466309
Epoch Step: 41 / 173 Loss: 2.354487 Tokens per Sec: 5415.204102
Epoch Step: 51 / 173 Loss: 2.166764 Tokens per Sec: 5383.121582
Epoch Step: 61 / 173 Loss: 2.017981 Tokens per Sec: 5454.762207
Epoch Step: 71 / 173 Loss: 1.354220 Tokens per Sec: 5265.392090
Epoch Step: 81 / 173 Loss: 2.951825 Tokens per Sec: 5459.701172
Epoch Step: 91 / 173 Loss: 2.203255 Tokens per Sec: 5364.461914
Epoch Step: 101 / 173 Loss: 1.894170 Tokens per Sec: 5392.530273
Epoch Step: 111 / 173 Loss: 1.601097 Tokens per Sec: 5407.582031
Epoch Step: 121 / 173 Loss: 2.462308 Tokens per Sec: 5433.416016
Epoch Step: 131 / 173 Loss: 1.819073 Tokens per Sec: 5374.836914
Epoch Step: 141 / 173 Loss: 2.727770 Tokens per Sec: 5476.442383
Epoch Step: 151 / 173 Loss: 3.235488 Tokens per Sec: 5345.680664
Epoch Step: 161 / 173 Loss: 1.881309 Tokens per Sec: 5388.512695
Epoch Step: 171 / 173 Loss: 2.006667 Tokens per Sec: 5327.841309
Epoch 4
Epoch Step: 1 / 173 Loss: 2.913820 Tokens per Sec: 5469.752441
Epoch Step: 11 / 173 Loss: 2.246065 Tokens per Sec: 5388.600586
Epoch Step: 21 / 173 Loss: 2.758710 Tokens per Sec: 5390.166016
Epoch Step: 31 / 173 Loss: 2.219267 Tokens per Sec: 5383.550293
Epoch Step: 41 / 173 Loss: 2.974216 Tokens per Sec: 5354.244141
Epoch Step: 51 / 173 Loss: 2.342198 Tokens per Sec: 5390.012207
Epoch Step: 61 / 173 Loss: 3.567517 Tokens per Sec: 5385.020996
Epoch Step: 71 / 173 Loss: 1.191687 Tokens per Sec: 5449.957520
Epoch Step: 81 / 173 Loss: 2.572480 Tokens per Sec: 5513.799316
Epoch Step: 91 / 173 Loss: 2.474531 Tokens per Sec: 5066.095215
Epoch Step: 101 / 173 Loss: 3.187842 Tokens per Sec: 5470.566406
Epoch Step: 111 / 173 Loss: 1.372908 Tokens per Sec: 5437.832520
Epoch Step: 121 / 173 Loss: 2.042761 Tokens per Sec: 5433.416016
Epoch Step: 131 / 173 Loss: 2.088945 Tokens per Sec: 5358.925781
Epoch Step: 141 / 173 Loss: 2.049259 Tokens per Sec: 5258.342285
Epoch Step: 151 / 173 Loss: 1.889085 Tokens per Sec: 5343.694824
Epoch Step: 161 / 173 Loss: 2.961245 Tokens per Sec: 5462.298828
Epoch Step: 171 / 173 Loss: 1.941023 Tokens per Sec: 5400.877441
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11035.08it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 5.902288 Tokens per Sec: 4997.842285
Epoch Step: 11 / 173 Loss: 3.919609 Tokens per Sec: 5440.704102
Epoch Step: 21 / 173 Loss: 3.433182 Tokens per Sec: 5499.483398
Epoch Step: 31 / 173 Loss: 3.446549 Tokens per Sec: 5427.175781
Epoch Step: 41 / 173 Loss: 3.952106 Tokens per Sec: 5490.275391
Epoch Step: 51 / 173 Loss: 3.810819 Tokens per Sec: 5440.718750
Epoch Step: 61 / 173 Loss: 3.637247 Tokens per Sec: 5335.694336
Epoch Step: 71 / 173 Loss: 3.989309 Tokens per Sec: 5364.564453
Epoch Step: 81 / 173 Loss: 3.306858 Tokens per Sec: 5328.187988
Epoch Step: 91 / 173 Loss: 2.999700 Tokens per Sec: 5391.858887
Epoch Step: 101 / 173 Loss: 3.135541 Tokens per Sec: 5214.984863
Epoch Step: 111 / 173 Loss: 2.911764 Tokens per Sec: 5290.290527
Epoch Step: 121 / 173 Loss: 2.809740 Tokens per Sec: 5395.816895
Epoch Step: 131 / 173 Loss: 3.831865 Tokens per Sec: 5484.931641
Epoch Step: 141 / 173 Loss: 3.470033 Tokens per Sec: 5371.473145
Epoch Step: 151 / 173 Loss: 2.556715 Tokens per Sec: 5421.274414
Epoch Step: 161 / 173 Loss: 3.348847 Tokens per Sec: 5466.077148
Epoch Step: 171 / 173 Loss: 3.220750 Tokens per Sec: 5368.379883
Epoch 1
Epoch Step: 1 / 173 Loss: 3.397061 Tokens per Sec: 5508.731445
Epoch Step: 11 / 173 Loss: 2.940862 Tokens per Sec: 5446.432129
Epoch Step: 21 / 173 Loss: 2.833503 Tokens per Sec: 5466.071777
Epoch Step: 31 / 173 Loss: 2.814728 Tokens per Sec: 5286.794922
Epoch Step: 41 / 173 Loss: 2.970178 Tokens per Sec: 5494.963379
Epoch Step: 51 / 173 Loss: 3.462730 Tokens per Sec: 5400.925293
Epoch Step: 61 / 173 Loss: 3.163472 Tokens per Sec: 5369.542480
Epoch Step: 71 / 173 Loss: 3.117854 Tokens per Sec: 5360.658203
Epoch Step: 81 / 173 Loss: 2.657325 Tokens per Sec: 5435.204102
Epoch Step: 91 / 173 Loss: 2.698990 Tokens per Sec: 5428.332031
Epoch Step: 101 / 173 Loss: 3.143754 Tokens per Sec: 5353.580566
Epoch Step: 111 / 173 Loss: 3.028540 Tokens per Sec: 5305.511719
Epoch Step: 121 / 173 Loss: 2.939984 Tokens per Sec: 5299.414551
Epoch Step: 131 / 173 Loss: 3.115092 Tokens per Sec: 5432.273438
Epoch Step: 141 / 173 Loss: 3.063841 Tokens per Sec: 5393.729004
Epoch Step: 151 / 173 Loss: 2.965851 Tokens per Sec: 5324.430176
Epoch Step: 161 / 173 Loss: 2.556489 Tokens per Sec: 5490.374512
Epoch Step: 171 / 173 Loss: 3.885424 Tokens per Sec: 5450.607422
Epoch 2
Epoch Step: 1 / 173 Loss: 3.398124 Tokens per Sec: 5058.665039
Epoch Step: 11 / 173 Loss: 2.976795 Tokens per Sec: 5401.018555
Epoch Step: 21 / 173 Loss: 3.017091 Tokens per Sec: 5279.209473
Epoch Step: 31 / 173 Loss: 3.374076 Tokens per Sec: 5459.853027
Epoch Step: 41 / 173 Loss: 3.154737 Tokens per Sec: 5391.904785
Epoch Step: 51 / 173 Loss: 3.188969 Tokens per Sec: 5437.784180
Epoch Step: 61 / 173 Loss: 2.620929 Tokens per Sec: 5352.877930
Epoch Step: 71 / 173 Loss: 2.895291 Tokens per Sec: 5312.893555
Epoch Step: 81 / 173 Loss: 2.463004 Tokens per Sec: 5474.497559
Epoch Step: 91 / 173 Loss: 3.105855 Tokens per Sec: 5457.710938
Epoch Step: 101 / 173 Loss: 3.722231 Tokens per Sec: 5424.635254
Epoch Step: 111 / 173 Loss: 3.800005 Tokens per Sec: 5429.026367
Epoch Step: 121 / 173 Loss: 2.728774 Tokens per Sec: 5410.558594
Epoch Step: 131 / 173 Loss: 2.780694 Tokens per Sec: 5398.914062
Epoch Step: 141 / 173 Loss: 2.422420 Tokens per Sec: 5160.390137
Epoch Step: 151 / 173 Loss: 3.171493 Tokens per Sec: 5403.084961
Epoch Step: 161 / 173 Loss: 3.162101 Tokens per Sec: 5373.929199
Epoch Step: 171 / 173 Loss: 3.034839 Tokens per Sec: 5351.590332
Epoch 3
Epoch Step: 1 / 173 Loss: 2.962698 Tokens per Sec: 5286.892578
Epoch Step: 11 / 173 Loss: 3.393288 Tokens per Sec: 5408.359375
Epoch Step: 21 / 173 Loss: 2.943214 Tokens per Sec: 5433.196289
Epoch Step: 31 / 173 Loss: 3.338688 Tokens per Sec: 5356.228027
Epoch Step: 41 / 173 Loss: 2.579251 Tokens per Sec: 5353.277344
Epoch Step: 51 / 173 Loss: 2.400808 Tokens per Sec: 5475.942383
Epoch Step: 61 / 173 Loss: 3.272899 Tokens per Sec: 5463.387695
Epoch Step: 71 / 173 Loss: 3.006759 Tokens per Sec: 5439.349609
Epoch Step: 81 / 173 Loss: 2.434243 Tokens per Sec: 5377.340820
Epoch Step: 91 / 173 Loss: 2.396945 Tokens per Sec: 5337.070312
Epoch Step: 101 / 173 Loss: 2.835207 Tokens per Sec: 5220.925781
Epoch Step: 111 / 173 Loss: 3.234967 Tokens per Sec: 5427.480469
Epoch Step: 121 / 173 Loss: 3.562751 Tokens per Sec: 5419.899902
Epoch Step: 131 / 173 Loss: 3.190746 Tokens per Sec: 5450.746094
Epoch Step: 141 / 173 Loss: 3.137684 Tokens per Sec: 5287.072266
Epoch Step: 151 / 173 Loss: 3.290076 Tokens per Sec: 5419.299316
Epoch Step: 161 / 173 Loss: 2.360362 Tokens per Sec: 5432.496094
Epoch Step: 171 / 173 Loss: 3.032686 Tokens per Sec: 5400.801270
Epoch 4
Epoch Step: 1 / 173 Loss: 2.891484 Tokens per Sec: 5313.309570
Epoch Step: 11 / 173 Loss: 3.749772 Tokens per Sec: 5387.872070
Epoch Step: 21 / 173 Loss: 3.496094 Tokens per Sec: 5461.590332
Epoch Step: 31 / 173 Loss: 2.228273 Tokens per Sec: 5416.019531
Epoch Step: 41 / 173 Loss: 2.293293 Tokens per Sec: 5414.128418
Epoch Step: 51 / 173 Loss: 3.076113 Tokens per Sec: 5360.198730
Epoch Step: 61 / 173 Loss: 2.601609 Tokens per Sec: 5324.231445
Epoch Step: 71 / 173 Loss: 2.877290 Tokens per Sec: 5420.567871
Epoch Step: 81 / 173 Loss: 2.792432 Tokens per Sec: 5399.882812
Epoch Step: 91 / 173 Loss: 3.110536 Tokens per Sec: 5391.354980
Epoch Step: 101 / 173 Loss: 2.561744 Tokens per Sec: 5368.819336
Epoch Step: 111 / 173 Loss: 3.501500 Tokens per Sec: 5451.643066
Epoch Step: 121 / 173 Loss: 2.811298 Tokens per Sec: 5450.315918
Epoch Step: 131 / 173 Loss: 2.978994 Tokens per Sec: 5507.096680
Epoch Step: 141 / 173 Loss: 2.950894 Tokens per Sec: 5460.299316
Epoch Step: 151 / 173 Loss: 2.863884 Tokens per Sec: 5402.215332
Epoch Step: 161 / 173 Loss: 3.079976 Tokens per Sec: 5477.455078
Epoch Step: 171 / 173 Loss: 3.127177 Tokens per Sec: 5327.201660
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  18%|█▊        | 27/154 [00:00<00:00, 269.11it/s]Loading hierarchy for column coarse_log_cluster_path:  36%|███▋      | 56/154 [00:00<00:00, 277.05it/s]Loading hierarchy for column coarse_log_cluster_path:  55%|█████▌    | 85/154 [00:00<00:00, 280.87it/s]Loading hierarchy for column coarse_log_cluster_path:  75%|███████▍  | 115/154 [00:00<00:00, 284.56it/s]Loading hierarchy for column coarse_log_cluster_path:  94%|█████████▍| 145/154 [00:00<00:00, 287.26it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 284.20it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 14738.73it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 3066it [00:00, 39494.17it/s]
INFO:root:Built hierarchy with 2095 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/1258 [00:00<?, ?it/s]Initializing gram_embedding connections:  10%|█         | 126/1258 [00:00<00:00, 1256.84it/s]Initializing gram_embedding connections:  20%|██        | 252/1258 [00:00<00:01, 643.99it/s] Initializing gram_embedding connections:  26%|██▋       | 332/1258 [00:00<00:02, 460.49it/s]Initializing gram_embedding connections:  31%|███       | 390/1258 [00:00<00:02, 368.90it/s]Initializing gram_embedding connections:  34%|███▍      | 434/1258 [00:01<00:02, 314.44it/s]Initializing gram_embedding connections:  37%|███▋      | 470/1258 [00:01<00:02, 279.59it/s]Initializing gram_embedding connections:  40%|███▉      | 501/1258 [00:01<00:03, 252.13it/s]Initializing gram_embedding connections:  42%|████▏     | 528/1258 [00:01<00:03, 229.77it/s]Initializing gram_embedding connections:  44%|████▍     | 552/1258 [00:01<00:03, 212.31it/s]Initializing gram_embedding connections:  46%|████▌     | 574/1258 [00:01<00:03, 198.85it/s]Initializing gram_embedding connections:  47%|████▋     | 594/1258 [00:02<00:03, 187.96it/s]Initializing gram_embedding connections:  49%|████▊     | 613/1258 [00:02<00:03, 178.90it/s]Initializing gram_embedding connections:  50%|█████     | 631/1258 [00:02<00:03, 170.24it/s]Initializing gram_embedding connections:  52%|█████▏    | 648/1258 [00:02<00:03, 162.94it/s]Initializing gram_embedding connections:  53%|█████▎    | 664/1258 [00:02<00:03, 156.97it/s]Initializing gram_embedding connections:  54%|█████▍    | 680/1258 [00:02<00:03, 150.88it/s]Initializing gram_embedding connections:  55%|█████▌    | 695/1258 [00:02<00:03, 145.00it/s]Initializing gram_embedding connections:  56%|█████▋    | 710/1258 [00:02<00:03, 139.79it/s]Initializing gram_embedding connections:  58%|█████▊    | 724/1258 [00:02<00:03, 135.47it/s]Initializing gram_embedding connections:  59%|█████▊    | 738/1258 [00:03<00:03, 132.19it/s]Initializing gram_embedding connections:  60%|█████▉    | 752/1258 [00:03<00:03, 129.46it/s]Initializing gram_embedding connections:  61%|██████    | 765/1258 [00:03<00:03, 126.94it/s]Initializing gram_embedding connections:  62%|██████▏   | 778/1258 [00:03<00:03, 124.36it/s]Initializing gram_embedding connections:  63%|██████▎   | 791/1258 [00:03<00:03, 121.82it/s]Initializing gram_embedding connections:  64%|██████▍   | 804/1258 [00:03<00:03, 119.61it/s]Initializing gram_embedding connections:  65%|██████▍   | 816/1258 [00:03<00:03, 117.73it/s]Initializing gram_embedding connections:  66%|██████▌   | 828/1258 [00:03<00:03, 115.93it/s]Initializing gram_embedding connections:  67%|██████▋   | 840/1258 [00:03<00:03, 114.24it/s]Initializing gram_embedding connections:  68%|██████▊   | 852/1258 [00:04<00:03, 112.85it/s]Initializing gram_embedding connections:  69%|██████▊   | 864/1258 [00:04<00:03, 111.45it/s]Initializing gram_embedding connections:  70%|██████▉   | 876/1258 [00:04<00:03, 110.12it/s]Initializing gram_embedding connections:  71%|███████   | 888/1258 [00:04<00:03, 108.64it/s]Initializing gram_embedding connections:  71%|███████▏  | 899/1258 [00:04<00:03, 107.26it/s]Initializing gram_embedding connections:  72%|███████▏  | 910/1258 [00:04<00:03, 106.08it/s]Initializing gram_embedding connections:  73%|███████▎  | 921/1258 [00:04<00:03, 105.02it/s]Initializing gram_embedding connections:  74%|███████▍  | 932/1258 [00:04<00:03, 104.01it/s]Initializing gram_embedding connections:  75%|███████▍  | 943/1258 [00:04<00:03, 102.90it/s]Initializing gram_embedding connections:  76%|███████▌  | 954/1258 [00:05<00:02, 101.99it/s]Initializing gram_embedding connections:  77%|███████▋  | 965/1258 [00:05<00:02, 100.96it/s]Initializing gram_embedding connections:  78%|███████▊  | 976/1258 [00:05<00:02, 100.01it/s]Initializing gram_embedding connections:  78%|███████▊  | 987/1258 [00:05<00:02, 98.90it/s] Initializing gram_embedding connections:  79%|███████▉  | 997/1258 [00:05<00:02, 98.18it/s]Initializing gram_embedding connections:  80%|████████  | 1007/1258 [00:05<00:02, 97.49it/s]Initializing gram_embedding connections:  81%|████████  | 1017/1258 [00:05<00:02, 96.56it/s]Initializing gram_embedding connections:  82%|████████▏ | 1027/1258 [00:05<00:02, 95.65it/s]Initializing gram_embedding connections:  82%|████████▏ | 1037/1258 [00:05<00:02, 94.55it/s]Initializing gram_embedding connections:  83%|████████▎ | 1047/1258 [00:06<00:02, 93.55it/s]Initializing gram_embedding connections:  84%|████████▍ | 1057/1258 [00:06<00:02, 92.54it/s]Initializing gram_embedding connections:  85%|████████▍ | 1067/1258 [00:06<00:02, 91.56it/s]Initializing gram_embedding connections:  86%|████████▌ | 1077/1258 [00:06<00:01, 90.84it/s]Initializing gram_embedding connections:  86%|████████▋ | 1087/1258 [00:06<00:01, 90.13it/s]Initializing gram_embedding connections:  87%|████████▋ | 1097/1258 [00:06<00:01, 89.38it/s]Initializing gram_embedding connections:  88%|████████▊ | 1106/1258 [00:06<00:01, 88.84it/s]Initializing gram_embedding connections:  89%|████████▊ | 1115/1258 [00:06<00:01, 88.33it/s]Initializing gram_embedding connections:  89%|████████▉ | 1124/1258 [00:06<00:01, 87.80it/s]Initializing gram_embedding connections:  90%|█████████ | 1133/1258 [00:06<00:01, 86.90it/s]Initializing gram_embedding connections:  91%|█████████ | 1142/1258 [00:07<00:01, 86.21it/s]Initializing gram_embedding connections:  91%|█████████▏| 1151/1258 [00:07<00:01, 85.51it/s]Initializing gram_embedding connections:  92%|█████████▏| 1160/1258 [00:07<00:01, 84.85it/s]Initializing gram_embedding connections:  93%|█████████▎| 1169/1258 [00:07<00:01, 84.23it/s]Initializing gram_embedding connections:  94%|█████████▎| 1178/1258 [00:07<00:00, 83.75it/s]Initializing gram_embedding connections:  94%|█████████▍| 1187/1258 [00:07<00:00, 83.24it/s]Initializing gram_embedding connections:  95%|█████████▌| 1196/1258 [00:07<00:00, 82.61it/s]Initializing gram_embedding connections:  96%|█████████▌| 1205/1258 [00:07<00:00, 82.04it/s]Initializing gram_embedding connections:  97%|█████████▋| 1214/1258 [00:07<00:00, 81.49it/s]Initializing gram_embedding connections:  97%|█████████▋| 1223/1258 [00:08<00:00, 80.83it/s]Initializing gram_embedding connections:  98%|█████████▊| 1232/1258 [00:08<00:00, 80.35it/s]Initializing gram_embedding connections:  99%|█████████▊| 1241/1258 [00:08<00:00, 79.76it/s]Initializing gram_embedding connections:  99%|█████████▉| 1249/1258 [00:08<00:00, 79.31it/s]Initializing gram_embedding connections: 100%|█████████▉| 1257/1258 [00:08<00:00, 78.67it/s]Initializing gram_embedding connections: 100%|██████████| 1258/1258 [00:08<00:00, 147.36it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:01,  1.09s/it]Calculating percentile frequencies...: 7it [00:01,  6.41it/s]
2023-05-24 20:04:23.430073: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:04:55.594421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:04:55.851944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:04:55.902572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:04:56.215172: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f9cac135c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:04:56.215215: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:04:56.215227: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:04:56.218754: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:04:56.300312: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 33s 33s/step - loss: 0.2156 - categorical_accuracy: 0.0059 - top_5_categorical_accuracy: 0.0332 - top_10_categorical_accuracy: 0.0801 - top_20_categorical_accuracy: 0.1680 - top_5_categorical_accuracy_cp0: 0.0577 - top_5_categorical_accuracy_cp1: 0.0357 - top_5_categorical_accuracy_cp2: 0.0207 - top_5_categorical_accuracy_cp3: 0.0351 - top_5_categorical_accuracy_cp4: 0.0246 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1111 - top_5_categorical_accuracy_p4: 0.0272 - top_10_categorical_accuracy_cp0: 0.1346 - top_10_categorical_accuracy_cp1: 0.0714 - top_10_categorical_accuracy_cp2: 0.0828 - top_10_categorical_accuracy_cp3: 0.0526 - top_10_categorical_accuracy_cp4: 0.0492 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1556 - top_10_categorical_accuracy_p4: 0.0771 - top_20_categorical_accuracy_cp0: 0.2596 - top_20_categorical_accuracy_cp1: 0.1905 - top_20_categorical_accuracy_cp2: 0.1586 - top_20_categorical_accuracy_cp3: 0.1228 - top_20_categorical_accuracy_cp4: 0.1066 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.3111 - top_20_categorical_accuracy_p4: 0.1587      3/Unknown - 33s 41ms/step - loss: 0.2120 - categorical_accuracy: 0.0456 - top_5_categorical_accuracy: 0.1517 - top_10_categorical_accuracy: 0.2344 - top_20_categorical_accuracy: 0.3581 - top_5_categorical_accuracy_cp0: 0.0586 - top_5_categorical_accuracy_cp1: 0.1058 - top_5_categorical_accuracy_cp2: 0.1618 - top_5_categorical_accuracy_cp3: 0.0556 - top_5_categorical_accuracy_cp4: 0.2883 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0625 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1037 - top_5_categorical_accuracy_p4: 0.1637 - top_10_categorical_accuracy_cp0: 0.1140 - top_10_categorical_accuracy_cp1: 0.1825 - top_10_categorical_accuracy_cp2: 0.2770 - top_10_categorical_accuracy_cp3: 0.0864 - top_10_categorical_accuracy_cp4: 0.3844 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1250 - top_10_categorical_accuracy_p2: 0.0208 - top_10_categorical_accuracy_p3: 0.1407 - top_10_categorical_accuracy_p4: 0.2538 - top_20_categorical_accuracy_cp0: 0.2378 - top_20_categorical_accuracy_cp1: 0.2810 - top_20_categorical_accuracy_cp2: 0.4363 - top_20_categorical_accuracy_cp3: 0.1975 - top_20_categorical_accuracy_cp4: 0.4935 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1875 - top_20_categorical_accuracy_p2: 0.1458 - top_20_categorical_accuracy_p3: 0.2963 - top_20_categorical_accuracy_p4: 0.3754                     5/Unknown - 33s 44ms/step - loss: 0.2083 - categorical_accuracy: 0.0781 - top_5_categorical_accuracy: 0.2617 - top_10_categorical_accuracy: 0.3570 - top_20_categorical_accuracy: 0.4766 - top_5_categorical_accuracy_cp0: 0.0639 - top_5_categorical_accuracy_cp1: 0.1663 - top_5_categorical_accuracy_cp2: 0.3242 - top_5_categorical_accuracy_cp3: 0.1018 - top_5_categorical_accuracy_cp4: 0.5113 - top_5_categorical_accuracy_p0: 0.0833 - top_5_categorical_accuracy_p1: 0.0741 - top_5_categorical_accuracy_p2: 0.0128 - top_5_categorical_accuracy_p3: 0.0879 - top_5_categorical_accuracy_p4: 0.2926 - top_10_categorical_accuracy_cp0: 0.1165 - top_10_categorical_accuracy_cp1: 0.2921 - top_10_categorical_accuracy_cp2: 0.4419 - top_10_categorical_accuracy_cp3: 0.1930 - top_10_categorical_accuracy_cp4: 0.5984 - top_10_categorical_accuracy_p0: 0.0833 - top_10_categorical_accuracy_p1: 0.1111 - top_10_categorical_accuracy_p2: 0.0513 - top_10_categorical_accuracy_p3: 0.1255 - top_10_categorical_accuracy_p4: 0.3975 - top_20_categorical_accuracy_cp0: 0.2444 - top_20_categorical_accuracy_cp1: 0.4286 - top_20_categorical_accuracy_cp2: 0.5780 - top_20_categorical_accuracy_cp3: 0.3368 - top_20_categorical_accuracy_cp4: 0.6694 - top_20_categorical_accuracy_p0: 0.0833 - top_20_categorical_accuracy_p1: 0.1481 - top_20_categorical_accuracy_p2: 0.1667 - top_20_categorical_accuracy_p3: 0.2636 - top_20_categorical_accuracy_p4: 0.5168                      6/Unknown - 33s 48ms/step - loss: 0.2060 - categorical_accuracy: 0.0902 - top_5_categorical_accuracy: 0.3034 - top_10_categorical_accuracy: 0.3997 - top_20_categorical_accuracy: 0.5133 - top_5_categorical_accuracy_cp0: 0.0639 - top_5_categorical_accuracy_cp1: 0.1830 - top_5_categorical_accuracy_cp2: 0.3835 - top_5_categorical_accuracy_cp3: 0.1276 - top_5_categorical_accuracy_cp4: 0.5858 - top_5_categorical_accuracy_p0: 0.0769 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0116 - top_5_categorical_accuracy_p3: 0.0877 - top_5_categorical_accuracy_p4: 0.3401 - top_10_categorical_accuracy_cp0: 0.1262 - top_10_categorical_accuracy_cp1: 0.3134 - top_10_categorical_accuracy_cp2: 0.5018 - top_10_categorical_accuracy_cp3: 0.2226 - top_10_categorical_accuracy_cp4: 0.6622 - top_10_categorical_accuracy_p0: 0.0769 - top_10_categorical_accuracy_p1: 0.0909 - top_10_categorical_accuracy_p2: 0.0698 - top_10_categorical_accuracy_p3: 0.1368 - top_10_categorical_accuracy_p4: 0.4441 - top_20_categorical_accuracy_cp0: 0.2492 - top_20_categorical_accuracy_cp1: 0.4547 - top_20_categorical_accuracy_cp2: 0.6227 - top_20_categorical_accuracy_cp3: 0.3739 - top_20_categorical_accuracy_cp4: 0.7225 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1860 - top_20_categorical_accuracy_p3: 0.2702 - top_20_categorical_accuracy_p4: 0.55712023-05-24 20:04:57.396455: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.210950
7/7 [==============================] - 53s 3s/step - loss: 0.2059 - categorical_accuracy: 0.0909 - top_5_categorical_accuracy: 0.3057 - top_10_categorical_accuracy: 0.4024 - top_20_categorical_accuracy: 0.5155 - top_5_categorical_accuracy_cp0: 0.0634 - top_5_categorical_accuracy_cp1: 0.1828 - top_5_categorical_accuracy_cp2: 0.3869 - top_5_categorical_accuracy_cp3: 0.1324 - top_5_categorical_accuracy_cp4: 0.5896 - top_5_categorical_accuracy_p0: 0.0714 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0116 - top_5_categorical_accuracy_p3: 0.0868 - top_5_categorical_accuracy_p4: 0.3429 - top_10_categorical_accuracy_cp0: 0.1284 - top_10_categorical_accuracy_cp1: 0.3154 - top_10_categorical_accuracy_cp2: 0.5036 - top_10_categorical_accuracy_cp3: 0.2265 - top_10_categorical_accuracy_cp4: 0.6653 - top_10_categorical_accuracy_p0: 0.1429 - top_10_categorical_accuracy_p1: 0.0909 - top_10_categorical_accuracy_p2: 0.0698 - top_10_categorical_accuracy_p3: 0.1389 - top_10_categorical_accuracy_p4: 0.4465 - top_20_categorical_accuracy_cp0: 0.2520 - top_20_categorical_accuracy_cp1: 0.4570 - top_20_categorical_accuracy_cp2: 0.6229 - top_20_categorical_accuracy_cp3: 0.3765 - top_20_categorical_accuracy_cp4: 0.7251 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1860 - top_20_categorical_accuracy_p3: 0.2743 - top_20_categorical_accuracy_p4: 0.5587 - val_loss: 0.2110 - val_categorical_accuracy: 0.0853 - val_top_5_categorical_accuracy: 0.3118 - val_top_10_categorical_accuracy: 0.4765 - val_top_20_categorical_accuracy: 0.6235 - val_top_5_categorical_accuracy_cp0: 0.0675 - val_top_5_categorical_accuracy_cp1: 0.5522 - val_top_5_categorical_accuracy_cp2: 0.2308 - val_top_5_categorical_accuracy_cp3: 0.6145 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.2000 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0732 - val_top_5_categorical_accuracy_p4: 0.5367 - val_top_10_categorical_accuracy_cp0: 0.2270 - val_top_10_categorical_accuracy_cp1: 0.6716 - val_top_10_categorical_accuracy_cp2: 0.4615 - val_top_10_categorical_accuracy_cp3: 0.8072 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.3000 - val_top_10_categorical_accuracy_p1: 0.2222 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.2602 - val_top_10_categorical_accuracy_p4: 0.7062 - val_top_20_categorical_accuracy_cp0: 0.3742 - val_top_20_categorical_accuracy_cp1: 0.8060 - val_top_20_categorical_accuracy_cp2: 0.6538 - val_top_20_categorical_accuracy_cp3: 0.9518 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.4000 - val_top_20_categorical_accuracy_p1: 0.4444 - val_top_20_categorical_accuracy_p2: 0.0476 - val_top_20_categorical_accuracy_p3: 0.4228 - val_top_20_categorical_accuracy_p4: 0.8531
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1827 - categorical_accuracy: 0.1738 - top_5_categorical_accuracy: 0.6172 - top_10_categorical_accuracy: 0.6875 - top_20_categorical_accuracy: 0.7852 - top_5_categorical_accuracy_cp0: 0.1200 - top_5_categorical_accuracy_cp1: 0.4624 - top_5_categorical_accuracy_cp2: 0.7899 - top_5_categorical_accuracy_cp3: 0.5357 - top_5_categorical_accuracy_cp4: 0.9760 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1591 - top_5_categorical_accuracy_p4: 0.6928 - top_10_categorical_accuracy_cp0: 0.2300 - top_10_categorical_accuracy_cp1: 0.5699 - top_10_categorical_accuracy_cp2: 0.8478 - top_10_categorical_accuracy_cp3: 0.6607 - top_10_categorical_accuracy_cp4: 0.9760 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.2000 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2955 - top_10_categorical_accuracy_p4: 0.7578 - top_20_categorical_accuracy_cp0: 0.4200 - top_20_categorical_accuracy_cp1: 0.7419 - top_20_categorical_accuracy_cp2: 0.9130 - top_20_categorical_accuracy_cp3: 0.7679 - top_20_categorical_accuracy_cp4: 0.9760 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.2000 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.4545 - top_20_categorical_accuracy_p4: 0.84983/7 [===========>..................] - ETA: 0s - loss: 0.1790 - categorical_accuracy: 0.1699 - top_5_categorical_accuracy: 0.5879 - top_10_categorical_accuracy: 0.6706 - top_20_categorical_accuracy: 0.7780 - top_5_categorical_accuracy_cp0: 0.1009 - top_5_categorical_accuracy_cp1: 0.4308 - top_5_categorical_accuracy_cp2: 0.7612 - top_5_categorical_accuracy_cp3: 0.5587 - top_5_categorical_accuracy_cp4: 0.9804 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0526 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.6777 - top_10_categorical_accuracy_cp0: 0.1869 - top_10_categorical_accuracy_cp1: 0.6192 - top_10_categorical_accuracy_cp2: 0.8184 - top_10_categorical_accuracy_cp3: 0.6983 - top_10_categorical_accuracy_cp4: 0.9832 - top_10_categorical_accuracy_p0: 0.1111 - top_10_categorical_accuracy_p1: 0.2105 - top_10_categorical_accuracy_p2: 0.0566 - top_10_categorical_accuracy_p3: 0.2237 - top_10_categorical_accuracy_p4: 0.7583 - top_20_categorical_accuracy_cp0: 0.3561 - top_20_categorical_accuracy_cp1: 0.7962 - top_20_categorical_accuracy_cp2: 0.9005 - top_20_categorical_accuracy_cp3: 0.8603 - top_20_categorical_accuracy_cp4: 0.9832 - top_20_categorical_accuracy_p0: 0.2222 - top_20_categorical_accuracy_p1: 0.2632 - top_20_categorical_accuracy_p2: 0.1509 - top_20_categorical_accuracy_p3: 0.3684 - top_20_categorical_accuracy_p4: 0.8626            5/7 [====================>.........] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.1773 - top_5_categorical_accuracy: 0.6156 - top_10_categorical_accuracy: 0.7008 - top_20_categorical_accuracy: 0.7965 - top_5_categorical_accuracy_cp0: 0.0937 - top_5_categorical_accuracy_cp1: 0.4464 - top_5_categorical_accuracy_cp2: 0.7974 - top_5_categorical_accuracy_cp3: 0.6014 - top_5_categorical_accuracy_cp4: 0.9823 - top_5_categorical_accuracy_p0: 0.0769 - top_5_categorical_accuracy_p1: 0.0345 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1186 - top_5_categorical_accuracy_p4: 0.7005 - top_10_categorical_accuracy_cp0: 0.1836 - top_10_categorical_accuracy_cp1: 0.6518 - top_10_categorical_accuracy_cp2: 0.8557 - top_10_categorical_accuracy_cp3: 0.7331 - top_10_categorical_accuracy_cp4: 0.9855 - top_10_categorical_accuracy_p0: 0.1538 - top_10_categorical_accuracy_p1: 0.1379 - top_10_categorical_accuracy_p2: 0.0400 - top_10_categorical_accuracy_p3: 0.2119 - top_10_categorical_accuracy_p4: 0.7861 - top_20_categorical_accuracy_cp0: 0.3461 - top_20_categorical_accuracy_cp1: 0.8125 - top_20_categorical_accuracy_cp2: 0.9169 - top_20_categorical_accuracy_cp3: 0.8932 - top_20_categorical_accuracy_cp4: 0.9871 - top_20_categorical_accuracy_p0: 0.2308 - top_20_categorical_accuracy_p1: 0.2069 - top_20_categorical_accuracy_p2: 0.1333 - top_20_categorical_accuracy_p3: 0.3602 - top_20_categorical_accuracy_p4: 0.8768    7/7 [==============================] - ETA: 0s - loss: 0.1688 - categorical_accuracy: 0.1794 - top_5_categorical_accuracy: 0.6247 - top_10_categorical_accuracy: 0.7139 - top_20_categorical_accuracy: 0.8051 - top_5_categorical_accuracy_cp0: 0.0935 - top_5_categorical_accuracy_cp1: 0.4642 - top_5_categorical_accuracy_cp2: 0.8078 - top_5_categorical_accuracy_cp3: 0.6353 - top_5_categorical_accuracy_cp4: 0.9841 - top_5_categorical_accuracy_p0: 0.0714 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.7082 - top_10_categorical_accuracy_cp0: 0.1949 - top_10_categorical_accuracy_cp1: 0.6792 - top_10_categorical_accuracy_cp2: 0.8637 - top_10_categorical_accuracy_cp3: 0.7676 - top_10_categorical_accuracy_cp4: 0.9867 - top_10_categorical_accuracy_p0: 0.1429 - top_10_categorical_accuracy_p1: 0.1515 - top_10_categorical_accuracy_p2: 0.0465 - top_10_categorical_accuracy_p3: 0.2188 - top_10_categorical_accuracy_p4: 0.7984 - top_20_categorical_accuracy_cp0: 0.3518 - top_20_categorical_accuracy_cp1: 0.8333 - top_20_categorical_accuracy_cp2: 0.9246 - top_20_categorical_accuracy_cp3: 0.9059 - top_20_categorical_accuracy_cp4: 0.9880 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.2121 - top_20_categorical_accuracy_p2: 0.1395 - top_20_categorical_accuracy_p3: 0.3576 - top_20_categorical_accuracy_p4: 0.8845DEBUG:root:Model metric val_loss improved from 0.210950 to 0.206614
7/7 [==============================] - 1s 126ms/step - loss: 0.1688 - categorical_accuracy: 0.1794 - top_5_categorical_accuracy: 0.6247 - top_10_categorical_accuracy: 0.7139 - top_20_categorical_accuracy: 0.8051 - top_5_categorical_accuracy_cp0: 0.0935 - top_5_categorical_accuracy_cp1: 0.4642 - top_5_categorical_accuracy_cp2: 0.8078 - top_5_categorical_accuracy_cp3: 0.6353 - top_5_categorical_accuracy_cp4: 0.9841 - top_5_categorical_accuracy_p0: 0.0714 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.7082 - top_10_categorical_accuracy_cp0: 0.1949 - top_10_categorical_accuracy_cp1: 0.6792 - top_10_categorical_accuracy_cp2: 0.8637 - top_10_categorical_accuracy_cp3: 0.7676 - top_10_categorical_accuracy_cp4: 0.9867 - top_10_categorical_accuracy_p0: 0.1429 - top_10_categorical_accuracy_p1: 0.1515 - top_10_categorical_accuracy_p2: 0.0465 - top_10_categorical_accuracy_p3: 0.2188 - top_10_categorical_accuracy_p4: 0.7984 - top_20_categorical_accuracy_cp0: 0.3518 - top_20_categorical_accuracy_cp1: 0.8333 - top_20_categorical_accuracy_cp2: 0.9246 - top_20_categorical_accuracy_cp3: 0.9059 - top_20_categorical_accuracy_cp4: 0.9880 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.2121 - top_20_categorical_accuracy_p2: 0.1395 - top_20_categorical_accuracy_p3: 0.3576 - top_20_categorical_accuracy_p4: 0.8845 - val_loss: 0.2066 - val_categorical_accuracy: 0.0235 - val_top_5_categorical_accuracy: 0.2912 - val_top_10_categorical_accuracy: 0.5206 - val_top_20_categorical_accuracy: 0.6441 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.5075 - val_top_5_categorical_accuracy_cp2: 0.3077 - val_top_5_categorical_accuracy_cp3: 0.6747 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5593 - val_top_10_categorical_accuracy_cp0: 0.1288 - val_top_10_categorical_accuracy_cp1: 0.7761 - val_top_10_categorical_accuracy_cp2: 0.7692 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.1000 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1626 - val_top_10_categorical_accuracy_p4: 0.8814 - val_top_20_categorical_accuracy_cp0: 0.3436 - val_top_20_categorical_accuracy_cp1: 0.8060 - val_top_20_categorical_accuracy_cp2: 0.9615 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.4000 - val_top_20_categorical_accuracy_p1: 0.3333 - val_top_20_categorical_accuracy_p2: 0.0476 - val_top_20_categorical_accuracy_p3: 0.3902 - val_top_20_categorical_accuracy_p4: 0.9209
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1537 - categorical_accuracy: 0.1836 - top_5_categorical_accuracy: 0.6543 - top_10_categorical_accuracy: 0.7891 - top_20_categorical_accuracy: 0.8750 - top_5_categorical_accuracy_cp0: 0.0495 - top_5_categorical_accuracy_cp1: 0.4146 - top_5_categorical_accuracy_cp2: 0.8980 - top_5_categorical_accuracy_cp3: 0.6981 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0652 - top_5_categorical_accuracy_p4: 0.7411 - top_10_categorical_accuracy_cp0: 0.1584 - top_10_categorical_accuracy_cp1: 0.8780 - top_10_categorical_accuracy_cp2: 0.9524 - top_10_categorical_accuracy_cp3: 0.9245 - top_10_categorical_accuracy_cp4: 0.9845 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1522 - top_10_categorical_accuracy_p4: 0.8862 - top_20_categorical_accuracy_cp0: 0.4257 - top_20_categorical_accuracy_cp1: 0.9512 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9811 - top_20_categorical_accuracy_cp4: 0.9922 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2857 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4348 - top_20_categorical_accuracy_p4: 0.95093/7 [===========>..................] - ETA: 0s - loss: 0.1594 - categorical_accuracy: 0.1725 - top_5_categorical_accuracy: 0.6120 - top_10_categorical_accuracy: 0.7656 - top_20_categorical_accuracy: 0.8503 - top_5_categorical_accuracy_cp0: 0.0482 - top_5_categorical_accuracy_cp1: 0.3895 - top_5_categorical_accuracy_cp2: 0.8695 - top_5_categorical_accuracy_cp3: 0.6552 - top_5_categorical_accuracy_cp4: 0.9888 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0733 - top_5_categorical_accuracy_p4: 0.7054 - top_10_categorical_accuracy_cp0: 0.1446 - top_10_categorical_accuracy_cp1: 0.8464 - top_10_categorical_accuracy_cp2: 0.9384 - top_10_categorical_accuracy_cp3: 0.9598 - top_10_categorical_accuracy_cp4: 0.9916 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1667 - top_10_categorical_accuracy_p4: 0.8740 - top_20_categorical_accuracy_cp0: 0.3735 - top_20_categorical_accuracy_cp1: 0.9476 - top_20_categorical_accuracy_cp2: 0.9901 - top_20_categorical_accuracy_cp3: 0.9885 - top_20_categorical_accuracy_cp4: 0.9944 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1000 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.3867 - top_20_categorical_accuracy_p4: 0.9423    5/7 [====================>.........] - ETA: 0s - loss: 0.1554 - categorical_accuracy: 0.1750 - top_5_categorical_accuracy: 0.6234 - top_10_categorical_accuracy: 0.7805 - top_20_categorical_accuracy: 0.8613 - top_5_categorical_accuracy_cp0: 0.0364 - top_5_categorical_accuracy_cp1: 0.4134 - top_5_categorical_accuracy_cp2: 0.8603 - top_5_categorical_accuracy_cp3: 0.6797 - top_5_categorical_accuracy_cp4: 0.9904 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0601 - top_5_categorical_accuracy_p4: 0.7139 - top_10_categorical_accuracy_cp0: 0.1398 - top_10_categorical_accuracy_cp1: 0.8636 - top_10_categorical_accuracy_cp2: 0.9421 - top_10_categorical_accuracy_cp3: 0.9751 - top_10_categorical_accuracy_cp4: 0.9936 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1502 - top_10_categorical_accuracy_p4: 0.8858 - top_20_categorical_accuracy_cp0: 0.3793 - top_20_categorical_accuracy_cp1: 0.9589 - top_20_categorical_accuracy_cp2: 0.9881 - top_20_categorical_accuracy_cp3: 0.9929 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1111 - top_20_categorical_accuracy_p2: 0.1111 - top_20_categorical_accuracy_p3: 0.3906 - top_20_categorical_accuracy_p4: 0.94907/7 [==============================] - ETA: 0s - loss: 0.1547 - categorical_accuracy: 0.1775 - top_5_categorical_accuracy: 0.6224 - top_10_categorical_accuracy: 0.7800 - top_20_categorical_accuracy: 0.8592 - top_5_categorical_accuracy_cp0: 0.0317 - top_5_categorical_accuracy_cp1: 0.4086 - top_5_categorical_accuracy_cp2: 0.8528 - top_5_categorical_accuracy_cp3: 0.7000 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0521 - top_5_categorical_accuracy_p4: 0.7145 - top_10_categorical_accuracy_cp0: 0.1300 - top_10_categorical_accuracy_cp1: 0.8638 - top_10_categorical_accuracy_cp2: 0.9428 - top_10_categorical_accuracy_cp3: 0.9794 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1424 - top_10_categorical_accuracy_p4: 0.8871 - top_20_categorical_accuracy_cp0: 0.3629 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 0.9891 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0909 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.3750 - top_20_categorical_accuracy_p4: 0.9497DEBUG:root:Model metric val_loss improved from 0.206614 to 0.198845
7/7 [==============================] - 1s 121ms/step - loss: 0.1547 - categorical_accuracy: 0.1775 - top_5_categorical_accuracy: 0.6224 - top_10_categorical_accuracy: 0.7800 - top_20_categorical_accuracy: 0.8592 - top_5_categorical_accuracy_cp0: 0.0317 - top_5_categorical_accuracy_cp1: 0.4086 - top_5_categorical_accuracy_cp2: 0.8528 - top_5_categorical_accuracy_cp3: 0.7000 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0521 - top_5_categorical_accuracy_p4: 0.7145 - top_10_categorical_accuracy_cp0: 0.1300 - top_10_categorical_accuracy_cp1: 0.8638 - top_10_categorical_accuracy_cp2: 0.9428 - top_10_categorical_accuracy_cp3: 0.9794 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1424 - top_10_categorical_accuracy_p4: 0.8871 - top_20_categorical_accuracy_cp0: 0.3629 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 0.9891 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0909 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.3750 - top_20_categorical_accuracy_p4: 0.9497 - val_loss: 0.1988 - val_categorical_accuracy: 0.1088 - val_top_5_categorical_accuracy: 0.3176 - val_top_10_categorical_accuracy: 0.4765 - val_top_20_categorical_accuracy: 0.6235 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.3134 - val_top_5_categorical_accuracy_cp2: 0.2692 - val_top_5_categorical_accuracy_cp3: 0.9518 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6102 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7761 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9153 - val_top_20_categorical_accuracy_cp0: 0.2945 - val_top_20_categorical_accuracy_cp1: 0.8060 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.3000 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3659 - val_top_20_categorical_accuracy_p4: 0.9266
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1431 - categorical_accuracy: 0.1914 - top_5_categorical_accuracy: 0.6387 - top_10_categorical_accuracy: 0.8125 - top_20_categorical_accuracy: 0.8906 - top_5_categorical_accuracy_cp0: 0.0206 - top_5_categorical_accuracy_cp1: 0.3836 - top_5_categorical_accuracy_cp2: 0.8050 - top_5_categorical_accuracy_cp3: 0.8182 - top_5_categorical_accuracy_cp4: 0.9688 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0408 - top_5_categorical_accuracy_p4: 0.7287 - top_10_categorical_accuracy_cp0: 0.1443 - top_10_categorical_accuracy_cp1: 0.8904 - top_10_categorical_accuracy_cp2: 0.9686 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1020 - top_10_categorical_accuracy_p4: 0.9215 - top_20_categorical_accuracy_cp0: 0.4227 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1667 - top_20_categorical_accuracy_p1: 0.5000 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4082 - top_20_categorical_accuracy_p4: 0.97313/7 [===========>..................] - ETA: 0s - loss: 0.1463 - categorical_accuracy: 0.1921 - top_5_categorical_accuracy: 0.6191 - top_10_categorical_accuracy: 0.7845 - top_20_categorical_accuracy: 0.8841 - top_5_categorical_accuracy_cp0: 0.0124 - top_5_categorical_accuracy_cp1: 0.3911 - top_5_categorical_accuracy_cp2: 0.8033 - top_5_categorical_accuracy_cp3: 0.8715 - top_5_categorical_accuracy_cp4: 0.9750 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0140 - top_5_categorical_accuracy_p4: 0.7146 - top_10_categorical_accuracy_cp0: 0.0963 - top_10_categorical_accuracy_cp1: 0.8871 - top_10_categorical_accuracy_cp2: 0.9742 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1119 - top_10_categorical_accuracy_p4: 0.8953 - top_20_categorical_accuracy_cp0: 0.4534 - top_20_categorical_accuracy_cp1: 0.9960 - top_20_categorical_accuracy_cp2: 0.9977 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.0909 - top_20_categorical_accuracy_p2: 0.0732 - top_20_categorical_accuracy_p3: 0.4476 - top_20_categorical_accuracy_p4: 0.9706    5/7 [====================>.........] - ETA: 0s - loss: 0.1438 - categorical_accuracy: 0.1934 - top_5_categorical_accuracy: 0.6223 - top_10_categorical_accuracy: 0.7922 - top_20_categorical_accuracy: 0.8848 - top_5_categorical_accuracy_cp0: 0.0134 - top_5_categorical_accuracy_cp1: 0.3831 - top_5_categorical_accuracy_cp2: 0.8058 - top_5_categorical_accuracy_cp3: 0.9101 - top_5_categorical_accuracy_cp4: 0.9727 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0167 - top_5_categorical_accuracy_p4: 0.7193 - top_10_categorical_accuracy_cp0: 0.0921 - top_10_categorical_accuracy_cp1: 0.9042 - top_10_categorical_accuracy_cp2: 0.9783 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1042 - top_10_categorical_accuracy_p4: 0.9067 - top_20_categorical_accuracy_cp0: 0.4415 - top_20_categorical_accuracy_cp1: 0.9933 - top_20_categorical_accuracy_cp2: 0.9986 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0769 - top_20_categorical_accuracy_p2: 0.0563 - top_20_categorical_accuracy_p3: 0.4500 - top_20_categorical_accuracy_p4: 0.97337/7 [==============================] - ETA: 0s - loss: 0.1427 - categorical_accuracy: 0.1959 - top_5_categorical_accuracy: 0.6279 - top_10_categorical_accuracy: 0.7938 - top_20_categorical_accuracy: 0.8860 - top_5_categorical_accuracy_cp0: 0.0127 - top_5_categorical_accuracy_cp1: 0.4176 - top_5_categorical_accuracy_cp2: 0.8078 - top_5_categorical_accuracy_cp3: 0.9265 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0174 - top_5_categorical_accuracy_p4: 0.7246 - top_10_categorical_accuracy_cp0: 0.0935 - top_10_categorical_accuracy_cp1: 0.9104 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1076 - top_10_categorical_accuracy_p4: 0.9068 - top_20_categorical_accuracy_cp0: 0.4485 - top_20_categorical_accuracy_cp1: 0.9910 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.4514 - top_20_categorical_accuracy_p4: 0.9735DEBUG:root:Model metric val_loss improved from 0.198845 to 0.188118
7/7 [==============================] - 1s 127ms/step - loss: 0.1427 - categorical_accuracy: 0.1959 - top_5_categorical_accuracy: 0.6279 - top_10_categorical_accuracy: 0.7938 - top_20_categorical_accuracy: 0.8860 - top_5_categorical_accuracy_cp0: 0.0127 - top_5_categorical_accuracy_cp1: 0.4176 - top_5_categorical_accuracy_cp2: 0.8078 - top_5_categorical_accuracy_cp3: 0.9265 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0174 - top_5_categorical_accuracy_p4: 0.7246 - top_10_categorical_accuracy_cp0: 0.0935 - top_10_categorical_accuracy_cp1: 0.9104 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1076 - top_10_categorical_accuracy_p4: 0.9068 - top_20_categorical_accuracy_cp0: 0.4485 - top_20_categorical_accuracy_cp1: 0.9910 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0606 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.4514 - top_20_categorical_accuracy_p4: 0.9735 - val_loss: 0.1881 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.4118 - val_top_10_categorical_accuracy: 0.4706 - val_top_20_categorical_accuracy: 0.5853 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.5970 - val_top_5_categorical_accuracy_cp2: 0.6154 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7910 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7463 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9040 - val_top_20_categorical_accuracy_cp0: 0.1411 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1870 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1334 - categorical_accuracy: 0.2207 - top_5_categorical_accuracy: 0.6699 - top_10_categorical_accuracy: 0.8223 - top_20_categorical_accuracy: 0.9082 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.5510 - top_5_categorical_accuracy_cp2: 0.8516 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9609 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7622 - top_10_categorical_accuracy_cp0: 0.1485 - top_10_categorical_accuracy_cp1: 0.9490 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1163 - top_10_categorical_accuracy_p4: 0.9244 - top_20_categorical_accuracy_cp0: 0.5347 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1875 - top_20_categorical_accuracy_p3: 0.5116 - top_20_categorical_accuracy_p4: 0.97783/7 [===========>..................] - ETA: 0s - loss: 0.1364 - categorical_accuracy: 0.2161 - top_5_categorical_accuracy: 0.6576 - top_10_categorical_accuracy: 0.7962 - top_20_categorical_accuracy: 0.8919 - top_5_categorical_accuracy_cp0: 0.0117 - top_5_categorical_accuracy_cp1: 0.5576 - top_5_categorical_accuracy_cp2: 0.8557 - top_5_categorical_accuracy_cp3: 0.9889 - top_5_categorical_accuracy_cp4: 0.9665 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0127 - top_5_categorical_accuracy_p4: 0.7701 - top_10_categorical_accuracy_cp0: 0.1320 - top_10_categorical_accuracy_cp1: 0.9442 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9944 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1076 - top_10_categorical_accuracy_p4: 0.9213 - top_20_categorical_accuracy_cp0: 0.5132 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0816 - top_20_categorical_accuracy_p3: 0.5063 - top_20_categorical_accuracy_p4: 0.9824        5/7 [====================>.........] - ETA: 0s - loss: 0.1347 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.6672 - top_10_categorical_accuracy: 0.8098 - top_20_categorical_accuracy: 0.8953 - top_5_categorical_accuracy_cp0: 0.0186 - top_5_categorical_accuracy_cp1: 0.5565 - top_5_categorical_accuracy_cp2: 0.8561 - top_5_categorical_accuracy_cp3: 0.9931 - top_5_categorical_accuracy_cp4: 0.9620 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0165 - top_5_categorical_accuracy_p4: 0.7742 - top_10_categorical_accuracy_cp0: 0.1508 - top_10_categorical_accuracy_cp1: 0.9478 - top_10_categorical_accuracy_cp2: 0.9940 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9950 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1358 - top_10_categorical_accuracy_p4: 0.9269 - top_20_categorical_accuracy_cp0: 0.5028 - top_20_categorical_accuracy_cp1: 0.9978 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0625 - top_20_categorical_accuracy_p3: 0.4815 - top_20_categorical_accuracy_p4: 0.9855    7/7 [==============================] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.2159 - top_5_categorical_accuracy: 0.6707 - top_10_categorical_accuracy: 0.8177 - top_20_categorical_accuracy: 0.8992 - top_5_categorical_accuracy_cp0: 0.0254 - top_5_categorical_accuracy_cp1: 0.5448 - top_5_categorical_accuracy_cp2: 0.8528 - top_5_categorical_accuracy_cp3: 0.9912 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0139 - top_5_categorical_accuracy_p4: 0.7745 - top_10_categorical_accuracy_cp0: 0.1601 - top_10_categorical_accuracy_cp1: 0.9534 - top_10_categorical_accuracy_cp2: 0.9927 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1250 - top_10_categorical_accuracy_p4: 0.9325 - top_20_categorical_accuracy_cp0: 0.5055 - top_20_categorical_accuracy_cp1: 0.9982 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.4722 - top_20_categorical_accuracy_p4: 0.9873DEBUG:root:Model metric val_loss improved from 0.188118 to 0.182072
7/7 [==============================] - 1s 123ms/step - loss: 0.1339 - categorical_accuracy: 0.2159 - top_5_categorical_accuracy: 0.6707 - top_10_categorical_accuracy: 0.8177 - top_20_categorical_accuracy: 0.8992 - top_5_categorical_accuracy_cp0: 0.0254 - top_5_categorical_accuracy_cp1: 0.5448 - top_5_categorical_accuracy_cp2: 0.8528 - top_5_categorical_accuracy_cp3: 0.9912 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0139 - top_5_categorical_accuracy_p4: 0.7745 - top_10_categorical_accuracy_cp0: 0.1601 - top_10_categorical_accuracy_cp1: 0.9534 - top_10_categorical_accuracy_cp2: 0.9927 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1250 - top_10_categorical_accuracy_p4: 0.9325 - top_20_categorical_accuracy_cp0: 0.5055 - top_20_categorical_accuracy_cp1: 0.9982 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.4722 - top_20_categorical_accuracy_p4: 0.9873 - val_loss: 0.1821 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.4441 - val_top_10_categorical_accuracy: 0.4853 - val_top_20_categorical_accuracy: 0.5412 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.6269 - val_top_5_categorical_accuracy_cp2: 0.9615 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8531 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8209 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9322 - val_top_20_categorical_accuracy_cp0: 0.0491 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0650 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.2246 - top_5_categorical_accuracy: 0.6758 - top_10_categorical_accuracy: 0.8184 - top_20_categorical_accuracy: 0.9082 - top_5_categorical_accuracy_cp0: 0.0924 - top_5_categorical_accuracy_cp1: 0.6505 - top_5_categorical_accuracy_cp2: 0.8545 - top_5_categorical_accuracy_cp3: 0.9697 - top_5_categorical_accuracy_cp4: 0.9649 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0377 - top_5_categorical_accuracy_p4: 0.7836 - top_10_categorical_accuracy_cp0: 0.2605 - top_10_categorical_accuracy_cp1: 0.9612 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9912 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2075 - top_10_categorical_accuracy_p4: 0.9294 - top_20_categorical_accuracy_cp0: 0.6050 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.5660 - top_20_categorical_accuracy_p4: 0.99093/7 [===========>..................] - ETA: 0s - loss: 0.1278 - categorical_accuracy: 0.2161 - top_5_categorical_accuracy: 0.7005 - top_10_categorical_accuracy: 0.8424 - top_20_categorical_accuracy: 0.9147 - top_5_categorical_accuracy_cp0: 0.0852 - top_5_categorical_accuracy_cp1: 0.5938 - top_5_categorical_accuracy_cp2: 0.9107 - top_5_categorical_accuracy_cp3: 0.9713 - top_5_categorical_accuracy_cp4: 0.9644 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0382 - top_5_categorical_accuracy_p4: 0.8010 - top_10_categorical_accuracy_cp0: 0.3218 - top_10_categorical_accuracy_cp1: 0.9375 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9890 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2443 - top_10_categorical_accuracy_p4: 0.9439 - top_20_categorical_accuracy_cp0: 0.5994 - top_20_categorical_accuracy_cp1: 0.9931 - top_20_categorical_accuracy_cp2: 0.9974 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0408 - top_20_categorical_accuracy_p3: 0.5725 - top_20_categorical_accuracy_p4: 0.9933    5/7 [====================>.........] - ETA: 0s - loss: 0.1276 - categorical_accuracy: 0.2141 - top_5_categorical_accuracy: 0.7051 - top_10_categorical_accuracy: 0.8406 - top_20_categorical_accuracy: 0.9168 - top_5_categorical_accuracy_cp0: 0.0872 - top_5_categorical_accuracy_cp1: 0.5579 - top_5_categorical_accuracy_cp2: 0.9244 - top_5_categorical_accuracy_cp3: 0.9745 - top_5_categorical_accuracy_cp4: 0.9682 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0429 - top_5_categorical_accuracy_p4: 0.8093 - top_10_categorical_accuracy_cp0: 0.3159 - top_10_categorical_accuracy_cp1: 0.9227 - top_10_categorical_accuracy_cp2: 0.9867 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9857 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2275 - top_10_categorical_accuracy_p4: 0.9463 - top_20_categorical_accuracy_cp0: 0.6027 - top_20_categorical_accuracy_cp1: 0.9914 - top_20_categorical_accuracy_cp2: 0.9970 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0400 - top_20_categorical_accuracy_p3: 0.5966 - top_20_categorical_accuracy_p4: 0.99417/7 [==============================] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.2159 - top_5_categorical_accuracy: 0.7084 - top_10_categorical_accuracy: 0.8421 - top_20_categorical_accuracy: 0.9169 - top_5_categorical_accuracy_cp0: 0.0887 - top_5_categorical_accuracy_cp1: 0.5735 - top_5_categorical_accuracy_cp2: 0.9258 - top_5_categorical_accuracy_cp3: 0.9735 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0451 - top_5_categorical_accuracy_p4: 0.8148 - top_10_categorical_accuracy_cp0: 0.3296 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2500 - top_10_categorical_accuracy_p4: 0.9474 - top_20_categorical_accuracy_cp0: 0.6101 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0349 - top_20_categorical_accuracy_p3: 0.6181 - top_20_categorical_accuracy_p4: 0.9933DEBUG:root:Model metric val_loss improved from 0.182072 to 0.179438
7/7 [==============================] - 1s 120ms/step - loss: 0.1274 - categorical_accuracy: 0.2159 - top_5_categorical_accuracy: 0.7084 - top_10_categorical_accuracy: 0.8421 - top_20_categorical_accuracy: 0.9169 - top_5_categorical_accuracy_cp0: 0.0887 - top_5_categorical_accuracy_cp1: 0.5735 - top_5_categorical_accuracy_cp2: 0.9258 - top_5_categorical_accuracy_cp3: 0.9735 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0451 - top_5_categorical_accuracy_p4: 0.8148 - top_10_categorical_accuracy_cp0: 0.3296 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2500 - top_10_categorical_accuracy_p4: 0.9474 - top_20_categorical_accuracy_cp0: 0.6101 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0349 - top_20_categorical_accuracy_p3: 0.6181 - top_20_categorical_accuracy_p4: 0.9933 - val_loss: 0.1794 - val_categorical_accuracy: 0.2353 - val_top_5_categorical_accuracy: 0.4382 - val_top_10_categorical_accuracy: 0.4824 - val_top_20_categorical_accuracy: 0.5471 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.5821 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8418 - val_top_10_categorical_accuracy_cp0: 0.0123 - val_top_10_categorical_accuracy_cp1: 0.7761 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0163 - val_top_10_categorical_accuracy_p4: 0.9153 - val_top_20_categorical_accuracy_cp0: 0.0613 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0813 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1232 - categorical_accuracy: 0.2266 - top_5_categorical_accuracy: 0.7383 - top_10_categorical_accuracy: 0.8574 - top_20_categorical_accuracy: 0.9219 - top_5_categorical_accuracy_cp0: 0.1354 - top_5_categorical_accuracy_cp1: 0.5843 - top_5_categorical_accuracy_cp2: 0.9396 - top_5_categorical_accuracy_cp3: 0.9796 - top_5_categorical_accuracy_cp4: 0.9690 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0727 - top_5_categorical_accuracy_p4: 0.8423 - top_10_categorical_accuracy_cp0: 0.3646 - top_10_categorical_accuracy_cp1: 0.9213 - top_10_categorical_accuracy_cp2: 0.9732 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2909 - top_10_categorical_accuracy_p4: 0.9527 - top_20_categorical_accuracy_cp0: 0.6146 - top_20_categorical_accuracy_cp1: 0.9775 - top_20_categorical_accuracy_cp2: 0.9933 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1667 - top_20_categorical_accuracy_p3: 0.5455 - top_20_categorical_accuracy_p4: 0.99323/7 [===========>..................] - ETA: 0s - loss: 0.1244 - categorical_accuracy: 0.2201 - top_5_categorical_accuracy: 0.7396 - top_10_categorical_accuracy: 0.8529 - top_20_categorical_accuracy: 0.9232 - top_5_categorical_accuracy_cp0: 0.1237 - top_5_categorical_accuracy_cp1: 0.5936 - top_5_categorical_accuracy_cp2: 0.9589 - top_5_categorical_accuracy_cp3: 0.9560 - top_5_categorical_accuracy_cp4: 0.9717 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0719 - top_5_categorical_accuracy_p4: 0.8503 - top_10_categorical_accuracy_cp0: 0.3445 - top_10_categorical_accuracy_cp1: 0.9323 - top_10_categorical_accuracy_cp2: 0.9863 - top_10_categorical_accuracy_cp3: 0.9811 - top_10_categorical_accuracy_cp4: 0.9897 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2614 - top_10_categorical_accuracy_p4: 0.9599 - top_20_categorical_accuracy_cp0: 0.6221 - top_20_categorical_accuracy_cp1: 0.9880 - top_20_categorical_accuracy_cp2: 0.9977 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9974 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0732 - top_20_categorical_accuracy_p3: 0.6340 - top_20_categorical_accuracy_p4: 0.99625/7 [====================>.........] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.2164 - top_5_categorical_accuracy: 0.7234 - top_10_categorical_accuracy: 0.8535 - top_20_categorical_accuracy: 0.9238 - top_5_categorical_accuracy_cp0: 0.1233 - top_5_categorical_accuracy_cp1: 0.5651 - top_5_categorical_accuracy_cp2: 0.9579 - top_5_categorical_accuracy_cp3: 0.9640 - top_5_categorical_accuracy_cp4: 0.9726 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0833 - top_5_categorical_accuracy_p4: 0.8305 - top_10_categorical_accuracy_cp0: 0.3834 - top_10_categorical_accuracy_cp1: 0.9227 - top_10_categorical_accuracy_cp2: 0.9855 - top_10_categorical_accuracy_cp3: 0.9856 - top_10_categorical_accuracy_cp4: 0.9903 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3042 - top_10_categorical_accuracy_p4: 0.9574 - top_20_categorical_accuracy_cp0: 0.6455 - top_20_categorical_accuracy_cp1: 0.9868 - top_20_categorical_accuracy_cp2: 0.9971 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9952 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0822 - top_20_categorical_accuracy_p3: 0.6833 - top_20_categorical_accuracy_p4: 0.99507/7 [==============================] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.2162 - top_5_categorical_accuracy: 0.7223 - top_10_categorical_accuracy: 0.8537 - top_20_categorical_accuracy: 0.9256 - top_5_categorical_accuracy_cp0: 0.1300 - top_5_categorical_accuracy_cp1: 0.5556 - top_5_categorical_accuracy_cp2: 0.9599 - top_5_categorical_accuracy_cp3: 0.9706 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0938 - top_5_categorical_accuracy_p4: 0.8256 - top_10_categorical_accuracy_cp0: 0.3978 - top_10_categorical_accuracy_cp1: 0.9122 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3056 - top_10_categorical_accuracy_p4: 0.9549 - top_20_categorical_accuracy_cp0: 0.6561 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.6806 - top_20_categorical_accuracy_p4: 0.9948DEBUG:root:Model metric val_loss improved from 0.179438 to 0.173252
7/7 [==============================] - 1s 126ms/step - loss: 0.1252 - categorical_accuracy: 0.2162 - top_5_categorical_accuracy: 0.7223 - top_10_categorical_accuracy: 0.8537 - top_20_categorical_accuracy: 0.9256 - top_5_categorical_accuracy_cp0: 0.1300 - top_5_categorical_accuracy_cp1: 0.5556 - top_5_categorical_accuracy_cp2: 0.9599 - top_5_categorical_accuracy_cp3: 0.9706 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0938 - top_5_categorical_accuracy_p4: 0.8256 - top_10_categorical_accuracy_cp0: 0.3978 - top_10_categorical_accuracy_cp1: 0.9122 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3056 - top_10_categorical_accuracy_p4: 0.9549 - top_20_categorical_accuracy_cp0: 0.6561 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0930 - top_20_categorical_accuracy_p3: 0.6806 - top_20_categorical_accuracy_p4: 0.9948 - val_loss: 0.1733 - val_categorical_accuracy: 0.2382 - val_top_5_categorical_accuracy: 0.4529 - val_top_10_categorical_accuracy: 0.4706 - val_top_20_categorical_accuracy: 0.5824 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.6567 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8701 - val_top_10_categorical_accuracy_cp0: 0.0123 - val_top_10_categorical_accuracy_cp1: 0.7164 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0163 - val_top_10_categorical_accuracy_p4: 0.8927 - val_top_20_categorical_accuracy_cp0: 0.1350 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1789 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1293 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6777 - top_10_categorical_accuracy: 0.8262 - top_20_categorical_accuracy: 0.9258 - top_5_categorical_accuracy_cp0: 0.1228 - top_5_categorical_accuracy_cp1: 0.5377 - top_5_categorical_accuracy_cp2: 0.9328 - top_5_categorical_accuracy_cp3: 0.9692 - top_5_categorical_accuracy_cp4: 0.9444 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0784 - top_5_categorical_accuracy_p4: 0.7831 - top_10_categorical_accuracy_cp0: 0.3947 - top_10_categorical_accuracy_cp1: 0.8868 - top_10_categorical_accuracy_cp2: 0.9748 - top_10_categorical_accuracy_cp3: 0.9846 - top_10_categorical_accuracy_cp4: 0.9630 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0667 - top_10_categorical_accuracy_p3: 0.2745 - top_10_categorical_accuracy_p4: 0.9315 - top_20_categorical_accuracy_cp0: 0.7193 - top_20_categorical_accuracy_cp1: 0.9623 - top_20_categorical_accuracy_cp2: 0.9916 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2667 - top_20_categorical_accuracy_p3: 0.7451 - top_20_categorical_accuracy_p4: 0.98633/7 [===========>..................] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.2220 - top_5_categorical_accuracy: 0.7240 - top_10_categorical_accuracy: 0.8581 - top_20_categorical_accuracy: 0.9219 - top_5_categorical_accuracy_cp0: 0.2037 - top_5_categorical_accuracy_cp1: 0.5618 - top_5_categorical_accuracy_cp2: 0.9342 - top_5_categorical_accuracy_cp3: 0.9775 - top_5_categorical_accuracy_cp4: 0.9663 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1667 - top_5_categorical_accuracy_p4: 0.8238 - top_10_categorical_accuracy_cp0: 0.4475 - top_10_categorical_accuracy_cp1: 0.9152 - top_10_categorical_accuracy_cp2: 0.9848 - top_10_categorical_accuracy_cp3: 0.9944 - top_10_categorical_accuracy_cp4: 0.9775 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0204 - top_10_categorical_accuracy_p3: 0.3986 - top_10_categorical_accuracy_p4: 0.9546 - top_20_categorical_accuracy_cp0: 0.6605 - top_20_categorical_accuracy_cp1: 0.9823 - top_20_categorical_accuracy_cp2: 0.9949 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9916 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1224 - top_20_categorical_accuracy_p3: 0.7174 - top_20_categorical_accuracy_p4: 0.99175/7 [====================>.........] - ETA: 0s - loss: 0.1223 - categorical_accuracy: 0.2207 - top_5_categorical_accuracy: 0.7309 - top_10_categorical_accuracy: 0.8648 - top_20_categorical_accuracy: 0.9273 - top_5_categorical_accuracy_cp0: 0.2098 - top_5_categorical_accuracy_cp1: 0.5727 - top_5_categorical_accuracy_cp2: 0.9316 - top_5_categorical_accuracy_cp3: 0.9684 - top_5_categorical_accuracy_cp4: 0.9690 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1583 - top_5_categorical_accuracy_p4: 0.8309 - top_10_categorical_accuracy_cp0: 0.4556 - top_10_categorical_accuracy_cp1: 0.9241 - top_10_categorical_accuracy_cp2: 0.9837 - top_10_categorical_accuracy_cp3: 0.9965 - top_10_categorical_accuracy_cp4: 0.9820 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0139 - top_10_categorical_accuracy_p3: 0.3792 - top_10_categorical_accuracy_p4: 0.9619 - top_20_categorical_accuracy_cp0: 0.6730 - top_20_categorical_accuracy_cp1: 0.9848 - top_20_categorical_accuracy_cp2: 0.9970 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9935 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1389 - top_20_categorical_accuracy_p3: 0.7167 - top_20_categorical_accuracy_p4: 0.99377/7 [==============================] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.2210 - top_5_categorical_accuracy: 0.7342 - top_10_categorical_accuracy: 0.8660 - top_20_categorical_accuracy: 0.9291 - top_5_categorical_accuracy_cp0: 0.2076 - top_5_categorical_accuracy_cp1: 0.5699 - top_5_categorical_accuracy_cp2: 0.9355 - top_5_categorical_accuracy_cp3: 0.9735 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1389 - top_5_categorical_accuracy_p4: 0.8345 - top_10_categorical_accuracy_cp0: 0.4548 - top_10_categorical_accuracy_cp1: 0.9194 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.3646 - top_10_categorical_accuracy_p4: 0.9620 - top_20_categorical_accuracy_cp0: 0.6767 - top_20_categorical_accuracy_cp1: 0.9821 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.7188 - top_20_categorical_accuracy_p4: 0.9937DEBUG:root:Model metric val_loss improved from 0.173252 to 0.167079
7/7 [==============================] - 1s 123ms/step - loss: 0.1218 - categorical_accuracy: 0.2210 - top_5_categorical_accuracy: 0.7342 - top_10_categorical_accuracy: 0.8660 - top_20_categorical_accuracy: 0.9291 - top_5_categorical_accuracy_cp0: 0.2076 - top_5_categorical_accuracy_cp1: 0.5699 - top_5_categorical_accuracy_cp2: 0.9355 - top_5_categorical_accuracy_cp3: 0.9735 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1389 - top_5_categorical_accuracy_p4: 0.8345 - top_10_categorical_accuracy_cp0: 0.4548 - top_10_categorical_accuracy_cp1: 0.9194 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.3646 - top_10_categorical_accuracy_p4: 0.9620 - top_20_categorical_accuracy_cp0: 0.6767 - top_20_categorical_accuracy_cp1: 0.9821 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.7188 - top_20_categorical_accuracy_p4: 0.9937 - val_loss: 0.1671 - val_categorical_accuracy: 0.2382 - val_top_5_categorical_accuracy: 0.4588 - val_top_10_categorical_accuracy: 0.4706 - val_top_20_categorical_accuracy: 0.7529 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.7015 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8814 - val_top_10_categorical_accuracy_cp0: 0.0061 - val_top_10_categorical_accuracy_cp1: 0.7313 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0081 - val_top_10_categorical_accuracy_p4: 0.8983 - val_top_20_categorical_accuracy_cp0: 0.4908 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.6504 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.2207 - top_5_categorical_accuracy: 0.7402 - top_10_categorical_accuracy: 0.8613 - top_20_categorical_accuracy: 0.9297 - top_5_categorical_accuracy_cp0: 0.2832 - top_5_categorical_accuracy_cp1: 0.6774 - top_5_categorical_accuracy_cp2: 0.8832 - top_5_categorical_accuracy_cp3: 0.9825 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1915 - top_5_categorical_accuracy_p4: 0.8409 - top_10_categorical_accuracy_cp0: 0.5310 - top_10_categorical_accuracy_cp1: 0.9247 - top_10_categorical_accuracy_cp2: 0.9489 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4468 - top_10_categorical_accuracy_p4: 0.9545 - top_20_categorical_accuracy_cp0: 0.7345 - top_20_categorical_accuracy_cp1: 0.9677 - top_20_categorical_accuracy_cp2: 0.9854 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0625 - top_20_categorical_accuracy_p3: 0.8723 - top_20_categorical_accuracy_p4: 0.98643/7 [===========>..................] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2220 - top_5_categorical_accuracy: 0.7337 - top_10_categorical_accuracy: 0.8665 - top_20_categorical_accuracy: 0.9362 - top_5_categorical_accuracy_cp0: 0.2252 - top_5_categorical_accuracy_cp1: 0.6287 - top_5_categorical_accuracy_cp2: 0.9289 - top_5_categorical_accuracy_cp3: 0.9830 - top_5_categorical_accuracy_cp4: 0.9474 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1389 - top_5_categorical_accuracy_p4: 0.8374 - top_10_categorical_accuracy_cp0: 0.5165 - top_10_categorical_accuracy_cp1: 0.9191 - top_10_categorical_accuracy_cp2: 0.9721 - top_10_categorical_accuracy_cp3: 0.9943 - top_10_categorical_accuracy_cp4: 0.9723 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4444 - top_10_categorical_accuracy_p4: 0.9584 - top_20_categorical_accuracy_cp0: 0.7327 - top_20_categorical_accuracy_cp1: 0.9853 - top_20_categorical_accuracy_cp2: 0.9949 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9917 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0851 - top_20_categorical_accuracy_p3: 0.8403 - top_20_categorical_accuracy_p4: 0.99325/7 [====================>.........] - ETA: 0s - loss: 0.1195 - categorical_accuracy: 0.2215 - top_5_categorical_accuracy: 0.7426 - top_10_categorical_accuracy: 0.8730 - top_20_categorical_accuracy: 0.9363 - top_5_categorical_accuracy_cp0: 0.2280 - top_5_categorical_accuracy_cp1: 0.6073 - top_5_categorical_accuracy_cp2: 0.9390 - top_5_categorical_accuracy_cp3: 0.9785 - top_5_categorical_accuracy_cp4: 0.9581 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1477 - top_5_categorical_accuracy_p4: 0.8447 - top_10_categorical_accuracy_cp0: 0.5019 - top_10_categorical_accuracy_cp1: 0.9206 - top_10_categorical_accuracy_cp2: 0.9777 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9807 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4473 - top_10_categorical_accuracy_p4: 0.9638 - top_20_categorical_accuracy_cp0: 0.7146 - top_20_categorical_accuracy_cp1: 0.9850 - top_20_categorical_accuracy_cp2: 0.9955 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1299 - top_20_categorical_accuracy_p3: 0.8143 - top_20_categorical_accuracy_p4: 0.99327/7 [==============================] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.2213 - top_5_categorical_accuracy: 0.7452 - top_10_categorical_accuracy: 0.8737 - top_20_categorical_accuracy: 0.9362 - top_5_categorical_accuracy_cp0: 0.2377 - top_5_categorical_accuracy_cp1: 0.5986 - top_5_categorical_accuracy_cp2: 0.9392 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1597 - top_5_categorical_accuracy_p4: 0.8449 - top_10_categorical_accuracy_cp0: 0.5055 - top_10_categorical_accuracy_cp1: 0.9158 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4479 - top_10_categorical_accuracy_p4: 0.9627 - top_20_categorical_accuracy_cp0: 0.7147 - top_20_categorical_accuracy_cp1: 0.9839 - top_20_categorical_accuracy_cp2: 0.9939 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1163 - top_20_categorical_accuracy_p3: 0.8056 - top_20_categorical_accuracy_p4: 0.9929DEBUG:root:Model metric val_loss improved from 0.167079 to 0.161898
7/7 [==============================] - 1s 117ms/step - loss: 0.1193 - categorical_accuracy: 0.2213 - top_5_categorical_accuracy: 0.7452 - top_10_categorical_accuracy: 0.8737 - top_20_categorical_accuracy: 0.9362 - top_5_categorical_accuracy_cp0: 0.2377 - top_5_categorical_accuracy_cp1: 0.5986 - top_5_categorical_accuracy_cp2: 0.9392 - top_5_categorical_accuracy_cp3: 0.9765 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1597 - top_5_categorical_accuracy_p4: 0.8449 - top_10_categorical_accuracy_cp0: 0.5055 - top_10_categorical_accuracy_cp1: 0.9158 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4479 - top_10_categorical_accuracy_p4: 0.9627 - top_20_categorical_accuracy_cp0: 0.7147 - top_20_categorical_accuracy_cp1: 0.9839 - top_20_categorical_accuracy_cp2: 0.9939 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1163 - top_20_categorical_accuracy_p3: 0.8056 - top_20_categorical_accuracy_p4: 0.9929 - val_loss: 0.1619 - val_categorical_accuracy: 0.2382 - val_top_5_categorical_accuracy: 0.4647 - val_top_10_categorical_accuracy: 0.5559 - val_top_20_categorical_accuracy: 0.8029 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.7313 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.8927 - val_top_10_categorical_accuracy_cp0: 0.1656 - val_top_10_categorical_accuracy_cp1: 0.7761 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.2195 - val_top_10_categorical_accuracy_p4: 0.9153 - val_top_20_categorical_accuracy_cp0: 0.6258 - val_top_20_categorical_accuracy_cp1: 0.9104 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8293 - val_top_20_categorical_accuracy_p4: 0.9661
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1121 - categorical_accuracy: 0.2285 - top_5_categorical_accuracy: 0.7793 - top_10_categorical_accuracy: 0.9102 - top_20_categorical_accuracy: 0.9531 - top_5_categorical_accuracy_cp0: 0.2619 - top_5_categorical_accuracy_cp1: 0.6400 - top_5_categorical_accuracy_cp2: 0.9306 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1860 - top_5_categorical_accuracy_p4: 0.8575 - top_10_categorical_accuracy_cp0: 0.5833 - top_10_categorical_accuracy_cp1: 0.9500 - top_10_categorical_accuracy_cp2: 0.9722 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4884 - top_10_categorical_accuracy_p4: 0.9759 - top_20_categorical_accuracy_cp0: 0.7738 - top_20_categorical_accuracy_cp1: 0.9800 - top_20_categorical_accuracy_cp2: 0.9861 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.8605 - top_20_categorical_accuracy_p4: 0.98903/7 [===========>..................] - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.2174 - top_5_categorical_accuracy: 0.7493 - top_10_categorical_accuracy: 0.8854 - top_20_categorical_accuracy: 0.9382 - top_5_categorical_accuracy_cp0: 0.2540 - top_5_categorical_accuracy_cp1: 0.5957 - top_5_categorical_accuracy_cp2: 0.9429 - top_5_categorical_accuracy_cp3: 0.9760 - top_5_categorical_accuracy_cp4: 0.9706 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1788 - top_5_categorical_accuracy_p4: 0.8483 - top_10_categorical_accuracy_cp0: 0.5460 - top_10_categorical_accuracy_cp1: 0.9278 - top_10_categorical_accuracy_cp2: 0.9801 - top_10_categorical_accuracy_cp3: 0.9940 - top_10_categorical_accuracy_cp4: 0.9893 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0270 - top_10_categorical_accuracy_p3: 0.4967 - top_10_categorical_accuracy_p4: 0.9691 - top_20_categorical_accuracy_cp0: 0.7460 - top_20_categorical_accuracy_cp1: 0.9747 - top_20_categorical_accuracy_cp2: 0.9876 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0625 - top_20_categorical_accuracy_p2: 0.1622 - top_20_categorical_accuracy_p3: 0.8278 - top_20_categorical_accuracy_p4: 0.9879            5/7 [====================>.........] - ETA: 0s - loss: 0.1183 - categorical_accuracy: 0.2195 - top_5_categorical_accuracy: 0.7484 - top_10_categorical_accuracy: 0.8844 - top_20_categorical_accuracy: 0.9379 - top_5_categorical_accuracy_cp0: 0.2544 - top_5_categorical_accuracy_cp1: 0.5875 - top_5_categorical_accuracy_cp2: 0.9353 - top_5_categorical_accuracy_cp3: 0.9745 - top_5_categorical_accuracy_cp4: 0.9713 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1807 - top_5_categorical_accuracy_p4: 0.8448 - top_10_categorical_accuracy_cp0: 0.5340 - top_10_categorical_accuracy_cp1: 0.9244 - top_10_categorical_accuracy_cp2: 0.9809 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9889 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0149 - top_10_categorical_accuracy_p3: 0.4832 - top_10_categorical_accuracy_p4: 0.9689 - top_20_categorical_accuracy_cp0: 0.7340 - top_20_categorical_accuracy_cp1: 0.9741 - top_20_categorical_accuracy_cp2: 0.9897 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9952 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0370 - top_20_categorical_accuracy_p2: 0.1343 - top_20_categorical_accuracy_p3: 0.8277 - top_20_categorical_accuracy_p4: 0.98967/7 [==============================] - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.7474 - top_10_categorical_accuracy: 0.8843 - top_20_categorical_accuracy: 0.9375 - top_5_categorical_accuracy_cp0: 0.2615 - top_5_categorical_accuracy_cp1: 0.5789 - top_5_categorical_accuracy_cp2: 0.9355 - top_5_categorical_accuracy_cp3: 0.9794 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1910 - top_5_categorical_accuracy_p4: 0.8442 - top_10_categorical_accuracy_cp0: 0.5325 - top_10_categorical_accuracy_cp1: 0.9265 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0116 - top_10_categorical_accuracy_p3: 0.4861 - top_10_categorical_accuracy_p4: 0.9706 - top_20_categorical_accuracy_cp0: 0.7306 - top_20_categorical_accuracy_cp1: 0.9785 - top_20_categorical_accuracy_cp2: 0.9915 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.1512 - top_20_categorical_accuracy_p3: 0.8264 - top_20_categorical_accuracy_p4: 0.9907DEBUG:root:Model metric val_loss improved from 0.161898 to 0.156352
7/7 [==============================] - 1s 115ms/step - loss: 0.1184 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.7474 - top_10_categorical_accuracy: 0.8843 - top_20_categorical_accuracy: 0.9375 - top_5_categorical_accuracy_cp0: 0.2615 - top_5_categorical_accuracy_cp1: 0.5789 - top_5_categorical_accuracy_cp2: 0.9355 - top_5_categorical_accuracy_cp3: 0.9794 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1910 - top_5_categorical_accuracy_p4: 0.8442 - top_10_categorical_accuracy_cp0: 0.5325 - top_10_categorical_accuracy_cp1: 0.9265 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9880 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0116 - top_10_categorical_accuracy_p3: 0.4861 - top_10_categorical_accuracy_p4: 0.9706 - top_20_categorical_accuracy_cp0: 0.7306 - top_20_categorical_accuracy_cp1: 0.9785 - top_20_categorical_accuracy_cp2: 0.9915 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.1512 - top_20_categorical_accuracy_p3: 0.8264 - top_20_categorical_accuracy_p4: 0.9907 - val_loss: 0.1564 - val_categorical_accuracy: 0.2294 - val_top_5_categorical_accuracy: 0.5353 - val_top_10_categorical_accuracy: 0.7000 - val_top_20_categorical_accuracy: 0.8118 - val_top_5_categorical_accuracy_cp0: 0.1595 - val_top_5_categorical_accuracy_cp1: 0.7313 - val_top_5_categorical_accuracy_cp2: 0.8846 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2114 - val_top_5_categorical_accuracy_p4: 0.8814 - val_top_10_categorical_accuracy_cp0: 0.4601 - val_top_10_categorical_accuracy_cp1: 0.7910 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.6098 - val_top_10_categorical_accuracy_p4: 0.9209 - val_top_20_categorical_accuracy_cp0: 0.6503 - val_top_20_categorical_accuracy_cp1: 0.8955 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8618 - val_top_20_categorical_accuracy_p4: 0.9605
INFO:root:Restoring best model weights with val_loss: 0.156352 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  7.24it/s]Calculating prediction outputs...: 1it [00:00,  7.23it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1052.37it/s]
INFO:root:Finished run efc242213f484be2bc80233eb2609214
Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 20:05:33.593666: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:05:34.106172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:05:34.106234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:05:34.106239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 0296784f45bd4f9fbf5b3ae2fcb61848
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12307.07it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13378.99it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13276.34it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.197741]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.260045]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.096100]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11617.56it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.165246 Tokens per Sec: 1009.995300
Epoch Step: 11 / 173 Loss: 3.704065 Tokens per Sec: 5353.457031
Epoch Step: 21 / 173 Loss: 3.983760 Tokens per Sec: 5432.217773
Epoch Step: 31 / 173 Loss: 3.923303 Tokens per Sec: 5382.512207
Epoch Step: 41 / 173 Loss: 3.785679 Tokens per Sec: 5428.508301
Epoch Step: 51 / 173 Loss: 3.884093 Tokens per Sec: 5335.076172
Epoch Step: 61 / 173 Loss: 3.145933 Tokens per Sec: 5292.443359
Epoch Step: 71 / 173 Loss: 3.718354 Tokens per Sec: 5204.295898
Epoch Step: 81 / 173 Loss: 3.109780 Tokens per Sec: 5335.687500
Epoch Step: 91 / 173 Loss: 3.489280 Tokens per Sec: 5301.182617
Epoch Step: 101 / 173 Loss: 3.997569 Tokens per Sec: 5394.015625
Epoch Step: 111 / 173 Loss: 3.479908 Tokens per Sec: 5457.297363
Epoch Step: 121 / 173 Loss: 3.696194 Tokens per Sec: 5415.513672
Epoch Step: 131 / 173 Loss: 2.957244 Tokens per Sec: 5359.562988
Epoch Step: 141 / 173 Loss: 3.281183 Tokens per Sec: 5458.060059
Epoch Step: 151 / 173 Loss: 3.235037 Tokens per Sec: 5401.335938
Epoch Step: 161 / 173 Loss: 3.411111 Tokens per Sec: 5486.194824
Epoch Step: 171 / 173 Loss: 3.539625 Tokens per Sec: 5411.190430
Epoch 1
Epoch Step: 1 / 173 Loss: 3.466316 Tokens per Sec: 5381.026367
Epoch Step: 11 / 173 Loss: 3.489893 Tokens per Sec: 5352.654785
Epoch Step: 21 / 173 Loss: 2.685488 Tokens per Sec: 5404.370117
Epoch Step: 31 / 173 Loss: 3.168634 Tokens per Sec: 5422.418457
Epoch Step: 41 / 173 Loss: 2.728146 Tokens per Sec: 5347.846680
Epoch Step: 51 / 173 Loss: 2.645779 Tokens per Sec: 5382.858398
Epoch Step: 61 / 173 Loss: 2.921784 Tokens per Sec: 5453.062500
Epoch Step: 71 / 173 Loss: 3.009420 Tokens per Sec: 5495.862305
Epoch Step: 81 / 173 Loss: 2.927124 Tokens per Sec: 5388.579590
Epoch Step: 91 / 173 Loss: 3.426927 Tokens per Sec: 5517.229492
Epoch Step: 101 / 173 Loss: 3.560334 Tokens per Sec: 5468.313477
Epoch Step: 111 / 173 Loss: 3.666295 Tokens per Sec: 5384.278809
Epoch Step: 121 / 173 Loss: 2.941808 Tokens per Sec: 5511.541016
Epoch Step: 131 / 173 Loss: 2.915550 Tokens per Sec: 5428.192383
Epoch Step: 141 / 173 Loss: 2.417211 Tokens per Sec: 5264.407227
Epoch Step: 151 / 173 Loss: 2.447340 Tokens per Sec: 5276.353027
Epoch Step: 161 / 173 Loss: 3.210042 Tokens per Sec: 5320.425781
Epoch Step: 171 / 173 Loss: 2.430115 Tokens per Sec: 5274.183594
Epoch 2
Epoch Step: 1 / 173 Loss: 3.518963 Tokens per Sec: 5536.436523
Epoch Step: 11 / 173 Loss: 3.146185 Tokens per Sec: 5338.354004
Epoch Step: 21 / 173 Loss: 3.173618 Tokens per Sec: 5425.030273
Epoch Step: 31 / 173 Loss: 2.307932 Tokens per Sec: 5281.718750
Epoch Step: 41 / 173 Loss: 2.678569 Tokens per Sec: 5335.123535
Epoch Step: 51 / 173 Loss: 2.730486 Tokens per Sec: 5297.306152
Epoch Step: 61 / 173 Loss: 3.400316 Tokens per Sec: 5443.464844
Epoch Step: 71 / 173 Loss: 2.868602 Tokens per Sec: 5372.101562
Epoch Step: 81 / 173 Loss: 3.353739 Tokens per Sec: 5352.032715
Epoch Step: 91 / 173 Loss: 2.388513 Tokens per Sec: 5371.491211
Epoch Step: 101 / 173 Loss: 2.318349 Tokens per Sec: 5321.503906
Epoch Step: 111 / 173 Loss: 3.053592 Tokens per Sec: 5387.759766
Epoch Step: 121 / 173 Loss: 3.364599 Tokens per Sec: 5352.338867
Epoch Step: 131 / 173 Loss: 2.247979 Tokens per Sec: 5170.335449
Epoch Step: 141 / 173 Loss: 3.717937 Tokens per Sec: 5387.597656
Epoch Step: 151 / 173 Loss: 3.329281 Tokens per Sec: 5315.607422
Epoch Step: 161 / 173 Loss: 3.149601 Tokens per Sec: 5441.989258
Epoch Step: 171 / 173 Loss: 3.204847 Tokens per Sec: 5460.666992
Epoch 3
Epoch Step: 1 / 173 Loss: 3.032425 Tokens per Sec: 5363.089355
Epoch Step: 11 / 173 Loss: 2.300077 Tokens per Sec: 5338.246582
Epoch Step: 21 / 173 Loss: 2.754936 Tokens per Sec: 5277.480469
Epoch Step: 31 / 173 Loss: 2.332437 Tokens per Sec: 5296.082520
Epoch Step: 41 / 173 Loss: 3.535856 Tokens per Sec: 5401.662109
Epoch Step: 51 / 173 Loss: 3.011068 Tokens per Sec: 5417.145508
Epoch Step: 61 / 173 Loss: 3.545446 Tokens per Sec: 5331.041016
Epoch Step: 71 / 173 Loss: 2.957291 Tokens per Sec: 5359.865234
Epoch Step: 81 / 173 Loss: 3.464225 Tokens per Sec: 5329.703125
Epoch Step: 91 / 173 Loss: 3.285911 Tokens per Sec: 5374.342285
Epoch Step: 101 / 173 Loss: 2.806142 Tokens per Sec: 5328.435059
Epoch Step: 111 / 173 Loss: 3.367499 Tokens per Sec: 5362.208984
Epoch Step: 121 / 173 Loss: 2.961358 Tokens per Sec: 5397.439941
Epoch Step: 131 / 173 Loss: 2.643751 Tokens per Sec: 5443.318848
Epoch Step: 141 / 173 Loss: 2.880951 Tokens per Sec: 5418.527832
Epoch Step: 151 / 173 Loss: 2.165620 Tokens per Sec: 5400.673340
Epoch Step: 161 / 173 Loss: 3.175308 Tokens per Sec: 5492.402832
Epoch Step: 171 / 173 Loss: 3.143007 Tokens per Sec: 5319.317383
Epoch 4
Epoch Step: 1 / 173 Loss: 2.891156 Tokens per Sec: 5580.092773
Epoch Step: 11 / 173 Loss: 2.654337 Tokens per Sec: 5452.907715
Epoch Step: 21 / 173 Loss: 2.759519 Tokens per Sec: 5396.183594
Epoch Step: 31 / 173 Loss: 3.111791 Tokens per Sec: 5330.957520
Epoch Step: 41 / 173 Loss: 3.477724 Tokens per Sec: 5325.328613
Epoch Step: 51 / 173 Loss: 2.421232 Tokens per Sec: 5333.524902
Epoch Step: 61 / 173 Loss: 3.001079 Tokens per Sec: 5437.179688
Epoch Step: 71 / 173 Loss: 2.681943 Tokens per Sec: 5370.840332
Epoch Step: 81 / 173 Loss: 3.129848 Tokens per Sec: 5387.927734
Epoch Step: 91 / 173 Loss: 3.534015 Tokens per Sec: 5400.132812
Epoch Step: 101 / 173 Loss: 3.148571 Tokens per Sec: 5428.801270
Epoch Step: 111 / 173 Loss: 3.337935 Tokens per Sec: 5350.626465
Epoch Step: 121 / 173 Loss: 2.991790 Tokens per Sec: 5273.458496
Epoch Step: 131 / 173 Loss: 2.922927 Tokens per Sec: 5418.724609
Epoch Step: 141 / 173 Loss: 3.018965 Tokens per Sec: 5229.950195
Epoch Step: 151 / 173 Loss: 2.273604 Tokens per Sec: 5375.797363
Epoch Step: 161 / 173 Loss: 2.989167 Tokens per Sec: 5304.297852
Epoch Step: 171 / 173 Loss: 2.083739 Tokens per Sec: 5332.263184
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10807.19it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.194641 Tokens per Sec: 5237.192383
Epoch Step: 11 / 173 Loss: 3.802303 Tokens per Sec: 5318.933594
Epoch Step: 21 / 173 Loss: 3.404074 Tokens per Sec: 5268.287109
Epoch Step: 31 / 173 Loss: 3.424200 Tokens per Sec: 5237.692383
Epoch Step: 41 / 173 Loss: 3.172154 Tokens per Sec: 5354.580566
Epoch Step: 51 / 173 Loss: 4.002326 Tokens per Sec: 5457.175781
Epoch Step: 61 / 173 Loss: 3.814949 Tokens per Sec: 5386.916992
Epoch Step: 71 / 173 Loss: 3.267171 Tokens per Sec: 5373.390137
Epoch Step: 81 / 173 Loss: 3.614060 Tokens per Sec: 5368.956055
Epoch Step: 91 / 173 Loss: 3.722820 Tokens per Sec: 5391.182129
Epoch Step: 101 / 173 Loss: 3.254459 Tokens per Sec: 5451.008789
Epoch Step: 111 / 173 Loss: 2.480947 Tokens per Sec: 5465.790039
Epoch Step: 121 / 173 Loss: 3.160195 Tokens per Sec: 5441.797363
Epoch Step: 131 / 173 Loss: 2.426476 Tokens per Sec: 5481.511230
Epoch Step: 141 / 173 Loss: 3.389704 Tokens per Sec: 5434.863281
Epoch Step: 151 / 173 Loss: 2.892499 Tokens per Sec: 5385.580566
Epoch Step: 161 / 173 Loss: 2.481787 Tokens per Sec: 5358.235840
Epoch Step: 171 / 173 Loss: 2.754398 Tokens per Sec: 5350.841797
Epoch 1
Epoch Step: 1 / 173 Loss: 3.470066 Tokens per Sec: 5484.551758
Epoch Step: 11 / 173 Loss: 3.174425 Tokens per Sec: 5433.124512
Epoch Step: 21 / 173 Loss: 3.472024 Tokens per Sec: 5348.187988
Epoch Step: 31 / 173 Loss: 3.321136 Tokens per Sec: 5434.444336
Epoch Step: 41 / 173 Loss: 3.678312 Tokens per Sec: 5326.926758
Epoch Step: 51 / 173 Loss: 2.362435 Tokens per Sec: 5315.563477
Epoch Step: 61 / 173 Loss: 2.655189 Tokens per Sec: 5455.364746
Epoch Step: 71 / 173 Loss: 3.504394 Tokens per Sec: 5445.629395
Epoch Step: 81 / 173 Loss: 3.632215 Tokens per Sec: 5339.400879
Epoch Step: 91 / 173 Loss: 3.123480 Tokens per Sec: 5338.646484
Epoch Step: 101 / 173 Loss: 3.111275 Tokens per Sec: 5339.923828
Epoch Step: 111 / 173 Loss: 2.417073 Tokens per Sec: 5385.676758
Epoch Step: 121 / 173 Loss: 2.924166 Tokens per Sec: 5417.213379
Epoch Step: 131 / 173 Loss: 2.662206 Tokens per Sec: 5401.562500
Epoch Step: 141 / 173 Loss: 3.625939 Tokens per Sec: 5530.541504
Epoch Step: 151 / 173 Loss: 3.249201 Tokens per Sec: 5424.789551
Epoch Step: 161 / 173 Loss: 3.060347 Tokens per Sec: 5288.092773
Epoch Step: 171 / 173 Loss: 2.634259 Tokens per Sec: 5385.253906
Epoch 2
Epoch Step: 1 / 173 Loss: 2.592786 Tokens per Sec: 5424.128418
Epoch Step: 11 / 173 Loss: 2.191669 Tokens per Sec: 5411.937012
Epoch Step: 21 / 173 Loss: 3.127479 Tokens per Sec: 5368.741211
Epoch Step: 31 / 173 Loss: 2.792314 Tokens per Sec: 5274.471680
Epoch Step: 41 / 173 Loss: 3.059475 Tokens per Sec: 5425.555664
Epoch Step: 51 / 173 Loss: 3.214341 Tokens per Sec: 5415.334961
Epoch Step: 61 / 173 Loss: 2.643857 Tokens per Sec: 5343.914062
Epoch Step: 71 / 173 Loss: 1.978115 Tokens per Sec: 5420.117188
Epoch Step: 81 / 173 Loss: 2.016902 Tokens per Sec: 5395.572266
Epoch Step: 91 / 173 Loss: 2.021786 Tokens per Sec: 5357.494629
Epoch Step: 101 / 173 Loss: 2.812747 Tokens per Sec: 5347.255859
Epoch Step: 111 / 173 Loss: 3.063861 Tokens per Sec: 5325.746582
Epoch Step: 121 / 173 Loss: 2.775584 Tokens per Sec: 5313.169922
Epoch Step: 131 / 173 Loss: 2.341985 Tokens per Sec: 5394.302246
Epoch Step: 141 / 173 Loss: 2.596205 Tokens per Sec: 5382.813965
Epoch Step: 151 / 173 Loss: 2.634454 Tokens per Sec: 5406.455566
Epoch Step: 161 / 173 Loss: 2.054790 Tokens per Sec: 5461.603516
Epoch Step: 171 / 173 Loss: 3.450967 Tokens per Sec: 5393.886230
Epoch 3
Epoch Step: 1 / 173 Loss: 2.721039 Tokens per Sec: 5465.854980
Epoch Step: 11 / 173 Loss: 1.872013 Tokens per Sec: 5361.664062
Epoch Step: 21 / 173 Loss: 2.636707 Tokens per Sec: 5388.641602
Epoch Step: 31 / 173 Loss: 1.838297 Tokens per Sec: 5422.009766
Epoch Step: 41 / 173 Loss: 2.198691 Tokens per Sec: 5371.120117
Epoch Step: 51 / 173 Loss: 2.569885 Tokens per Sec: 5353.154297
Epoch Step: 61 / 173 Loss: 2.151865 Tokens per Sec: 5324.376953
Epoch Step: 71 / 173 Loss: 2.623931 Tokens per Sec: 5353.805664
Epoch Step: 81 / 173 Loss: 3.166364 Tokens per Sec: 5440.129395
Epoch Step: 91 / 173 Loss: 1.894662 Tokens per Sec: 5298.411621
Epoch Step: 101 / 173 Loss: 2.768433 Tokens per Sec: 5467.826172
Epoch Step: 111 / 173 Loss: 1.962238 Tokens per Sec: 5185.871094
Epoch Step: 121 / 173 Loss: 1.677285 Tokens per Sec: 5399.870117
Epoch Step: 131 / 173 Loss: 1.648435 Tokens per Sec: 5441.738770
Epoch Step: 141 / 173 Loss: 2.525101 Tokens per Sec: 5446.354004
Epoch Step: 151 / 173 Loss: 2.451664 Tokens per Sec: 5463.461914
Epoch Step: 161 / 173 Loss: 2.599097 Tokens per Sec: 5405.204590
Epoch Step: 171 / 173 Loss: 2.089526 Tokens per Sec: 5321.216309
Epoch 4
Epoch Step: 1 / 173 Loss: 2.952290 Tokens per Sec: 5179.667480
Epoch Step: 11 / 173 Loss: 1.953931 Tokens per Sec: 5427.990234
Epoch Step: 21 / 173 Loss: 2.790173 Tokens per Sec: 5456.394531
Epoch Step: 31 / 173 Loss: 1.444052 Tokens per Sec: 5505.437012
Epoch Step: 41 / 173 Loss: 1.316016 Tokens per Sec: 5442.546387
Epoch Step: 51 / 173 Loss: 1.479888 Tokens per Sec: 5350.009277
Epoch Step: 61 / 173 Loss: 1.442152 Tokens per Sec: 5359.014648
Epoch Step: 71 / 173 Loss: 2.175665 Tokens per Sec: 5396.393066
Epoch Step: 81 / 173 Loss: 2.630667 Tokens per Sec: 5329.076172
Epoch Step: 91 / 173 Loss: 1.466802 Tokens per Sec: 5256.177734
Epoch Step: 101 / 173 Loss: 1.507042 Tokens per Sec: 5406.884277
Epoch Step: 111 / 173 Loss: 0.945893 Tokens per Sec: 5327.952148
Epoch Step: 121 / 173 Loss: 2.700194 Tokens per Sec: 5381.606445
Epoch Step: 131 / 173 Loss: 3.043091 Tokens per Sec: 5403.376953
Epoch Step: 141 / 173 Loss: 2.940624 Tokens per Sec: 5373.628418
Epoch Step: 151 / 173 Loss: 2.371980 Tokens per Sec: 5374.686035
Epoch Step: 161 / 173 Loss: 1.450154 Tokens per Sec: 5390.655273
Epoch Step: 171 / 173 Loss: 2.504329 Tokens per Sec: 5368.855957
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11011.75it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 20:07:53.590678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.590920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.591980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.592158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.592313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.592463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.592840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:07:53.657990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.658190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.658346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.658481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.658611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:53.658741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.040658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.040869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.041027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.041164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.041296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.041419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10883 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:07:54.041817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:07:54.041927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22327 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Epoch 0
Epoch Step: 1 / 173 Loss: 6.586740 Tokens per Sec: 5394.757812
Epoch Step: 11 / 173 Loss: 3.826428 Tokens per Sec: 5146.204102
Epoch Step: 21 / 173 Loss: 3.793367 Tokens per Sec: 5276.067383
Epoch Step: 31 / 173 Loss: 4.256355 Tokens per Sec: 5375.418457
Epoch Step: 41 / 173 Loss: 3.508960 Tokens per Sec: 5372.690918
Epoch Step: 51 / 173 Loss: 3.367573 Tokens per Sec: 5407.399902
Epoch Step: 61 / 173 Loss: 3.280999 Tokens per Sec: 5341.263672
Epoch Step: 71 / 173 Loss: 3.417769 Tokens per Sec: 5437.913574
Epoch Step: 81 / 173 Loss: 3.629044 Tokens per Sec: 5402.876465
Epoch Step: 91 / 173 Loss: 3.755396 Tokens per Sec: 5403.969238
Epoch Step: 101 / 173 Loss: 3.495573 Tokens per Sec: 5297.315430
Epoch Step: 111 / 173 Loss: 3.435251 Tokens per Sec: 5330.213867
Epoch Step: 121 / 173 Loss: 3.041333 Tokens per Sec: 5290.425781
Epoch Step: 131 / 173 Loss: 2.443200 Tokens per Sec: 5370.499512
Epoch Step: 141 / 173 Loss: 2.949100 Tokens per Sec: 5426.042969
Epoch Step: 151 / 173 Loss: 3.593511 Tokens per Sec: 5282.990234
Epoch Step: 161 / 173 Loss: 2.848682 Tokens per Sec: 5379.748535
Epoch Step: 171 / 173 Loss: 2.678208 Tokens per Sec: 5409.079102
Epoch 1
Epoch Step: 1 / 173 Loss: 2.939589 Tokens per Sec: 5232.825684
Epoch Step: 11 / 173 Loss: 3.183508 Tokens per Sec: 5326.811523
Epoch Step: 21 / 173 Loss: 2.564925 Tokens per Sec: 5211.730957
Epoch Step: 31 / 173 Loss: 3.666078 Tokens per Sec: 5331.039062
Epoch Step: 41 / 173 Loss: 3.001569 Tokens per Sec: 5432.092773
Epoch Step: 51 / 173 Loss: 3.388008 Tokens per Sec: 5350.367676
Epoch Step: 61 / 173 Loss: 3.194175 Tokens per Sec: 5347.121094
Epoch Step: 71 / 173 Loss: 3.183053 Tokens per Sec: 5370.342285
Epoch Step: 81 / 173 Loss: 3.254478 Tokens per Sec: 5288.945801
Epoch Step: 91 / 173 Loss: 2.471814 Tokens per Sec: 5340.600098
Epoch Step: 101 / 173 Loss: 3.544769 Tokens per Sec: 5460.690430
Epoch Step: 111 / 173 Loss: 2.583230 Tokens per Sec: 5386.628418
Epoch Step: 121 / 173 Loss: 3.258833 Tokens per Sec: 5412.552734
Epoch Step: 131 / 173 Loss: 3.371089 Tokens per Sec: 5365.336426
Epoch Step: 141 / 173 Loss: 2.719842 Tokens per Sec: 5391.020020
Epoch Step: 151 / 173 Loss: 2.345170 Tokens per Sec: 5370.822266
Epoch Step: 161 / 173 Loss: 2.365213 Tokens per Sec: 5392.788086
Epoch Step: 171 / 173 Loss: 3.154598 Tokens per Sec: 5299.623535
Epoch 2
Epoch Step: 1 / 173 Loss: 3.185775 Tokens per Sec: 5493.589844
Epoch Step: 11 / 173 Loss: 2.157925 Tokens per Sec: 5246.301758
Epoch Step: 21 / 173 Loss: 2.459367 Tokens per Sec: 5277.901367
Epoch Step: 31 / 173 Loss: 3.548826 Tokens per Sec: 5357.063477
Epoch Step: 41 / 173 Loss: 3.297112 Tokens per Sec: 5360.607910
Epoch Step: 51 / 173 Loss: 3.808409 Tokens per Sec: 5446.917480
Epoch Step: 61 / 173 Loss: 2.922442 Tokens per Sec: 5374.509766
Epoch Step: 71 / 173 Loss: 2.970008 Tokens per Sec: 5309.559082
Epoch Step: 81 / 173 Loss: 3.832729 Tokens per Sec: 5320.944336
Epoch Step: 91 / 173 Loss: 2.221889 Tokens per Sec: 5336.381348
Epoch Step: 101 / 173 Loss: 2.797820 Tokens per Sec: 5374.711426
Epoch Step: 111 / 173 Loss: 2.985645 Tokens per Sec: 5382.702148
Epoch Step: 121 / 173 Loss: 3.335127 Tokens per Sec: 5401.866699
Epoch Step: 131 / 173 Loss: 2.373647 Tokens per Sec: 5312.735840
Epoch Step: 141 / 173 Loss: 3.455212 Tokens per Sec: 5328.334473
Epoch Step: 151 / 173 Loss: 2.226772 Tokens per Sec: 5295.389160
Epoch Step: 161 / 173 Loss: 2.799870 Tokens per Sec: 5358.554199
Epoch Step: 171 / 173 Loss: 3.514841 Tokens per Sec: 5468.410156
Epoch 3
Epoch Step: 1 / 173 Loss: 2.414903 Tokens per Sec: 5234.070801
Epoch Step: 11 / 173 Loss: 2.729935 Tokens per Sec: 5380.171387
Epoch Step: 21 / 173 Loss: 2.434959 Tokens per Sec: 5327.914551
Epoch Step: 31 / 173 Loss: 3.182148 Tokens per Sec: 5257.959473
Epoch Step: 41 / 173 Loss: 2.610682 Tokens per Sec: 5254.589355
Epoch Step: 51 / 173 Loss: 2.980644 Tokens per Sec: 5332.036133
Epoch Step: 61 / 173 Loss: 2.026002 Tokens per Sec: 5316.132812
Epoch Step: 71 / 173 Loss: 2.362488 Tokens per Sec: 5407.575195
Epoch Step: 81 / 173 Loss: 2.798403 Tokens per Sec: 5299.259277
Epoch Step: 91 / 173 Loss: 2.426978 Tokens per Sec: 5339.530762
Epoch Step: 101 / 173 Loss: 2.402441 Tokens per Sec: 5018.685059
Epoch Step: 111 / 173 Loss: 2.994294 Tokens per Sec: 5154.229492
Epoch Step: 121 / 173 Loss: 2.979330 Tokens per Sec: 5366.338379
Epoch Step: 131 / 173 Loss: 2.839107 Tokens per Sec: 5387.536621
Epoch Step: 141 / 173 Loss: 2.408738 Tokens per Sec: 5309.224121
Epoch Step: 151 / 173 Loss: 2.929377 Tokens per Sec: 5422.581055
Epoch Step: 161 / 173 Loss: 2.946285 Tokens per Sec: 5382.264648
Epoch Step: 171 / 173 Loss: 2.430085 Tokens per Sec: 5392.055664
Epoch 4
Epoch Step: 1 / 173 Loss: 2.313690 Tokens per Sec: 5254.374023
Epoch Step: 11 / 173 Loss: 3.118774 Tokens per Sec: 5343.252441
Epoch Step: 21 / 173 Loss: 2.336006 Tokens per Sec: 5362.151367
Epoch Step: 31 / 173 Loss: 3.534165 Tokens per Sec: 5536.506348
Epoch Step: 41 / 173 Loss: 2.708168 Tokens per Sec: 5332.696777
Epoch Step: 51 / 173 Loss: 2.876362 Tokens per Sec: 5119.822754
Epoch Step: 61 / 173 Loss: 3.170900 Tokens per Sec: 5349.460938
Epoch Step: 71 / 173 Loss: 3.017635 Tokens per Sec: 5386.812012
Epoch Step: 81 / 173 Loss: 2.844064 Tokens per Sec: 5401.953125
Epoch Step: 91 / 173 Loss: 2.979468 Tokens per Sec: 5285.892578
Epoch Step: 101 / 173 Loss: 3.158173 Tokens per Sec: 5285.461426
Epoch Step: 111 / 173 Loss: 2.098524 Tokens per Sec: 5330.082031
Epoch Step: 121 / 173 Loss: 2.926681 Tokens per Sec: 5367.646484
Epoch Step: 131 / 173 Loss: 2.574022 Tokens per Sec: 5296.357422
Epoch Step: 141 / 173 Loss: 2.394996 Tokens per Sec: 5446.007812
Epoch Step: 151 / 173 Loss: 2.807573 Tokens per Sec: 5375.939453
Epoch Step: 161 / 173 Loss: 3.063888 Tokens per Sec: 5388.291992
Epoch Step: 171 / 173 Loss: 2.306935 Tokens per Sec: 5247.884277
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12741.13it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13671.57it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13167.67it/s]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.190756]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.126363]
Processed 100.0% of log lines.
Parsing done. [Time taken: 0:00:00.095397]
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 11718.74it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.131082 Tokens per Sec: 5144.753418
Epoch Step: 11 / 173 Loss: 3.731776 Tokens per Sec: 5329.126953
Epoch Step: 21 / 173 Loss: 3.935227 Tokens per Sec: 5451.081055
Epoch Step: 31 / 173 Loss: 3.822073 Tokens per Sec: 5469.825684
Epoch Step: 41 / 173 Loss: 3.766991 Tokens per Sec: 5395.105469
Epoch Step: 51 / 173 Loss: 3.534909 Tokens per Sec: 5393.391113
Epoch Step: 61 / 173 Loss: 3.038650 Tokens per Sec: 5291.205566
Epoch Step: 71 / 173 Loss: 3.621464 Tokens per Sec: 5379.053711
Epoch Step: 81 / 173 Loss: 3.106925 Tokens per Sec: 5323.991211
Epoch Step: 91 / 173 Loss: 2.915304 Tokens per Sec: 5354.608398
Epoch Step: 101 / 173 Loss: 2.981459 Tokens per Sec: 5414.897949
Epoch Step: 111 / 173 Loss: 3.128831 Tokens per Sec: 5422.624512
Epoch Step: 121 / 173 Loss: 2.805523 Tokens per Sec: 5265.410645
Epoch Step: 131 / 173 Loss: 2.828173 Tokens per Sec: 5319.437500
Epoch Step: 141 / 173 Loss: 2.775884 Tokens per Sec: 5332.008301
Epoch Step: 151 / 173 Loss: 2.746968 Tokens per Sec: 5452.945312
Epoch Step: 161 / 173 Loss: 2.762067 Tokens per Sec: 5315.978027
Epoch Step: 171 / 173 Loss: 3.393774 Tokens per Sec: 5410.919434
Epoch 1
Epoch Step: 1 / 173 Loss: 3.633523 Tokens per Sec: 4968.106934
Epoch Step: 11 / 173 Loss: 3.060786 Tokens per Sec: 5383.296387
Epoch Step: 21 / 173 Loss: 3.246349 Tokens per Sec: 5389.418945
Epoch Step: 31 / 173 Loss: 2.866095 Tokens per Sec: 5366.389160
Epoch Step: 41 / 173 Loss: 2.123050 Tokens per Sec: 5379.863281
Epoch Step: 51 / 173 Loss: 2.461495 Tokens per Sec: 5270.326660
Epoch Step: 61 / 173 Loss: 3.046979 Tokens per Sec: 5426.508301
Epoch Step: 71 / 173 Loss: 2.797654 Tokens per Sec: 5315.649414
Epoch Step: 81 / 173 Loss: 3.549958 Tokens per Sec: 5350.389648
Epoch Step: 91 / 173 Loss: 2.460412 Tokens per Sec: 5390.232910
Epoch Step: 101 / 173 Loss: 2.903933 Tokens per Sec: 5373.889160
Epoch Step: 111 / 173 Loss: 2.323309 Tokens per Sec: 5361.180176
Epoch Step: 121 / 173 Loss: 2.372211 Tokens per Sec: 5428.343750
Epoch Step: 131 / 173 Loss: 3.068180 Tokens per Sec: 5438.305176
Epoch Step: 141 / 173 Loss: 2.248375 Tokens per Sec: 5455.477539
Epoch Step: 151 / 173 Loss: 3.348452 Tokens per Sec: 5355.167969
Epoch Step: 161 / 173 Loss: 3.009456 Tokens per Sec: 5414.899902
Epoch Step: 171 / 173 Loss: 3.171233 Tokens per Sec: 5390.186035
Epoch 2
Epoch Step: 1 / 173 Loss: 3.361394 Tokens per Sec: 5346.783691
Epoch Step: 11 / 173 Loss: 2.516325 Tokens per Sec: 5458.177246
Epoch Step: 21 / 173 Loss: 2.539571 Tokens per Sec: 5321.020996
Epoch Step: 31 / 173 Loss: 2.815587 Tokens per Sec: 5466.262695
Epoch Step: 41 / 173 Loss: 1.884398 Tokens per Sec: 5217.851562
Epoch Step: 51 / 173 Loss: 2.164431 Tokens per Sec: 5388.213867
Epoch Step: 61 / 173 Loss: 3.375689 Tokens per Sec: 5306.235352
Epoch Step: 71 / 173 Loss: 2.134211 Tokens per Sec: 5304.227539
Epoch Step: 81 / 173 Loss: 3.034954 Tokens per Sec: 5304.718750
Epoch Step: 91 / 173 Loss: 3.672974 Tokens per Sec: 4767.698730
Epoch Step: 101 / 173 Loss: 3.285059 Tokens per Sec: 5409.123535
Epoch Step: 111 / 173 Loss: 3.050808 Tokens per Sec: 5394.158203
Epoch Step: 121 / 173 Loss: 2.583733 Tokens per Sec: 5280.946289
Epoch Step: 131 / 173 Loss: 3.042276 Tokens per Sec: 5457.395996
Epoch Step: 141 / 173 Loss: 2.663216 Tokens per Sec: 5414.405273
Epoch Step: 151 / 173 Loss: 2.960033 Tokens per Sec: 5413.193359
Epoch Step: 161 / 173 Loss: 3.142611 Tokens per Sec: 5463.820801
Epoch Step: 171 / 173 Loss: 3.080620 Tokens per Sec: 5406.775879
Epoch 3
Epoch Step: 1 / 173 Loss: 2.755199 Tokens per Sec: 5300.764648
Epoch Step: 11 / 173 Loss: 2.259241 Tokens per Sec: 5446.770508
Epoch Step: 21 / 173 Loss: 3.106458 Tokens per Sec: 5480.703613
Epoch Step: 31 / 173 Loss: 2.226007 Tokens per Sec: 5347.839355
Epoch Step: 41 / 173 Loss: 1.956773 Tokens per Sec: 5265.347656
Epoch Step: 51 / 173 Loss: 3.420367 Tokens per Sec: 5441.106445
Epoch Step: 61 / 173 Loss: 2.622930 Tokens per Sec: 5425.088379
Epoch Step: 71 / 173 Loss: 2.012080 Tokens per Sec: 5326.709961
Epoch Step: 81 / 173 Loss: 2.539122 Tokens per Sec: 5403.318359
Epoch Step: 91 / 173 Loss: 2.191771 Tokens per Sec: 5325.790527
Epoch Step: 101 / 173 Loss: 2.301012 Tokens per Sec: 5316.727051
Epoch Step: 111 / 173 Loss: 1.953719 Tokens per Sec: 5365.045410
Epoch Step: 121 / 173 Loss: 2.634125 Tokens per Sec: 5378.859375
Epoch Step: 131 / 173 Loss: 2.503635 Tokens per Sec: 5347.852051
Epoch Step: 141 / 173 Loss: 2.964549 Tokens per Sec: 5372.153320
Epoch Step: 151 / 173 Loss: 2.184629 Tokens per Sec: 5378.646484
Epoch Step: 161 / 173 Loss: 3.297135 Tokens per Sec: 5424.447266
Epoch Step: 171 / 173 Loss: 2.880515 Tokens per Sec: 5394.942383
Epoch 4
Epoch Step: 1 / 173 Loss: 2.268571 Tokens per Sec: 5471.842773
Epoch Step: 11 / 173 Loss: 2.644408 Tokens per Sec: 5402.550781
Epoch Step: 21 / 173 Loss: 2.611265 Tokens per Sec: 5253.063477
Epoch Step: 31 / 173 Loss: 2.103224 Tokens per Sec: 5322.325195
Epoch Step: 41 / 173 Loss: 2.880565 Tokens per Sec: 5484.571777
Epoch Step: 51 / 173 Loss: 1.877080 Tokens per Sec: 5405.133789
Epoch Step: 61 / 173 Loss: 2.666411 Tokens per Sec: 5329.477539
Epoch Step: 71 / 173 Loss: 3.103093 Tokens per Sec: 5372.673340
Epoch Step: 81 / 173 Loss: 1.981359 Tokens per Sec: 5284.148926
Epoch Step: 91 / 173 Loss: 2.296101 Tokens per Sec: 5183.246094
Epoch Step: 101 / 173 Loss: 2.362965 Tokens per Sec: 5300.216797
Epoch Step: 111 / 173 Loss: 2.648743 Tokens per Sec: 5295.425293
Epoch Step: 121 / 173 Loss: 3.222499 Tokens per Sec: 4817.245605
Epoch Step: 131 / 173 Loss: 2.834996 Tokens per Sec: 5445.051270
Epoch Step: 141 / 173 Loss: 2.680692 Tokens per Sec: 5409.175293
Epoch Step: 151 / 173 Loss: 2.851885 Tokens per Sec: 5444.060547
Epoch Step: 161 / 173 Loss: 2.334140 Tokens per Sec: 5388.206543
Epoch Step: 171 / 173 Loss: 2.835523 Tokens per Sec: 5377.318848
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10937.39it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.198821 Tokens per Sec: 4905.575684
Epoch Step: 11 / 173 Loss: 4.300676 Tokens per Sec: 5330.064453
Epoch Step: 21 / 173 Loss: 3.045460 Tokens per Sec: 5373.186523
Epoch Step: 31 / 173 Loss: 3.571107 Tokens per Sec: 5391.633789
Epoch Step: 41 / 173 Loss: 3.535074 Tokens per Sec: 5399.474609
Epoch Step: 51 / 173 Loss: 3.363234 Tokens per Sec: 5481.127441
Epoch Step: 61 / 173 Loss: 2.868993 Tokens per Sec: 5434.831055
Epoch Step: 71 / 173 Loss: 4.183610 Tokens per Sec: 5487.055176
Epoch Step: 81 / 173 Loss: 3.125044 Tokens per Sec: 5287.213379
Epoch Step: 91 / 173 Loss: 3.110804 Tokens per Sec: 5457.799316
Epoch Step: 101 / 173 Loss: 3.404287 Tokens per Sec: 5353.329590
Epoch Step: 111 / 173 Loss: 3.063574 Tokens per Sec: 5358.596680
Epoch Step: 121 / 173 Loss: 3.205396 Tokens per Sec: 5382.592773
Epoch Step: 131 / 173 Loss: 2.881467 Tokens per Sec: 5335.616699
Epoch Step: 141 / 173 Loss: 2.868836 Tokens per Sec: 5465.828125
Epoch Step: 151 / 173 Loss: 3.816951 Tokens per Sec: 5359.274902
Epoch Step: 161 / 173 Loss: 2.550832 Tokens per Sec: 5328.458008
Epoch Step: 171 / 173 Loss: 3.163367 Tokens per Sec: 5364.698242
Epoch 1
Epoch Step: 1 / 173 Loss: 3.637400 Tokens per Sec: 5477.304688
Epoch Step: 11 / 173 Loss: 3.681951 Tokens per Sec: 5424.103516
Epoch Step: 21 / 173 Loss: 3.658911 Tokens per Sec: 5380.414551
Epoch Step: 31 / 173 Loss: 2.508452 Tokens per Sec: 5351.296875
Epoch Step: 41 / 173 Loss: 3.610915 Tokens per Sec: 5398.008789
Epoch Step: 51 / 173 Loss: 3.177392 Tokens per Sec: 5402.805176
Epoch Step: 61 / 173 Loss: 2.948711 Tokens per Sec: 5245.645996
Epoch Step: 71 / 173 Loss: 3.440361 Tokens per Sec: 5330.058594
Epoch Step: 81 / 173 Loss: 2.427361 Tokens per Sec: 5470.188477
Epoch Step: 91 / 173 Loss: 3.488297 Tokens per Sec: 5471.629395
Epoch Step: 101 / 173 Loss: 3.239536 Tokens per Sec: 5391.959473
Epoch Step: 111 / 173 Loss: 2.495102 Tokens per Sec: 5301.951660
Epoch Step: 121 / 173 Loss: 3.067171 Tokens per Sec: 5373.274414
Epoch Step: 131 / 173 Loss: 3.207727 Tokens per Sec: 5458.765137
Epoch Step: 141 / 173 Loss: 2.635121 Tokens per Sec: 5476.875000
Epoch Step: 151 / 173 Loss: 2.580592 Tokens per Sec: 5426.141602
Epoch Step: 161 / 173 Loss: 3.137171 Tokens per Sec: 5316.999023
Epoch Step: 171 / 173 Loss: 2.526508 Tokens per Sec: 5240.563965
Epoch 2
Epoch Step: 1 / 173 Loss: 3.070347 Tokens per Sec: 5417.916016
Epoch Step: 11 / 173 Loss: 2.977918 Tokens per Sec: 5401.427246
Epoch Step: 21 / 173 Loss: 3.240709 Tokens per Sec: 5449.971680
Epoch Step: 31 / 173 Loss: 2.449659 Tokens per Sec: 5361.036621
Epoch Step: 41 / 173 Loss: 2.901386 Tokens per Sec: 5418.638184
Epoch Step: 51 / 173 Loss: 2.551372 Tokens per Sec: 5385.501953
Epoch Step: 61 / 173 Loss: 2.905819 Tokens per Sec: 5415.609375
Epoch Step: 71 / 173 Loss: 2.308271 Tokens per Sec: 5389.646484
Epoch Step: 81 / 173 Loss: 2.283624 Tokens per Sec: 5364.885742
Epoch Step: 91 / 173 Loss: 2.250959 Tokens per Sec: 5405.718750
Epoch Step: 101 / 173 Loss: 2.048194 Tokens per Sec: 5365.584961
Epoch Step: 111 / 173 Loss: 3.274863 Tokens per Sec: 5446.177734
Epoch Step: 121 / 173 Loss: 3.505128 Tokens per Sec: 5327.455078
Epoch Step: 131 / 173 Loss: 2.586987 Tokens per Sec: 5479.096191
Epoch Step: 141 / 173 Loss: 3.107613 Tokens per Sec: 5398.908691
Epoch Step: 151 / 173 Loss: 2.509016 Tokens per Sec: 5387.461914
Epoch Step: 161 / 173 Loss: 2.589360 Tokens per Sec: 5274.180664
Epoch Step: 171 / 173 Loss: 2.739346 Tokens per Sec: 5256.104004
Epoch 3
Epoch Step: 1 / 173 Loss: 2.343771 Tokens per Sec: 5212.988770
Epoch Step: 11 / 173 Loss: 2.258386 Tokens per Sec: 5401.962402
Epoch Step: 21 / 173 Loss: 2.408965 Tokens per Sec: 5381.789062
Epoch Step: 31 / 173 Loss: 2.439578 Tokens per Sec: 5472.798828
Epoch Step: 41 / 173 Loss: 3.120558 Tokens per Sec: 5430.357422
Epoch Step: 51 / 173 Loss: 3.087269 Tokens per Sec: 5307.679688
Epoch Step: 61 / 173 Loss: 2.316808 Tokens per Sec: 5372.513184
Epoch Step: 71 / 173 Loss: 2.324523 Tokens per Sec: 5317.646484
Epoch Step: 81 / 173 Loss: 2.051094 Tokens per Sec: 5304.359375
Epoch Step: 91 / 173 Loss: 2.060047 Tokens per Sec: 5356.397949
Epoch Step: 101 / 173 Loss: 2.965835 Tokens per Sec: 5370.824707
Epoch Step: 111 / 173 Loss: 2.335203 Tokens per Sec: 5402.455566
Epoch Step: 121 / 173 Loss: 3.371094 Tokens per Sec: 5407.910645
Epoch Step: 131 / 173 Loss: 3.430333 Tokens per Sec: 5434.319824
Epoch Step: 141 / 173 Loss: 2.772293 Tokens per Sec: 5313.043945
Epoch Step: 151 / 173 Loss: 2.744382 Tokens per Sec: 5342.292480
Epoch Step: 161 / 173 Loss: 3.679237 Tokens per Sec: 5245.732910
Epoch Step: 171 / 173 Loss: 2.982706 Tokens per Sec: 5389.712402
Epoch 4
Epoch Step: 1 / 173 Loss: 2.035006 Tokens per Sec: 5164.797852
Epoch Step: 11 / 173 Loss: 2.189029 Tokens per Sec: 5354.558105
Epoch Step: 21 / 173 Loss: 2.939082 Tokens per Sec: 5378.517578
Epoch Step: 31 / 173 Loss: 2.465551 Tokens per Sec: 5313.475586
Epoch Step: 41 / 173 Loss: 2.901864 Tokens per Sec: 5409.617676
Epoch Step: 51 / 173 Loss: 3.211632 Tokens per Sec: 5442.833496
Epoch Step: 61 / 173 Loss: 3.079211 Tokens per Sec: 5390.220703
Epoch Step: 71 / 173 Loss: 2.750481 Tokens per Sec: 5361.244629
Epoch Step: 81 / 173 Loss: 2.704556 Tokens per Sec: 5413.988281
Epoch Step: 91 / 173 Loss: 2.867924 Tokens per Sec: 5365.140625
Epoch Step: 101 / 173 Loss: 3.258429 Tokens per Sec: 5359.944824
Epoch Step: 111 / 173 Loss: 2.849334 Tokens per Sec: 5343.303223
Epoch Step: 121 / 173 Loss: 3.181814 Tokens per Sec: 5377.838867
Epoch Step: 131 / 173 Loss: 2.453598 Tokens per Sec: 5302.058105
Epoch Step: 141 / 173 Loss: 2.208974 Tokens per Sec: 5284.150391
Epoch Step: 151 / 173 Loss: 2.964340 Tokens per Sec: 5398.613281
Epoch Step: 161 / 173 Loss: 3.261210 Tokens per Sec: 5503.851562
Epoch Step: 171 / 173 Loss: 2.982194 Tokens per Sec: 4277.967773
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
  0%|          | 0/863 [00:00<?, ?it/s]100%|██████████| 863/863 [00:00<00:00, 10874.66it/s]
/home/i40/pacev/Domain-Guided-Monitoring/src/features/preprocessing/nulog.py:745: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(p)
Epoch 0
Epoch Step: 1 / 173 Loss: 6.031300 Tokens per Sec: 5004.023926
Epoch Step: 11 / 173 Loss: 3.813618 Tokens per Sec: 5150.221191
Epoch Step: 21 / 173 Loss: 3.970090 Tokens per Sec: 5289.004883
Epoch Step: 31 / 173 Loss: 3.853893 Tokens per Sec: 4941.624023
Epoch Step: 41 / 173 Loss: 3.141693 Tokens per Sec: 5083.151855
Epoch Step: 51 / 173 Loss: 3.859478 Tokens per Sec: 5184.571289
Epoch Step: 61 / 173 Loss: 3.123569 Tokens per Sec: 5134.952148
Epoch Step: 71 / 173 Loss: 2.768066 Tokens per Sec: 5205.608887
Epoch Step: 81 / 173 Loss: 3.812531 Tokens per Sec: 5194.530273
Epoch Step: 91 / 173 Loss: 3.185525 Tokens per Sec: 5157.988770
Epoch Step: 101 / 173 Loss: 3.021845 Tokens per Sec: 5137.939453
Epoch Step: 111 / 173 Loss: 2.963013 Tokens per Sec: 5103.196289
Epoch Step: 121 / 173 Loss: 3.476504 Tokens per Sec: 5043.772461
Epoch Step: 131 / 173 Loss: 2.401659 Tokens per Sec: 5256.301270
Epoch Step: 141 / 173 Loss: 3.465366 Tokens per Sec: 4930.388184
Epoch Step: 151 / 173 Loss: 3.796294 Tokens per Sec: 5190.820312
Epoch Step: 161 / 173 Loss: 2.811181 Tokens per Sec: 4996.912109
Epoch Step: 171 / 173 Loss: 2.586257 Tokens per Sec: 5074.763184
Epoch 1
Epoch Step: 1 / 173 Loss: 2.459829 Tokens per Sec: 5104.810547
Epoch Step: 11 / 173 Loss: 2.939189 Tokens per Sec: 5102.791504
Epoch Step: 21 / 173 Loss: 3.757594 Tokens per Sec: 5199.583984
Epoch Step: 31 / 173 Loss: 2.667982 Tokens per Sec: 5178.952637
Epoch Step: 41 / 173 Loss: 2.936235 Tokens per Sec: 5217.312988
Epoch Step: 51 / 173 Loss: 2.146659 Tokens per Sec: 5331.293457
Epoch Step: 61 / 173 Loss: 2.469311 Tokens per Sec: 5248.105957
Epoch Step: 71 / 173 Loss: 2.756414 Tokens per Sec: 5470.264648
Epoch Step: 81 / 173 Loss: 3.445403 Tokens per Sec: 5358.937988
Epoch Step: 91 / 173 Loss: 2.502998 Tokens per Sec: 5377.273438
Epoch Step: 101 / 173 Loss: 2.308136 Tokens per Sec: 5342.717285
Epoch Step: 111 / 173 Loss: 1.940306 Tokens per Sec: 5352.558105
Epoch Step: 121 / 173 Loss: 1.798180 Tokens per Sec: 5427.352051
Epoch Step: 131 / 173 Loss: 2.676176 Tokens per Sec: 5299.670410
Epoch Step: 141 / 173 Loss: 2.871108 Tokens per Sec: 5359.173340
Epoch Step: 151 / 173 Loss: 2.547827 Tokens per Sec: 5441.025879
Epoch Step: 161 / 173 Loss: 1.838826 Tokens per Sec: 5365.915039
Epoch Step: 171 / 173 Loss: 2.800865 Tokens per Sec: 5464.369141
Epoch 2
Epoch Step: 1 / 173 Loss: 2.314374 Tokens per Sec: 5222.606934
Epoch Step: 11 / 173 Loss: 3.430936 Tokens per Sec: 5417.556641
Epoch Step: 21 / 173 Loss: 1.769969 Tokens per Sec: 5403.528809
Epoch Step: 31 / 173 Loss: 2.057359 Tokens per Sec: 5365.394043
Epoch Step: 41 / 173 Loss: 3.127277 Tokens per Sec: 5339.091797
Epoch Step: 51 / 173 Loss: 2.564328 Tokens per Sec: 5380.311523
Epoch Step: 61 / 173 Loss: 2.324009 Tokens per Sec: 5395.294922
Epoch Step: 71 / 173 Loss: 2.473484 Tokens per Sec: 5359.012695
Epoch Step: 81 / 173 Loss: 1.844618 Tokens per Sec: 5232.666992
Epoch Step: 91 / 173 Loss: 2.303493 Tokens per Sec: 5397.273438
Epoch Step: 101 / 173 Loss: 3.153861 Tokens per Sec: 5460.542480
Epoch Step: 111 / 173 Loss: 3.343642 Tokens per Sec: 5453.088867
Epoch Step: 121 / 173 Loss: 2.390957 Tokens per Sec: 5396.536621
Epoch Step: 131 / 173 Loss: 1.673341 Tokens per Sec: 5226.023438
Epoch Step: 141 / 173 Loss: 2.942317 Tokens per Sec: 5422.219238
Epoch Step: 151 / 173 Loss: 2.453766 Tokens per Sec: 5367.635742
Epoch Step: 161 / 173 Loss: 2.248619 Tokens per Sec: 5454.141113
Epoch Step: 171 / 173 Loss: 2.677457 Tokens per Sec: 5413.393555
Epoch 3
Epoch Step: 1 / 173 Loss: 2.673226 Tokens per Sec: 5512.329102
Epoch Step: 11 / 173 Loss: 2.725044 Tokens per Sec: 5284.506836
Epoch Step: 21 / 173 Loss: 2.672213 Tokens per Sec: 5422.028809
Epoch Step: 31 / 173 Loss: 2.725440 Tokens per Sec: 5388.700684
Epoch Step: 41 / 173 Loss: 1.709982 Tokens per Sec: 5342.771484
Epoch Step: 51 / 173 Loss: 2.769634 Tokens per Sec: 5454.397949
Epoch Step: 61 / 173 Loss: 2.481476 Tokens per Sec: 5471.405273
Epoch Step: 71 / 173 Loss: 1.471065 Tokens per Sec: 5291.870117
Epoch Step: 81 / 173 Loss: 1.356461 Tokens per Sec: 5507.097656
Epoch Step: 91 / 173 Loss: 2.037397 Tokens per Sec: 5335.433594
Epoch Step: 101 / 173 Loss: 1.292081 Tokens per Sec: 5384.093750
Epoch Step: 111 / 173 Loss: 2.279302 Tokens per Sec: 5365.463379
Epoch Step: 121 / 173 Loss: 2.933315 Tokens per Sec: 5414.617188
Epoch Step: 131 / 173 Loss: 2.058812 Tokens per Sec: 5396.081543
Epoch Step: 141 / 173 Loss: 2.660129 Tokens per Sec: 5380.775879
Epoch Step: 151 / 173 Loss: 2.387323 Tokens per Sec: 5273.746582
Epoch Step: 161 / 173 Loss: 2.631048 Tokens per Sec: 5374.151367
Epoch Step: 171 / 173 Loss: 1.928144 Tokens per Sec: 5364.605469
Epoch 4
Epoch Step: 1 / 173 Loss: 2.176511 Tokens per Sec: 5244.372070
Epoch Step: 11 / 173 Loss: 1.936714 Tokens per Sec: 5306.508301
Epoch Step: 21 / 173 Loss: 2.126922 Tokens per Sec: 5447.763672
Epoch Step: 31 / 173 Loss: 3.021574 Tokens per Sec: 5310.008301
Epoch Step: 41 / 173 Loss: 2.068652 Tokens per Sec: 5331.780273
Epoch Step: 51 / 173 Loss: 2.035496 Tokens per Sec: 5401.344238
Epoch Step: 61 / 173 Loss: 2.178796 Tokens per Sec: 5368.776855
Epoch Step: 71 / 173 Loss: 1.133109 Tokens per Sec: 5387.366211
Epoch Step: 81 / 173 Loss: 2.607109 Tokens per Sec: 5357.668945
Epoch Step: 91 / 173 Loss: 1.814054 Tokens per Sec: 5453.079590
Epoch Step: 101 / 173 Loss: 1.882409 Tokens per Sec: 5448.418457
Epoch Step: 111 / 173 Loss: 0.904324 Tokens per Sec: 5419.046387
Epoch Step: 121 / 173 Loss: 1.254301 Tokens per Sec: 5354.140625
Epoch Step: 131 / 173 Loss: 2.471555 Tokens per Sec: 5429.230957
Epoch Step: 141 / 173 Loss: 1.749297 Tokens per Sec: 5343.382812
Epoch Step: 151 / 173 Loss: 1.893902 Tokens per Sec: 5409.394531
Epoch Step: 161 / 173 Loss: 2.585979 Tokens per Sec: 5411.500977
Epoch Step: 171 / 173 Loss: 0.945026 Tokens per Sec: 5339.913574
Epoch Step: 1 / 173
Epoch Step: 11 / 173
Epoch Step: 21 / 173
Epoch Step: 31 / 173
Epoch Step: 41 / 173
Epoch Step: 51 / 173
Epoch Step: 61 / 173
Epoch Step: 71 / 173
Epoch Step: 81 / 173
Epoch Step: 91 / 173
Epoch Step: 101 / 173
Epoch Step: 111 / 173
Epoch Step: 121 / 173
Epoch Step: 131 / 173
Epoch Step: 141 / 173
Epoch Step: 151 / 173
Epoch Step: 161 / 173
Epoch Step: 171 / 173
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  18%|█▊        | 27/154 [00:00<00:00, 269.53it/s]Loading hierarchy for column coarse_log_cluster_path:  36%|███▌      | 55/154 [00:00<00:00, 275.62it/s]Loading hierarchy for column coarse_log_cluster_path:  55%|█████▍    | 84/154 [00:00<00:00, 279.41it/s]Loading hierarchy for column coarse_log_cluster_path:  73%|███████▎  | 113/154 [00:00<00:00, 282.72it/s]Loading hierarchy for column coarse_log_cluster_path:  93%|█████████▎| 143/154 [00:00<00:00, 285.52it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 282.78it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 14628.89it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 3064it [00:00, 38359.37it/s]
INFO:root:Built hierarchy with 2091 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/1262 [00:00<?, ?it/s]Initializing gram_embedding connections:  10%|▉         | 122/1262 [00:00<00:00, 1202.25it/s]Initializing gram_embedding connections:  19%|█▉        | 243/1262 [00:00<00:01, 619.34it/s] Initializing gram_embedding connections:  25%|██▌       | 320/1262 [00:00<00:01, 477.95it/s]Initializing gram_embedding connections:  30%|██▉       | 377/1262 [00:00<00:02, 389.36it/s]Initializing gram_embedding connections:  33%|███▎      | 422/1262 [00:01<00:02, 334.82it/s]Initializing gram_embedding connections:  36%|███▋      | 459/1262 [00:01<00:02, 296.38it/s]Initializing gram_embedding connections:  39%|███▉      | 491/1262 [00:01<00:02, 267.52it/s]Initializing gram_embedding connections:  41%|████      | 519/1262 [00:01<00:03, 245.39it/s]Initializing gram_embedding connections:  43%|████▎     | 544/1262 [00:01<00:03, 228.25it/s]Initializing gram_embedding connections:  45%|████▍     | 567/1262 [00:01<00:03, 214.49it/s]Initializing gram_embedding connections:  47%|████▋     | 589/1262 [00:01<00:03, 201.07it/s]Initializing gram_embedding connections:  48%|████▊     | 609/1262 [00:02<00:03, 189.51it/s]Initializing gram_embedding connections:  50%|████▉     | 628/1262 [00:02<00:03, 180.47it/s]Initializing gram_embedding connections:  51%|█████     | 646/1262 [00:02<00:03, 172.08it/s]Initializing gram_embedding connections:  53%|█████▎    | 663/1262 [00:02<00:03, 164.28it/s]Initializing gram_embedding connections:  54%|█████▍    | 680/1262 [00:02<00:03, 157.01it/s]Initializing gram_embedding connections:  55%|█████▌    | 696/1262 [00:02<00:03, 150.25it/s]Initializing gram_embedding connections:  56%|█████▋    | 711/1262 [00:02<00:03, 144.86it/s]Initializing gram_embedding connections:  58%|█████▊    | 726/1262 [00:02<00:03, 140.32it/s]Initializing gram_embedding connections:  59%|█████▊    | 740/1262 [00:02<00:03, 136.73it/s]Initializing gram_embedding connections:  60%|█████▉    | 754/1262 [00:03<00:03, 133.59it/s]Initializing gram_embedding connections:  61%|██████    | 768/1262 [00:03<00:03, 130.56it/s]Initializing gram_embedding connections:  62%|██████▏   | 781/1262 [00:03<00:03, 127.82it/s]Initializing gram_embedding connections:  63%|██████▎   | 794/1262 [00:03<00:03, 125.47it/s]Initializing gram_embedding connections:  64%|██████▍   | 807/1262 [00:03<00:03, 123.65it/s]Initializing gram_embedding connections:  65%|██████▍   | 820/1262 [00:03<00:03, 122.20it/s]Initializing gram_embedding connections:  66%|██████▌   | 833/1262 [00:03<00:03, 119.99it/s]Initializing gram_embedding connections:  67%|██████▋   | 845/1262 [00:03<00:03, 118.03it/s]Initializing gram_embedding connections:  68%|██████▊   | 857/1262 [00:03<00:03, 116.04it/s]Initializing gram_embedding connections:  69%|██████▉   | 869/1262 [00:04<00:03, 114.42it/s]Initializing gram_embedding connections:  70%|██████▉   | 881/1262 [00:04<00:03, 112.93it/s]Initializing gram_embedding connections:  71%|███████   | 893/1262 [00:04<00:03, 111.41it/s]Initializing gram_embedding connections:  72%|███████▏  | 905/1262 [00:04<00:03, 109.82it/s]Initializing gram_embedding connections:  73%|███████▎  | 916/1262 [00:04<00:03, 108.69it/s]Initializing gram_embedding connections:  73%|███████▎  | 927/1262 [00:04<00:03, 107.29it/s]Initializing gram_embedding connections:  74%|███████▍  | 938/1262 [00:04<00:03, 105.86it/s]Initializing gram_embedding connections:  75%|███████▌  | 949/1262 [00:04<00:03, 104.09it/s]Initializing gram_embedding connections:  76%|███████▌  | 960/1262 [00:04<00:02, 102.63it/s]Initializing gram_embedding connections:  77%|███████▋  | 971/1262 [00:05<00:02, 100.89it/s]Initializing gram_embedding connections:  78%|███████▊  | 982/1262 [00:05<00:02, 99.15it/s] Initializing gram_embedding connections:  79%|███████▊  | 992/1262 [00:05<00:02, 97.85it/s]Initializing gram_embedding connections:  79%|███████▉  | 1002/1262 [00:05<00:02, 96.93it/s]Initializing gram_embedding connections:  80%|████████  | 1012/1262 [00:05<00:02, 96.18it/s]Initializing gram_embedding connections:  81%|████████  | 1022/1262 [00:05<00:02, 95.48it/s]Initializing gram_embedding connections:  82%|████████▏ | 1032/1262 [00:05<00:02, 94.80it/s]Initializing gram_embedding connections:  83%|████████▎ | 1042/1262 [00:05<00:02, 93.79it/s]Initializing gram_embedding connections:  83%|████████▎ | 1052/1262 [00:05<00:02, 92.96it/s]Initializing gram_embedding connections:  84%|████████▍ | 1062/1262 [00:06<00:02, 92.29it/s]Initializing gram_embedding connections:  85%|████████▍ | 1072/1262 [00:06<00:02, 91.54it/s]Initializing gram_embedding connections:  86%|████████▌ | 1082/1262 [00:06<00:01, 90.83it/s]Initializing gram_embedding connections:  87%|████████▋ | 1092/1262 [00:06<00:01, 89.93it/s]Initializing gram_embedding connections:  87%|████████▋ | 1101/1262 [00:06<00:01, 89.50it/s]Initializing gram_embedding connections:  88%|████████▊ | 1110/1262 [00:06<00:01, 88.93it/s]Initializing gram_embedding connections:  89%|████████▊ | 1119/1262 [00:06<00:01, 88.50it/s]Initializing gram_embedding connections:  89%|████████▉ | 1128/1262 [00:06<00:01, 87.98it/s]Initializing gram_embedding connections:  90%|█████████ | 1137/1262 [00:06<00:01, 87.59it/s]Initializing gram_embedding connections:  91%|█████████ | 1146/1262 [00:06<00:01, 87.16it/s]Initializing gram_embedding connections:  92%|█████████▏| 1155/1262 [00:07<00:01, 86.70it/s]Initializing gram_embedding connections:  92%|█████████▏| 1164/1262 [00:07<00:01, 85.85it/s]Initializing gram_embedding connections:  93%|█████████▎| 1173/1262 [00:07<00:01, 84.95it/s]Initializing gram_embedding connections:  94%|█████████▎| 1182/1262 [00:07<00:00, 84.36it/s]Initializing gram_embedding connections:  94%|█████████▍| 1191/1262 [00:07<00:00, 83.67it/s]Initializing gram_embedding connections:  95%|█████████▌| 1200/1262 [00:07<00:00, 83.01it/s]Initializing gram_embedding connections:  96%|█████████▌| 1209/1262 [00:07<00:00, 82.37it/s]Initializing gram_embedding connections:  97%|█████████▋| 1218/1262 [00:07<00:00, 81.72it/s]Initializing gram_embedding connections:  97%|█████████▋| 1227/1262 [00:07<00:00, 80.93it/s]Initializing gram_embedding connections:  98%|█████████▊| 1236/1262 [00:08<00:00, 80.35it/s]Initializing gram_embedding connections:  99%|█████████▊| 1245/1262 [00:08<00:00, 79.80it/s]Initializing gram_embedding connections:  99%|█████████▉| 1253/1262 [00:08<00:00, 79.16it/s]Initializing gram_embedding connections: 100%|█████████▉| 1261/1262 [00:08<00:00, 78.76it/s]Initializing gram_embedding connections: 100%|██████████| 1262/1262 [00:08<00:00, 149.96it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.04it/s]Calculating percentile frequencies...: 7it [00:00,  7.25it/s]
2023-05-24 20:10:23.995845: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:10:56.385844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:10:56.626180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:10:56.665255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:10:57.009867: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb908002cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:10:57.009908: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:10:57.009913: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:10:57.013820: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:10:57.095893: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 33s 33s/step - loss: 0.2136 - categorical_accuracy: 0.0176 - top_5_categorical_accuracy: 0.0781 - top_10_categorical_accuracy: 0.1660 - top_20_categorical_accuracy: 0.3203 - top_5_categorical_accuracy_cp0: 0.0385 - top_5_categorical_accuracy_cp1: 0.0357 - top_5_categorical_accuracy_cp2: 0.1103 - top_5_categorical_accuracy_cp3: 0.0175 - top_5_categorical_accuracy_cp4: 0.1311 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0698 - top_5_categorical_accuracy_p4: 0.0839 - top_10_categorical_accuracy_cp0: 0.0865 - top_10_categorical_accuracy_cp1: 0.1071 - top_10_categorical_accuracy_cp2: 0.2207 - top_10_categorical_accuracy_cp3: 0.0351 - top_10_categorical_accuracy_cp4: 0.2705 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1395 - top_10_categorical_accuracy_p4: 0.1791 - top_20_categorical_accuracy_cp0: 0.1731 - top_20_categorical_accuracy_cp1: 0.2738 - top_20_categorical_accuracy_cp2: 0.4207 - top_20_categorical_accuracy_cp3: 0.1579 - top_20_categorical_accuracy_cp4: 0.4344 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1500 - top_20_categorical_accuracy_p3: 0.2093 - top_20_categorical_accuracy_p4: 0.3424      3/Unknown - 33s 45ms/step - loss: 0.2097 - categorical_accuracy: 0.0794 - top_5_categorical_accuracy: 0.2708 - top_10_categorical_accuracy: 0.3704 - top_20_categorical_accuracy: 0.5020 - top_5_categorical_accuracy_cp0: 0.0651 - top_5_categorical_accuracy_cp1: 0.0730 - top_5_categorical_accuracy_cp2: 0.4044 - top_5_categorical_accuracy_cp3: 0.0494 - top_5_categorical_accuracy_cp4: 0.5273 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0588 - top_5_categorical_accuracy_p2: 0.0870 - top_5_categorical_accuracy_p3: 0.0956 - top_5_categorical_accuracy_p4: 0.2988 - top_10_categorical_accuracy_cp0: 0.1401 - top_10_categorical_accuracy_cp1: 0.1496 - top_10_categorical_accuracy_cp2: 0.5221 - top_10_categorical_accuracy_cp3: 0.1173 - top_10_categorical_accuracy_cp4: 0.6571 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.1304 - top_10_categorical_accuracy_p3: 0.1691 - top_10_categorical_accuracy_p4: 0.4039 - top_20_categorical_accuracy_cp0: 0.2410 - top_20_categorical_accuracy_cp1: 0.3175 - top_20_categorical_accuracy_cp2: 0.6691 - top_20_categorical_accuracy_cp3: 0.2840 - top_20_categorical_accuracy_cp4: 0.7558 - top_20_categorical_accuracy_p0: 0.4000 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.2174 - top_20_categorical_accuracy_p3: 0.2721 - top_20_categorical_accuracy_p4: 0.5405                         5/Unknown - 34s 50ms/step - loss: 0.2061 - categorical_accuracy: 0.1078 - top_5_categorical_accuracy: 0.3570 - top_10_categorical_accuracy: 0.4484 - top_20_categorical_accuracy: 0.5645 - top_5_categorical_accuracy_cp0: 0.0564 - top_5_categorical_accuracy_cp1: 0.1279 - top_5_categorical_accuracy_cp2: 0.5291 - top_5_categorical_accuracy_cp3: 0.1789 - top_5_categorical_accuracy_cp4: 0.6887 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0714 - top_5_categorical_accuracy_p2: 0.0533 - top_5_categorical_accuracy_p3: 0.0747 - top_5_categorical_accuracy_p4: 0.4038 - top_10_categorical_accuracy_cp0: 0.1429 - top_10_categorical_accuracy_cp1: 0.2281 - top_10_categorical_accuracy_cp2: 0.6239 - top_10_categorical_accuracy_cp3: 0.2667 - top_10_categorical_accuracy_cp4: 0.7758 - top_10_categorical_accuracy_p0: 0.0833 - top_10_categorical_accuracy_p1: 0.1429 - top_10_categorical_accuracy_p2: 0.0933 - top_10_categorical_accuracy_p3: 0.1784 - top_10_categorical_accuracy_p4: 0.4959 - top_20_categorical_accuracy_cp0: 0.2462 - top_20_categorical_accuracy_cp1: 0.4115 - top_20_categorical_accuracy_cp2: 0.7324 - top_20_categorical_accuracy_cp3: 0.4316 - top_20_categorical_accuracy_cp4: 0.8371 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.1867 - top_20_categorical_accuracy_p3: 0.2946 - top_20_categorical_accuracy_p4: 0.6139          7/Unknown - 34s 49ms/step - loss: 0.2036 - categorical_accuracy: 0.1198 - top_5_categorical_accuracy: 0.3940 - top_10_categorical_accuracy: 0.4832 - top_20_categorical_accuracy: 0.5986 - top_5_categorical_accuracy_cp0: 0.0523 - top_5_categorical_accuracy_cp1: 0.1613 - top_5_categorical_accuracy_cp2: 0.5681 - top_5_categorical_accuracy_cp3: 0.2265 - top_5_categorical_accuracy_cp4: 0.7384 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0465 - top_5_categorical_accuracy_p3: 0.0729 - top_5_categorical_accuracy_p4: 0.4458 - top_10_categorical_accuracy_cp0: 0.1395 - top_10_categorical_accuracy_cp1: 0.2706 - top_10_categorical_accuracy_cp2: 0.6569 - top_10_categorical_accuracy_cp3: 0.3206 - top_10_categorical_accuracy_cp4: 0.8127 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.1212 - top_10_categorical_accuracy_p2: 0.0814 - top_10_categorical_accuracy_p3: 0.1806 - top_10_categorical_accuracy_p4: 0.5352 - top_20_categorical_accuracy_cp0: 0.2583 - top_20_categorical_accuracy_cp1: 0.4552 - top_20_categorical_accuracy_cp2: 0.7543 - top_20_categorical_accuracy_cp3: 0.5000 - top_20_categorical_accuracy_cp4: 0.8645 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1628 - top_20_categorical_accuracy_p3: 0.3194 - top_20_categorical_accuracy_p4: 0.65002023-05-24 20:10:58.201372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.211679
7/7 [==============================] - 53s 3s/step - loss: 0.2036 - categorical_accuracy: 0.1198 - top_5_categorical_accuracy: 0.3940 - top_10_categorical_accuracy: 0.4832 - top_20_categorical_accuracy: 0.5986 - top_5_categorical_accuracy_cp0: 0.0523 - top_5_categorical_accuracy_cp1: 0.1613 - top_5_categorical_accuracy_cp2: 0.5681 - top_5_categorical_accuracy_cp3: 0.2265 - top_5_categorical_accuracy_cp4: 0.7384 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0606 - top_5_categorical_accuracy_p2: 0.0465 - top_5_categorical_accuracy_p3: 0.0729 - top_5_categorical_accuracy_p4: 0.4458 - top_10_categorical_accuracy_cp0: 0.1395 - top_10_categorical_accuracy_cp1: 0.2706 - top_10_categorical_accuracy_cp2: 0.6569 - top_10_categorical_accuracy_cp3: 0.3206 - top_10_categorical_accuracy_cp4: 0.8127 - top_10_categorical_accuracy_p0: 0.0714 - top_10_categorical_accuracy_p1: 0.1212 - top_10_categorical_accuracy_p2: 0.0814 - top_10_categorical_accuracy_p3: 0.1806 - top_10_categorical_accuracy_p4: 0.5352 - top_20_categorical_accuracy_cp0: 0.2583 - top_20_categorical_accuracy_cp1: 0.4552 - top_20_categorical_accuracy_cp2: 0.7543 - top_20_categorical_accuracy_cp3: 0.5000 - top_20_categorical_accuracy_cp4: 0.8645 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.1212 - top_20_categorical_accuracy_p2: 0.1628 - top_20_categorical_accuracy_p3: 0.3194 - top_20_categorical_accuracy_p4: 0.6500 - val_loss: 0.2117 - val_categorical_accuracy: 0.0647 - val_top_5_categorical_accuracy: 0.2000 - val_top_10_categorical_accuracy: 0.3706 - val_top_20_categorical_accuracy: 0.5735 - val_top_5_categorical_accuracy_cp0: 0.1718 - val_top_5_categorical_accuracy_cp1: 0.2537 - val_top_5_categorical_accuracy_cp2: 0.0385 - val_top_5_categorical_accuracy_cp3: 0.2651 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2276 - val_top_5_categorical_accuracy_p4: 0.2260 - val_top_10_categorical_accuracy_cp0: 0.3313 - val_top_10_categorical_accuracy_cp1: 0.4478 - val_top_10_categorical_accuracy_cp2: 0.2692 - val_top_10_categorical_accuracy_cp3: 0.4217 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0769 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.4309 - val_top_10_categorical_accuracy_p4: 0.4068 - val_top_20_categorical_accuracy_cp0: 0.5153 - val_top_20_categorical_accuracy_cp1: 0.6269 - val_top_20_categorical_accuracy_cp2: 0.3077 - val_top_20_categorical_accuracy_cp3: 0.7349 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.3077 - val_top_20_categorical_accuracy_p1: 0.1667 - val_top_20_categorical_accuracy_p2: 0.0476 - val_top_20_categorical_accuracy_p3: 0.6341 - val_top_20_categorical_accuracy_p4: 0.6271
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1803 - categorical_accuracy: 0.1973 - top_5_categorical_accuracy: 0.5801 - top_10_categorical_accuracy: 0.6875 - top_20_categorical_accuracy: 0.7930 - top_5_categorical_accuracy_cp0: 0.0900 - top_5_categorical_accuracy_cp1: 0.2581 - top_5_categorical_accuracy_cp2: 0.7899 - top_5_categorical_accuracy_cp3: 0.6429 - top_5_categorical_accuracy_cp4: 0.9520 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0769 - top_5_categorical_accuracy_p3: 0.1556 - top_5_categorical_accuracy_p4: 0.6480 - top_10_categorical_accuracy_cp0: 0.2200 - top_10_categorical_accuracy_cp1: 0.5484 - top_10_categorical_accuracy_cp2: 0.8478 - top_10_categorical_accuracy_cp3: 0.7321 - top_10_categorical_accuracy_cp4: 0.9680 - top_10_categorical_accuracy_p0: 1.0000 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0769 - top_10_categorical_accuracy_p3: 0.3556 - top_10_categorical_accuracy_p4: 0.7489 - top_20_categorical_accuracy_cp0: 0.4100 - top_20_categorical_accuracy_cp1: 0.7742 - top_20_categorical_accuracy_cp2: 0.8913 - top_20_categorical_accuracy_cp3: 0.8571 - top_20_categorical_accuracy_cp4: 0.9760 - top_20_categorical_accuracy_p0: 1.0000 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1538 - top_20_categorical_accuracy_p3: 0.6000 - top_20_categorical_accuracy_p4: 0.84303/7 [===========>..................] - ETA: 0s - loss: 0.1758 - categorical_accuracy: 0.1823 - top_5_categorical_accuracy: 0.5775 - top_10_categorical_accuracy: 0.6816 - top_20_categorical_accuracy: 0.7806 - top_5_categorical_accuracy_cp0: 0.0772 - top_5_categorical_accuracy_cp1: 0.2923 - top_5_categorical_accuracy_cp2: 0.8085 - top_5_categorical_accuracy_cp3: 0.6145 - top_5_categorical_accuracy_cp4: 0.9777 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0588 - top_5_categorical_accuracy_p2: 0.0536 - top_5_categorical_accuracy_p3: 0.1192 - top_5_categorical_accuracy_p4: 0.6639 - top_10_categorical_accuracy_cp0: 0.2018 - top_10_categorical_accuracy_cp1: 0.5500 - top_10_categorical_accuracy_cp2: 0.8756 - top_10_categorical_accuracy_cp3: 0.7374 - top_10_categorical_accuracy_cp4: 0.9832 - top_10_categorical_accuracy_p0: 0.3333 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.0893 - top_10_categorical_accuracy_p3: 0.3179 - top_10_categorical_accuracy_p4: 0.7590 - top_20_categorical_accuracy_cp0: 0.3620 - top_20_categorical_accuracy_cp1: 0.7538 - top_20_categorical_accuracy_cp2: 0.9154 - top_20_categorical_accuracy_cp3: 0.8883 - top_20_categorical_accuracy_cp4: 0.9888 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.2353 - top_20_categorical_accuracy_p2: 0.1607 - top_20_categorical_accuracy_p3: 0.4834 - top_20_categorical_accuracy_p4: 0.8519            5/7 [====================>.........] - ETA: 0s - loss: 0.1683 - categorical_accuracy: 0.1801 - top_5_categorical_accuracy: 0.5992 - top_10_categorical_accuracy: 0.7051 - top_20_categorical_accuracy: 0.7977 - top_5_categorical_accuracy_cp0: 0.0593 - top_5_categorical_accuracy_cp1: 0.2946 - top_5_categorical_accuracy_cp2: 0.8426 - top_5_categorical_accuracy_cp3: 0.6370 - top_5_categorical_accuracy_cp4: 0.9871 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0370 - top_5_categorical_accuracy_p2: 0.0400 - top_5_categorical_accuracy_p3: 0.0928 - top_5_categorical_accuracy_p4: 0.6833 - top_10_categorical_accuracy_cp0: 0.1721 - top_10_categorical_accuracy_cp1: 0.5848 - top_10_categorical_accuracy_cp2: 0.9038 - top_10_categorical_accuracy_cp3: 0.7722 - top_10_categorical_accuracy_cp4: 0.9904 - top_10_categorical_accuracy_p0: 0.2143 - top_10_categorical_accuracy_p1: 0.0741 - top_10_categorical_accuracy_p2: 0.0667 - top_10_categorical_accuracy_p3: 0.2785 - top_10_categorical_accuracy_p4: 0.7834 - top_20_categorical_accuracy_cp0: 0.3365 - top_20_categorical_accuracy_cp1: 0.7768 - top_20_categorical_accuracy_cp2: 0.9431 - top_20_categorical_accuracy_cp3: 0.9004 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.2143 - top_20_categorical_accuracy_p1: 0.1852 - top_20_categorical_accuracy_p2: 0.1200 - top_20_categorical_accuracy_p3: 0.4557 - top_20_categorical_accuracy_p4: 0.86867/7 [==============================] - ETA: 0s - loss: 0.1666 - categorical_accuracy: 0.1794 - top_5_categorical_accuracy: 0.5979 - top_10_categorical_accuracy: 0.7107 - top_20_categorical_accuracy: 0.8038 - top_5_categorical_accuracy_cp0: 0.0571 - top_5_categorical_accuracy_cp1: 0.2849 - top_5_categorical_accuracy_cp2: 0.8443 - top_5_categorical_accuracy_cp3: 0.6559 - top_5_categorical_accuracy_cp4: 0.9880 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0303 - top_5_categorical_accuracy_p2: 0.0349 - top_5_categorical_accuracy_p3: 0.0938 - top_5_categorical_accuracy_p4: 0.6802 - top_10_categorical_accuracy_cp0: 0.1648 - top_10_categorical_accuracy_cp1: 0.6004 - top_10_categorical_accuracy_cp2: 0.9124 - top_10_categorical_accuracy_cp3: 0.7941 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.2143 - top_10_categorical_accuracy_p1: 0.0606 - top_10_categorical_accuracy_p2: 0.0581 - top_10_categorical_accuracy_p3: 0.2743 - top_10_categorical_accuracy_p4: 0.7890 - top_20_categorical_accuracy_cp0: 0.3376 - top_20_categorical_accuracy_cp1: 0.7939 - top_20_categorical_accuracy_cp2: 0.9489 - top_20_categorical_accuracy_cp3: 0.9118 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.2143 - top_20_categorical_accuracy_p1: 0.1818 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.4688 - top_20_categorical_accuracy_p4: 0.8722DEBUG:root:Model metric val_loss improved from 0.211679 to 0.208504
7/7 [==============================] - 1s 116ms/step - loss: 0.1666 - categorical_accuracy: 0.1794 - top_5_categorical_accuracy: 0.5979 - top_10_categorical_accuracy: 0.7107 - top_20_categorical_accuracy: 0.8038 - top_5_categorical_accuracy_cp0: 0.0571 - top_5_categorical_accuracy_cp1: 0.2849 - top_5_categorical_accuracy_cp2: 0.8443 - top_5_categorical_accuracy_cp3: 0.6559 - top_5_categorical_accuracy_cp4: 0.9880 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0303 - top_5_categorical_accuracy_p2: 0.0349 - top_5_categorical_accuracy_p3: 0.0938 - top_5_categorical_accuracy_p4: 0.6802 - top_10_categorical_accuracy_cp0: 0.1648 - top_10_categorical_accuracy_cp1: 0.6004 - top_10_categorical_accuracy_cp2: 0.9124 - top_10_categorical_accuracy_cp3: 0.7941 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.2143 - top_10_categorical_accuracy_p1: 0.0606 - top_10_categorical_accuracy_p2: 0.0581 - top_10_categorical_accuracy_p3: 0.2743 - top_10_categorical_accuracy_p4: 0.7890 - top_20_categorical_accuracy_cp0: 0.3376 - top_20_categorical_accuracy_cp1: 0.7939 - top_20_categorical_accuracy_cp2: 0.9489 - top_20_categorical_accuracy_cp3: 0.9118 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.2143 - top_20_categorical_accuracy_p1: 0.1818 - top_20_categorical_accuracy_p2: 0.1279 - top_20_categorical_accuracy_p3: 0.4688 - top_20_categorical_accuracy_p4: 0.8722 - val_loss: 0.2085 - val_categorical_accuracy: 0.1500 - val_top_5_categorical_accuracy: 0.4235 - val_top_10_categorical_accuracy: 0.6029 - val_top_20_categorical_accuracy: 0.7206 - val_top_5_categorical_accuracy_cp0: 0.2945 - val_top_5_categorical_accuracy_cp1: 0.3731 - val_top_5_categorical_accuracy_cp2: 0.2692 - val_top_5_categorical_accuracy_cp3: 0.7711 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.3902 - val_top_5_categorical_accuracy_p4: 0.5424 - val_top_10_categorical_accuracy_cp0: 0.4724 - val_top_10_categorical_accuracy_cp1: 0.6716 - val_top_10_categorical_accuracy_cp2: 0.5000 - val_top_10_categorical_accuracy_cp3: 0.8434 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0769 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.6179 - val_top_10_categorical_accuracy_p4: 0.7232 - val_top_20_categorical_accuracy_cp0: 0.5951 - val_top_20_categorical_accuracy_cp1: 0.8657 - val_top_20_categorical_accuracy_cp2: 0.5769 - val_top_20_categorical_accuracy_cp3: 0.9036 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.1538 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.7724 - val_top_20_categorical_accuracy_p4: 0.8362
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.1797 - top_5_categorical_accuracy: 0.6191 - top_10_categorical_accuracy: 0.7656 - top_20_categorical_accuracy: 0.8516 - top_5_categorical_accuracy_cp0: 0.0396 - top_5_categorical_accuracy_cp1: 0.1585 - top_5_categorical_accuracy_cp2: 0.8980 - top_5_categorical_accuracy_cp3: 0.7358 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0652 - top_5_categorical_accuracy_p4: 0.7009 - top_10_categorical_accuracy_cp0: 0.1683 - top_10_categorical_accuracy_cp1: 0.6951 - top_10_categorical_accuracy_cp2: 0.9660 - top_10_categorical_accuracy_cp3: 0.8868 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3261 - top_10_categorical_accuracy_p4: 0.8415 - top_20_categorical_accuracy_cp0: 0.3663 - top_20_categorical_accuracy_cp1: 0.9024 - top_20_categorical_accuracy_cp2: 0.9932 - top_20_categorical_accuracy_cp3: 0.9434 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1429 - top_20_categorical_accuracy_p3: 0.6522 - top_20_categorical_accuracy_p4: 0.90403/7 [===========>..................] - ETA: 0s - loss: 0.1567 - categorical_accuracy: 0.1660 - top_5_categorical_accuracy: 0.5833 - top_10_categorical_accuracy: 0.7611 - top_20_categorical_accuracy: 0.8503 - top_5_categorical_accuracy_cp0: 0.0331 - top_5_categorical_accuracy_cp1: 0.1760 - top_5_categorical_accuracy_cp2: 0.8892 - top_5_categorical_accuracy_cp3: 0.6897 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0662 - top_5_categorical_accuracy_p4: 0.6727 - top_10_categorical_accuracy_cp0: 0.1627 - top_10_categorical_accuracy_cp1: 0.7341 - top_10_categorical_accuracy_cp2: 0.9803 - top_10_categorical_accuracy_cp3: 0.9425 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2848 - top_10_categorical_accuracy_p4: 0.8550 - top_20_categorical_accuracy_cp0: 0.3765 - top_20_categorical_accuracy_cp1: 0.9401 - top_20_categorical_accuracy_cp2: 0.9926 - top_20_categorical_accuracy_cp3: 0.9770 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0976 - top_20_categorical_accuracy_p3: 0.5497 - top_20_categorical_accuracy_p4: 0.9248    5/7 [====================>.........] - ETA: 0s - loss: 0.1529 - categorical_accuracy: 0.1711 - top_5_categorical_accuracy: 0.6008 - top_10_categorical_accuracy: 0.7750 - top_20_categorical_accuracy: 0.8617 - top_5_categorical_accuracy_cp0: 0.0307 - top_5_categorical_accuracy_cp1: 0.2056 - top_5_categorical_accuracy_cp2: 0.8900 - top_5_categorical_accuracy_cp3: 0.7438 - top_5_categorical_accuracy_cp4: 0.9952 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0606 - top_5_categorical_accuracy_p4: 0.6877 - top_10_categorical_accuracy_cp0: 0.1398 - top_10_categorical_accuracy_cp1: 0.7814 - top_10_categorical_accuracy_cp2: 0.9822 - top_10_categorical_accuracy_cp3: 0.9502 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2554 - top_10_categorical_accuracy_p4: 0.8687 - top_20_categorical_accuracy_cp0: 0.3755 - top_20_categorical_accuracy_cp1: 0.9545 - top_20_categorical_accuracy_cp2: 0.9955 - top_20_categorical_accuracy_cp3: 0.9858 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0909 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0658 - top_20_categorical_accuracy_p3: 0.5455 - top_20_categorical_accuracy_p4: 0.93597/7 [==============================] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.1749 - top_5_categorical_accuracy: 0.6053 - top_10_categorical_accuracy: 0.7803 - top_20_categorical_accuracy: 0.8653 - top_5_categorical_accuracy_cp0: 0.0269 - top_5_categorical_accuracy_cp1: 0.2204 - top_5_categorical_accuracy_cp2: 0.8869 - top_5_categorical_accuracy_cp3: 0.7706 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0521 - top_5_categorical_accuracy_p4: 0.6947 - top_10_categorical_accuracy_cp0: 0.1363 - top_10_categorical_accuracy_cp1: 0.8029 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9588 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2431 - top_10_categorical_accuracy_p4: 0.8766 - top_20_categorical_accuracy_cp0: 0.3851 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.5556 - top_20_categorical_accuracy_p4: 0.9392DEBUG:root:Model metric val_loss improved from 0.208504 to 0.202110
7/7 [==============================] - 1s 123ms/step - loss: 0.1517 - categorical_accuracy: 0.1749 - top_5_categorical_accuracy: 0.6053 - top_10_categorical_accuracy: 0.7803 - top_20_categorical_accuracy: 0.8653 - top_5_categorical_accuracy_cp0: 0.0269 - top_5_categorical_accuracy_cp1: 0.2204 - top_5_categorical_accuracy_cp2: 0.8869 - top_5_categorical_accuracy_cp3: 0.7706 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0521 - top_5_categorical_accuracy_p4: 0.6947 - top_10_categorical_accuracy_cp0: 0.1363 - top_10_categorical_accuracy_cp1: 0.8029 - top_10_categorical_accuracy_cp2: 0.9842 - top_10_categorical_accuracy_cp3: 0.9588 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2431 - top_10_categorical_accuracy_p4: 0.8766 - top_20_categorical_accuracy_cp0: 0.3851 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.5556 - top_20_categorical_accuracy_p4: 0.9392 - val_loss: 0.2021 - val_categorical_accuracy: 0.2294 - val_top_5_categorical_accuracy: 0.4882 - val_top_10_categorical_accuracy: 0.6794 - val_top_20_categorical_accuracy: 0.7941 - val_top_5_categorical_accuracy_cp0: 0.2761 - val_top_5_categorical_accuracy_cp1: 0.4328 - val_top_5_categorical_accuracy_cp2: 0.5385 - val_top_5_categorical_accuracy_cp3: 0.9398 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.3659 - val_top_5_categorical_accuracy_p4: 0.6836 - val_top_10_categorical_accuracy_cp0: 0.4724 - val_top_10_categorical_accuracy_cp1: 0.8657 - val_top_10_categorical_accuracy_cp2: 0.6923 - val_top_10_categorical_accuracy_cp3: 0.9398 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.6260 - val_top_10_categorical_accuracy_p4: 0.8701 - val_top_20_categorical_accuracy_cp0: 0.6748 - val_top_20_categorical_accuracy_cp1: 0.9254 - val_top_20_categorical_accuracy_cp2: 0.7692 - val_top_20_categorical_accuracy_cp3: 0.9398 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.0769 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8862 - val_top_20_categorical_accuracy_p4: 0.9040
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1403 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6816 - top_10_categorical_accuracy: 0.8223 - top_20_categorical_accuracy: 0.9062 - top_5_categorical_accuracy_cp0: 0.0206 - top_5_categorical_accuracy_cp1: 0.4110 - top_5_categorical_accuracy_cp2: 0.8868 - top_5_categorical_accuracy_cp3: 0.9273 - top_5_categorical_accuracy_cp4: 0.9766 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0417 - top_5_categorical_accuracy_p4: 0.7780 - top_10_categorical_accuracy_cp0: 0.1753 - top_10_categorical_accuracy_cp1: 0.8904 - top_10_categorical_accuracy_cp2: 0.9874 - top_10_categorical_accuracy_cp3: 0.9818 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2708 - top_10_categorical_accuracy_p4: 0.9148 - top_20_categorical_accuracy_cp0: 0.5155 - top_20_categorical_accuracy_cp1: 0.9863 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6250 - top_20_categorical_accuracy_p4: 0.97313/7 [===========>..................] - ETA: 0s - loss: 0.1424 - categorical_accuracy: 0.1979 - top_5_categorical_accuracy: 0.6536 - top_10_categorical_accuracy: 0.7988 - top_20_categorical_accuracy: 0.8945 - top_5_categorical_accuracy_cp0: 0.0186 - top_5_categorical_accuracy_cp1: 0.4798 - top_5_categorical_accuracy_cp2: 0.8665 - top_5_categorical_accuracy_cp3: 0.9106 - top_5_categorical_accuracy_cp4: 0.9611 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0357 - top_5_categorical_accuracy_p4: 0.7523 - top_10_categorical_accuracy_cp0: 0.1304 - top_10_categorical_accuracy_cp1: 0.9073 - top_10_categorical_accuracy_cp2: 0.9953 - top_10_categorical_accuracy_cp3: 0.9777 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2214 - top_10_categorical_accuracy_p4: 0.9006 - top_20_categorical_accuracy_cp0: 0.5000 - top_20_categorical_accuracy_cp1: 0.9960 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1000 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6071 - top_20_categorical_accuracy_p4: 0.9699    5/7 [====================>.........] - ETA: 0s - loss: 0.1402 - categorical_accuracy: 0.2008 - top_5_categorical_accuracy: 0.6547 - top_10_categorical_accuracy: 0.8062 - top_20_categorical_accuracy: 0.8996 - top_5_categorical_accuracy_cp0: 0.0173 - top_5_categorical_accuracy_cp1: 0.4722 - top_5_categorical_accuracy_cp2: 0.8623 - top_5_categorical_accuracy_cp3: 0.9317 - top_5_categorical_accuracy_cp4: 0.9662 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0332 - top_5_categorical_accuracy_p4: 0.7551 - top_10_categorical_accuracy_cp0: 0.1382 - top_10_categorical_accuracy_cp1: 0.9131 - top_10_categorical_accuracy_cp2: 0.9942 - top_10_categorical_accuracy_cp3: 0.9856 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2116 - top_10_categorical_accuracy_p4: 0.9113 - top_20_categorical_accuracy_cp0: 0.5106 - top_20_categorical_accuracy_cp1: 0.9955 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0833 - top_20_categorical_accuracy_p1: 0.0370 - top_20_categorical_accuracy_p2: 0.0141 - top_20_categorical_accuracy_p3: 0.6224 - top_20_categorical_accuracy_p4: 0.9733        7/7 [==============================] - ETA: 0s - loss: 0.1394 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6534 - top_10_categorical_accuracy: 0.8044 - top_20_categorical_accuracy: 0.9017 - top_5_categorical_accuracy_cp0: 0.0158 - top_5_categorical_accuracy_cp1: 0.4892 - top_5_categorical_accuracy_cp2: 0.8504 - top_5_categorical_accuracy_cp3: 0.9441 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0278 - top_5_categorical_accuracy_p4: 0.7529 - top_10_categorical_accuracy_cp0: 0.1347 - top_10_categorical_accuracy_cp1: 0.9104 - top_10_categorical_accuracy_cp2: 0.9927 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2014 - top_10_categorical_accuracy_p4: 0.9091 - top_20_categorical_accuracy_cp0: 0.5198 - top_20_categorical_accuracy_cp1: 0.9964 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.0233 - top_20_categorical_accuracy_p3: 0.6181 - top_20_categorical_accuracy_p4: 0.9754DEBUG:root:Model metric val_loss improved from 0.202110 to 0.187992
7/7 [==============================] - 1s 122ms/step - loss: 0.1394 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6534 - top_10_categorical_accuracy: 0.8044 - top_20_categorical_accuracy: 0.9017 - top_5_categorical_accuracy_cp0: 0.0158 - top_5_categorical_accuracy_cp1: 0.4892 - top_5_categorical_accuracy_cp2: 0.8504 - top_5_categorical_accuracy_cp3: 0.9441 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0278 - top_5_categorical_accuracy_p4: 0.7529 - top_10_categorical_accuracy_cp0: 0.1347 - top_10_categorical_accuracy_cp1: 0.9104 - top_10_categorical_accuracy_cp2: 0.9927 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2014 - top_10_categorical_accuracy_p4: 0.9091 - top_20_categorical_accuracy_cp0: 0.5198 - top_20_categorical_accuracy_cp1: 0.9964 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.0233 - top_20_categorical_accuracy_p3: 0.6181 - top_20_categorical_accuracy_p4: 0.9754 - val_loss: 0.1880 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.4529 - val_top_10_categorical_accuracy: 0.6676 - val_top_20_categorical_accuracy: 0.7647 - val_top_5_categorical_accuracy_cp0: 0.0675 - val_top_5_categorical_accuracy_cp1: 0.6269 - val_top_5_categorical_accuracy_cp2: 0.6923 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0894 - val_top_5_categorical_accuracy_p4: 0.8079 - val_top_10_categorical_accuracy_cp0: 0.3313 - val_top_10_categorical_accuracy_cp1: 0.9851 - val_top_10_categorical_accuracy_cp2: 0.8846 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.4390 - val_top_10_categorical_accuracy_p4: 0.9774 - val_top_20_categorical_accuracy_cp0: 0.5276 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 0.8846 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.6992 - val_top_20_categorical_accuracy_p4: 0.9831
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1319 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.6934 - top_10_categorical_accuracy: 0.8164 - top_20_categorical_accuracy: 0.9160 - top_5_categorical_accuracy_cp0: 0.0396 - top_5_categorical_accuracy_cp1: 0.5714 - top_5_categorical_accuracy_cp2: 0.8672 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0698 - top_5_categorical_accuracy_p4: 0.7822 - top_10_categorical_accuracy_cp0: 0.1584 - top_10_categorical_accuracy_cp1: 0.9082 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1860 - top_10_categorical_accuracy_p4: 0.9111 - top_20_categorical_accuracy_cp0: 0.5743 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.5581 - top_20_categorical_accuracy_p4: 0.98893/7 [===========>..................] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.2214 - top_5_categorical_accuracy: 0.6686 - top_10_categorical_accuracy: 0.8060 - top_20_categorical_accuracy: 0.9036 - top_5_categorical_accuracy_cp0: 0.0381 - top_5_categorical_accuracy_cp1: 0.5725 - top_5_categorical_accuracy_cp2: 0.8582 - top_5_categorical_accuracy_cp3: 0.9944 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0377 - top_5_categorical_accuracy_p4: 0.7800 - top_10_categorical_accuracy_cp0: 0.1935 - top_10_categorical_accuracy_cp1: 0.9257 - top_10_categorical_accuracy_cp2: 0.9923 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2075 - top_10_categorical_accuracy_p4: 0.9206 - top_20_categorical_accuracy_cp0: 0.5689 - top_20_categorical_accuracy_cp1: 0.9963 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0213 - top_20_categorical_accuracy_p3: 0.5912 - top_20_categorical_accuracy_p4: 0.9878    5/7 [====================>.........] - ETA: 0s - loss: 0.1329 - categorical_accuracy: 0.2223 - top_5_categorical_accuracy: 0.6832 - top_10_categorical_accuracy: 0.8227 - top_20_categorical_accuracy: 0.9082 - top_5_categorical_accuracy_cp0: 0.0391 - top_5_categorical_accuracy_cp1: 0.5978 - top_5_categorical_accuracy_cp2: 0.8666 - top_5_categorical_accuracy_cp3: 0.9966 - top_5_categorical_accuracy_cp4: 0.9670 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0408 - top_5_categorical_accuracy_p4: 0.7901 - top_10_categorical_accuracy_cp0: 0.2272 - top_10_categorical_accuracy_cp1: 0.9283 - top_10_categorical_accuracy_cp2: 0.9910 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2204 - top_10_categorical_accuracy_p4: 0.9323 - top_20_categorical_accuracy_cp0: 0.5680 - top_20_categorical_accuracy_cp1: 0.9935 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0128 - top_20_categorical_accuracy_p3: 0.6122 - top_20_categorical_accuracy_p4: 0.98777/7 [==============================] - ETA: 0s - loss: 0.1322 - categorical_accuracy: 0.2207 - top_5_categorical_accuracy: 0.6862 - top_10_categorical_accuracy: 0.8251 - top_20_categorical_accuracy: 0.9111 - top_5_categorical_accuracy_cp0: 0.0349 - top_5_categorical_accuracy_cp1: 0.5914 - top_5_categorical_accuracy_cp2: 0.8674 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0347 - top_5_categorical_accuracy_p4: 0.7902 - top_10_categorical_accuracy_cp0: 0.2266 - top_10_categorical_accuracy_cp1: 0.9229 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2188 - top_10_categorical_accuracy_p4: 0.9310 - top_20_categorical_accuracy_cp0: 0.5705 - top_20_categorical_accuracy_cp1: 0.9910 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0116 - top_20_categorical_accuracy_p3: 0.6111 - top_20_categorical_accuracy_p4: 0.9881DEBUG:root:Model metric val_loss improved from 0.187992 to 0.178998
7/7 [==============================] - 1s 123ms/step - loss: 0.1322 - categorical_accuracy: 0.2207 - top_5_categorical_accuracy: 0.6862 - top_10_categorical_accuracy: 0.8251 - top_20_categorical_accuracy: 0.9111 - top_5_categorical_accuracy_cp0: 0.0349 - top_5_categorical_accuracy_cp1: 0.5914 - top_5_categorical_accuracy_cp2: 0.8674 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0347 - top_5_categorical_accuracy_p4: 0.7902 - top_10_categorical_accuracy_cp0: 0.2266 - top_10_categorical_accuracy_cp1: 0.9229 - top_10_categorical_accuracy_cp2: 0.9866 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2188 - top_10_categorical_accuracy_p4: 0.9310 - top_20_categorical_accuracy_cp0: 0.5705 - top_20_categorical_accuracy_cp1: 0.9910 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0116 - top_20_categorical_accuracy_p3: 0.6111 - top_20_categorical_accuracy_p4: 0.9881 - val_loss: 0.1790 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.4235 - val_top_10_categorical_accuracy: 0.6294 - val_top_20_categorical_accuracy: 0.7706 - val_top_5_categorical_accuracy_cp0: 0.0061 - val_top_5_categorical_accuracy_cp1: 0.6269 - val_top_5_categorical_accuracy_cp2: 0.6923 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0081 - val_top_5_categorical_accuracy_p4: 0.8079 - val_top_10_categorical_accuracy_cp0: 0.2577 - val_top_10_categorical_accuracy_cp1: 0.9851 - val_top_10_categorical_accuracy_cp2: 0.8846 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.3415 - val_top_10_categorical_accuracy_p4: 0.9718 - val_top_20_categorical_accuracy_cp0: 0.5276 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.6992 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1294 - categorical_accuracy: 0.2168 - top_5_categorical_accuracy: 0.6719 - top_10_categorical_accuracy: 0.8379 - top_20_categorical_accuracy: 0.9258 - top_5_categorical_accuracy_cp0: 0.1008 - top_5_categorical_accuracy_cp1: 0.5631 - top_5_categorical_accuracy_cp2: 0.9273 - top_5_categorical_accuracy_cp3: 0.9697 - top_5_categorical_accuracy_cp4: 0.9474 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0556 - top_5_categorical_accuracy_p4: 0.7768 - top_10_categorical_accuracy_cp0: 0.3697 - top_10_categorical_accuracy_cp1: 0.9417 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9825 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3333 - top_10_categorical_accuracy_p4: 0.9362 - top_20_categorical_accuracy_cp0: 0.6807 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6667 - top_20_categorical_accuracy_p4: 0.99773/7 [===========>..................] - ETA: 0s - loss: 0.1276 - categorical_accuracy: 0.2122 - top_5_categorical_accuracy: 0.7018 - top_10_categorical_accuracy: 0.8522 - top_20_categorical_accuracy: 0.9232 - top_5_categorical_accuracy_cp0: 0.1041 - top_5_categorical_accuracy_cp1: 0.5972 - top_5_categorical_accuracy_cp2: 0.9031 - top_5_categorical_accuracy_cp3: 0.9655 - top_5_categorical_accuracy_cp4: 0.9616 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0597 - top_5_categorical_accuracy_p4: 0.8003 - top_10_categorical_accuracy_cp0: 0.3754 - top_10_categorical_accuracy_cp1: 0.9340 - top_10_categorical_accuracy_cp2: 0.9898 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9836 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3582 - top_10_categorical_accuracy_p4: 0.9432 - top_20_categorical_accuracy_cp0: 0.6498 - top_20_categorical_accuracy_cp1: 0.9826 - top_20_categorical_accuracy_cp2: 0.9974 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6791 - top_20_categorical_accuracy_p4: 0.99255/7 [====================>.........] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.7012 - top_10_categorical_accuracy: 0.8523 - top_20_categorical_accuracy: 0.9250 - top_5_categorical_accuracy_cp0: 0.1008 - top_5_categorical_accuracy_cp1: 0.5579 - top_5_categorical_accuracy_cp2: 0.9037 - top_5_categorical_accuracy_cp3: 0.9600 - top_5_categorical_accuracy_cp4: 0.9697 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0598 - top_5_categorical_accuracy_p4: 0.8030 - top_10_categorical_accuracy_cp0: 0.3702 - top_10_categorical_accuracy_cp1: 0.9249 - top_10_categorical_accuracy_cp2: 0.9896 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3632 - top_10_categorical_accuracy_p4: 0.9454 - top_20_categorical_accuracy_cp0: 0.6473 - top_20_categorical_accuracy_cp1: 0.9850 - top_20_categorical_accuracy_cp2: 0.9985 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0411 - top_20_categorical_accuracy_p3: 0.6966 - top_20_categorical_accuracy_p4: 0.9928    7/7 [==============================] - ETA: 0s - loss: 0.1270 - categorical_accuracy: 0.2101 - top_5_categorical_accuracy: 0.7059 - top_10_categorical_accuracy: 0.8524 - top_20_categorical_accuracy: 0.9259 - top_5_categorical_accuracy_cp0: 0.1094 - top_5_categorical_accuracy_cp1: 0.5681 - top_5_categorical_accuracy_cp2: 0.9088 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0729 - top_5_categorical_accuracy_p4: 0.8088 - top_10_categorical_accuracy_cp0: 0.3835 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9867 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3750 - top_10_categorical_accuracy_p4: 0.9460 - top_20_categorical_accuracy_cp0: 0.6529 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.7083 - top_20_categorical_accuracy_p4: 0.9937DEBUG:root:Model metric val_loss improved from 0.178998 to 0.176363
7/7 [==============================] - 1s 123ms/step - loss: 0.1270 - categorical_accuracy: 0.2101 - top_5_categorical_accuracy: 0.7059 - top_10_categorical_accuracy: 0.8524 - top_20_categorical_accuracy: 0.9259 - top_5_categorical_accuracy_cp0: 0.1094 - top_5_categorical_accuracy_cp1: 0.5681 - top_5_categorical_accuracy_cp2: 0.9088 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0729 - top_5_categorical_accuracy_p4: 0.8088 - top_10_categorical_accuracy_cp0: 0.3835 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9854 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9867 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3750 - top_10_categorical_accuracy_p4: 0.9460 - top_20_categorical_accuracy_cp0: 0.6529 - top_20_categorical_accuracy_cp1: 0.9857 - top_20_categorical_accuracy_cp2: 0.9988 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.7083 - top_20_categorical_accuracy_p4: 0.9937 - val_loss: 0.1764 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.3765 - val_top_10_categorical_accuracy: 0.6118 - val_top_20_categorical_accuracy: 0.8412 - val_top_5_categorical_accuracy_cp0: 0.0184 - val_top_5_categorical_accuracy_cp1: 0.3582 - val_top_5_categorical_accuracy_cp2: 0.6923 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0244 - val_top_5_categorical_accuracy_p4: 0.7062 - val_top_10_categorical_accuracy_cp0: 0.3129 - val_top_10_categorical_accuracy_cp1: 0.8060 - val_top_10_categorical_accuracy_cp2: 0.7692 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.4146 - val_top_10_categorical_accuracy_p4: 0.8870 - val_top_20_categorical_accuracy_cp0: 0.6748 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8943 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1224 - categorical_accuracy: 0.2129 - top_5_categorical_accuracy: 0.7383 - top_10_categorical_accuracy: 0.8691 - top_20_categorical_accuracy: 0.9492 - top_5_categorical_accuracy_cp0: 0.1562 - top_5_categorical_accuracy_cp1: 0.5618 - top_5_categorical_accuracy_cp2: 0.9262 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9767 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1455 - top_5_categorical_accuracy_p4: 0.8333 - top_10_categorical_accuracy_cp0: 0.4583 - top_10_categorical_accuracy_cp1: 0.9213 - top_10_categorical_accuracy_cp2: 0.9664 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9767 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4182 - top_10_categorical_accuracy_p4: 0.9505 - top_20_categorical_accuracy_cp0: 0.7500 - top_20_categorical_accuracy_cp1: 0.9888 - top_20_categorical_accuracy_cp2: 0.9933 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.7818 - top_20_categorical_accuracy_p4: 0.99553/7 [===========>..................] - ETA: 0s - loss: 0.1242 - categorical_accuracy: 0.2148 - top_5_categorical_accuracy: 0.7246 - top_10_categorical_accuracy: 0.8600 - top_20_categorical_accuracy: 0.9303 - top_5_categorical_accuracy_cp0: 0.1237 - top_5_categorical_accuracy_cp1: 0.5498 - top_5_categorical_accuracy_cp2: 0.9292 - top_5_categorical_accuracy_cp3: 0.9560 - top_5_categorical_accuracy_cp4: 0.9743 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1234 - top_5_categorical_accuracy_p4: 0.8269 - top_10_categorical_accuracy_cp0: 0.4080 - top_10_categorical_accuracy_cp1: 0.9243 - top_10_categorical_accuracy_cp2: 0.9772 - top_10_categorical_accuracy_cp3: 0.9874 - top_10_categorical_accuracy_cp4: 0.9820 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3831 - top_10_categorical_accuracy_p4: 0.9539 - top_20_categorical_accuracy_cp0: 0.6722 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 0.9954 - top_20_categorical_accuracy_cp3: 0.9937 - top_20_categorical_accuracy_cp4: 0.9974 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1026 - top_20_categorical_accuracy_p3: 0.7273 - top_20_categorical_accuracy_p4: 0.99245/7 [====================>.........] - ETA: 0s - loss: 0.1251 - categorical_accuracy: 0.2121 - top_5_categorical_accuracy: 0.7098 - top_10_categorical_accuracy: 0.8629 - top_20_categorical_accuracy: 0.9281 - top_5_categorical_accuracy_cp0: 0.1349 - top_5_categorical_accuracy_cp1: 0.5298 - top_5_categorical_accuracy_cp2: 0.9260 - top_5_categorical_accuracy_cp3: 0.9496 - top_5_categorical_accuracy_cp4: 0.9742 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.8101 - top_10_categorical_accuracy_cp0: 0.4412 - top_10_categorical_accuracy_cp1: 0.9294 - top_10_categorical_accuracy_cp2: 0.9782 - top_10_categorical_accuracy_cp3: 0.9856 - top_10_categorical_accuracy_cp4: 0.9839 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4417 - top_10_categorical_accuracy_p4: 0.9533 - top_20_categorical_accuracy_cp0: 0.6782 - top_20_categorical_accuracy_cp1: 0.9779 - top_20_categorical_accuracy_cp2: 0.9942 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0556 - top_20_categorical_accuracy_p3: 0.7708 - top_20_categorical_accuracy_p4: 0.99147/7 [==============================] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.2123 - top_5_categorical_accuracy: 0.7101 - top_10_categorical_accuracy: 0.8653 - top_20_categorical_accuracy: 0.9288 - top_5_categorical_accuracy_cp0: 0.1442 - top_5_categorical_accuracy_cp1: 0.5215 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.8081 - top_10_categorical_accuracy_cp0: 0.4564 - top_10_categorical_accuracy_cp1: 0.9283 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4479 - top_10_categorical_accuracy_p4: 0.9530 - top_20_categorical_accuracy_cp0: 0.6878 - top_20_categorical_accuracy_cp1: 0.9713 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.7743 - top_20_categorical_accuracy_p4: 0.9896DEBUG:root:Model metric val_loss improved from 0.176363 to 0.168175
7/7 [==============================] - 1s 124ms/step - loss: 0.1247 - categorical_accuracy: 0.2123 - top_5_categorical_accuracy: 0.7101 - top_10_categorical_accuracy: 0.8653 - top_20_categorical_accuracy: 0.9288 - top_5_categorical_accuracy_cp0: 0.1442 - top_5_categorical_accuracy_cp1: 0.5215 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1250 - top_5_categorical_accuracy_p4: 0.8081 - top_10_categorical_accuracy_cp0: 0.4564 - top_10_categorical_accuracy_cp1: 0.9283 - top_10_categorical_accuracy_cp2: 0.9793 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4479 - top_10_categorical_accuracy_p4: 0.9530 - top_20_categorical_accuracy_cp0: 0.6878 - top_20_categorical_accuracy_cp1: 0.9713 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.7743 - top_20_categorical_accuracy_p4: 0.9896 - val_loss: 0.1682 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.3912 - val_top_10_categorical_accuracy: 0.6118 - val_top_20_categorical_accuracy: 0.8412 - val_top_5_categorical_accuracy_cp0: 0.0736 - val_top_5_categorical_accuracy_cp1: 0.2985 - val_top_5_categorical_accuracy_cp2: 0.6923 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0976 - val_top_5_categorical_accuracy_p4: 0.6836 - val_top_10_categorical_accuracy_cp0: 0.3252 - val_top_10_categorical_accuracy_cp1: 0.7463 - val_top_10_categorical_accuracy_cp2: 0.8462 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.4309 - val_top_10_categorical_accuracy_p4: 0.8757 - val_top_20_categorical_accuracy_cp0: 0.6748 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8943 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1285 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.6914 - top_10_categorical_accuracy: 0.8398 - top_20_categorical_accuracy: 0.9219 - top_5_categorical_accuracy_cp0: 0.1491 - top_5_categorical_accuracy_cp1: 0.5943 - top_5_categorical_accuracy_cp2: 0.9244 - top_5_categorical_accuracy_cp3: 0.9692 - top_5_categorical_accuracy_cp4: 0.9352 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0943 - top_5_categorical_accuracy_p4: 0.7968 - top_10_categorical_accuracy_cp0: 0.4561 - top_10_categorical_accuracy_cp1: 0.9057 - top_10_categorical_accuracy_cp2: 0.9748 - top_10_categorical_accuracy_cp3: 0.9846 - top_10_categorical_accuracy_cp4: 0.9444 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.3962 - top_10_categorical_accuracy_p4: 0.9338 - top_20_categorical_accuracy_cp0: 0.7193 - top_20_categorical_accuracy_cp1: 0.9623 - top_20_categorical_accuracy_cp2: 0.9916 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9722 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.8113 - top_20_categorical_accuracy_p4: 0.97953/7 [===========>..................] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.2174 - top_5_categorical_accuracy: 0.7194 - top_10_categorical_accuracy: 0.8698 - top_20_categorical_accuracy: 0.9310 - top_5_categorical_accuracy_cp0: 0.1821 - top_5_categorical_accuracy_cp1: 0.5654 - top_5_categorical_accuracy_cp2: 0.9367 - top_5_categorical_accuracy_cp3: 0.9719 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1500 - top_5_categorical_accuracy_p4: 0.8200 - top_10_categorical_accuracy_cp0: 0.5123 - top_10_categorical_accuracy_cp1: 0.9223 - top_10_categorical_accuracy_cp2: 0.9797 - top_10_categorical_accuracy_cp3: 0.9888 - top_10_categorical_accuracy_cp4: 0.9719 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5071 - top_10_categorical_accuracy_p4: 0.9569 - top_20_categorical_accuracy_cp0: 0.7037 - top_20_categorical_accuracy_cp1: 0.9823 - top_20_categorical_accuracy_cp2: 0.9949 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9916 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0217 - top_20_categorical_accuracy_p3: 0.8429 - top_20_categorical_accuracy_p4: 0.9917    5/7 [====================>.........] - ETA: 0s - loss: 0.1217 - categorical_accuracy: 0.2195 - top_5_categorical_accuracy: 0.7270 - top_10_categorical_accuracy: 0.8703 - top_20_categorical_accuracy: 0.9336 - top_5_categorical_accuracy_cp0: 0.2004 - top_5_categorical_accuracy_cp1: 0.5662 - top_5_categorical_accuracy_cp2: 0.9272 - top_5_categorical_accuracy_cp3: 0.9684 - top_5_categorical_accuracy_cp4: 0.9706 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1488 - top_5_categorical_accuracy_p4: 0.8273 - top_10_categorical_accuracy_cp0: 0.5028 - top_10_categorical_accuracy_cp1: 0.9219 - top_10_categorical_accuracy_cp2: 0.9777 - top_10_categorical_accuracy_cp3: 0.9860 - top_10_categorical_accuracy_cp4: 0.9771 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4752 - top_10_categorical_accuracy_p4: 0.9578 - top_20_categorical_accuracy_cp0: 0.7032 - top_20_categorical_accuracy_cp1: 0.9826 - top_20_categorical_accuracy_cp2: 0.9970 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9951 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0290 - top_20_categorical_accuracy_p3: 0.8099 - top_20_categorical_accuracy_p4: 0.99377/7 [==============================] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.2194 - top_5_categorical_accuracy: 0.7274 - top_10_categorical_accuracy: 0.8711 - top_20_categorical_accuracy: 0.9336 - top_5_categorical_accuracy_cp0: 0.1981 - top_5_categorical_accuracy_cp1: 0.5609 - top_5_categorical_accuracy_cp2: 0.9258 - top_5_categorical_accuracy_cp3: 0.9676 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1458 - top_5_categorical_accuracy_p4: 0.8259 - top_10_categorical_accuracy_cp0: 0.4992 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9769 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4792 - top_10_categorical_accuracy_p4: 0.9564 - top_20_categorical_accuracy_cp0: 0.7005 - top_20_categorical_accuracy_cp1: 0.9785 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0349 - top_20_categorical_accuracy_p3: 0.7986 - top_20_categorical_accuracy_p4: 0.9933DEBUG:root:Model metric val_loss improved from 0.168175 to 0.162011
7/7 [==============================] - 1s 126ms/step - loss: 0.1214 - categorical_accuracy: 0.2194 - top_5_categorical_accuracy: 0.7274 - top_10_categorical_accuracy: 0.8711 - top_20_categorical_accuracy: 0.9336 - top_5_categorical_accuracy_cp0: 0.1981 - top_5_categorical_accuracy_cp1: 0.5609 - top_5_categorical_accuracy_cp2: 0.9258 - top_5_categorical_accuracy_cp3: 0.9676 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1458 - top_5_categorical_accuracy_p4: 0.8259 - top_10_categorical_accuracy_cp0: 0.4992 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9769 - top_10_categorical_accuracy_cp3: 0.9882 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4792 - top_10_categorical_accuracy_p4: 0.9564 - top_20_categorical_accuracy_cp0: 0.7005 - top_20_categorical_accuracy_cp1: 0.9785 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0349 - top_20_categorical_accuracy_p3: 0.7986 - top_20_categorical_accuracy_p4: 0.9933 - val_loss: 0.1620 - val_categorical_accuracy: 0.2441 - val_top_5_categorical_accuracy: 0.3706 - val_top_10_categorical_accuracy: 0.6559 - val_top_20_categorical_accuracy: 0.8471 - val_top_5_categorical_accuracy_cp0: 0.0429 - val_top_5_categorical_accuracy_cp1: 0.2537 - val_top_5_categorical_accuracy_cp2: 0.7308 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0569 - val_top_5_categorical_accuracy_p4: 0.6723 - val_top_10_categorical_accuracy_cp0: 0.3436 - val_top_10_categorical_accuracy_cp1: 0.9254 - val_top_10_categorical_accuracy_cp2: 0.8462 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.4553 - val_top_10_categorical_accuracy_p4: 0.9435 - val_top_20_categorical_accuracy_cp0: 0.6871 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.9106 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1226 - categorical_accuracy: 0.2227 - top_5_categorical_accuracy: 0.7090 - top_10_categorical_accuracy: 0.8594 - top_20_categorical_accuracy: 0.9297 - top_5_categorical_accuracy_cp0: 0.2035 - top_5_categorical_accuracy_cp1: 0.6237 - top_5_categorical_accuracy_cp2: 0.8686 - top_5_categorical_accuracy_cp3: 0.9825 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1633 - top_5_categorical_accuracy_p4: 0.8068 - top_10_categorical_accuracy_cp0: 0.5310 - top_10_categorical_accuracy_cp1: 0.9140 - top_10_categorical_accuracy_cp2: 0.9489 - top_10_categorical_accuracy_cp3: 0.9825 - top_10_categorical_accuracy_cp4: 0.9732 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5102 - top_10_categorical_accuracy_p4: 0.9432 - top_20_categorical_accuracy_cp0: 0.7345 - top_20_categorical_accuracy_cp1: 0.9677 - top_20_categorical_accuracy_cp2: 0.9854 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0769 - top_20_categorical_accuracy_p3: 0.8367 - top_20_categorical_accuracy_p4: 0.98643/7 [===========>..................] - ETA: 0s - loss: 0.1208 - categorical_accuracy: 0.2194 - top_5_categorical_accuracy: 0.7220 - top_10_categorical_accuracy: 0.8652 - top_20_categorical_accuracy: 0.9329 - top_5_categorical_accuracy_cp0: 0.2102 - top_5_categorical_accuracy_cp1: 0.5882 - top_5_categorical_accuracy_cp2: 0.9137 - top_5_categorical_accuracy_cp3: 0.9886 - top_5_categorical_accuracy_cp4: 0.9557 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1769 - top_5_categorical_accuracy_p4: 0.8192 - top_10_categorical_accuracy_cp0: 0.5165 - top_10_categorical_accuracy_cp1: 0.9228 - top_10_categorical_accuracy_cp2: 0.9670 - top_10_categorical_accuracy_cp3: 0.9943 - top_10_categorical_accuracy_cp4: 0.9695 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4626 - top_10_categorical_accuracy_p4: 0.9539 - top_20_categorical_accuracy_cp0: 0.7267 - top_20_categorical_accuracy_cp1: 0.9743 - top_20_categorical_accuracy_cp2: 0.9924 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9945 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0714 - top_20_categorical_accuracy_p3: 0.8163 - top_20_categorical_accuracy_p4: 0.99095/7 [====================>.........] - ETA: 0s - loss: 0.1196 - categorical_accuracy: 0.2230 - top_5_categorical_accuracy: 0.7316 - top_10_categorical_accuracy: 0.8723 - top_20_categorical_accuracy: 0.9348 - top_5_categorical_accuracy_cp0: 0.2088 - top_5_categorical_accuracy_cp1: 0.5794 - top_5_categorical_accuracy_cp2: 0.9211 - top_5_categorical_accuracy_cp3: 0.9857 - top_5_categorical_accuracy_cp4: 0.9662 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1757 - top_5_categorical_accuracy_p4: 0.8289 - top_10_categorical_accuracy_cp0: 0.5038 - top_10_categorical_accuracy_cp1: 0.9227 - top_10_categorical_accuracy_cp2: 0.9732 - top_10_categorical_accuracy_cp3: 0.9928 - top_10_categorical_accuracy_cp4: 0.9807 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.4854 - top_10_categorical_accuracy_p4: 0.9584 - top_20_categorical_accuracy_cp0: 0.7126 - top_20_categorical_accuracy_cp1: 0.9742 - top_20_categorical_accuracy_cp2: 0.9955 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0694 - top_20_categorical_accuracy_p3: 0.8201 - top_20_categorical_accuracy_p4: 0.99237/7 [==============================] - ETA: 0s - loss: 0.1192 - categorical_accuracy: 0.2239 - top_5_categorical_accuracy: 0.7355 - top_10_categorical_accuracy: 0.8760 - top_20_categorical_accuracy: 0.9369 - top_5_categorical_accuracy_cp0: 0.2171 - top_5_categorical_accuracy_cp1: 0.5806 - top_5_categorical_accuracy_cp2: 0.9234 - top_5_categorical_accuracy_cp3: 0.9824 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1771 - top_5_categorical_accuracy_p4: 0.8319 - top_10_categorical_accuracy_cp0: 0.5151 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9781 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9801 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5000 - top_10_categorical_accuracy_p4: 0.9597 - top_20_categorical_accuracy_cp0: 0.7179 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9964 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.8299 - top_20_categorical_accuracy_p4: 0.9929DEBUG:root:Model metric val_loss improved from 0.162011 to 0.156669
7/7 [==============================] - 1s 125ms/step - loss: 0.1192 - categorical_accuracy: 0.2239 - top_5_categorical_accuracy: 0.7355 - top_10_categorical_accuracy: 0.8760 - top_20_categorical_accuracy: 0.9369 - top_5_categorical_accuracy_cp0: 0.2171 - top_5_categorical_accuracy_cp1: 0.5806 - top_5_categorical_accuracy_cp2: 0.9234 - top_5_categorical_accuracy_cp3: 0.9824 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1771 - top_5_categorical_accuracy_p4: 0.8319 - top_10_categorical_accuracy_cp0: 0.5151 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9781 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9801 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5000 - top_10_categorical_accuracy_p4: 0.9597 - top_20_categorical_accuracy_cp0: 0.7179 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9964 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.8299 - top_20_categorical_accuracy_p4: 0.9929 - val_loss: 0.1567 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.5353 - val_top_10_categorical_accuracy: 0.7676 - val_top_20_categorical_accuracy: 0.8529 - val_top_5_categorical_accuracy_cp0: 0.2086 - val_top_5_categorical_accuracy_cp1: 0.6866 - val_top_5_categorical_accuracy_cp2: 0.7308 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2764 - val_top_5_categorical_accuracy_p4: 0.8362 - val_top_10_categorical_accuracy_cp0: 0.5583 - val_top_10_categorical_accuracy_cp1: 0.9552 - val_top_10_categorical_accuracy_cp2: 0.8846 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.7398 - val_top_10_categorical_accuracy_p4: 0.9605 - val_top_20_categorical_accuracy_cp0: 0.6994 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.9268 - val_top_20_categorical_accuracy_p4: 0.9944
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1122 - categorical_accuracy: 0.2188 - top_5_categorical_accuracy: 0.7773 - top_10_categorical_accuracy: 0.9180 - top_20_categorical_accuracy: 0.9551 - top_5_categorical_accuracy_cp0: 0.3452 - top_5_categorical_accuracy_cp1: 0.5800 - top_5_categorical_accuracy_cp2: 0.9028 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9781 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2143 - top_5_categorical_accuracy_p4: 0.8531 - top_10_categorical_accuracy_cp0: 0.6429 - top_10_categorical_accuracy_cp1: 0.9400 - top_10_categorical_accuracy_cp2: 0.9722 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.6429 - top_10_categorical_accuracy_p4: 0.9715 - top_20_categorical_accuracy_cp0: 0.7857 - top_20_categorical_accuracy_cp1: 0.9700 - top_20_categorical_accuracy_cp2: 0.9931 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1111 - top_20_categorical_accuracy_p3: 0.8810 - top_20_categorical_accuracy_p4: 0.98903/7 [===========>..................] - ETA: 0s - loss: 0.1176 - categorical_accuracy: 0.2240 - top_5_categorical_accuracy: 0.7487 - top_10_categorical_accuracy: 0.8841 - top_20_categorical_accuracy: 0.9388 - top_5_categorical_accuracy_cp0: 0.2762 - top_5_categorical_accuracy_cp1: 0.5812 - top_5_categorical_accuracy_cp2: 0.9206 - top_5_categorical_accuracy_cp3: 0.9880 - top_5_categorical_accuracy_cp4: 0.9786 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2095 - top_5_categorical_accuracy_p4: 0.8445 - top_10_categorical_accuracy_cp0: 0.5651 - top_10_categorical_accuracy_cp1: 0.9097 - top_10_categorical_accuracy_cp2: 0.9727 - top_10_categorical_accuracy_cp3: 0.9940 - top_10_categorical_accuracy_cp4: 0.9893 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5811 - top_10_categorical_accuracy_p4: 0.9600 - top_20_categorical_accuracy_cp0: 0.7429 - top_20_categorical_accuracy_cp1: 0.9675 - top_20_categorical_accuracy_cp2: 0.9926 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0976 - top_20_categorical_accuracy_p3: 0.8514 - top_20_categorical_accuracy_p4: 0.99025/7 [====================>.........] - ETA: 0s - loss: 0.1177 - categorical_accuracy: 0.2211 - top_5_categorical_accuracy: 0.7496 - top_10_categorical_accuracy: 0.8875 - top_20_categorical_accuracy: 0.9387 - top_5_categorical_accuracy_cp0: 0.2680 - top_5_categorical_accuracy_cp1: 0.5788 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9854 - top_5_categorical_accuracy_cp4: 0.9729 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1949 - top_5_categorical_accuracy_p4: 0.8448 - top_10_categorical_accuracy_cp0: 0.5592 - top_10_categorical_accuracy_cp1: 0.9179 - top_10_categorical_accuracy_cp2: 0.9794 - top_10_categorical_accuracy_cp3: 0.9964 - top_10_categorical_accuracy_cp4: 0.9873 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5551 - top_10_categorical_accuracy_p4: 0.9657 - top_20_categorical_accuracy_cp0: 0.7301 - top_20_categorical_accuracy_cp1: 0.9719 - top_20_categorical_accuracy_cp2: 0.9956 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0580 - top_20_categorical_accuracy_p3: 0.8475 - top_20_categorical_accuracy_p4: 0.99197/7 [==============================] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.2226 - top_5_categorical_accuracy: 0.7490 - top_10_categorical_accuracy: 0.8856 - top_20_categorical_accuracy: 0.9385 - top_5_categorical_accuracy_cp0: 0.2789 - top_5_categorical_accuracy_cp1: 0.5717 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2153 - top_5_categorical_accuracy_p4: 0.8435 - top_10_categorical_accuracy_cp0: 0.5610 - top_10_categorical_accuracy_cp1: 0.9176 - top_10_categorical_accuracy_cp2: 0.9781 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5660 - top_10_categorical_accuracy_p4: 0.9638 - top_20_categorical_accuracy_cp0: 0.7306 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.8542 - top_20_categorical_accuracy_p4: 0.9922DEBUG:root:Model metric val_loss improved from 0.156669 to 0.151148
7/7 [==============================] - 1s 121ms/step - loss: 0.1175 - categorical_accuracy: 0.2226 - top_5_categorical_accuracy: 0.7490 - top_10_categorical_accuracy: 0.8856 - top_20_categorical_accuracy: 0.9385 - top_5_categorical_accuracy_cp0: 0.2789 - top_5_categorical_accuracy_cp1: 0.5717 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9695 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.2153 - top_5_categorical_accuracy_p4: 0.8435 - top_10_categorical_accuracy_cp0: 0.5610 - top_10_categorical_accuracy_cp1: 0.9176 - top_10_categorical_accuracy_cp2: 0.9781 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 0.9827 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.5660 - top_10_categorical_accuracy_p4: 0.9638 - top_20_categorical_accuracy_cp0: 0.7306 - top_20_categorical_accuracy_cp1: 0.9767 - top_20_categorical_accuracy_cp2: 0.9951 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0581 - top_20_categorical_accuracy_p3: 0.8542 - top_20_categorical_accuracy_p4: 0.9922 - val_loss: 0.1511 - val_categorical_accuracy: 0.2412 - val_top_5_categorical_accuracy: 0.6588 - val_top_10_categorical_accuracy: 0.7824 - val_top_20_categorical_accuracy: 0.8588 - val_top_5_categorical_accuracy_cp0: 0.4356 - val_top_5_categorical_accuracy_cp1: 0.7761 - val_top_5_categorical_accuracy_cp2: 0.6923 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.5772 - val_top_5_categorical_accuracy_p4: 0.8644 - val_top_10_categorical_accuracy_cp0: 0.5951 - val_top_10_categorical_accuracy_cp1: 0.9701 - val_top_10_categorical_accuracy_cp2: 0.8077 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.7886 - val_top_10_categorical_accuracy_p4: 0.9548 - val_top_20_categorical_accuracy_cp0: 0.7117 - val_top_20_categorical_accuracy_cp1: 0.9851 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.9431 - val_top_20_categorical_accuracy_p4: 0.9944
INFO:root:Restoring best model weights with val_loss: 0.151148 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  7.23it/s]Calculating prediction outputs...: 1it [00:00,  7.22it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1106.30it/s]
INFO:root:Finished run 0296784f45bd4f9fbf5b3ae2fcb61848
for knowledge_type in gram gram gram ; do \
	for col_name in fine_log_cluster_template medium_log_cluster_template coarse_log_cluster_template ; do \
		~/miniconda3/envs/lena/bin/python main.py \
			--experimentconfig_sequence_type huawei_logs \
			--experimentconfig_model_type $knowledge_type \
			--huaweipreprocessorconfig_min_causality 0.01 \
			--experimentconfig_batch_size 128 \
			--no-modelconfig_base_feature_embeddings_trainable \
			--no-modelconfig_base_hidden_embeddings_trainable \
			--sequenceconfig_y_sequence_column_name attributes \
			--sequenceconfig_x_sequence_column_name $col_name \
			--huaweipreprocessorconfig_relevant_log_column $col_name \
			--sequenceconfig_max_window_size 10 \
			--sequenceconfig_min_window_size 10 \
			--experimentconfig_multilabel_classification \
			--sequenceconfig_flatten_y \
			--modelconfig_rnn_type gru \
			--modelconfig_rnn_dim 200 \
			--modelconfig_embedding_dim 300 \
			--modelconfig_attention_dim 100 \
			--huaweipreprocessorconfig_log_parser drain \
			 ; \
	done ; \
done ; \

2023-05-24 20:12:47.772520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:12:48.283848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:12:48.283907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:12:48.283913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run d0c96a18d63347bf8c385fe6e455213c
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12121.28it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13264.71it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13062.48it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 23999.45it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:12:50.629181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.629554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.630507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.630676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.630823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.630969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.631393: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:12:50.759508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.759736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.759898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.760037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.760169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:50.760297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.329680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.329876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.330028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.330160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.330289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.330405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:12:52.330803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:12:52.330917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12708.51it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13304.81it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13154.23it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24179.31it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 287.67it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 58/154 [00:00<00:00, 287.88it/s]Loading hierarchy for column coarse_log_cluster_path:  56%|█████▋    | 87/154 [00:00<00:00, 287.89it/s]Loading hierarchy for column coarse_log_cluster_path:  75%|███████▌  | 116/154 [00:00<00:00, 288.37it/s]Loading hierarchy for column coarse_log_cluster_path:  95%|█████████▍| 146/154 [00:00<00:00, 289.86it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 289.08it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:51,  7.72it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5178.65it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 38721.47it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/198 [00:00<?, ?it/s]Initializing gram_embedding connections:  42%|████▏     | 83/198 [00:00<00:00, 816.68it/s]Initializing gram_embedding connections:  83%|████████▎ | 165/198 [00:00<00:00, 398.77it/s]Initializing gram_embedding connections: 100%|██████████| 198/198 [00:00<00:00, 363.12it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.07it/s]Calculating percentile frequencies...: 7it [00:00,  7.45it/s]
2023-05-24 20:12:57.005795: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:13:29.825060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:13:30.406797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:13:30.540201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:13:30.957619: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f8750002190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:13:30.957661: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:13:30.957672: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:13:30.964215: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:13:31.078427: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1928 - categorical_accuracy: 0.0172 - top_5_categorical_accuracy: 0.0728 - top_10_categorical_accuracy: 0.1341 - top_20_categorical_accuracy: 0.2395 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.0909 - top_5_categorical_accuracy_cp2: 0.1786 - top_5_categorical_accuracy_cp3: 0.0424 - top_5_categorical_accuracy_cp4: 0.0410 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.1111 - top_5_categorical_accuracy_p3: 0.0263 - top_5_categorical_accuracy_p4: 0.0763 - top_10_categorical_accuracy_cp0: 0.0808 - top_10_categorical_accuracy_cp1: 0.1313 - top_10_categorical_accuracy_cp2: 0.2500 - top_10_categorical_accuracy_cp3: 0.1017 - top_10_categorical_accuracy_cp4: 0.1311 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.2222 - top_10_categorical_accuracy_p3: 0.0526 - top_10_categorical_accuracy_p4: 0.1394 - top_20_categorical_accuracy_cp0: 0.1616 - top_20_categorical_accuracy_cp1: 0.2525 - top_20_categorical_accuracy_cp2: 0.3929 - top_20_categorical_accuracy_cp3: 0.1864 - top_20_categorical_accuracy_cp4: 0.2377 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2778 - top_20_categorical_accuracy_p3: 0.1316 - top_20_categorical_accuracy_p4: 0.2505      3/Unknown - 34s 36ms/step - loss: 0.1930 - categorical_accuracy: 0.0960 - top_5_categorical_accuracy: 0.2746 - top_10_categorical_accuracy: 0.3764 - top_20_categorical_accuracy: 0.4851 - top_5_categorical_accuracy_cp0: 0.0273 - top_5_categorical_accuracy_cp1: 0.0708 - top_5_categorical_accuracy_cp2: 0.4226 - top_5_categorical_accuracy_cp3: 0.3776 - top_5_categorical_accuracy_cp4: 0.4545 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0426 - top_5_categorical_accuracy_p3: 0.0345 - top_5_categorical_accuracy_p4: 0.3069 - top_10_categorical_accuracy_cp0: 0.0717 - top_10_categorical_accuracy_cp1: 0.1477 - top_10_categorical_accuracy_cp2: 0.5858 - top_10_categorical_accuracy_cp3: 0.5166 - top_10_categorical_accuracy_cp4: 0.5506 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.1064 - top_10_categorical_accuracy_p3: 0.0862 - top_10_categorical_accuracy_p4: 0.4157 - top_20_categorical_accuracy_cp0: 0.1604 - top_20_categorical_accuracy_cp1: 0.2954 - top_20_categorical_accuracy_cp2: 0.7155 - top_20_categorical_accuracy_cp3: 0.6193 - top_20_categorical_accuracy_cp4: 0.6338 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1111 - top_20_categorical_accuracy_p2: 0.1915 - top_20_categorical_accuracy_p3: 0.1552 - top_20_categorical_accuracy_p4: 0.5288         5/Unknown - 35s 37ms/step - loss: 0.1930 - categorical_accuracy: 0.1186 - top_5_categorical_accuracy: 0.3782 - top_10_categorical_accuracy: 0.4850 - top_20_categorical_accuracy: 0.5849 - top_5_categorical_accuracy_cp0: 0.0173 - top_5_categorical_accuracy_cp1: 0.0762 - top_5_categorical_accuracy_cp2: 0.5666 - top_5_categorical_accuracy_cp3: 0.5809 - top_5_categorical_accuracy_cp4: 0.6516 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0263 - top_5_categorical_accuracy_p3: 0.0190 - top_5_categorical_accuracy_p4: 0.4298 - top_10_categorical_accuracy_cp0: 0.0710 - top_10_categorical_accuracy_cp1: 0.2196 - top_10_categorical_accuracy_cp2: 0.7311 - top_10_categorical_accuracy_cp3: 0.7068 - top_10_categorical_accuracy_cp4: 0.7177 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0658 - top_10_categorical_accuracy_p3: 0.0664 - top_10_categorical_accuracy_p4: 0.5463 - top_20_categorical_accuracy_cp0: 0.1804 - top_20_categorical_accuracy_cp1: 0.4029 - top_20_categorical_accuracy_cp2: 0.8198 - top_20_categorical_accuracy_cp3: 0.7734 - top_20_categorical_accuracy_cp4: 0.7726 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1000 - top_20_categorical_accuracy_p2: 0.1711 - top_20_categorical_accuracy_p3: 0.1801 - top_20_categorical_accuracy_p4: 0.6454      7/Unknown - 35s 36ms/step - loss: 0.1923 - categorical_accuracy: 0.1237 - top_5_categorical_accuracy: 0.4159 - top_10_categorical_accuracy: 0.5261 - top_20_categorical_accuracy: 0.6218 - top_5_categorical_accuracy_cp0: 0.0162 - top_5_categorical_accuracy_cp1: 0.0749 - top_5_categorical_accuracy_cp2: 0.6173 - top_5_categorical_accuracy_cp3: 0.6361 - top_5_categorical_accuracy_cp4: 0.7118 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0235 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.4714 - top_10_categorical_accuracy_cp0: 0.0713 - top_10_categorical_accuracy_cp1: 0.2492 - top_10_categorical_accuracy_cp2: 0.7798 - top_10_categorical_accuracy_cp3: 0.7574 - top_10_categorical_accuracy_cp4: 0.7676 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0588 - top_10_categorical_accuracy_p3: 0.0667 - top_10_categorical_accuracy_p4: 0.5916 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.4419 - top_20_categorical_accuracy_cp2: 0.8580 - top_20_categorical_accuracy_cp3: 0.8136 - top_20_categorical_accuracy_cp4: 0.8127 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1529 - top_20_categorical_accuracy_p3: 0.1686 - top_20_categorical_accuracy_p4: 0.68742023-05-24 20:13:32.100333: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195326
7/7 [==============================] - 53s 3s/step - loss: 0.1923 - categorical_accuracy: 0.1237 - top_5_categorical_accuracy: 0.4159 - top_10_categorical_accuracy: 0.5261 - top_20_categorical_accuracy: 0.6218 - top_5_categorical_accuracy_cp0: 0.0162 - top_5_categorical_accuracy_cp1: 0.0749 - top_5_categorical_accuracy_cp2: 0.6173 - top_5_categorical_accuracy_cp3: 0.6361 - top_5_categorical_accuracy_cp4: 0.7118 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0235 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.4714 - top_10_categorical_accuracy_cp0: 0.0713 - top_10_categorical_accuracy_cp1: 0.2492 - top_10_categorical_accuracy_cp2: 0.7798 - top_10_categorical_accuracy_cp3: 0.7574 - top_10_categorical_accuracy_cp4: 0.7676 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0588 - top_10_categorical_accuracy_p3: 0.0667 - top_10_categorical_accuracy_p4: 0.5916 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.4419 - top_20_categorical_accuracy_cp2: 0.8580 - top_20_categorical_accuracy_cp3: 0.8136 - top_20_categorical_accuracy_cp4: 0.8127 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1529 - top_20_categorical_accuracy_p3: 0.1686 - top_20_categorical_accuracy_p4: 0.6874 - val_loss: 0.1953 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2901 - val_top_10_categorical_accuracy: 0.4873 - val_top_20_categorical_accuracy: 0.5014 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9882 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5309 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9130 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8918 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9175
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1883 - categorical_accuracy: 0.1328 - top_5_categorical_accuracy: 0.5712 - top_10_categorical_accuracy: 0.7002 - top_20_categorical_accuracy: 0.7951 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0090 - top_5_categorical_accuracy_cp2: 0.8442 - top_5_categorical_accuracy_cp3: 0.9573 - top_5_categorical_accuracy_cp4: 0.9840 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6459 - top_10_categorical_accuracy_cp0: 0.0515 - top_10_categorical_accuracy_cp1: 0.4144 - top_10_categorical_accuracy_cp2: 0.9870 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1081 - top_10_categorical_accuracy_p4: 0.7833 - top_20_categorical_accuracy_cp0: 0.2268 - top_20_categorical_accuracy_cp1: 0.7027 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.2703 - top_20_categorical_accuracy_p4: 0.87343/7 [===========>..................] - ETA: 0s - loss: 0.1862 - categorical_accuracy: 0.1294 - top_5_categorical_accuracy: 0.5533 - top_10_categorical_accuracy: 0.6872 - top_20_categorical_accuracy: 0.7836 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0224 - top_5_categorical_accuracy_cp2: 0.8417 - top_5_categorical_accuracy_cp3: 0.9091 - top_5_categorical_accuracy_cp4: 0.9860 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6402 - top_10_categorical_accuracy_cp0: 0.0554 - top_10_categorical_accuracy_cp1: 0.4135 - top_10_categorical_accuracy_cp2: 0.9917 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0597 - top_10_categorical_accuracy_p4: 0.7893 - top_20_categorical_accuracy_cp0: 0.2338 - top_20_categorical_accuracy_cp1: 0.7051 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0952 - top_20_categorical_accuracy_p2: 0.0600 - top_20_categorical_accuracy_p3: 0.2239 - top_20_categorical_accuracy_p4: 0.88115/7 [====================>.........] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.1333 - top_5_categorical_accuracy: 0.5625 - top_10_categorical_accuracy: 0.6950 - top_20_categorical_accuracy: 0.7978 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0170 - top_5_categorical_accuracy_cp2: 0.8418 - top_5_categorical_accuracy_cp3: 0.9119 - top_5_categorical_accuracy_cp4: 0.9887 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6422 - top_10_categorical_accuracy_cp0: 0.0530 - top_10_categorical_accuracy_cp1: 0.4015 - top_10_categorical_accuracy_cp2: 0.9951 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0529 - top_10_categorical_accuracy_p4: 0.7887 - top_20_categorical_accuracy_cp0: 0.2318 - top_20_categorical_accuracy_cp1: 0.7348 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0690 - top_20_categorical_accuracy_p2: 0.1067 - top_20_categorical_accuracy_p3: 0.2115 - top_20_categorical_accuracy_p4: 0.88747/7 [==============================] - ETA: 0s - loss: 0.1810 - categorical_accuracy: 0.1312 - top_5_categorical_accuracy: 0.5565 - top_10_categorical_accuracy: 0.6930 - top_20_categorical_accuracy: 0.8001 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0199 - top_5_categorical_accuracy_cp2: 0.8354 - top_5_categorical_accuracy_cp3: 0.8994 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6341 - top_10_categorical_accuracy_cp0: 0.0502 - top_10_categorical_accuracy_cp1: 0.4052 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.7858 - top_20_categorical_accuracy_cp0: 0.2285 - top_20_categorical_accuracy_cp1: 0.7538 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.8888DEBUG:root:Model metric val_loss improved from 0.195326 to 0.186910
7/7 [==============================] - 1s 105ms/step - loss: 0.1810 - categorical_accuracy: 0.1312 - top_5_categorical_accuracy: 0.5565 - top_10_categorical_accuracy: 0.6930 - top_20_categorical_accuracy: 0.8001 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0199 - top_5_categorical_accuracy_cp2: 0.8354 - top_5_categorical_accuracy_cp3: 0.8994 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6341 - top_10_categorical_accuracy_cp0: 0.0502 - top_10_categorical_accuracy_cp1: 0.4052 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.7858 - top_20_categorical_accuracy_cp0: 0.2285 - top_20_categorical_accuracy_cp1: 0.7538 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.8888 - val_loss: 0.1869 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.0930 - val_top_10_categorical_accuracy: 0.4761 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.0941 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.1701 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8551 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8711 - val_top_20_categorical_accuracy_cp0: 0.0057 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0081 - val_top_20_categorical_accuracy_p4: 0.9175
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1558 - categorical_accuracy: 0.1293 - top_5_categorical_accuracy: 0.5798 - top_10_categorical_accuracy: 0.7053 - top_20_categorical_accuracy: 0.8118 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0198 - top_5_categorical_accuracy_cp2: 0.9167 - top_5_categorical_accuracy_cp3: 0.8448 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6503 - top_10_categorical_accuracy_cp0: 0.0208 - top_10_categorical_accuracy_cp1: 0.3960 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7889 - top_20_categorical_accuracy_cp0: 0.2083 - top_20_categorical_accuracy_cp1: 0.7723 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2162 - top_20_categorical_accuracy_p4: 0.89343/7 [===========>..................] - ETA: 0s - loss: 0.1492 - categorical_accuracy: 0.1156 - top_5_categorical_accuracy: 0.5289 - top_10_categorical_accuracy: 0.6768 - top_20_categorical_accuracy: 0.8070 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0153 - top_5_categorical_accuracy_cp2: 0.8293 - top_5_categorical_accuracy_cp3: 0.8054 - top_5_categorical_accuracy_cp4: 0.9944 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6036 - top_10_categorical_accuracy_cp0: 0.0257 - top_10_categorical_accuracy_cp1: 0.3761 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9940 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0238 - top_10_categorical_accuracy_p4: 0.7703 - top_20_categorical_accuracy_cp0: 0.2315 - top_20_categorical_accuracy_cp1: 0.8012 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0238 - top_20_categorical_accuracy_p3: 0.2222 - top_20_categorical_accuracy_p4: 0.8993        5/7 [====================>.........] - ETA: 0s - loss: 0.1468 - categorical_accuracy: 0.1181 - top_5_categorical_accuracy: 0.5286 - top_10_categorical_accuracy: 0.6955 - top_20_categorical_accuracy: 0.8197 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0147 - top_5_categorical_accuracy_cp2: 0.8040 - top_5_categorical_accuracy_cp3: 0.7896 - top_5_categorical_accuracy_cp4: 0.9968 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6002 - top_10_categorical_accuracy_cp0: 0.0318 - top_10_categorical_accuracy_cp1: 0.4330 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9946 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0149 - top_10_categorical_accuracy_p4: 0.7884 - top_20_categorical_accuracy_cp0: 0.2406 - top_20_categorical_accuracy_cp1: 0.8330 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0357 - top_20_categorical_accuracy_p2: 0.0571 - top_20_categorical_accuracy_p3: 0.1940 - top_20_categorical_accuracy_p4: 0.91177/7 [==============================] - ETA: 0s - loss: 0.1468 - categorical_accuracy: 0.1177 - top_5_categorical_accuracy: 0.5254 - top_10_categorical_accuracy: 0.6955 - top_20_categorical_accuracy: 0.8214 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0122 - top_5_categorical_accuracy_cp2: 0.7942 - top_5_categorical_accuracy_cp3: 0.7855 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5987 - top_10_categorical_accuracy_cp0: 0.0292 - top_10_categorical_accuracy_cp1: 0.4373 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9956 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.7915 - top_20_categorical_accuracy_cp0: 0.2366 - top_20_categorical_accuracy_cp1: 0.8502 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.9163DEBUG:root:Model metric val_loss improved from 0.186910 to 0.184671
7/7 [==============================] - 1s 112ms/step - loss: 0.1468 - categorical_accuracy: 0.1177 - top_5_categorical_accuracy: 0.5254 - top_10_categorical_accuracy: 0.6955 - top_20_categorical_accuracy: 0.8214 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0122 - top_5_categorical_accuracy_cp2: 0.7942 - top_5_categorical_accuracy_cp3: 0.7855 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5987 - top_10_categorical_accuracy_cp0: 0.0292 - top_10_categorical_accuracy_cp1: 0.4373 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9956 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.7915 - top_20_categorical_accuracy_cp0: 0.2366 - top_20_categorical_accuracy_cp1: 0.8502 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.9163 - val_loss: 0.1847 - val_categorical_accuracy: 0.0000e+00 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4704 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8261 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8608 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1311 - categorical_accuracy: 0.1284 - top_5_categorical_accuracy: 0.5728 - top_10_categorical_accuracy: 0.7241 - top_20_categorical_accuracy: 0.8372 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.7941 - top_5_categorical_accuracy_cp3: 0.8125 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6458 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.4045 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8164 - top_20_categorical_accuracy_cp0: 0.2198 - top_20_categorical_accuracy_cp1: 0.8427 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.1463 - top_20_categorical_accuracy_p4: 0.92873/7 [===========>..................] - ETA: 0s - loss: 0.1359 - categorical_accuracy: 0.1233 - top_5_categorical_accuracy: 0.5442 - top_10_categorical_accuracy: 0.6985 - top_20_categorical_accuracy: 0.8293 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0066 - top_5_categorical_accuracy_cp2: 0.8023 - top_5_categorical_accuracy_cp3: 0.8659 - top_5_categorical_accuracy_cp4: 0.9750 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6181 - top_10_categorical_accuracy_cp0: 0.0064 - top_10_categorical_accuracy_cp1: 0.4507 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7933 - top_20_categorical_accuracy_cp0: 0.2212 - top_20_categorical_accuracy_cp1: 0.9112 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0256 - top_20_categorical_accuracy_p3: 0.1322 - top_20_categorical_accuracy_p4: 0.9296        5/7 [====================>.........] - ETA: 0s - loss: 0.1346 - categorical_accuracy: 0.1300 - top_5_categorical_accuracy: 0.5465 - top_10_categorical_accuracy: 0.7092 - top_20_categorical_accuracy: 0.8438 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0188 - top_5_categorical_accuracy_cp2: 0.8213 - top_5_categorical_accuracy_cp3: 0.8971 - top_5_categorical_accuracy_cp4: 0.9437 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6224 - top_10_categorical_accuracy_cp0: 0.0099 - top_10_categorical_accuracy_cp1: 0.5009 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0048 - top_10_categorical_accuracy_p4: 0.8073 - top_20_categorical_accuracy_cp0: 0.2465 - top_20_categorical_accuracy_cp1: 0.9416 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0290 - top_20_categorical_accuracy_p3: 0.1722 - top_20_categorical_accuracy_p4: 0.9444    7/7 [==============================] - ETA: 0s - loss: 0.1349 - categorical_accuracy: 0.1347 - top_5_categorical_accuracy: 0.5471 - top_10_categorical_accuracy: 0.7112 - top_20_categorical_accuracy: 0.8462 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0245 - top_5_categorical_accuracy_cp2: 0.8313 - top_5_categorical_accuracy_cp3: 0.9068 - top_5_categorical_accuracy_cp4: 0.9429 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6234 - top_10_categorical_accuracy_cp0: 0.0113 - top_10_categorical_accuracy_cp1: 0.5260 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8101 - top_20_categorical_accuracy_cp0: 0.2577 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9474DEBUG:root:Model metric val_loss improved from 0.184671 to 0.176666
7/7 [==============================] - 1s 105ms/step - loss: 0.1349 - categorical_accuracy: 0.1347 - top_5_categorical_accuracy: 0.5471 - top_10_categorical_accuracy: 0.7112 - top_20_categorical_accuracy: 0.8462 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0245 - top_5_categorical_accuracy_cp2: 0.8313 - top_5_categorical_accuracy_cp3: 0.9068 - top_5_categorical_accuracy_cp4: 0.9429 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6234 - top_10_categorical_accuracy_cp0: 0.0113 - top_10_categorical_accuracy_cp1: 0.5260 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8101 - top_20_categorical_accuracy_cp0: 0.2577 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9474 - val_loss: 0.1767 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.3408 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1594 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6237 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1332 - categorical_accuracy: 0.1559 - top_5_categorical_accuracy: 0.5741 - top_10_categorical_accuracy: 0.7357 - top_20_categorical_accuracy: 0.8574 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1207 - top_5_categorical_accuracy_cp2: 0.8312 - top_5_categorical_accuracy_cp3: 0.9907 - top_5_categorical_accuracy_cp4: 0.9141 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6467 - top_10_categorical_accuracy_cp0: 0.0103 - top_10_categorical_accuracy_cp1: 0.6379 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8287 - top_20_categorical_accuracy_cp0: 0.2474 - top_20_categorical_accuracy_cp1: 0.9828 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1053 - top_20_categorical_accuracy_p4: 0.95723/7 [===========>..................] - ETA: 0s - loss: 0.1344 - categorical_accuracy: 0.1736 - top_5_categorical_accuracy: 0.5627 - top_10_categorical_accuracy: 0.7136 - top_20_categorical_accuracy: 0.8390 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0774 - top_5_categorical_accuracy_cp2: 0.8347 - top_5_categorical_accuracy_cp3: 0.9849 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6482 - top_10_categorical_accuracy_cp0: 0.0061 - top_10_categorical_accuracy_cp1: 0.6192 - top_10_categorical_accuracy_cp2: 0.9958 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8219 - top_20_categorical_accuracy_cp0: 0.2432 - top_20_categorical_accuracy_cp1: 0.9845 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1397 - top_20_categorical_accuracy_p4: 0.95265/7 [====================>.........] - ETA: 0s - loss: 0.1322 - categorical_accuracy: 0.1769 - top_5_categorical_accuracy: 0.5677 - top_10_categorical_accuracy: 0.7180 - top_20_categorical_accuracy: 0.8497 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0776 - top_5_categorical_accuracy_cp2: 0.8041 - top_5_categorical_accuracy_cp3: 0.9823 - top_5_categorical_accuracy_cp4: 0.9571 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6504 - top_10_categorical_accuracy_cp0: 0.0057 - top_10_categorical_accuracy_cp1: 0.5989 - top_10_categorical_accuracy_cp2: 0.9949 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9983 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8226 - top_20_categorical_accuracy_cp0: 0.2595 - top_20_categorical_accuracy_cp1: 0.9871 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1549 - top_20_categorical_accuracy_p4: 0.95907/7 [==============================] - ETA: 0s - loss: 0.1309 - categorical_accuracy: 0.1767 - top_5_categorical_accuracy: 0.5734 - top_10_categorical_accuracy: 0.7235 - top_20_categorical_accuracy: 0.8569 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0856 - top_5_categorical_accuracy_cp2: 0.7963 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6534 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5994 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8244 - top_20_categorical_accuracy_cp0: 0.2771 - top_20_categorical_accuracy_cp1: 0.9847 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1608 - top_20_categorical_accuracy_p4: 0.9617DEBUG:root:Model metric val_loss improved from 0.176666 to 0.172919
7/7 [==============================] - 1s 112ms/step - loss: 0.1309 - categorical_accuracy: 0.1767 - top_5_categorical_accuracy: 0.5734 - top_10_categorical_accuracy: 0.7235 - top_20_categorical_accuracy: 0.8569 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0856 - top_5_categorical_accuracy_cp2: 0.7963 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6534 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5994 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8244 - top_20_categorical_accuracy_cp0: 0.2771 - top_20_categorical_accuracy_cp1: 0.9847 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1608 - top_20_categorical_accuracy_p4: 0.9617 - val_loss: 0.1729 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3296 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1014 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6031 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1334 - categorical_accuracy: 0.1695 - top_5_categorical_accuracy: 0.5028 - top_10_categorical_accuracy: 0.6836 - top_20_categorical_accuracy: 0.8569 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0709 - top_5_categorical_accuracy_cp2: 0.5645 - top_5_categorical_accuracy_cp3: 0.9825 - top_5_categorical_accuracy_cp4: 0.9737 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5693 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5827 - top_10_categorical_accuracy_cp2: 0.9677 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7740 - top_20_categorical_accuracy_cp0: 0.3509 - top_20_categorical_accuracy_cp1: 0.9843 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0976 - top_20_categorical_accuracy_p4: 0.96163/7 [===========>..................] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.1816 - top_5_categorical_accuracy: 0.5576 - top_10_categorical_accuracy: 0.7203 - top_20_categorical_accuracy: 0.8703 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1029 - top_5_categorical_accuracy_cp2: 0.6856 - top_5_categorical_accuracy_cp3: 0.9852 - top_5_categorical_accuracy_cp4: 0.9781 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6293 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.6147 - top_10_categorical_accuracy_cp2: 0.9782 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0175 - top_10_categorical_accuracy_p4: 0.8114 - top_20_categorical_accuracy_cp0: 0.3463 - top_20_categorical_accuracy_cp1: 0.9912 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1754 - top_20_categorical_accuracy_p4: 0.9679    5/7 [====================>.........] - ETA: 0s - loss: 0.1257 - categorical_accuracy: 0.1873 - top_5_categorical_accuracy: 0.5763 - top_10_categorical_accuracy: 0.7297 - top_20_categorical_accuracy: 0.8691 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1199 - top_5_categorical_accuracy_cp2: 0.7328 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9777 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6557 - top_10_categorical_accuracy_cp0: 0.0099 - top_10_categorical_accuracy_cp1: 0.6328 - top_10_categorical_accuracy_cp2: 0.9771 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0190 - top_10_categorical_accuracy_p4: 0.8285 - top_20_categorical_accuracy_cp0: 0.3274 - top_20_categorical_accuracy_cp1: 0.9945 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2000 - top_20_categorical_accuracy_p4: 0.97067/7 [==============================] - ETA: 0s - loss: 0.1257 - categorical_accuracy: 0.1899 - top_5_categorical_accuracy: 0.5794 - top_10_categorical_accuracy: 0.7313 - top_20_categorical_accuracy: 0.8657 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1254 - top_5_categorical_accuracy_cp2: 0.7469 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6602 - top_10_categorical_accuracy_cp0: 0.0146 - top_10_categorical_accuracy_cp1: 0.6346 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8315 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9893 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9689DEBUG:root:Model metric val_loss improved from 0.172919 to 0.166714
7/7 [==============================] - 1s 112ms/step - loss: 0.1257 - categorical_accuracy: 0.1899 - top_5_categorical_accuracy: 0.5794 - top_10_categorical_accuracy: 0.7313 - top_20_categorical_accuracy: 0.8657 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1254 - top_5_categorical_accuracy_cp2: 0.7469 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6602 - top_10_categorical_accuracy_cp0: 0.0146 - top_10_categorical_accuracy_cp1: 0.6346 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8315 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9893 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9689 - val_loss: 0.1667 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3099 - val_top_10_categorical_accuracy: 0.3521 - val_top_20_categorical_accuracy: 0.5127 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5670 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6443 - val_top_20_categorical_accuracy_cp0: 0.0170 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9381
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1182 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6272 - top_10_categorical_accuracy: 0.7629 - top_20_categorical_accuracy: 0.8738 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1731 - top_5_categorical_accuracy_cp2: 0.8851 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7100 - top_10_categorical_accuracy_cp0: 0.0326 - top_10_categorical_accuracy_cp1: 0.6635 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0426 - top_10_categorical_accuracy_p4: 0.8593 - top_20_categorical_accuracy_cp0: 0.2826 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1702 - top_20_categorical_accuracy_p4: 0.97194/7 [================>.............] - ETA: 0s - loss: 0.1208 - categorical_accuracy: 0.2052 - top_5_categorical_accuracy: 0.6326 - top_10_categorical_accuracy: 0.7533 - top_20_categorical_accuracy: 0.8612 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2469 - top_5_categorical_accuracy_cp2: 0.8764 - top_5_categorical_accuracy_cp3: 0.9638 - top_5_categorical_accuracy_cp4: 0.9821 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7250 - top_10_categorical_accuracy_cp0: 0.0302 - top_10_categorical_accuracy_cp1: 0.6840 - top_10_categorical_accuracy_cp2: 0.9943 - top_10_categorical_accuracy_cp3: 0.9977 - top_10_categorical_accuracy_cp4: 0.9980 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0282 - top_10_categorical_accuracy_p4: 0.8606 - top_20_categorical_accuracy_cp0: 0.2872 - top_20_categorical_accuracy_cp1: 0.9802 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1921 - top_20_categorical_accuracy_p4: 0.96836/7 [========================>.....] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.2064 - top_5_categorical_accuracy: 0.6294 - top_10_categorical_accuracy: 0.7559 - top_20_categorical_accuracy: 0.8710 - top_5_categorical_accuracy_cp0: 0.0033 - top_5_categorical_accuracy_cp1: 0.2890 - top_5_categorical_accuracy_cp2: 0.8857 - top_5_categorical_accuracy_cp3: 0.9657 - top_5_categorical_accuracy_cp4: 0.9731 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7179 - top_10_categorical_accuracy_cp0: 0.0408 - top_10_categorical_accuracy_cp1: 0.7326 - top_10_categorical_accuracy_cp2: 0.9917 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9946 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.8597 - top_20_categorical_accuracy_cp0: 0.3556 - top_20_categorical_accuracy_cp1: 0.9815 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9707    DEBUG:root:Model metric val_loss improved from 0.166714 to 0.160820
7/7 [==============================] - 1s 101ms/step - loss: 0.1213 - categorical_accuracy: 0.2062 - top_5_categorical_accuracy: 0.6309 - top_10_categorical_accuracy: 0.7574 - top_20_categorical_accuracy: 0.8716 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.2920 - top_5_categorical_accuracy_cp2: 0.8868 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7189 - top_10_categorical_accuracy_cp0: 0.0421 - top_10_categorical_accuracy_cp1: 0.7355 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.8605 - top_20_categorical_accuracy_cp0: 0.3566 - top_20_categorical_accuracy_cp1: 0.9817 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9707 - val_loss: 0.1608 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3408 - val_top_10_categorical_accuracy: 0.3577 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2029 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6237 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6546 - val_top_20_categorical_accuracy_cp0: 0.3523 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3871 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.2023 - top_5_categorical_accuracy: 0.6068 - top_10_categorical_accuracy: 0.7448 - top_20_categorical_accuracy: 0.8639 - top_5_categorical_accuracy_cp0: 0.0168 - top_5_categorical_accuracy_cp1: 0.4576 - top_5_categorical_accuracy_cp2: 0.8354 - top_5_categorical_accuracy_cp3: 0.9429 - top_5_categorical_accuracy_cp4: 0.9259 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7055 - top_10_categorical_accuracy_cp0: 0.0924 - top_10_categorical_accuracy_cp1: 0.8475 - top_10_categorical_accuracy_cp2: 0.9620 - top_10_categorical_accuracy_cp3: 0.9905 - top_10_categorical_accuracy_cp4: 0.9537 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8637 - top_20_categorical_accuracy_cp0: 0.4286 - top_20_categorical_accuracy_cp1: 0.9661 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3333 - top_20_categorical_accuracy_p4: 0.96703/7 [===========>..................] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.2110 - top_5_categorical_accuracy: 0.6312 - top_10_categorical_accuracy: 0.7636 - top_20_categorical_accuracy: 0.8745 - top_5_categorical_accuracy_cp0: 0.0159 - top_5_categorical_accuracy_cp1: 0.4192 - top_5_categorical_accuracy_cp2: 0.8402 - top_5_categorical_accuracy_cp3: 0.9453 - top_5_categorical_accuracy_cp4: 0.9410 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7212 - top_10_categorical_accuracy_cp0: 0.1048 - top_10_categorical_accuracy_cp1: 0.8114 - top_10_categorical_accuracy_cp2: 0.9549 - top_10_categorical_accuracy_cp3: 0.9848 - top_10_categorical_accuracy_cp4: 0.9663 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0500 - top_10_categorical_accuracy_p4: 0.8682 - top_20_categorical_accuracy_cp0: 0.4000 - top_20_categorical_accuracy_cp1: 0.9790 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3250 - top_20_categorical_accuracy_p4: 0.97105/7 [====================>.........] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.2080 - top_5_categorical_accuracy: 0.6395 - top_10_categorical_accuracy: 0.7764 - top_20_categorical_accuracy: 0.8814 - top_5_categorical_accuracy_cp0: 0.0097 - top_5_categorical_accuracy_cp1: 0.4220 - top_5_categorical_accuracy_cp2: 0.8471 - top_5_categorical_accuracy_cp3: 0.9463 - top_5_categorical_accuracy_cp4: 0.9477 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7304 - top_10_categorical_accuracy_cp0: 0.1301 - top_10_categorical_accuracy_cp1: 0.8275 - top_10_categorical_accuracy_cp2: 0.9549 - top_10_categorical_accuracy_cp3: 0.9803 - top_10_categorical_accuracy_cp4: 0.9722 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.8780 - top_20_categorical_accuracy_cp0: 0.4233 - top_20_categorical_accuracy_cp1: 0.9761 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3667 - top_20_categorical_accuracy_p4: 0.97317/7 [==============================] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.2084 - top_5_categorical_accuracy: 0.6428 - top_10_categorical_accuracy: 0.7806 - top_20_categorical_accuracy: 0.8861 - top_5_categorical_accuracy_cp0: 0.0113 - top_5_categorical_accuracy_cp1: 0.4174 - top_5_categorical_accuracy_cp2: 0.8498 - top_5_categorical_accuracy_cp3: 0.9482 - top_5_categorical_accuracy_cp4: 0.9482 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7325 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 0.9778 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8813 - top_20_categorical_accuracy_cp0: 0.4408 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3765 - top_20_categorical_accuracy_p4: 0.9753DEBUG:root:Model metric val_loss improved from 0.160820 to 0.160260
7/7 [==============================] - 1s 108ms/step - loss: 0.1191 - categorical_accuracy: 0.2084 - top_5_categorical_accuracy: 0.6428 - top_10_categorical_accuracy: 0.7806 - top_20_categorical_accuracy: 0.8861 - top_5_categorical_accuracy_cp0: 0.0113 - top_5_categorical_accuracy_cp1: 0.4174 - top_5_categorical_accuracy_cp2: 0.8498 - top_5_categorical_accuracy_cp3: 0.9482 - top_5_categorical_accuracy_cp4: 0.9482 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7325 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 0.9778 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8813 - top_20_categorical_accuracy_cp0: 0.4408 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3765 - top_20_categorical_accuracy_p4: 0.9753 - val_loss: 0.1603 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3239 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.8225 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2029 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5928 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.6477 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.8065 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1219 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6352 - top_10_categorical_accuracy: 0.7807 - top_20_categorical_accuracy: 0.8809 - top_5_categorical_accuracy_cp0: 0.0270 - top_5_categorical_accuracy_cp1: 0.4732 - top_5_categorical_accuracy_cp2: 0.8395 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7241 - top_10_categorical_accuracy_cp0: 0.1892 - top_10_categorical_accuracy_cp1: 0.9018 - top_10_categorical_accuracy_cp2: 0.9506 - top_10_categorical_accuracy_cp3: 0.9469 - top_10_categorical_accuracy_cp4: 0.9554 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1190 - top_10_categorical_accuracy_p4: 0.8793 - top_20_categorical_accuracy_cp0: 0.4775 - top_20_categorical_accuracy_cp1: 0.9732 - top_20_categorical_accuracy_cp2: 0.9877 - top_20_categorical_accuracy_cp3: 0.9912 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3810 - top_20_categorical_accuracy_p4: 0.96984/7 [================>.............] - ETA: 0s - loss: 0.1195 - categorical_accuracy: 0.2033 - top_5_categorical_accuracy: 0.6398 - top_10_categorical_accuracy: 0.7820 - top_20_categorical_accuracy: 0.8896 - top_5_categorical_accuracy_cp0: 0.0192 - top_5_categorical_accuracy_cp1: 0.4521 - top_5_categorical_accuracy_cp2: 0.8257 - top_5_categorical_accuracy_cp3: 0.9459 - top_5_categorical_accuracy_cp4: 0.9416 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7282 - top_10_categorical_accuracy_cp0: 0.1731 - top_10_categorical_accuracy_cp1: 0.8664 - top_10_categorical_accuracy_cp2: 0.9539 - top_10_categorical_accuracy_cp3: 0.9617 - top_10_categorical_accuracy_cp4: 0.9497 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1059 - top_10_categorical_accuracy_p4: 0.8803 - top_20_categorical_accuracy_cp0: 0.4952 - top_20_categorical_accuracy_cp1: 0.9733 - top_20_categorical_accuracy_cp2: 0.9934 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 0.9899 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4176 - top_20_categorical_accuracy_p4: 0.97416/7 [========================>.....] - ETA: 0s - loss: 0.1180 - categorical_accuracy: 0.2053 - top_5_categorical_accuracy: 0.6497 - top_10_categorical_accuracy: 0.7897 - top_20_categorical_accuracy: 0.8921 - top_5_categorical_accuracy_cp0: 0.0164 - top_5_categorical_accuracy_cp1: 0.4652 - top_5_categorical_accuracy_cp2: 0.8150 - top_5_categorical_accuracy_cp3: 0.9491 - top_5_categorical_accuracy_cp4: 0.9505 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7404 - top_10_categorical_accuracy_cp0: 0.1793 - top_10_categorical_accuracy_cp1: 0.8640 - top_10_categorical_accuracy_cp2: 0.9522 - top_10_categorical_accuracy_cp3: 0.9671 - top_10_categorical_accuracy_cp4: 0.9586 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1304 - top_10_categorical_accuracy_p4: 0.8879 - top_20_categorical_accuracy_cp0: 0.4901 - top_20_categorical_accuracy_cp1: 0.9737 - top_20_categorical_accuracy_cp2: 0.9938 - top_20_categorical_accuracy_cp3: 0.9925 - top_20_categorical_accuracy_cp4: 0.9933 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4269 - top_20_categorical_accuracy_p4: 0.97767/7 [==============================] - 1s 98ms/step - loss: 0.1181 - categorical_accuracy: 0.2053 - top_5_categorical_accuracy: 0.6497 - top_10_categorical_accuracy: 0.7894 - top_20_categorical_accuracy: 0.8923 - top_5_categorical_accuracy_cp0: 0.0162 - top_5_categorical_accuracy_cp1: 0.4679 - top_5_categorical_accuracy_cp2: 0.8148 - top_5_categorical_accuracy_cp3: 0.9497 - top_5_categorical_accuracy_cp4: 0.9509 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7403 - top_10_categorical_accuracy_cp0: 0.1799 - top_10_categorical_accuracy_cp1: 0.8639 - top_10_categorical_accuracy_cp2: 0.9527 - top_10_categorical_accuracy_cp3: 0.9675 - top_10_categorical_accuracy_cp4: 0.9588 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1333 - top_10_categorical_accuracy_p4: 0.8873 - top_20_categorical_accuracy_cp0: 0.4927 - top_20_categorical_accuracy_cp1: 0.9740 - top_20_categorical_accuracy_cp2: 0.9938 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4275 - top_20_categorical_accuracy_p4: 0.9778 - val_loss: 0.1611 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3239 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.7042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2029 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5928 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.4091 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4597 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1111 - categorical_accuracy: 0.2057 - top_5_categorical_accuracy: 0.6895 - top_10_categorical_accuracy: 0.8305 - top_20_categorical_accuracy: 0.9200 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.5263 - top_5_categorical_accuracy_cp2: 0.8077 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7621 - top_10_categorical_accuracy_cp0: 0.2169 - top_10_categorical_accuracy_cp1: 0.9035 - top_10_categorical_accuracy_cp2: 0.9487 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1389 - top_10_categorical_accuracy_p4: 0.9074 - top_20_categorical_accuracy_cp0: 0.5301 - top_20_categorical_accuracy_cp1: 0.9825 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9912 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3889 - top_20_categorical_accuracy_p4: 0.98744/7 [================>.............] - ETA: 0s - loss: 0.1163 - categorical_accuracy: 0.2082 - top_5_categorical_accuracy: 0.6640 - top_10_categorical_accuracy: 0.8018 - top_20_categorical_accuracy: 0.8931 - top_5_categorical_accuracy_cp0: 0.0226 - top_5_categorical_accuracy_cp1: 0.4844 - top_5_categorical_accuracy_cp2: 0.8356 - top_5_categorical_accuracy_cp3: 0.9537 - top_5_categorical_accuracy_cp4: 0.9683 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7555 - top_10_categorical_accuracy_cp0: 0.2035 - top_10_categorical_accuracy_cp1: 0.8711 - top_10_categorical_accuracy_cp2: 0.9597 - top_10_categorical_accuracy_cp3: 0.9670 - top_10_categorical_accuracy_cp4: 0.9702 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1000 - top_10_categorical_accuracy_p4: 0.9032 - top_20_categorical_accuracy_cp0: 0.4724 - top_20_categorical_accuracy_cp1: 0.9800 - top_20_categorical_accuracy_cp2: 0.9966 - top_20_categorical_accuracy_cp3: 0.9934 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3588 - top_20_categorical_accuracy_p4: 0.9832    6/7 [========================>.....] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.2067 - top_5_categorical_accuracy: 0.6554 - top_10_categorical_accuracy: 0.7964 - top_20_categorical_accuracy: 0.8925 - top_5_categorical_accuracy_cp0: 0.0213 - top_5_categorical_accuracy_cp1: 0.4628 - top_5_categorical_accuracy_cp2: 0.8447 - top_5_categorical_accuracy_cp3: 0.9507 - top_5_categorical_accuracy_cp4: 0.9544 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7467 - top_10_categorical_accuracy_cp0: 0.2144 - top_10_categorical_accuracy_cp1: 0.8622 - top_10_categorical_accuracy_cp2: 0.9627 - top_10_categorical_accuracy_cp3: 0.9611 - top_10_categorical_accuracy_cp4: 0.9611 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1181 - top_10_categorical_accuracy_p4: 0.8967 - top_20_categorical_accuracy_cp0: 0.4845 - top_20_categorical_accuracy_cp1: 0.9752 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9955 - top_20_categorical_accuracy_cp4: 0.9946 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3780 - top_20_categorical_accuracy_p4: 0.98237/7 [==============================] - 1s 108ms/step - loss: 0.1168 - categorical_accuracy: 0.2068 - top_5_categorical_accuracy: 0.6554 - top_10_categorical_accuracy: 0.7966 - top_20_categorical_accuracy: 0.8923 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4618 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9512 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7468 - top_10_categorical_accuracy_cp0: 0.2156 - top_10_categorical_accuracy_cp1: 0.8609 - top_10_categorical_accuracy_cp2: 0.9630 - top_10_categorical_accuracy_cp3: 0.9615 - top_10_categorical_accuracy_cp4: 0.9615 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1176 - top_10_categorical_accuracy_p4: 0.8970 - top_20_categorical_accuracy_cp0: 0.4830 - top_20_categorical_accuracy_cp1: 0.9755 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3765 - top_20_categorical_accuracy_p4: 0.9825 - val_loss: 0.1626 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3408 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.5803 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2029 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6237 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.1591 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1048 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.160260 from epoch 7
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.32it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1298.95it/s]
INFO:root:Finished run d0c96a18d63347bf8c385fe6e455213c
2023-05-24 20:14:05.744293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:14:06.261689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:14:06.261756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:14:06.261762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run eae9297c1c1e47219293da380b91cae9
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12173.47it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13492.01it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13223.41it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 25015.73it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:14:08.592569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.592765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.593554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.593715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.593841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.593966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.594369: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:14:08.723977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.724189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.724337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.724466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.724591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:08.724715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.281859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.282050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.282197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.282328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.282454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.282575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:14:10.282980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:14:10.283085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12979.68it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13508.67it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13396.25it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 25135.66it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 30/154 [00:00<00:00, 292.64it/s]Loading hierarchy for column coarse_log_cluster_path:  39%|███▉      | 60/154 [00:00<00:00, 293.99it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 90/154 [00:00<00:00, 296.00it/s]Loading hierarchy for column coarse_log_cluster_path:  78%|███████▊  | 120/154 [00:00<00:00, 296.99it/s]Loading hierarchy for column coarse_log_cluster_path:  98%|█████████▊| 151/154 [00:00<00:00, 298.22it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 296.90it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:51,  7.75it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5208.94it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1338it [00:00, 38401.91it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/174 [00:00<?, ?it/s]Initializing gram_embedding connections:  48%|████▊     | 83/174 [00:00<00:00, 811.80it/s]Initializing gram_embedding connections:  95%|█████████▍| 165/174 [00:00<00:00, 393.79it/s]Initializing gram_embedding connections: 100%|██████████| 174/174 [00:00<00:00, 405.28it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.11it/s]Calculating percentile frequencies...: 7it [00:00,  7.75it/s]
2023-05-24 20:14:14.724363: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:14:47.222122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:14:47.780228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:14:47.924044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:14:48.349285: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x857863d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:14:48.349334: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:14:48.349346: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:14:48.353310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:14:48.436054: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1929 - categorical_accuracy: 0.0077 - top_5_categorical_accuracy: 0.0402 - top_10_categorical_accuracy: 0.0824 - top_20_categorical_accuracy: 0.1609 - top_5_categorical_accuracy_cp0: 0.0808 - top_5_categorical_accuracy_cp1: 0.0101 - top_5_categorical_accuracy_cp2: 0.0119 - top_5_categorical_accuracy_cp3: 0.0085 - top_5_categorical_accuracy_cp4: 0.0820 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.1429 - top_5_categorical_accuracy_p2: 0.0588 - top_5_categorical_accuracy_p3: 0.0526 - top_5_categorical_accuracy_p4: 0.0370 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.0606 - top_10_categorical_accuracy_cp2: 0.0238 - top_10_categorical_accuracy_cp3: 0.0169 - top_10_categorical_accuracy_cp4: 0.1639 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1429 - top_10_categorical_accuracy_p2: 0.2353 - top_10_categorical_accuracy_p3: 0.0526 - top_10_categorical_accuracy_p4: 0.0784 - top_20_categorical_accuracy_cp0: 0.2020 - top_20_categorical_accuracy_cp1: 0.1414 - top_20_categorical_accuracy_cp2: 0.0952 - top_20_categorical_accuracy_cp3: 0.0424 - top_20_categorical_accuracy_cp4: 0.3033 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.4118 - top_20_categorical_accuracy_p3: 0.0526 - top_20_categorical_accuracy_p4: 0.1612      3/Unknown - 34s 38ms/step - loss: 0.1932 - categorical_accuracy: 0.0744 - top_5_categorical_accuracy: 0.2206 - top_10_categorical_accuracy: 0.3058 - top_20_categorical_accuracy: 0.4304 - top_5_categorical_accuracy_cp0: 0.0478 - top_5_categorical_accuracy_cp1: 0.0523 - top_5_categorical_accuracy_cp2: 0.2050 - top_5_categorical_accuracy_cp3: 0.1934 - top_5_categorical_accuracy_cp4: 0.5273 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0625 - top_5_categorical_accuracy_p2: 0.0426 - top_5_categorical_accuracy_p3: 0.0259 - top_5_categorical_accuracy_p4: 0.2457 - top_10_categorical_accuracy_cp0: 0.1092 - top_10_categorical_accuracy_cp1: 0.0923 - top_10_categorical_accuracy_cp2: 0.2929 - top_10_categorical_accuracy_cp3: 0.2991 - top_10_categorical_accuracy_cp4: 0.6494 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0625 - top_10_categorical_accuracy_p2: 0.1064 - top_10_categorical_accuracy_p3: 0.0603 - top_10_categorical_accuracy_p4: 0.3372 - top_20_categorical_accuracy_cp0: 0.2184 - top_20_categorical_accuracy_cp1: 0.2092 - top_20_categorical_accuracy_cp2: 0.4561 - top_20_categorical_accuracy_cp3: 0.4502 - top_20_categorical_accuracy_cp4: 0.7455 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1250 - top_20_categorical_accuracy_p2: 0.1915 - top_20_categorical_accuracy_p3: 0.1207 - top_20_categorical_accuracy_p4: 0.4697      5/Unknown - 34s 36ms/step - loss: 0.1933 - categorical_accuracy: 0.1038 - top_5_categorical_accuracy: 0.3322 - top_10_categorical_accuracy: 0.4192 - top_20_categorical_accuracy: 0.5321 - top_5_categorical_accuracy_cp0: 0.0326 - top_5_categorical_accuracy_cp1: 0.0708 - top_5_categorical_accuracy_cp2: 0.3760 - top_5_categorical_accuracy_cp3: 0.4317 - top_5_categorical_accuracy_cp4: 0.7000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0333 - top_5_categorical_accuracy_p2: 0.0267 - top_5_categorical_accuracy_p3: 0.0190 - top_5_categorical_accuracy_p4: 0.3768 - top_10_categorical_accuracy_cp0: 0.0806 - top_10_categorical_accuracy_cp1: 0.1452 - top_10_categorical_accuracy_cp2: 0.5013 - top_10_categorical_accuracy_cp3: 0.5468 - top_10_categorical_accuracy_cp4: 0.7823 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0333 - top_10_categorical_accuracy_p2: 0.0667 - top_10_categorical_accuracy_p3: 0.0521 - top_10_categorical_accuracy_p4: 0.4720 - top_20_categorical_accuracy_cp0: 0.1881 - top_20_categorical_accuracy_cp1: 0.3031 - top_20_categorical_accuracy_cp2: 0.6423 - top_20_categorical_accuracy_cp3: 0.6601 - top_20_categorical_accuracy_cp4: 0.8419 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.1000 - top_20_categorical_accuracy_p2: 0.1733 - top_20_categorical_accuracy_p3: 0.1185 - top_20_categorical_accuracy_p4: 0.5902          7/Unknown - 34s 36ms/step - loss: 0.1927 - categorical_accuracy: 0.1146 - top_5_categorical_accuracy: 0.3751 - top_10_categorical_accuracy: 0.4652 - top_20_categorical_accuracy: 0.5750 - top_5_categorical_accuracy_cp0: 0.0292 - top_5_categorical_accuracy_cp1: 0.0780 - top_5_categorical_accuracy_cp2: 0.4444 - top_5_categorical_accuracy_cp3: 0.5118 - top_5_categorical_accuracy_cp4: 0.7490 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0157 - top_5_categorical_accuracy_p4: 0.4245 - top_10_categorical_accuracy_cp0: 0.0794 - top_10_categorical_accuracy_cp1: 0.1667 - top_10_categorical_accuracy_cp2: 0.5967 - top_10_categorical_accuracy_cp3: 0.6154 - top_10_categorical_accuracy_cp4: 0.8207 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.1059 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.5225 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.3502 - top_20_categorical_accuracy_cp2: 0.7181 - top_20_categorical_accuracy_cp3: 0.7189 - top_20_categorical_accuracy_cp4: 0.8699 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.2000 - top_20_categorical_accuracy_p3: 0.1020 - top_20_categorical_accuracy_p4: 0.63812023-05-24 20:14:49.430909: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195864
7/7 [==============================] - 53s 3s/step - loss: 0.1927 - categorical_accuracy: 0.1146 - top_5_categorical_accuracy: 0.3751 - top_10_categorical_accuracy: 0.4652 - top_20_categorical_accuracy: 0.5750 - top_5_categorical_accuracy_cp0: 0.0292 - top_5_categorical_accuracy_cp1: 0.0780 - top_5_categorical_accuracy_cp2: 0.4444 - top_5_categorical_accuracy_cp3: 0.5118 - top_5_categorical_accuracy_cp4: 0.7490 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0157 - top_5_categorical_accuracy_p4: 0.4245 - top_10_categorical_accuracy_cp0: 0.0794 - top_10_categorical_accuracy_cp1: 0.1667 - top_10_categorical_accuracy_cp2: 0.5967 - top_10_categorical_accuracy_cp3: 0.6154 - top_10_categorical_accuracy_cp4: 0.8207 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.1059 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.5225 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.3502 - top_20_categorical_accuracy_cp2: 0.7181 - top_20_categorical_accuracy_cp3: 0.7189 - top_20_categorical_accuracy_cp4: 0.8699 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.2000 - top_20_categorical_accuracy_p3: 0.1020 - top_20_categorical_accuracy_p4: 0.6381 - val_loss: 0.1959 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2761 - val_top_10_categorical_accuracy: 0.3239 - val_top_20_categorical_accuracy: 0.4338 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.5833 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5052 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0725 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5928 - val_top_20_categorical_accuracy_cp0: 0.0057 - val_top_20_categorical_accuracy_cp1: 0.6232 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0081 - val_top_20_categorical_accuracy_p4: 0.7887
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1898 - categorical_accuracy: 0.1499 - top_5_categorical_accuracy: 0.5844 - top_10_categorical_accuracy: 0.7040 - top_20_categorical_accuracy: 0.7761 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1441 - top_5_categorical_accuracy_cp2: 0.8442 - top_5_categorical_accuracy_cp3: 0.9060 - top_5_categorical_accuracy_cp4: 0.9680 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6609 - top_10_categorical_accuracy_cp0: 0.0309 - top_10_categorical_accuracy_cp1: 0.4685 - top_10_categorical_accuracy_cp2: 0.9610 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0769 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7940 - top_20_categorical_accuracy_cp0: 0.1237 - top_20_categorical_accuracy_cp1: 0.7027 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.1111 - top_20_categorical_accuracy_p2: 0.0769 - top_20_categorical_accuracy_p3: 0.0270 - top_20_categorical_accuracy_p4: 0.86913/7 [===========>..................] - ETA: 0s - loss: 0.1881 - categorical_accuracy: 0.1415 - top_5_categorical_accuracy: 0.5571 - top_10_categorical_accuracy: 0.6846 - top_20_categorical_accuracy: 0.7678 - top_5_categorical_accuracy_cp0: 0.0062 - top_5_categorical_accuracy_cp1: 0.1154 - top_5_categorical_accuracy_cp2: 0.7625 - top_5_categorical_accuracy_cp3: 0.8915 - top_5_categorical_accuracy_cp4: 0.9860 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6446 - top_10_categorical_accuracy_cp0: 0.0523 - top_10_categorical_accuracy_cp1: 0.4231 - top_10_categorical_accuracy_cp2: 0.9667 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0435 - top_10_categorical_accuracy_p2: 0.0408 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7900 - top_20_categorical_accuracy_cp0: 0.1723 - top_20_categorical_accuracy_cp1: 0.6891 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1304 - top_20_categorical_accuracy_p2: 0.0816 - top_20_categorical_accuracy_p3: 0.0672 - top_20_categorical_accuracy_p4: 0.8759        5/7 [====================>.........] - ETA: 0s - loss: 0.1857 - categorical_accuracy: 0.1432 - top_5_categorical_accuracy: 0.5605 - top_10_categorical_accuracy: 0.6976 - top_20_categorical_accuracy: 0.7848 - top_5_categorical_accuracy_cp0: 0.0039 - top_5_categorical_accuracy_cp1: 0.0985 - top_5_categorical_accuracy_cp2: 0.7445 - top_5_categorical_accuracy_cp3: 0.8903 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6400 - top_10_categorical_accuracy_cp0: 0.0530 - top_10_categorical_accuracy_cp1: 0.4318 - top_10_categorical_accuracy_cp2: 0.9732 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0357 - top_10_categorical_accuracy_p2: 0.0395 - top_10_categorical_accuracy_p3: 0.0048 - top_10_categorical_accuracy_p4: 0.7943 - top_20_categorical_accuracy_cp0: 0.1768 - top_20_categorical_accuracy_cp1: 0.7235 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.1071 - top_20_categorical_accuracy_p2: 0.1053 - top_20_categorical_accuracy_p3: 0.0769 - top_20_categorical_accuracy_p4: 0.8835    7/7 [==============================] - ETA: 0s - loss: 0.1844 - categorical_accuracy: 0.1406 - top_5_categorical_accuracy: 0.5543 - top_10_categorical_accuracy: 0.6984 - top_20_categorical_accuracy: 0.7863 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.0994 - top_5_categorical_accuracy_cp2: 0.7284 - top_5_categorical_accuracy_cp3: 0.8861 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6316 - top_10_categorical_accuracy_cp0: 0.0535 - top_10_categorical_accuracy_cp1: 0.4450 - top_10_categorical_accuracy_cp2: 0.9733 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7933 - top_20_categorical_accuracy_cp0: 0.1718 - top_20_categorical_accuracy_cp1: 0.7401 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.0784 - top_20_categorical_accuracy_p4: 0.8838DEBUG:root:Model metric val_loss improved from 0.195864 to 0.189672
7/7 [==============================] - 1s 113ms/step - loss: 0.1844 - categorical_accuracy: 0.1406 - top_5_categorical_accuracy: 0.5543 - top_10_categorical_accuracy: 0.6984 - top_20_categorical_accuracy: 0.7863 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.0994 - top_5_categorical_accuracy_cp2: 0.7284 - top_5_categorical_accuracy_cp3: 0.8861 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6316 - top_10_categorical_accuracy_cp0: 0.0535 - top_10_categorical_accuracy_cp1: 0.4450 - top_10_categorical_accuracy_cp2: 0.9733 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7933 - top_20_categorical_accuracy_cp0: 0.1718 - top_20_categorical_accuracy_cp1: 0.7401 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.0784 - top_20_categorical_accuracy_p4: 0.8838 - val_loss: 0.1897 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3155 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0290 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5773 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1664 - categorical_accuracy: 0.1217 - top_5_categorical_accuracy: 0.5494 - top_10_categorical_accuracy: 0.7072 - top_20_categorical_accuracy: 0.8213 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0594 - top_5_categorical_accuracy_cp2: 0.7024 - top_5_categorical_accuracy_cp3: 0.8276 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6162 - top_10_categorical_accuracy_cp0: 0.0417 - top_10_categorical_accuracy_cp1: 0.4059 - top_10_categorical_accuracy_cp2: 0.9881 - top_10_categorical_accuracy_cp3: 0.9914 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7910 - top_20_categorical_accuracy_cp0: 0.1771 - top_20_categorical_accuracy_cp1: 0.8515 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1081 - top_20_categorical_accuracy_p4: 0.91263/7 [===========>..................] - ETA: 0s - loss: 0.1596 - categorical_accuracy: 0.1117 - top_5_categorical_accuracy: 0.5092 - top_10_categorical_accuracy: 0.6832 - top_20_categorical_accuracy: 0.8051 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0550 - top_5_categorical_accuracy_cp2: 0.6707 - top_5_categorical_accuracy_cp3: 0.7874 - top_5_categorical_accuracy_cp4: 0.9972 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5812 - top_10_categorical_accuracy_cp0: 0.0418 - top_10_categorical_accuracy_cp1: 0.4067 - top_10_categorical_accuracy_cp2: 0.9837 - top_10_categorical_accuracy_cp3: 0.9910 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0238 - top_10_categorical_accuracy_p4: 0.7775 - top_20_categorical_accuracy_cp0: 0.1768 - top_20_categorical_accuracy_cp1: 0.8440 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0227 - top_20_categorical_accuracy_p3: 0.0952 - top_20_categorical_accuracy_p4: 0.9087        5/7 [====================>.........] - ETA: 0s - loss: 0.1518 - categorical_accuracy: 0.1166 - top_5_categorical_accuracy: 0.5137 - top_10_categorical_accuracy: 0.6966 - top_20_categorical_accuracy: 0.8133 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0587 - top_5_categorical_accuracy_cp2: 0.6784 - top_5_categorical_accuracy_cp3: 0.7680 - top_5_categorical_accuracy_cp4: 0.9952 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5833 - top_10_categorical_accuracy_cp0: 0.0378 - top_10_categorical_accuracy_cp1: 0.4477 - top_10_categorical_accuracy_cp2: 0.9824 - top_10_categorical_accuracy_cp3: 0.9928 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0149 - top_10_categorical_accuracy_p4: 0.7897 - top_20_categorical_accuracy_cp0: 0.1670 - top_20_categorical_accuracy_cp1: 0.8697 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0141 - top_20_categorical_accuracy_p3: 0.0746 - top_20_categorical_accuracy_p4: 0.91617/7 [==============================] - ETA: 0s - loss: 0.1512 - categorical_accuracy: 0.1168 - top_5_categorical_accuracy: 0.5104 - top_10_categorical_accuracy: 0.6996 - top_20_categorical_accuracy: 0.8136 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0566 - top_5_categorical_accuracy_cp2: 0.6646 - top_5_categorical_accuracy_cp3: 0.7648 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5815 - top_10_categorical_accuracy_cp0: 0.0373 - top_10_categorical_accuracy_cp1: 0.4648 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.7961 - top_20_categorical_accuracy_cp0: 0.1653 - top_20_categorical_accuracy_cp1: 0.8792 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.0667 - top_20_categorical_accuracy_p4: 0.92027/7 [==============================] - 1s 111ms/step - loss: 0.1512 - categorical_accuracy: 0.1168 - top_5_categorical_accuracy: 0.5104 - top_10_categorical_accuracy: 0.6996 - top_20_categorical_accuracy: 0.8136 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0566 - top_5_categorical_accuracy_cp2: 0.6646 - top_5_categorical_accuracy_cp3: 0.7648 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5815 - top_10_categorical_accuracy_cp0: 0.0373 - top_10_categorical_accuracy_cp1: 0.4648 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.7961 - top_20_categorical_accuracy_cp0: 0.1653 - top_20_categorical_accuracy_cp1: 0.8792 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.0667 - top_20_categorical_accuracy_p4: 0.9202 - val_loss: 0.1962 - val_categorical_accuracy: 0.0056 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5070 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0057 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9278
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1343 - categorical_accuracy: 0.1188 - top_5_categorical_accuracy: 0.5613 - top_10_categorical_accuracy: 0.7203 - top_20_categorical_accuracy: 0.8487 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0337 - top_5_categorical_accuracy_cp2: 0.6765 - top_5_categorical_accuracy_cp3: 0.8571 - top_5_categorical_accuracy_cp4: 0.9766 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6328 - top_10_categorical_accuracy_cp0: 0.0220 - top_10_categorical_accuracy_cp1: 0.3820 - top_10_categorical_accuracy_cp2: 0.9902 - top_10_categorical_accuracy_cp3: 0.9911 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8121 - top_20_categorical_accuracy_cp0: 0.1978 - top_20_categorical_accuracy_cp1: 0.9326 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0488 - top_20_categorical_accuracy_p4: 0.95253/7 [===========>..................] - ETA: 0s - loss: 0.1375 - categorical_accuracy: 0.1106 - top_5_categorical_accuracy: 0.5291 - top_10_categorical_accuracy: 0.7048 - top_20_categorical_accuracy: 0.8483 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0461 - top_5_categorical_accuracy_cp2: 0.6844 - top_5_categorical_accuracy_cp3: 0.8571 - top_5_categorical_accuracy_cp4: 0.9694 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6009 - top_10_categorical_accuracy_cp0: 0.0192 - top_10_categorical_accuracy_cp1: 0.4770 - top_10_categorical_accuracy_cp2: 0.9962 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8004 - top_20_categorical_accuracy_cp0: 0.2628 - top_20_categorical_accuracy_cp1: 0.9671 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0833 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0909 - top_20_categorical_accuracy_p4: 0.9548    5/7 [====================>.........] - ETA: 0s - loss: 0.1356 - categorical_accuracy: 0.1193 - top_5_categorical_accuracy: 0.5324 - top_10_categorical_accuracy: 0.7100 - top_20_categorical_accuracy: 0.8544 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0358 - top_5_categorical_accuracy_cp2: 0.6860 - top_5_categorical_accuracy_cp3: 0.8881 - top_5_categorical_accuracy_cp4: 0.9678 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6063 - top_10_categorical_accuracy_cp0: 0.0179 - top_10_categorical_accuracy_cp1: 0.5009 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8086 - top_20_categorical_accuracy_cp0: 0.2644 - top_20_categorical_accuracy_cp1: 0.9774 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0667 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1005 - top_20_categorical_accuracy_p4: 0.96357/7 [==============================] - ETA: 0s - loss: 0.1359 - categorical_accuracy: 0.1259 - top_5_categorical_accuracy: 0.5308 - top_10_categorical_accuracy: 0.7116 - top_20_categorical_accuracy: 0.8547 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0336 - top_5_categorical_accuracy_cp2: 0.7016 - top_5_categorical_accuracy_cp3: 0.8979 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6048 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.5245 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8108 - top_20_categorical_accuracy_cp0: 0.2707 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1059 - top_20_categorical_accuracy_p4: 0.9639DEBUG:root:Model metric val_loss improved from 0.189672 to 0.175453
7/7 [==============================] - 1s 106ms/step - loss: 0.1359 - categorical_accuracy: 0.1259 - top_5_categorical_accuracy: 0.5308 - top_10_categorical_accuracy: 0.7116 - top_20_categorical_accuracy: 0.8547 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0336 - top_5_categorical_accuracy_cp2: 0.7016 - top_5_categorical_accuracy_cp3: 0.8979 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6048 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.5245 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8108 - top_20_categorical_accuracy_cp0: 0.2707 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1059 - top_20_categorical_accuracy_p4: 0.9639 - val_loss: 0.1755 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1342 - categorical_accuracy: 0.1635 - top_5_categorical_accuracy: 0.5494 - top_10_categorical_accuracy: 0.7319 - top_20_categorical_accuracy: 0.8764 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0431 - top_5_categorical_accuracy_cp2: 0.8182 - top_5_categorical_accuracy_cp3: 0.9352 - top_5_categorical_accuracy_cp4: 0.9375 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6188 - top_10_categorical_accuracy_cp0: 0.0103 - top_10_categorical_accuracy_cp1: 0.6121 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8244 - top_20_categorical_accuracy_cp0: 0.3299 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1316 - top_20_categorical_accuracy_p4: 0.97643/7 [===========>..................] - ETA: 0s - loss: 0.1356 - categorical_accuracy: 0.1730 - top_5_categorical_accuracy: 0.5393 - top_10_categorical_accuracy: 0.7091 - top_20_categorical_accuracy: 0.8517 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0248 - top_5_categorical_accuracy_cp2: 0.7754 - top_5_categorical_accuracy_cp3: 0.9608 - top_5_categorical_accuracy_cp4: 0.9525 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6212 - top_10_categorical_accuracy_cp0: 0.0091 - top_10_categorical_accuracy_cp1: 0.5882 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8168 - top_20_categorical_accuracy_cp0: 0.3009 - top_20_categorical_accuracy_cp1: 0.9876 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0956 - top_20_categorical_accuracy_p4: 0.97155/7 [====================>.........] - ETA: 0s - loss: 0.1330 - categorical_accuracy: 0.1781 - top_5_categorical_accuracy: 0.5472 - top_10_categorical_accuracy: 0.7180 - top_20_categorical_accuracy: 0.8577 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0333 - top_5_categorical_accuracy_cp2: 0.7354 - top_5_categorical_accuracy_cp3: 0.9681 - top_5_categorical_accuracy_cp4: 0.9653 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6269 - top_10_categorical_accuracy_cp0: 0.0076 - top_10_categorical_accuracy_cp1: 0.5915 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8226 - top_20_categorical_accuracy_cp0: 0.3015 - top_20_categorical_accuracy_cp1: 0.9852 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0986 - top_20_categorical_accuracy_p4: 0.97347/7 [==============================] - ETA: 0s - loss: 0.1317 - categorical_accuracy: 0.1758 - top_5_categorical_accuracy: 0.5543 - top_10_categorical_accuracy: 0.7235 - top_20_categorical_accuracy: 0.8635 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0382 - top_5_categorical_accuracy_cp2: 0.7469 - top_5_categorical_accuracy_cp3: 0.9645 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6316 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5887 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8244 - top_20_categorical_accuracy_cp0: 0.3096 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0941 - top_20_categorical_accuracy_p4: 0.9753DEBUG:root:Model metric val_loss improved from 0.175453 to 0.172760
7/7 [==============================] - 1s 107ms/step - loss: 0.1317 - categorical_accuracy: 0.1758 - top_5_categorical_accuracy: 0.5543 - top_10_categorical_accuracy: 0.7235 - top_20_categorical_accuracy: 0.8635 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0382 - top_5_categorical_accuracy_cp2: 0.7469 - top_5_categorical_accuracy_cp3: 0.9645 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6316 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5887 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8244 - top_20_categorical_accuracy_cp0: 0.3096 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0941 - top_20_categorical_accuracy_p4: 0.9753 - val_loss: 0.1728 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3296 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1014 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6031 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1330 - categorical_accuracy: 0.1582 - top_5_categorical_accuracy: 0.5235 - top_10_categorical_accuracy: 0.6874 - top_20_categorical_accuracy: 0.8625 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0551 - top_5_categorical_accuracy_cp2: 0.7581 - top_5_categorical_accuracy_cp3: 0.9912 - top_5_categorical_accuracy_cp4: 0.9737 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5928 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5827 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7783 - top_20_categorical_accuracy_cp0: 0.3684 - top_20_categorical_accuracy_cp1: 0.9921 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1220 - top_20_categorical_accuracy_p4: 0.96594/7 [================>.............] - ETA: 0s - loss: 0.1286 - categorical_accuracy: 0.1672 - top_5_categorical_accuracy: 0.5644 - top_10_categorical_accuracy: 0.7211 - top_20_categorical_accuracy: 0.8698 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0884 - top_5_categorical_accuracy_cp2: 0.7233 - top_5_categorical_accuracy_cp3: 0.9798 - top_5_categorical_accuracy_cp4: 0.9857 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6411 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5918 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8192 - top_20_categorical_accuracy_cp0: 0.3528 - top_20_categorical_accuracy_cp1: 0.9819 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1615 - top_20_categorical_accuracy_p4: 0.97416/7 [========================>.....] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.1761 - top_5_categorical_accuracy: 0.5793 - top_10_categorical_accuracy: 0.7256 - top_20_categorical_accuracy: 0.8677 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1049 - top_5_categorical_accuracy_cp2: 0.7630 - top_5_categorical_accuracy_cp3: 0.9776 - top_5_categorical_accuracy_cp4: 0.9893 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6594 - top_10_categorical_accuracy_cp0: 0.0115 - top_10_categorical_accuracy_cp1: 0.5972 - top_10_categorical_accuracy_cp2: 0.9958 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8259 - top_20_categorical_accuracy_cp0: 0.3350 - top_20_categorical_accuracy_cp1: 0.9815 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1548 - top_20_categorical_accuracy_p4: 0.9736DEBUG:root:Model metric val_loss improved from 0.172760 to 0.167796
7/7 [==============================] - 1s 101ms/step - loss: 0.1271 - categorical_accuracy: 0.1764 - top_5_categorical_accuracy: 0.5797 - top_10_categorical_accuracy: 0.7257 - top_20_categorical_accuracy: 0.8669 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1055 - top_5_categorical_accuracy_cp2: 0.7654 - top_5_categorical_accuracy_cp3: 0.9778 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6606 - top_10_categorical_accuracy_cp0: 0.0113 - top_10_categorical_accuracy_cp1: 0.5994 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8269 - top_20_categorical_accuracy_cp0: 0.3323 - top_20_categorical_accuracy_cp1: 0.9817 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1529 - top_20_categorical_accuracy_p4: 0.9739 - val_loss: 0.1678 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3042 - val_top_10_categorical_accuracy: 0.3521 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5567 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6443 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.1989 - top_5_categorical_accuracy: 0.6501 - top_10_categorical_accuracy: 0.7629 - top_20_categorical_accuracy: 0.8795 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2019 - top_5_categorical_accuracy_cp2: 0.9425 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7359 - top_10_categorical_accuracy_cp0: 0.0109 - top_10_categorical_accuracy_cp1: 0.6923 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9910 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8636 - top_20_categorical_accuracy_cp0: 0.3152 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1915 - top_20_categorical_accuracy_p4: 0.97623/7 [===========>..................] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2017 - top_5_categorical_accuracy: 0.6438 - top_10_categorical_accuracy: 0.7608 - top_20_categorical_accuracy: 0.8683 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2415 - top_5_categorical_accuracy_cp2: 0.9401 - top_5_categorical_accuracy_cp3: 0.9455 - top_5_categorical_accuracy_cp4: 0.9717 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7381 - top_10_categorical_accuracy_cp0: 0.0240 - top_10_categorical_accuracy_cp1: 0.6939 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0071 - top_10_categorical_accuracy_p4: 0.8716 - top_20_categorical_accuracy_cp0: 0.3014 - top_20_categorical_accuracy_cp1: 0.9898 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1429 - top_20_categorical_accuracy_p4: 0.9810    5/7 [====================>.........] - ETA: 0s - loss: 0.1222 - categorical_accuracy: 0.2025 - top_5_categorical_accuracy: 0.6338 - top_10_categorical_accuracy: 0.7575 - top_20_categorical_accuracy: 0.8717 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2717 - top_5_categorical_accuracy_cp2: 0.9416 - top_5_categorical_accuracy_cp3: 0.9478 - top_5_categorical_accuracy_cp4: 0.9775 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7239 - top_10_categorical_accuracy_cp0: 0.0373 - top_10_categorical_accuracy_cp1: 0.7302 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 0.9946 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0094 - top_10_categorical_accuracy_p4: 0.8643 - top_20_categorical_accuracy_cp0: 0.3517 - top_20_categorical_accuracy_cp1: 0.9868 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1784 - top_20_categorical_accuracy_p4: 0.97917/7 [==============================] - ETA: 0s - loss: 0.1219 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6359 - top_10_categorical_accuracy: 0.7593 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2875 - top_5_categorical_accuracy_cp2: 0.9465 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7246 - top_10_categorical_accuracy_cp0: 0.0438 - top_10_categorical_accuracy_cp1: 0.7355 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9956 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8637 - top_20_categorical_accuracy_cp0: 0.3679 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9764DEBUG:root:Model metric val_loss improved from 0.167796 to 0.162609
7/7 [==============================] - 1s 107ms/step - loss: 0.1219 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6359 - top_10_categorical_accuracy: 0.7593 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2875 - top_5_categorical_accuracy_cp2: 0.9465 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7246 - top_10_categorical_accuracy_cp0: 0.0438 - top_10_categorical_accuracy_cp1: 0.7355 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9956 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8637 - top_20_categorical_accuracy_cp0: 0.3679 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9764 - val_loss: 0.1626 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3014 - val_top_10_categorical_accuracy: 0.3577 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5515 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6546 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1253 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.5992 - top_10_categorical_accuracy: 0.7429 - top_20_categorical_accuracy: 0.8696 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3983 - top_5_categorical_accuracy_cp2: 0.8734 - top_5_categorical_accuracy_cp3: 0.9619 - top_5_categorical_accuracy_cp4: 0.9259 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6967 - top_10_categorical_accuracy_cp0: 0.0840 - top_10_categorical_accuracy_cp1: 0.8136 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 0.9810 - top_10_categorical_accuracy_cp4: 0.9815 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8615 - top_20_categorical_accuracy_cp0: 0.4454 - top_20_categorical_accuracy_cp1: 0.9746 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2353 - top_20_categorical_accuracy_p4: 0.98463/7 [===========>..................] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2060 - top_5_categorical_accuracy: 0.6343 - top_10_categorical_accuracy: 0.7719 - top_20_categorical_accuracy: 0.8771 - top_5_categorical_accuracy_cp0: 0.0063 - top_5_categorical_accuracy_cp1: 0.3563 - top_5_categorical_accuracy_cp2: 0.9344 - top_5_categorical_accuracy_cp3: 0.9574 - top_5_categorical_accuracy_cp4: 0.9466 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7248 - top_10_categorical_accuracy_cp0: 0.1016 - top_10_categorical_accuracy_cp1: 0.8084 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9757 - top_10_categorical_accuracy_cp4: 0.9916 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0500 - top_10_categorical_accuracy_p4: 0.8776 - top_20_categorical_accuracy_cp0: 0.4190 - top_20_categorical_accuracy_cp1: 0.9671 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2583 - top_20_categorical_accuracy_p4: 0.9797    5/7 [====================>.........] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6449 - top_10_categorical_accuracy: 0.7798 - top_20_categorical_accuracy: 0.8825 - top_5_categorical_accuracy_cp0: 0.0039 - top_5_categorical_accuracy_cp1: 0.3743 - top_5_categorical_accuracy_cp2: 0.9248 - top_5_categorical_accuracy_cp3: 0.9553 - top_5_categorical_accuracy_cp4: 0.9592 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7364 - top_10_categorical_accuracy_cp0: 0.1223 - top_10_categorical_accuracy_cp1: 0.8128 - top_10_categorical_accuracy_cp2: 0.9925 - top_10_categorical_accuracy_cp3: 0.9714 - top_10_categorical_accuracy_cp4: 0.9902 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0714 - top_10_categorical_accuracy_p4: 0.8841 - top_20_categorical_accuracy_cp0: 0.4350 - top_20_categorical_accuracy_cp1: 0.9688 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2952 - top_20_categorical_accuracy_p4: 0.98097/7 [==============================] - ETA: 0s - loss: 0.1186 - categorical_accuracy: 0.2075 - top_5_categorical_accuracy: 0.6503 - top_10_categorical_accuracy: 0.7841 - top_20_categorical_accuracy: 0.8845 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.3792 - top_5_categorical_accuracy_cp2: 0.9321 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7411 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.8135 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.8859 - top_20_categorical_accuracy_cp0: 0.4441 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.98077/7 [==============================] - 1s 106ms/step - loss: 0.1186 - categorical_accuracy: 0.2075 - top_5_categorical_accuracy: 0.6503 - top_10_categorical_accuracy: 0.7841 - top_20_categorical_accuracy: 0.8845 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.3792 - top_5_categorical_accuracy_cp2: 0.9321 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7411 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.8135 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.8859 - top_20_categorical_accuracy_cp0: 0.4441 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.9807 - val_loss: 0.1631 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3408 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.5408 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2029 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6237 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6352 - top_10_categorical_accuracy: 0.7637 - top_20_categorical_accuracy: 0.8941 - top_5_categorical_accuracy_cp0: 0.0180 - top_5_categorical_accuracy_cp1: 0.4554 - top_5_categorical_accuracy_cp2: 0.8765 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7241 - top_10_categorical_accuracy_cp0: 0.1712 - top_10_categorical_accuracy_cp1: 0.8393 - top_10_categorical_accuracy_cp2: 0.9630 - top_10_categorical_accuracy_cp3: 0.9292 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1190 - top_10_categorical_accuracy_p4: 0.8599 - top_20_categorical_accuracy_cp0: 0.5315 - top_20_categorical_accuracy_cp1: 0.9911 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9823 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4048 - top_20_categorical_accuracy_p4: 0.98284/7 [================>.............] - ETA: 0s - loss: 0.1189 - categorical_accuracy: 0.2081 - top_5_categorical_accuracy: 0.6450 - top_10_categorical_accuracy: 0.7900 - top_20_categorical_accuracy: 0.8967 - top_5_categorical_accuracy_cp0: 0.0120 - top_5_categorical_accuracy_cp1: 0.4499 - top_5_categorical_accuracy_cp2: 0.8618 - top_5_categorical_accuracy_cp3: 0.9459 - top_5_categorical_accuracy_cp4: 0.9497 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7341 - top_10_categorical_accuracy_cp0: 0.1971 - top_10_categorical_accuracy_cp1: 0.8597 - top_10_categorical_accuracy_cp2: 0.9770 - top_10_categorical_accuracy_cp3: 0.9527 - top_10_categorical_accuracy_cp4: 0.9638 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1294 - top_10_categorical_accuracy_p4: 0.8873 - top_20_categorical_accuracy_cp0: 0.5361 - top_20_categorical_accuracy_cp1: 0.9621 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9887 - top_20_categorical_accuracy_cp4: 0.9940 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4235 - top_20_categorical_accuracy_p4: 0.98176/7 [========================>.....] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.2110 - top_5_categorical_accuracy: 0.6523 - top_10_categorical_accuracy: 0.7960 - top_20_categorical_accuracy: 0.8956 - top_5_categorical_accuracy_cp0: 0.0099 - top_5_categorical_accuracy_cp1: 0.4389 - top_5_categorical_accuracy_cp2: 0.8545 - top_5_categorical_accuracy_cp3: 0.9536 - top_5_categorical_accuracy_cp4: 0.9599 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7433 - top_10_categorical_accuracy_cp0: 0.1974 - top_10_categorical_accuracy_cp1: 0.8501 - top_10_categorical_accuracy_cp2: 0.9792 - top_10_categorical_accuracy_cp3: 0.9611 - top_10_categorical_accuracy_cp4: 0.9706 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1423 - top_10_categorical_accuracy_p4: 0.8941 - top_20_categorical_accuracy_cp0: 0.5197 - top_20_categorical_accuracy_cp1: 0.9598 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9880 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4150 - top_20_categorical_accuracy_p4: 0.98267/7 [==============================] - 1s 106ms/step - loss: 0.1175 - categorical_accuracy: 0.2112 - top_5_categorical_accuracy: 0.6522 - top_10_categorical_accuracy: 0.7960 - top_20_categorical_accuracy: 0.8958 - top_5_categorical_accuracy_cp0: 0.0097 - top_5_categorical_accuracy_cp1: 0.4419 - top_5_categorical_accuracy_cp2: 0.8539 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7432 - top_10_categorical_accuracy_cp0: 0.1977 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9794 - top_10_categorical_accuracy_cp3: 0.9615 - top_10_categorical_accuracy_cp4: 0.9708 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1412 - top_10_categorical_accuracy_p4: 0.8941 - top_20_categorical_accuracy_cp0: 0.5219 - top_20_categorical_accuracy_cp1: 0.9602 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4157 - top_20_categorical_accuracy_p4: 0.9828 - val_loss: 0.1633 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6845 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3693 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1127 - categorical_accuracy: 0.2000 - top_5_categorical_accuracy: 0.6800 - top_10_categorical_accuracy: 0.8362 - top_20_categorical_accuracy: 0.9276 - top_5_categorical_accuracy_cp0: 0.0120 - top_5_categorical_accuracy_cp1: 0.4649 - top_5_categorical_accuracy_cp2: 0.8205 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7516 - top_10_categorical_accuracy_cp0: 0.2048 - top_10_categorical_accuracy_cp1: 0.9035 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 0.9735 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1111 - top_10_categorical_accuracy_p4: 0.9158 - top_20_categorical_accuracy_cp0: 0.5783 - top_20_categorical_accuracy_cp1: 0.9737 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.5000 - top_20_categorical_accuracy_p4: 0.98743/7 [===========>..................] - ETA: 0s - loss: 0.1173 - categorical_accuracy: 0.2022 - top_5_categorical_accuracy: 0.6603 - top_10_categorical_accuracy: 0.8016 - top_20_categorical_accuracy: 0.8986 - top_5_categorical_accuracy_cp0: 0.0166 - top_5_categorical_accuracy_cp1: 0.4488 - top_5_categorical_accuracy_cp2: 0.8640 - top_5_categorical_accuracy_cp3: 0.9561 - top_5_categorical_accuracy_cp4: 0.9733 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7507 - top_10_categorical_accuracy_cp0: 0.2152 - top_10_categorical_accuracy_cp1: 0.8464 - top_10_categorical_accuracy_cp2: 0.9737 - top_10_categorical_accuracy_cp3: 0.9708 - top_10_categorical_accuracy_cp4: 0.9759 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1163 - top_10_categorical_accuracy_p4: 0.9006 - top_20_categorical_accuracy_cp0: 0.5099 - top_20_categorical_accuracy_cp1: 0.9729 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9942 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3953 - top_20_categorical_accuracy_p4: 0.98495/7 [====================>.........] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.2005 - top_5_categorical_accuracy: 0.6572 - top_10_categorical_accuracy: 0.7991 - top_20_categorical_accuracy: 0.8961 - top_5_categorical_accuracy_cp0: 0.0219 - top_5_categorical_accuracy_cp1: 0.4338 - top_5_categorical_accuracy_cp2: 0.8677 - top_5_categorical_accuracy_cp3: 0.9519 - top_5_categorical_accuracy_cp4: 0.9634 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7483 - top_10_categorical_accuracy_cp0: 0.2191 - top_10_categorical_accuracy_cp1: 0.8364 - top_10_categorical_accuracy_cp2: 0.9796 - top_10_categorical_accuracy_cp3: 0.9661 - top_10_categorical_accuracy_cp4: 0.9682 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1368 - top_10_categorical_accuracy_p4: 0.8973 - top_20_categorical_accuracy_cp0: 0.5100 - top_20_categorical_accuracy_cp1: 0.9669 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9929 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3962 - top_20_categorical_accuracy_p4: 0.98407/7 [==============================] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6544 - top_10_categorical_accuracy: 0.7988 - top_20_categorical_accuracy: 0.8964 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.4373 - top_5_categorical_accuracy_cp2: 0.8683 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7457 - top_10_categorical_accuracy_cp0: 0.2253 - top_10_categorical_accuracy_cp1: 0.8410 - top_10_categorical_accuracy_cp2: 0.9794 - top_10_categorical_accuracy_cp3: 0.9675 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8970 - top_20_categorical_accuracy_cp0: 0.5170 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4039 - top_20_categorical_accuracy_p4: 0.98467/7 [==============================] - 1s 110ms/step - loss: 0.1174 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6544 - top_10_categorical_accuracy: 0.7988 - top_20_categorical_accuracy: 0.8964 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.4373 - top_5_categorical_accuracy_cp2: 0.8683 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7457 - top_10_categorical_accuracy_cp0: 0.2253 - top_10_categorical_accuracy_cp1: 0.8410 - top_10_categorical_accuracy_cp2: 0.9794 - top_10_categorical_accuracy_cp3: 0.9675 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8970 - top_20_categorical_accuracy_cp0: 0.5170 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4039 - top_20_categorical_accuracy_p4: 0.9846 - val_loss: 0.1646 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6845 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3693 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.162609 from epoch 6
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.35it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 2379.26it/s]
INFO:root:Finished run eae9297c1c1e47219293da380b91cae9
2023-05-24 20:15:23.071131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:15:23.589107: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:15:23.589170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:15:23.589175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 5d035b515012444a9a0fd6c4bf0c12ef
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12117.33it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13204.26it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13072.29it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24701.44it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:15:25.948050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.948246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.949027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.949180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.949322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.949482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:25.949879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:15:26.084332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:26.084550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:26.084706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:26.084845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:26.084974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:26.085101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.653735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:15:27.654152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:15:27.654259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12740.64it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13386.41it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13244.78it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24399.67it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 289.47it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 59/154 [00:00<00:00, 291.98it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 89/154 [00:00<00:00, 294.50it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 119/154 [00:00<00:00, 295.04it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 149/154 [00:00<00:00, 295.83it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 294.68it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:52,  7.70it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5162.68it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1298it [00:00, 38961.50it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/154 [00:00<?, ?it/s]Initializing gram_embedding connections:  53%|█████▎    | 82/154 [00:00<00:00, 804.66it/s]Initializing gram_embedding connections: 100%|██████████| 154/154 [00:00<00:00, 448.53it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.02it/s]Calculating percentile frequencies...: 7it [00:00,  7.14it/s]
2023-05-24 20:15:32.104137: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:16:04.672977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:16:05.226808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:16:05.320508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:16:05.783642: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fcc08882370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:16:05.783704: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:16:05.783727: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:16:05.789116: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:16:05.872771: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1930 - categorical_accuracy: 0.0019 - top_5_categorical_accuracy: 0.0383 - top_10_categorical_accuracy: 0.0785 - top_20_categorical_accuracy: 0.1322 - top_5_categorical_accuracy_cp0: 0.0202 - top_5_categorical_accuracy_cp1: 0.1111 - top_5_categorical_accuracy_cp2: 0.0595 - top_5_categorical_accuracy_cp3: 0.0169 - top_5_categorical_accuracy_cp4: 0.0000e+00 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0526 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.0414 - top_10_categorical_accuracy_cp0: 0.0404 - top_10_categorical_accuracy_cp1: 0.1818 - top_10_categorical_accuracy_cp2: 0.1429 - top_10_categorical_accuracy_cp3: 0.0424 - top_10_categorical_accuracy_cp4: 0.0164 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0526 - top_10_categorical_accuracy_p3: 0.0263 - top_10_categorical_accuracy_p4: 0.0850 - top_20_categorical_accuracy_cp0: 0.1111 - top_20_categorical_accuracy_cp1: 0.2525 - top_20_categorical_accuracy_cp2: 0.2143 - top_20_categorical_accuracy_cp3: 0.0847 - top_20_categorical_accuracy_cp4: 0.0410 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2105 - top_20_categorical_accuracy_p3: 0.0789 - top_20_categorical_accuracy_p4: 0.1351      3/Unknown - 34s 40ms/step - loss: 0.1932 - categorical_accuracy: 0.0534 - top_5_categorical_accuracy: 0.2092 - top_10_categorical_accuracy: 0.2975 - top_20_categorical_accuracy: 0.4247 - top_5_categorical_accuracy_cp0: 0.0239 - top_5_categorical_accuracy_cp1: 0.1262 - top_5_categorical_accuracy_cp2: 0.2050 - top_5_categorical_accuracy_cp3: 0.3263 - top_5_categorical_accuracy_cp4: 0.3221 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0213 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.2363 - top_10_categorical_accuracy_cp0: 0.0580 - top_10_categorical_accuracy_cp1: 0.2092 - top_10_categorical_accuracy_cp2: 0.3598 - top_10_categorical_accuracy_cp3: 0.4139 - top_10_categorical_accuracy_cp4: 0.4156 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0426 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.3321 - top_20_categorical_accuracy_cp0: 0.1365 - top_20_categorical_accuracy_cp1: 0.3569 - top_20_categorical_accuracy_cp2: 0.4854 - top_20_categorical_accuracy_cp3: 0.5619 - top_20_categorical_accuracy_cp4: 0.5455 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1277 - top_20_categorical_accuracy_p3: 0.1207 - top_20_categorical_accuracy_p4: 0.4654             5/Unknown - 34s 39ms/step - loss: 0.1933 - categorical_accuracy: 0.0851 - top_5_categorical_accuracy: 0.3227 - top_10_categorical_accuracy: 0.4208 - top_20_categorical_accuracy: 0.5405 - top_5_categorical_accuracy_cp0: 0.0250 - top_5_categorical_accuracy_cp1: 0.1216 - top_5_categorical_accuracy_cp2: 0.2637 - top_5_categorical_accuracy_cp3: 0.5737 - top_5_categorical_accuracy_cp4: 0.5629 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0133 - top_5_categorical_accuracy_p3: 0.0095 - top_5_categorical_accuracy_p4: 0.3677 - top_10_categorical_accuracy_cp0: 0.0672 - top_10_categorical_accuracy_cp1: 0.2595 - top_10_categorical_accuracy_cp2: 0.4752 - top_10_categorical_accuracy_cp3: 0.6403 - top_10_categorical_accuracy_cp4: 0.6306 - top_10_categorical_accuracy_p0: 0.1429 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0533 - top_10_categorical_accuracy_p3: 0.0427 - top_10_categorical_accuracy_p4: 0.4746 - top_20_categorical_accuracy_cp0: 0.1631 - top_20_categorical_accuracy_cp1: 0.4410 - top_20_categorical_accuracy_cp2: 0.6266 - top_20_categorical_accuracy_cp3: 0.7374 - top_20_categorical_accuracy_cp4: 0.7161 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.0333 - top_20_categorical_accuracy_p2: 0.1333 - top_20_categorical_accuracy_p3: 0.1327 - top_20_categorical_accuracy_p4: 0.5993                  7/Unknown - 34s 37ms/step - loss: 0.1927 - categorical_accuracy: 0.0942 - top_5_categorical_accuracy: 0.3616 - top_10_categorical_accuracy: 0.4680 - top_20_categorical_accuracy: 0.5847 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.1223 - top_5_categorical_accuracy_cp2: 0.2922 - top_5_categorical_accuracy_cp3: 0.6464 - top_5_categorical_accuracy_cp4: 0.6375 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.4109 - top_10_categorical_accuracy_cp0: 0.0746 - top_10_categorical_accuracy_cp1: 0.2722 - top_10_categorical_accuracy_cp2: 0.5494 - top_10_categorical_accuracy_cp3: 0.7041 - top_10_categorical_accuracy_cp4: 0.6959 - top_10_categorical_accuracy_p0: 0.1250 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.0510 - top_10_categorical_accuracy_p4: 0.5265 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.4602 - top_20_categorical_accuracy_cp2: 0.7016 - top_20_categorical_accuracy_cp3: 0.7840 - top_20_categorical_accuracy_cp4: 0.7663 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.1529 - top_20_categorical_accuracy_p4: 0.64662023-05-24 20:16:06.905348: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195359
7/7 [==============================] - 53s 3s/step - loss: 0.1927 - categorical_accuracy: 0.0942 - top_5_categorical_accuracy: 0.3616 - top_10_categorical_accuracy: 0.4680 - top_20_categorical_accuracy: 0.5847 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.1223 - top_5_categorical_accuracy_cp2: 0.2922 - top_5_categorical_accuracy_cp3: 0.6464 - top_5_categorical_accuracy_cp4: 0.6375 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.4109 - top_10_categorical_accuracy_cp0: 0.0746 - top_10_categorical_accuracy_cp1: 0.2722 - top_10_categorical_accuracy_cp2: 0.5494 - top_10_categorical_accuracy_cp3: 0.7041 - top_10_categorical_accuracy_cp4: 0.6959 - top_10_categorical_accuracy_p0: 0.1250 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.0510 - top_10_categorical_accuracy_p4: 0.5265 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.4602 - top_20_categorical_accuracy_cp2: 0.7016 - top_20_categorical_accuracy_cp3: 0.7840 - top_20_categorical_accuracy_cp4: 0.7663 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.1529 - top_20_categorical_accuracy_p4: 0.6466 - val_loss: 0.1954 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2648 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.3333 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4845 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2029 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.1080 - val_top_20_categorical_accuracy_cp1: 0.7246 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1532 - val_top_20_categorical_accuracy_p4: 0.8247
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1894 - categorical_accuracy: 0.1290 - top_5_categorical_accuracy: 0.5484 - top_10_categorical_accuracy: 0.7021 - top_20_categorical_accuracy: 0.7856 - top_5_categorical_accuracy_cp0: 0.0103 - top_5_categorical_accuracy_cp1: 0.0541 - top_5_categorical_accuracy_cp2: 0.5455 - top_5_categorical_accuracy_cp3: 0.9915 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6202 - top_10_categorical_accuracy_cp0: 0.0722 - top_10_categorical_accuracy_cp1: 0.4505 - top_10_categorical_accuracy_cp2: 0.9221 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0541 - top_10_categorical_accuracy_p4: 0.7897 - top_20_categorical_accuracy_cp0: 0.1649 - top_20_categorical_accuracy_cp1: 0.7207 - top_20_categorical_accuracy_cp2: 0.9870 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.0625 - top_20_categorical_accuracy_p3: 0.1351 - top_20_categorical_accuracy_p4: 0.87344/7 [================>.............] - ETA: 0s - loss: 0.1867 - categorical_accuracy: 0.1214 - top_5_categorical_accuracy: 0.5283 - top_10_categorical_accuracy: 0.6763 - top_20_categorical_accuracy: 0.7749 - top_5_categorical_accuracy_cp0: 0.0047 - top_5_categorical_accuracy_cp1: 0.0431 - top_5_categorical_accuracy_cp2: 0.5181 - top_5_categorical_accuracy_cp3: 0.9933 - top_5_categorical_accuracy_cp4: 0.9979 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6086 - top_10_categorical_accuracy_cp0: 0.0443 - top_10_categorical_accuracy_cp1: 0.4019 - top_10_categorical_accuracy_cp2: 0.9398 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0469 - top_10_categorical_accuracy_p3: 0.0230 - top_10_categorical_accuracy_p4: 0.7752 - top_20_categorical_accuracy_cp0: 0.1911 - top_20_categorical_accuracy_cp1: 0.7033 - top_20_categorical_accuracy_cp2: 0.9940 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1538 - top_20_categorical_accuracy_p1: 0.1154 - top_20_categorical_accuracy_p2: 0.2188 - top_20_categorical_accuracy_p3: 0.1207 - top_20_categorical_accuracy_p4: 0.8706        6/7 [========================>.....] - ETA: 0s - loss: 0.1838 - categorical_accuracy: 0.1214 - top_5_categorical_accuracy: 0.5377 - top_10_categorical_accuracy: 0.6845 - top_20_categorical_accuracy: 0.7892 - top_5_categorical_accuracy_cp0: 0.0033 - top_5_categorical_accuracy_cp1: 0.0448 - top_5_categorical_accuracy_cp2: 0.5394 - top_5_categorical_accuracy_cp3: 0.9940 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6132 - top_10_categorical_accuracy_cp0: 0.0375 - top_10_categorical_accuracy_cp1: 0.4198 - top_10_categorical_accuracy_cp2: 0.9419 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0357 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.7780 - top_20_categorical_accuracy_cp0: 0.1922 - top_20_categorical_accuracy_cp1: 0.7423 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1905 - top_20_categorical_accuracy_p3: 0.1378 - top_20_categorical_accuracy_p4: 0.8796DEBUG:root:Model metric val_loss improved from 0.195359 to 0.188507
7/7 [==============================] - 1s 103ms/step - loss: 0.1836 - categorical_accuracy: 0.1221 - top_5_categorical_accuracy: 0.5389 - top_10_categorical_accuracy: 0.6858 - top_20_categorical_accuracy: 0.7903 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.0443 - top_5_categorical_accuracy_cp2: 0.5391 - top_5_categorical_accuracy_cp3: 0.9941 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6141 - top_10_categorical_accuracy_cp0: 0.0373 - top_10_categorical_accuracy_cp1: 0.4205 - top_10_categorical_accuracy_cp2: 0.9424 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0353 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.7790 - top_20_categorical_accuracy_cp0: 0.1929 - top_20_categorical_accuracy_cp1: 0.7431 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1882 - top_20_categorical_accuracy_p3: 0.1373 - top_20_categorical_accuracy_p4: 0.8805 - val_loss: 0.1885 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3155 - val_top_20_categorical_accuracy: 0.5070 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0290 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5773 - val_top_20_categorical_accuracy_cp0: 0.0057 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0081 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1639 - categorical_accuracy: 0.1236 - top_5_categorical_accuracy: 0.5475 - top_10_categorical_accuracy: 0.6977 - top_20_categorical_accuracy: 0.7966 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0099 - top_5_categorical_accuracy_cp2: 0.5119 - top_5_categorical_accuracy_cp3: 0.9914 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6141 - top_10_categorical_accuracy_cp0: 0.0104 - top_10_categorical_accuracy_cp1: 0.3960 - top_10_categorical_accuracy_cp2: 0.9643 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7825 - top_20_categorical_accuracy_cp0: 0.1979 - top_20_categorical_accuracy_cp1: 0.7030 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0833 - top_20_categorical_accuracy_p3: 0.1351 - top_20_categorical_accuracy_p4: 0.88064/7 [================>.............] - ETA: 0s - loss: 0.1512 - categorical_accuracy: 0.1198 - top_5_categorical_accuracy: 0.5324 - top_10_categorical_accuracy: 0.7004 - top_20_categorical_accuracy: 0.7987 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0143 - top_5_categorical_accuracy_cp2: 0.5091 - top_5_categorical_accuracy_cp3: 0.9888 - top_5_categorical_accuracy_cp4: 0.9980 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6036 - top_10_categorical_accuracy_cp0: 0.0150 - top_10_categorical_accuracy_cp1: 0.4667 - top_10_categorical_accuracy_cp2: 0.9665 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0065 - top_10_categorical_accuracy_p4: 0.7934 - top_20_categorical_accuracy_cp0: 0.1554 - top_20_categorical_accuracy_cp1: 0.7976 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0909 - top_20_categorical_accuracy_p1: 0.0435 - top_20_categorical_accuracy_p2: 0.1207 - top_20_categorical_accuracy_p3: 0.0710 - top_20_categorical_accuracy_p4: 0.8945            6/7 [========================>.....] - ETA: 0s - loss: 0.1513 - categorical_accuracy: 0.1168 - top_5_categorical_accuracy: 0.5247 - top_10_categorical_accuracy: 0.7037 - top_20_categorical_accuracy: 0.8027 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0155 - top_5_categorical_accuracy_cp2: 0.4927 - top_5_categorical_accuracy_cp3: 0.9925 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5980 - top_10_categorical_accuracy_cp0: 0.0180 - top_10_categorical_accuracy_cp1: 0.5070 - top_10_categorical_accuracy_cp2: 0.9688 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0119 - top_10_categorical_accuracy_p3: 0.0119 - top_10_categorical_accuracy_p4: 0.8004 - top_20_categorical_accuracy_cp0: 0.1702 - top_20_categorical_accuracy_cp1: 0.8223 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0303 - top_20_categorical_accuracy_p2: 0.1310 - top_20_categorical_accuracy_p3: 0.0751 - top_20_categorical_accuracy_p4: 0.9031    DEBUG:root:Model metric val_loss improved from 0.188507 to 0.186872
7/7 [==============================] - 1s 101ms/step - loss: 0.1511 - categorical_accuracy: 0.1171 - top_5_categorical_accuracy: 0.5251 - top_10_categorical_accuracy: 0.7037 - top_20_categorical_accuracy: 0.8032 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0153 - top_5_categorical_accuracy_cp2: 0.4938 - top_5_categorical_accuracy_cp3: 0.9926 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5984 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.5061 - top_10_categorical_accuracy_cp2: 0.9691 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8004 - top_20_categorical_accuracy_cp0: 0.1702 - top_20_categorical_accuracy_cp1: 0.8242 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.0784 - top_20_categorical_accuracy_p4: 0.9034 - val_loss: 0.1869 - val_categorical_accuracy: 0.0056 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3155 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0290 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5773 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1334 - categorical_accuracy: 0.1130 - top_5_categorical_accuracy: 0.5747 - top_10_categorical_accuracy: 0.7318 - top_20_categorical_accuracy: 0.8276 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0112 - top_5_categorical_accuracy_cp2: 0.5882 - top_5_categorical_accuracy_cp3: 0.9911 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6479 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.4831 - top_10_categorical_accuracy_cp2: 0.9706 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8251 - top_20_categorical_accuracy_cp0: 0.1868 - top_20_categorical_accuracy_cp1: 0.8202 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.0732 - top_20_categorical_accuracy_p4: 0.92444/7 [================>.............] - ETA: 0s - loss: 0.1358 - categorical_accuracy: 0.1260 - top_5_categorical_accuracy: 0.5394 - top_10_categorical_accuracy: 0.7082 - top_20_categorical_accuracy: 0.8246 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0072 - top_5_categorical_accuracy_cp2: 0.6066 - top_5_categorical_accuracy_cp3: 0.9801 - top_5_categorical_accuracy_cp4: 0.9959 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6148 - top_10_categorical_accuracy_cp0: 0.0096 - top_10_categorical_accuracy_cp1: 0.5242 - top_10_categorical_accuracy_cp2: 0.9850 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8072 - top_20_categorical_accuracy_cp0: 0.2091 - top_20_categorical_accuracy_cp1: 0.9034 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0400 - top_20_categorical_accuracy_p2: 0.0179 - top_20_categorical_accuracy_p3: 0.0671 - top_20_categorical_accuracy_p4: 0.9328        7/7 [==============================] - ETA: 0s - loss: 0.1357 - categorical_accuracy: 0.1321 - top_5_categorical_accuracy: 0.5377 - top_10_categorical_accuracy: 0.7128 - top_20_categorical_accuracy: 0.8340 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0107 - top_5_categorical_accuracy_cp2: 0.6276 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6127 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5443 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8122 - top_20_categorical_accuracy_cp0: 0.2253 - top_20_categorical_accuracy_cp1: 0.9220 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.0863 - top_20_categorical_accuracy_p4: 0.9413DEBUG:root:Model metric val_loss improved from 0.186872 to 0.176554
7/7 [==============================] - 1s 101ms/step - loss: 0.1357 - categorical_accuracy: 0.1321 - top_5_categorical_accuracy: 0.5377 - top_10_categorical_accuracy: 0.7128 - top_20_categorical_accuracy: 0.8340 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0107 - top_5_categorical_accuracy_cp2: 0.6276 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6127 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5443 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8122 - top_20_categorical_accuracy_cp0: 0.2253 - top_20_categorical_accuracy_cp1: 0.9220 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.0863 - top_20_categorical_accuracy_p4: 0.9413 - val_loss: 0.1766 - val_categorical_accuracy: 0.2028 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3239 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0725 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5928 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1343 - categorical_accuracy: 0.1407 - top_5_categorical_accuracy: 0.5456 - top_10_categorical_accuracy: 0.7243 - top_20_categorical_accuracy: 0.8517 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0517 - top_5_categorical_accuracy_cp2: 0.8052 - top_5_categorical_accuracy_cp3: 0.9259 - top_5_categorical_accuracy_cp4: 0.9297 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6146 - top_10_categorical_accuracy_cp0: 0.0103 - top_10_categorical_accuracy_cp1: 0.5776 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8158 - top_20_categorical_accuracy_cp0: 0.2474 - top_20_categorical_accuracy_cp1: 0.9569 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1053 - top_20_categorical_accuracy_p4: 0.95073/7 [===========>..................] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.1362 - top_5_categorical_accuracy: 0.5304 - top_10_categorical_accuracy: 0.7047 - top_20_categorical_accuracy: 0.8428 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0588 - top_5_categorical_accuracy_cp2: 0.7542 - top_5_categorical_accuracy_cp3: 0.9157 - top_5_categorical_accuracy_cp4: 0.9385 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6109 - top_10_categorical_accuracy_cp0: 0.0061 - top_10_categorical_accuracy_cp1: 0.5697 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8117 - top_20_categorical_accuracy_cp0: 0.2888 - top_20_categorical_accuracy_cp1: 0.9567 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1985 - top_20_categorical_accuracy_p4: 0.95115/7 [====================>.........] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.1446 - top_5_categorical_accuracy: 0.5434 - top_10_categorical_accuracy: 0.7150 - top_20_categorical_accuracy: 0.8550 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0573 - top_5_categorical_accuracy_cp2: 0.7735 - top_5_categorical_accuracy_cp3: 0.9202 - top_5_categorical_accuracy_cp4: 0.9472 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6225 - top_10_categorical_accuracy_cp0: 0.0057 - top_10_categorical_accuracy_cp1: 0.5786 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8191 - top_20_categorical_accuracy_cp0: 0.3073 - top_20_categorical_accuracy_cp1: 0.9667 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2254 - top_20_categorical_accuracy_p4: 0.95867/7 [==============================] - ETA: 0s - loss: 0.1326 - categorical_accuracy: 0.1481 - top_5_categorical_accuracy: 0.5515 - top_10_categorical_accuracy: 0.7216 - top_20_categorical_accuracy: 0.8606 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0673 - top_5_categorical_accuracy_cp2: 0.7675 - top_5_categorical_accuracy_cp3: 0.9275 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6284 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5826 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8222 - top_20_categorical_accuracy_cp0: 0.3112 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.9617DEBUG:root:Model metric val_loss improved from 0.176554 to 0.172826
7/7 [==============================] - 1s 113ms/step - loss: 0.1326 - categorical_accuracy: 0.1481 - top_5_categorical_accuracy: 0.5515 - top_10_categorical_accuracy: 0.7216 - top_20_categorical_accuracy: 0.8606 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0673 - top_5_categorical_accuracy_cp2: 0.7675 - top_5_categorical_accuracy_cp3: 0.9275 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6284 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5826 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8222 - top_20_categorical_accuracy_cp0: 0.3112 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.9617 - val_loss: 0.1728 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3268 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0870 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5979 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1343 - categorical_accuracy: 0.1469 - top_5_categorical_accuracy: 0.5254 - top_10_categorical_accuracy: 0.6874 - top_20_categorical_accuracy: 0.8550 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0787 - top_5_categorical_accuracy_cp2: 0.7903 - top_5_categorical_accuracy_cp3: 0.9649 - top_5_categorical_accuracy_cp4: 0.9649 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5949 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.5906 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7783 - top_20_categorical_accuracy_cp0: 0.3684 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1707 - top_20_categorical_accuracy_p4: 0.95313/7 [===========>..................] - ETA: 0s - loss: 0.1289 - categorical_accuracy: 0.1595 - top_5_categorical_accuracy: 0.5614 - top_10_categorical_accuracy: 0.7247 - top_20_categorical_accuracy: 0.8677 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0853 - top_5_categorical_accuracy_cp2: 0.7642 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9699 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6336 - top_10_categorical_accuracy_cp0: 0.0032 - top_10_categorical_accuracy_cp1: 0.6265 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8179 - top_20_categorical_accuracy_cp0: 0.3528 - top_20_categorical_accuracy_cp1: 0.9735 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1667 - top_20_categorical_accuracy_p4: 0.9657    5/7 [====================>.........] - ETA: 0s - loss: 0.1278 - categorical_accuracy: 0.1599 - top_5_categorical_accuracy: 0.5725 - top_10_categorical_accuracy: 0.7282 - top_20_categorical_accuracy: 0.8637 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1052 - top_5_categorical_accuracy_cp2: 0.7481 - top_5_categorical_accuracy_cp3: 0.9677 - top_5_categorical_accuracy_cp4: 0.9777 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6514 - top_10_categorical_accuracy_cp0: 0.0020 - top_10_categorical_accuracy_cp1: 0.6199 - top_10_categorical_accuracy_cp2: 0.9949 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8285 - top_20_categorical_accuracy_cp0: 0.3195 - top_20_categorical_accuracy_cp1: 0.9760 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1667 - top_20_categorical_accuracy_p4: 0.96757/7 [==============================] - ETA: 0s - loss: 0.1277 - categorical_accuracy: 0.1632 - top_5_categorical_accuracy: 0.5734 - top_10_categorical_accuracy: 0.7279 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1086 - top_5_categorical_accuracy_cp2: 0.7490 - top_5_categorical_accuracy_cp3: 0.9675 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6534 - top_10_categorical_accuracy_cp0: 0.0016 - top_10_categorical_accuracy_cp1: 0.6193 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8294 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1725 - top_20_categorical_accuracy_p4: 0.9678DEBUG:root:Model metric val_loss improved from 0.172826 to 0.168711
7/7 [==============================] - 1s 111ms/step - loss: 0.1277 - categorical_accuracy: 0.1632 - top_5_categorical_accuracy: 0.5734 - top_10_categorical_accuracy: 0.7279 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1086 - top_5_categorical_accuracy_cp2: 0.7490 - top_5_categorical_accuracy_cp3: 0.9675 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6534 - top_10_categorical_accuracy_cp0: 0.0016 - top_10_categorical_accuracy_cp1: 0.6193 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8294 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1725 - top_20_categorical_accuracy_p4: 0.9678 - val_loss: 0.1687 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3014 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.8750 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5515 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.1931 - top_5_categorical_accuracy: 0.6080 - top_10_categorical_accuracy: 0.7495 - top_20_categorical_accuracy: 0.8872 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1827 - top_5_categorical_accuracy_cp2: 0.7356 - top_5_categorical_accuracy_cp3: 0.9730 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6883 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.6250 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8485 - top_20_categorical_accuracy_cp0: 0.4130 - top_20_categorical_accuracy_cp1: 0.9519 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2766 - top_20_categorical_accuracy_p4: 0.97623/7 [===========>..................] - ETA: 0s - loss: 0.1222 - categorical_accuracy: 0.2048 - top_5_categorical_accuracy: 0.6221 - top_10_categorical_accuracy: 0.7519 - top_20_categorical_accuracy: 0.8651 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1905 - top_5_categorical_accuracy_cp2: 0.7978 - top_5_categorical_accuracy_cp3: 0.9848 - top_5_categorical_accuracy_cp4: 0.9871 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7133 - top_10_categorical_accuracy_cp0: 0.0068 - top_10_categorical_accuracy_cp1: 0.6599 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8621 - top_20_categorical_accuracy_cp0: 0.3253 - top_20_categorical_accuracy_cp1: 0.9490 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1929 - top_20_categorical_accuracy_p4: 0.9723    5/7 [====================>.........] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6125 - top_10_categorical_accuracy: 0.7499 - top_20_categorical_accuracy: 0.8630 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2245 - top_5_categorical_accuracy_cp2: 0.8127 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9823 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6996 - top_10_categorical_accuracy_cp0: 0.0196 - top_10_categorical_accuracy_cp1: 0.7057 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0047 - top_10_categorical_accuracy_p4: 0.8561 - top_20_categorical_accuracy_cp0: 0.3399 - top_20_categorical_accuracy_cp1: 0.9547 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2207 - top_20_categorical_accuracy_p4: 0.9652    7/7 [==============================] - ETA: 0s - loss: 0.1231 - categorical_accuracy: 0.2068 - top_5_categorical_accuracy: 0.6152 - top_10_categorical_accuracy: 0.7524 - top_20_categorical_accuracy: 0.8663 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2355 - top_5_categorical_accuracy_cp2: 0.8251 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7010 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.7125 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8562 - top_20_categorical_accuracy_cp0: 0.3533 - top_20_categorical_accuracy_cp1: 0.9587 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2235 - top_20_categorical_accuracy_p4: 0.9667DEBUG:root:Model metric val_loss improved from 0.168711 to 0.162643
7/7 [==============================] - 1s 111ms/step - loss: 0.1231 - categorical_accuracy: 0.2068 - top_5_categorical_accuracy: 0.6152 - top_10_categorical_accuracy: 0.7524 - top_20_categorical_accuracy: 0.8663 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2355 - top_5_categorical_accuracy_cp2: 0.8251 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7010 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.7125 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8562 - top_20_categorical_accuracy_cp0: 0.3533 - top_20_categorical_accuracy_cp1: 0.9587 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2235 - top_20_categorical_accuracy_p4: 0.9667 - val_loss: 0.1626 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3296 - val_top_10_categorical_accuracy: 0.4958 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6031 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9565 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9072 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.2079 - top_5_categorical_accuracy: 0.5936 - top_10_categorical_accuracy: 0.7278 - top_20_categorical_accuracy: 0.8677 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3475 - top_5_categorical_accuracy_cp2: 0.8228 - top_5_categorical_accuracy_cp3: 0.9905 - top_5_categorical_accuracy_cp4: 0.9630 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6901 - top_10_categorical_accuracy_cp0: 0.0672 - top_10_categorical_accuracy_cp1: 0.7373 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9907 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8418 - top_20_categorical_accuracy_cp0: 0.4286 - top_20_categorical_accuracy_cp1: 0.9831 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2745 - top_20_categorical_accuracy_p4: 0.97803/7 [===========>..................] - ETA: 0s - loss: 0.1223 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.6255 - top_10_categorical_accuracy: 0.7503 - top_20_categorical_accuracy: 0.8726 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3503 - top_5_categorical_accuracy_cp2: 0.8566 - top_5_categorical_accuracy_cp3: 0.9696 - top_5_categorical_accuracy_cp4: 0.9607 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7147 - top_10_categorical_accuracy_cp0: 0.0635 - top_10_categorical_accuracy_cp1: 0.7156 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9944 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0333 - top_10_categorical_accuracy_p4: 0.8545 - top_20_categorical_accuracy_cp0: 0.3841 - top_20_categorical_accuracy_cp1: 0.9790 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3000 - top_20_categorical_accuracy_p4: 0.97105/7 [====================>.........] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.2114 - top_5_categorical_accuracy: 0.6350 - top_10_categorical_accuracy: 0.7654 - top_20_categorical_accuracy: 0.8730 - top_5_categorical_accuracy_cp0: 0.0058 - top_5_categorical_accuracy_cp1: 0.3688 - top_5_categorical_accuracy_cp2: 0.8446 - top_5_categorical_accuracy_cp3: 0.9606 - top_5_categorical_accuracy_cp4: 0.9673 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7251 - top_10_categorical_accuracy_cp0: 0.0854 - top_10_categorical_accuracy_cp1: 0.7523 - top_10_categorical_accuracy_cp2: 0.9850 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9918 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0571 - top_10_categorical_accuracy_p4: 0.8689 - top_20_categorical_accuracy_cp0: 0.3748 - top_20_categorical_accuracy_cp1: 0.9780 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2905 - top_20_categorical_accuracy_p4: 0.9705    7/7 [==============================] - ETA: 0s - loss: 0.1201 - categorical_accuracy: 0.2116 - top_5_categorical_accuracy: 0.6397 - top_10_categorical_accuracy: 0.7724 - top_20_categorical_accuracy: 0.8776 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.3746 - top_5_categorical_accuracy_cp2: 0.8477 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7289 - top_10_categorical_accuracy_cp0: 0.0940 - top_10_categorical_accuracy_cp1: 0.7661 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0706 - top_10_categorical_accuracy_p4: 0.8737 - top_20_categorical_accuracy_cp0: 0.3922 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3020 - top_20_categorical_accuracy_p4: 0.9725DEBUG:root:Model metric val_loss improved from 0.162643 to 0.162332
7/7 [==============================] - 1s 111ms/step - loss: 0.1201 - categorical_accuracy: 0.2116 - top_5_categorical_accuracy: 0.6397 - top_10_categorical_accuracy: 0.7724 - top_20_categorical_accuracy: 0.8776 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.3746 - top_5_categorical_accuracy_cp2: 0.8477 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7289 - top_10_categorical_accuracy_cp0: 0.0940 - top_10_categorical_accuracy_cp1: 0.7661 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0706 - top_10_categorical_accuracy_p4: 0.8737 - top_20_categorical_accuracy_cp0: 0.3922 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3020 - top_20_categorical_accuracy_p4: 0.9725 - val_loss: 0.1623 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3296 - val_top_10_categorical_accuracy: 0.3887 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6031 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.4058 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7113 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1219 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6276 - top_10_categorical_accuracy: 0.7675 - top_20_categorical_accuracy: 0.8828 - top_5_categorical_accuracy_cp0: 0.0090 - top_5_categorical_accuracy_cp1: 0.4643 - top_5_categorical_accuracy_cp2: 0.8025 - top_5_categorical_accuracy_cp3: 0.9381 - top_5_categorical_accuracy_cp4: 0.9643 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7155 - top_10_categorical_accuracy_cp0: 0.1802 - top_10_categorical_accuracy_cp1: 0.8036 - top_10_categorical_accuracy_cp2: 0.9383 - top_10_categorical_accuracy_cp3: 0.9735 - top_10_categorical_accuracy_cp4: 0.9821 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.8664 - top_20_categorical_accuracy_cp0: 0.4685 - top_20_categorical_accuracy_cp1: 0.9732 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2857 - top_20_categorical_accuracy_p4: 0.98063/7 [===========>..................] - ETA: 0s - loss: 0.1204 - categorical_accuracy: 0.2069 - top_5_categorical_accuracy: 0.6397 - top_10_categorical_accuracy: 0.7710 - top_20_categorical_accuracy: 0.8826 - top_5_categorical_accuracy_cp0: 0.0185 - top_5_categorical_accuracy_cp1: 0.4576 - top_5_categorical_accuracy_cp2: 0.8391 - top_5_categorical_accuracy_cp3: 0.9529 - top_5_categorical_accuracy_cp4: 0.9418 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7295 - top_10_categorical_accuracy_cp0: 0.1759 - top_10_categorical_accuracy_cp1: 0.7909 - top_10_categorical_accuracy_cp2: 0.9565 - top_10_categorical_accuracy_cp3: 0.9824 - top_10_categorical_accuracy_cp4: 0.9695 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0916 - top_10_categorical_accuracy_p4: 0.8705 - top_20_categorical_accuracy_cp0: 0.4691 - top_20_categorical_accuracy_cp1: 0.9636 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9945 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3053 - top_20_categorical_accuracy_p4: 0.97775/7 [====================>.........] - ETA: 0s - loss: 0.1192 - categorical_accuracy: 0.2027 - top_5_categorical_accuracy: 0.6494 - top_10_categorical_accuracy: 0.7817 - top_20_categorical_accuracy: 0.8837 - top_5_categorical_accuracy_cp0: 0.0195 - top_5_categorical_accuracy_cp1: 0.4459 - top_5_categorical_accuracy_cp2: 0.8463 - top_5_categorical_accuracy_cp3: 0.9567 - top_5_categorical_accuracy_cp4: 0.9485 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7410 - top_10_categorical_accuracy_cp0: 0.1735 - top_10_categorical_accuracy_cp1: 0.8037 - top_10_categorical_accuracy_cp2: 0.9496 - top_10_categorical_accuracy_cp3: 0.9838 - top_10_categorical_accuracy_cp4: 0.9775 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1075 - top_10_categorical_accuracy_p4: 0.8820 - top_20_categorical_accuracy_cp0: 0.4542 - top_20_categorical_accuracy_cp1: 0.9560 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3318 - top_20_categorical_accuracy_p4: 0.97747/7 [==============================] - ETA: 0s - loss: 0.1186 - categorical_accuracy: 0.2034 - top_5_categorical_accuracy: 0.6510 - top_10_categorical_accuracy: 0.7869 - top_20_categorical_accuracy: 0.8889 - top_5_categorical_accuracy_cp0: 0.0194 - top_5_categorical_accuracy_cp1: 0.4388 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7418 - top_10_categorical_accuracy_cp0: 0.1977 - top_10_categorical_accuracy_cp1: 0.8073 - top_10_categorical_accuracy_cp2: 0.9444 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1255 - top_10_categorical_accuracy_p4: 0.8852 - top_20_categorical_accuracy_cp0: 0.4733 - top_20_categorical_accuracy_cp1: 0.9602 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3608 - top_20_categorical_accuracy_p4: 0.9800DEBUG:root:Model metric val_loss improved from 0.162332 to 0.162147
7/7 [==============================] - 1s 111ms/step - loss: 0.1186 - categorical_accuracy: 0.2034 - top_5_categorical_accuracy: 0.6510 - top_10_categorical_accuracy: 0.7869 - top_20_categorical_accuracy: 0.8889 - top_5_categorical_accuracy_cp0: 0.0194 - top_5_categorical_accuracy_cp1: 0.4388 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7418 - top_10_categorical_accuracy_cp0: 0.1977 - top_10_categorical_accuracy_cp1: 0.8073 - top_10_categorical_accuracy_cp2: 0.9444 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1255 - top_10_categorical_accuracy_p4: 0.8852 - top_20_categorical_accuracy_cp0: 0.4733 - top_20_categorical_accuracy_cp1: 0.9602 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9960 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3608 - top_20_categorical_accuracy_p4: 0.9800 - val_loss: 0.1621 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6789 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3580 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9845
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1120 - categorical_accuracy: 0.2095 - top_5_categorical_accuracy: 0.6952 - top_10_categorical_accuracy: 0.8438 - top_20_categorical_accuracy: 0.9276 - top_5_categorical_accuracy_cp0: 0.0723 - top_5_categorical_accuracy_cp1: 0.4912 - top_5_categorical_accuracy_cp2: 0.8333 - top_5_categorical_accuracy_cp3: 0.9469 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7684 - top_10_categorical_accuracy_cp0: 0.2771 - top_10_categorical_accuracy_cp1: 0.9035 - top_10_categorical_accuracy_cp2: 0.9615 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9708 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1389 - top_10_categorical_accuracy_p4: 0.9221 - top_20_categorical_accuracy_cp0: 0.5904 - top_20_categorical_accuracy_cp1: 0.9737 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4722 - top_20_categorical_accuracy_p4: 0.98953/7 [===========>..................] - ETA: 0s - loss: 0.1167 - categorical_accuracy: 0.2066 - top_5_categorical_accuracy: 0.6629 - top_10_categorical_accuracy: 0.7991 - top_20_categorical_accuracy: 0.9018 - top_5_categorical_accuracy_cp0: 0.0430 - top_5_categorical_accuracy_cp1: 0.4578 - top_5_categorical_accuracy_cp2: 0.8465 - top_5_categorical_accuracy_cp3: 0.9591 - top_5_categorical_accuracy_cp4: 0.9626 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7536 - top_10_categorical_accuracy_cp0: 0.2384 - top_10_categorical_accuracy_cp1: 0.8253 - top_10_categorical_accuracy_cp2: 0.9474 - top_10_categorical_accuracy_cp3: 0.9708 - top_10_categorical_accuracy_cp4: 0.9813 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1318 - top_10_categorical_accuracy_p4: 0.8963 - top_20_categorical_accuracy_cp0: 0.5298 - top_20_categorical_accuracy_cp1: 0.9669 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4419 - top_20_categorical_accuracy_p4: 0.98415/7 [====================>.........] - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.2009 - top_5_categorical_accuracy: 0.6541 - top_10_categorical_accuracy: 0.7979 - top_20_categorical_accuracy: 0.8984 - top_5_categorical_accuracy_cp0: 0.0378 - top_5_categorical_accuracy_cp1: 0.4301 - top_5_categorical_accuracy_cp2: 0.8397 - top_5_categorical_accuracy_cp3: 0.9554 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7444 - top_10_categorical_accuracy_cp0: 0.2530 - top_10_categorical_accuracy_cp1: 0.8235 - top_10_categorical_accuracy_cp2: 0.9338 - top_10_categorical_accuracy_cp3: 0.9715 - top_10_categorical_accuracy_cp4: 0.9713 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1509 - top_10_categorical_accuracy_p4: 0.8947 - top_20_categorical_accuracy_cp0: 0.5199 - top_20_categorical_accuracy_cp1: 0.9632 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4292 - top_20_categorical_accuracy_p4: 0.9835    7/7 [==============================] - ETA: 0s - loss: 0.1172 - categorical_accuracy: 0.2021 - top_5_categorical_accuracy: 0.6525 - top_10_categorical_accuracy: 0.7960 - top_20_categorical_accuracy: 0.8980 - top_5_categorical_accuracy_cp0: 0.0405 - top_5_categorical_accuracy_cp1: 0.4327 - top_5_categorical_accuracy_cp2: 0.8416 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7432 - top_10_categorical_accuracy_cp0: 0.2512 - top_10_categorical_accuracy_cp1: 0.8272 - top_10_categorical_accuracy_cp2: 0.9403 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8938 - top_20_categorical_accuracy_cp0: 0.5235 - top_20_categorical_accuracy_cp1: 0.9648 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4353 - top_20_categorical_accuracy_p4: 0.98357/7 [==============================] - 1s 110ms/step - loss: 0.1172 - categorical_accuracy: 0.2021 - top_5_categorical_accuracy: 0.6525 - top_10_categorical_accuracy: 0.7960 - top_20_categorical_accuracy: 0.8980 - top_5_categorical_accuracy_cp0: 0.0405 - top_5_categorical_accuracy_cp1: 0.4327 - top_5_categorical_accuracy_cp2: 0.8416 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7432 - top_10_categorical_accuracy_cp0: 0.2512 - top_10_categorical_accuracy_cp1: 0.8272 - top_10_categorical_accuracy_cp2: 0.9403 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8938 - top_20_categorical_accuracy_cp0: 0.5235 - top_20_categorical_accuracy_cp1: 0.9648 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4353 - top_20_categorical_accuracy_p4: 0.9835 - val_loss: 0.1637 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6958 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3920 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4355 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.162147 from epoch 8
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.66it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 2236.28it/s]
INFO:root:Finished run 5d035b515012444a9a0fd6c4bf0c12ef
2023-05-24 20:16:40.527569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:16:41.043284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:16:41.043349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:16:41.043355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 235d27e6e22d4e6590d93396f7925255
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12168.88it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13304.28it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13021.55it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24347.74it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:16:43.356300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.356495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.357278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.357437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.357574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.357708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.358094: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:16:43.493994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.494204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.494356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.494487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.494610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:43.494733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.050907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.051103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.051259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.051392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.051518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.051632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:16:45.052019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:16:45.052132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12745.67it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13466.86it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13242.03it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24100.58it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 30/154 [00:00<00:00, 291.68it/s]Loading hierarchy for column coarse_log_cluster_path:  39%|███▉      | 60/154 [00:00<00:00, 293.43it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 90/154 [00:00<00:00, 294.84it/s]Loading hierarchy for column coarse_log_cluster_path:  78%|███████▊  | 120/154 [00:00<00:00, 295.67it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 150/154 [00:00<00:00, 297.19it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 295.87it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:48,  7.94it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5298.74it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 38194.06it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/198 [00:00<?, ?it/s]Initializing gram_embedding connections:  42%|████▏     | 83/198 [00:00<00:00, 823.49it/s]Initializing gram_embedding connections:  84%|████████▍ | 166/198 [00:00<00:00, 395.72it/s]Initializing gram_embedding connections: 100%|██████████| 198/198 [00:00<00:00, 362.61it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.07it/s]Calculating percentile frequencies...: 7it [00:00,  7.48it/s]
2023-05-24 20:16:49.632426: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:17:22.312392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:17:22.952579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:17:23.077700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:17:23.517682: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x91131330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:17:23.517723: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:17:23.517729: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:17:23.522758: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:17:23.623318: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1929 - categorical_accuracy: 0.0172 - top_5_categorical_accuracy: 0.0766 - top_10_categorical_accuracy: 0.1092 - top_20_categorical_accuracy: 0.1801 - top_5_categorical_accuracy_cp0: 0.0303 - top_5_categorical_accuracy_cp1: 0.0606 - top_5_categorical_accuracy_cp2: 0.1310 - top_5_categorical_accuracy_cp3: 0.1356 - top_5_categorical_accuracy_cp4: 0.0328 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0263 - top_5_categorical_accuracy_p4: 0.0850 - top_10_categorical_accuracy_cp0: 0.0606 - top_10_categorical_accuracy_cp1: 0.0808 - top_10_categorical_accuracy_cp2: 0.1905 - top_10_categorical_accuracy_cp3: 0.1525 - top_10_categorical_accuracy_cp4: 0.0738 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0556 - top_10_categorical_accuracy_p3: 0.0526 - top_10_categorical_accuracy_p4: 0.1176 - top_20_categorical_accuracy_cp0: 0.0808 - top_20_categorical_accuracy_cp1: 0.1818 - top_20_categorical_accuracy_cp2: 0.3333 - top_20_categorical_accuracy_cp3: 0.1949 - top_20_categorical_accuracy_cp4: 0.1393 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0556 - top_20_categorical_accuracy_p3: 0.1053 - top_20_categorical_accuracy_p4: 0.1939      3/Unknown - 34s 30ms/step - loss: 0.1931 - categorical_accuracy: 0.0788 - top_5_categorical_accuracy: 0.2460 - top_10_categorical_accuracy: 0.3357 - top_20_categorical_accuracy: 0.4304 - top_5_categorical_accuracy_cp0: 0.0205 - top_5_categorical_accuracy_cp1: 0.0738 - top_5_categorical_accuracy_cp2: 0.2552 - top_5_categorical_accuracy_cp3: 0.3746 - top_5_categorical_accuracy_cp4: 0.4468 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0208 - top_5_categorical_accuracy_p3: 0.0086 - top_5_categorical_accuracy_p4: 0.2774 - top_10_categorical_accuracy_cp0: 0.0478 - top_10_categorical_accuracy_cp1: 0.1323 - top_10_categorical_accuracy_cp2: 0.3849 - top_10_categorical_accuracy_cp3: 0.4924 - top_10_categorical_accuracy_cp4: 0.5610 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0625 - top_10_categorical_accuracy_p3: 0.0259 - top_10_categorical_accuracy_p4: 0.3754 - top_20_categorical_accuracy_cp0: 0.1160 - top_20_categorical_accuracy_cp1: 0.2462 - top_20_categorical_accuracy_cp2: 0.5230 - top_20_categorical_accuracy_cp3: 0.5680 - top_20_categorical_accuracy_cp4: 0.6494 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1765 - top_20_categorical_accuracy_p2: 0.1458 - top_20_categorical_accuracy_p3: 0.0776 - top_20_categorical_accuracy_p4: 0.4741                 5/Unknown - 34s 32ms/step - loss: 0.1930 - categorical_accuracy: 0.1190 - top_5_categorical_accuracy: 0.3440 - top_10_categorical_accuracy: 0.4382 - top_20_categorical_accuracy: 0.5367 - top_5_categorical_accuracy_cp0: 0.0115 - top_5_categorical_accuracy_cp1: 0.0744 - top_5_categorical_accuracy_cp2: 0.3211 - top_5_categorical_accuracy_cp3: 0.6025 - top_5_categorical_accuracy_cp4: 0.6452 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0130 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.3924 - top_10_categorical_accuracy_cp0: 0.0480 - top_10_categorical_accuracy_cp1: 0.1906 - top_10_categorical_accuracy_cp2: 0.4856 - top_10_categorical_accuracy_cp3: 0.6942 - top_10_categorical_accuracy_cp4: 0.7274 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0345 - top_10_categorical_accuracy_p2: 0.0390 - top_10_categorical_accuracy_p3: 0.0332 - top_10_categorical_accuracy_p4: 0.4963 - top_20_categorical_accuracy_cp0: 0.1305 - top_20_categorical_accuracy_cp1: 0.3666 - top_20_categorical_accuracy_cp2: 0.6397 - top_20_categorical_accuracy_cp3: 0.7410 - top_20_categorical_accuracy_cp4: 0.7823 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1724 - top_20_categorical_accuracy_p2: 0.1429 - top_20_categorical_accuracy_p3: 0.1043 - top_20_categorical_accuracy_p4: 0.5971      7/Unknown - 35s 32ms/step - loss: 0.1924 - categorical_accuracy: 0.1296 - top_5_categorical_accuracy: 0.3792 - top_10_categorical_accuracy: 0.4787 - top_20_categorical_accuracy: 0.5766 - top_5_categorical_accuracy_cp0: 0.0097 - top_5_categorical_accuracy_cp1: 0.0719 - top_5_categorical_accuracy_cp2: 0.3477 - top_5_categorical_accuracy_cp3: 0.6701 - top_5_categorical_accuracy_cp4: 0.7078 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.4313 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.2141 - top_10_categorical_accuracy_cp2: 0.5576 - top_10_categorical_accuracy_cp3: 0.7470 - top_10_categorical_accuracy_cp4: 0.7756 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0353 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.5415 - top_20_categorical_accuracy_cp0: 0.1264 - top_20_categorical_accuracy_cp1: 0.4144 - top_20_categorical_accuracy_cp2: 0.6955 - top_20_categorical_accuracy_cp3: 0.7870 - top_20_categorical_accuracy_cp4: 0.8207 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.1020 - top_20_categorical_accuracy_p4: 0.64202023-05-24 20:17:24.615356: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195332
7/7 [==============================] - 53s 3s/step - loss: 0.1924 - categorical_accuracy: 0.1296 - top_5_categorical_accuracy: 0.3792 - top_10_categorical_accuracy: 0.4787 - top_20_categorical_accuracy: 0.5766 - top_5_categorical_accuracy_cp0: 0.0097 - top_5_categorical_accuracy_cp1: 0.0719 - top_5_categorical_accuracy_cp2: 0.3477 - top_5_categorical_accuracy_cp3: 0.6701 - top_5_categorical_accuracy_cp4: 0.7078 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.4313 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.2141 - top_10_categorical_accuracy_cp2: 0.5576 - top_10_categorical_accuracy_cp3: 0.7470 - top_10_categorical_accuracy_cp4: 0.7756 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0353 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.5415 - top_20_categorical_accuracy_cp0: 0.1264 - top_20_categorical_accuracy_cp1: 0.4144 - top_20_categorical_accuracy_cp2: 0.6955 - top_20_categorical_accuracy_cp3: 0.7870 - top_20_categorical_accuracy_cp4: 0.8207 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.1020 - top_20_categorical_accuracy_p4: 0.6420 - val_loss: 0.1953 - val_categorical_accuracy: 0.1099 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3521 - val_top_20_categorical_accuracy: 0.5549 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6443 - val_top_20_categorical_accuracy_cp0: 0.1080 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.1579 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1290 - val_top_20_categorical_accuracy_p4: 0.9175
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.1784 - top_5_categorical_accuracy: 0.5408 - top_10_categorical_accuracy: 0.6831 - top_20_categorical_accuracy: 0.7913 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0270 - top_5_categorical_accuracy_cp2: 0.5325 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6116 - top_10_categorical_accuracy_cp0: 0.0412 - top_10_categorical_accuracy_cp1: 0.4054 - top_10_categorical_accuracy_cp2: 0.8961 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0541 - top_10_categorical_accuracy_p4: 0.7682 - top_20_categorical_accuracy_cp0: 0.1753 - top_20_categorical_accuracy_cp1: 0.7477 - top_20_categorical_accuracy_cp2: 0.9740 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2222 - top_20_categorical_accuracy_p2: 0.1333 - top_20_categorical_accuracy_p3: 0.1351 - top_20_categorical_accuracy_p4: 0.87553/7 [===========>..................] - ETA: 0s - loss: 0.1860 - categorical_accuracy: 0.1631 - top_5_categorical_accuracy: 0.5209 - top_10_categorical_accuracy: 0.6618 - top_20_categorical_accuracy: 0.7684 - top_5_categorical_accuracy_cp0: 0.0031 - top_5_categorical_accuracy_cp1: 0.0288 - top_5_categorical_accuracy_cp2: 0.4792 - top_5_categorical_accuracy_cp3: 0.9941 - top_5_categorical_accuracy_cp4: 0.9972 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0075 - top_5_categorical_accuracy_p4: 0.6021 - top_10_categorical_accuracy_cp0: 0.0215 - top_10_categorical_accuracy_cp1: 0.3974 - top_10_categorical_accuracy_cp2: 0.8875 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0224 - top_10_categorical_accuracy_p4: 0.7636 - top_20_categorical_accuracy_cp0: 0.1508 - top_20_categorical_accuracy_cp1: 0.7308 - top_20_categorical_accuracy_cp2: 0.9792 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1304 - top_20_categorical_accuracy_p2: 0.0784 - top_20_categorical_accuracy_p3: 0.1269 - top_20_categorical_accuracy_p4: 0.8715        5/7 [====================>.........] - ETA: 0s - loss: 0.1825 - categorical_accuracy: 0.1561 - top_5_categorical_accuracy: 0.5347 - top_10_categorical_accuracy: 0.6858 - top_20_categorical_accuracy: 0.7818 - top_5_categorical_accuracy_cp0: 0.0020 - top_5_categorical_accuracy_cp1: 0.0303 - top_5_categorical_accuracy_cp2: 0.5182 - top_5_categorical_accuracy_cp3: 0.9946 - top_5_categorical_accuracy_cp4: 0.9984 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0048 - top_5_categorical_accuracy_p4: 0.6100 - top_10_categorical_accuracy_cp0: 0.0275 - top_10_categorical_accuracy_cp1: 0.4337 - top_10_categorical_accuracy_cp2: 0.9246 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0240 - top_10_categorical_accuracy_p4: 0.7809 - top_20_categorical_accuracy_cp0: 0.1591 - top_20_categorical_accuracy_cp1: 0.7348 - top_20_categorical_accuracy_cp2: 0.9878 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1034 - top_20_categorical_accuracy_p2: 0.0533 - top_20_categorical_accuracy_p3: 0.1442 - top_20_categorical_accuracy_p4: 0.87657/7 [==============================] - ETA: 0s - loss: 0.1806 - categorical_accuracy: 0.1516 - top_5_categorical_accuracy: 0.5336 - top_10_categorical_accuracy: 0.6877 - top_20_categorical_accuracy: 0.7850 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.0291 - top_5_categorical_accuracy_cp2: 0.5288 - top_5_categorical_accuracy_cp3: 0.9926 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.6077 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.4511 - top_10_categorical_accuracy_cp2: 0.9259 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7811 - top_20_categorical_accuracy_cp0: 0.1524 - top_20_categorical_accuracy_cp1: 0.7599 - top_20_categorical_accuracy_cp2: 0.9897 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1333 - top_20_categorical_accuracy_p4: 0.8798DEBUG:root:Model metric val_loss improved from 0.195332 to 0.188547
7/7 [==============================] - 1s 111ms/step - loss: 0.1806 - categorical_accuracy: 0.1516 - top_5_categorical_accuracy: 0.5336 - top_10_categorical_accuracy: 0.6877 - top_20_categorical_accuracy: 0.7850 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.0291 - top_5_categorical_accuracy_cp2: 0.5288 - top_5_categorical_accuracy_cp3: 0.9926 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.6077 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.4511 - top_10_categorical_accuracy_cp2: 0.9259 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7811 - top_20_categorical_accuracy_cp0: 0.1524 - top_20_categorical_accuracy_cp1: 0.7599 - top_20_categorical_accuracy_cp2: 0.9897 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1333 - top_20_categorical_accuracy_p4: 0.8798 - val_loss: 0.1885 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1546 - categorical_accuracy: 0.1426 - top_5_categorical_accuracy: 0.5589 - top_10_categorical_accuracy: 0.7129 - top_20_categorical_accuracy: 0.7947 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0198 - top_5_categorical_accuracy_cp2: 0.5595 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6269 - top_10_categorical_accuracy_cp0: 0.0104 - top_10_categorical_accuracy_cp1: 0.4653 - top_10_categorical_accuracy_cp2: 0.9762 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7996 - top_20_categorical_accuracy_cp0: 0.1875 - top_20_categorical_accuracy_cp1: 0.7030 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1351 - top_20_categorical_accuracy_p4: 0.87853/7 [===========>..................] - ETA: 0s - loss: 0.1492 - categorical_accuracy: 0.1206 - top_5_categorical_accuracy: 0.5206 - top_10_categorical_accuracy: 0.6883 - top_20_categorical_accuracy: 0.7867 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0214 - top_5_categorical_accuracy_cp2: 0.5041 - top_5_categorical_accuracy_cp3: 0.9940 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5942 - top_10_categorical_accuracy_cp0: 0.0096 - top_10_categorical_accuracy_cp1: 0.4618 - top_10_categorical_accuracy_cp2: 0.9715 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0079 - top_10_categorical_accuracy_p4: 0.7848 - top_20_categorical_accuracy_cp0: 0.1640 - top_20_categorical_accuracy_cp1: 0.7676 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0500 - top_20_categorical_accuracy_p2: 0.0952 - top_20_categorical_accuracy_p3: 0.1032 - top_20_categorical_accuracy_p4: 0.8848        5/7 [====================>.........] - ETA: 0s - loss: 0.1460 - categorical_accuracy: 0.1200 - top_5_categorical_accuracy: 0.5263 - top_10_categorical_accuracy: 0.7020 - top_20_categorical_accuracy: 0.7969 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0239 - top_5_categorical_accuracy_cp2: 0.5050 - top_5_categorical_accuracy_cp3: 0.9802 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5976 - top_10_categorical_accuracy_cp0: 0.0080 - top_10_categorical_accuracy_cp1: 0.5009 - top_10_categorical_accuracy_cp2: 0.9724 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0100 - top_10_categorical_accuracy_p4: 0.7962 - top_20_categorical_accuracy_cp0: 0.1531 - top_20_categorical_accuracy_cp1: 0.8037 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0645 - top_20_categorical_accuracy_p2: 0.0580 - top_20_categorical_accuracy_p3: 0.1194 - top_20_categorical_accuracy_p4: 0.89187/7 [==============================] - ETA: 0s - loss: 0.1464 - categorical_accuracy: 0.1208 - top_5_categorical_accuracy: 0.5251 - top_10_categorical_accuracy: 0.6996 - top_20_categorical_accuracy: 0.7985 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0229 - top_5_categorical_accuracy_cp2: 0.5041 - top_5_categorical_accuracy_cp3: 0.9778 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5984 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.4939 - top_10_categorical_accuracy_cp2: 0.9733 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7965 - top_20_categorical_accuracy_cp0: 0.1524 - top_20_categorical_accuracy_cp1: 0.8180 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.1255 - top_20_categorical_accuracy_p4: 0.8959DEBUG:root:Model metric val_loss improved from 0.188547 to 0.184722
7/7 [==============================] - 1s 116ms/step - loss: 0.1464 - categorical_accuracy: 0.1208 - top_5_categorical_accuracy: 0.5251 - top_10_categorical_accuracy: 0.6996 - top_20_categorical_accuracy: 0.7985 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0229 - top_5_categorical_accuracy_cp2: 0.5041 - top_5_categorical_accuracy_cp3: 0.9778 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5984 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.4939 - top_10_categorical_accuracy_cp2: 0.9733 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7965 - top_20_categorical_accuracy_cp0: 0.1524 - top_20_categorical_accuracy_cp1: 0.8180 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.1255 - top_20_categorical_accuracy_p4: 0.8959 - val_loss: 0.1847 - val_categorical_accuracy: 0.0085 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1315 - categorical_accuracy: 0.1360 - top_5_categorical_accuracy: 0.5766 - top_10_categorical_accuracy: 0.7280 - top_20_categorical_accuracy: 0.8391 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0449 - top_5_categorical_accuracy_cp2: 0.6176 - top_5_categorical_accuracy_cp3: 0.9464 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6501 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.4382 - top_10_categorical_accuracy_cp2: 0.9902 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8207 - top_20_categorical_accuracy_cp0: 0.1648 - top_20_categorical_accuracy_cp1: 0.9101 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1220 - top_20_categorical_accuracy_p4: 0.93523/7 [===========>..................] - ETA: 0s - loss: 0.1370 - categorical_accuracy: 0.1290 - top_5_categorical_accuracy: 0.5411 - top_10_categorical_accuracy: 0.6991 - top_20_categorical_accuracy: 0.8262 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0296 - top_5_categorical_accuracy_cp2: 0.6198 - top_5_categorical_accuracy_cp3: 0.9563 - top_5_categorical_accuracy_cp4: 0.9889 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6145 - top_10_categorical_accuracy_cp0: 0.0096 - top_10_categorical_accuracy_cp1: 0.4605 - top_10_categorical_accuracy_cp2: 0.9886 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0165 - top_10_categorical_accuracy_p4: 0.7925 - top_20_categorical_accuracy_cp0: 0.1923 - top_20_categorical_accuracy_cp1: 0.9243 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1322 - top_20_categorical_accuracy_p4: 0.9268        5/7 [====================>.........] - ETA: 0s - loss: 0.1354 - categorical_accuracy: 0.1315 - top_5_categorical_accuracy: 0.5438 - top_10_categorical_accuracy: 0.7100 - top_20_categorical_accuracy: 0.8415 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0245 - top_5_categorical_accuracy_cp2: 0.6570 - top_5_categorical_accuracy_cp3: 0.9585 - top_5_categorical_accuracy_cp4: 0.9823 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6194 - top_10_categorical_accuracy_cp0: 0.0119 - top_10_categorical_accuracy_cp1: 0.5085 - top_10_categorical_accuracy_cp2: 0.9928 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0191 - top_10_categorical_accuracy_p4: 0.8069 - top_20_categorical_accuracy_cp0: 0.2286 - top_20_categorical_accuracy_cp1: 0.9473 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1818 - top_20_categorical_accuracy_p4: 0.94187/7 [==============================] - ETA: 0s - loss: 0.1356 - categorical_accuracy: 0.1378 - top_5_categorical_accuracy: 0.5414 - top_10_categorical_accuracy: 0.7078 - top_20_categorical_accuracy: 0.8424 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0229 - top_5_categorical_accuracy_cp2: 0.6790 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9748 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6170 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5153 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8051 - top_20_categorical_accuracy_cp0: 0.2334 - top_20_categorical_accuracy_cp1: 0.9557 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9438DEBUG:root:Model metric val_loss improved from 0.184722 to 0.177542
7/7 [==============================] - 1s 113ms/step - loss: 0.1356 - categorical_accuracy: 0.1378 - top_5_categorical_accuracy: 0.5414 - top_10_categorical_accuracy: 0.7078 - top_20_categorical_accuracy: 0.8424 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0229 - top_5_categorical_accuracy_cp2: 0.6790 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9748 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6170 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5153 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8051 - top_20_categorical_accuracy_cp0: 0.2334 - top_20_categorical_accuracy_cp1: 0.9557 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9438 - val_loss: 0.1775 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3296 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1014 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6031 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.1654 - top_5_categorical_accuracy: 0.5513 - top_10_categorical_accuracy: 0.7338 - top_20_categorical_accuracy: 0.8631 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0862 - top_5_categorical_accuracy_cp2: 0.7922 - top_5_categorical_accuracy_cp3: 0.9815 - top_5_categorical_accuracy_cp4: 0.8828 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6210 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.6293 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8266 - top_20_categorical_accuracy_cp0: 0.2784 - top_20_categorical_accuracy_cp1: 0.9828 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1579 - top_20_categorical_accuracy_p4: 0.95933/7 [===========>..................] - ETA: 0s - loss: 0.1354 - categorical_accuracy: 0.1749 - top_5_categorical_accuracy: 0.5482 - top_10_categorical_accuracy: 0.7091 - top_20_categorical_accuracy: 0.8498 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0929 - top_5_categorical_accuracy_cp2: 0.8051 - top_5_categorical_accuracy_cp3: 0.9759 - top_5_categorical_accuracy_cp4: 0.8966 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6314 - top_10_categorical_accuracy_cp0: 0.0030 - top_10_categorical_accuracy_cp1: 0.5944 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0074 - top_10_categorical_accuracy_p4: 0.8161 - top_20_categorical_accuracy_cp0: 0.2948 - top_20_categorical_accuracy_cp1: 0.9845 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0200 - top_20_categorical_accuracy_p3: 0.1912 - top_20_categorical_accuracy_p4: 0.9591            5/7 [====================>.........] - ETA: 0s - loss: 0.1332 - categorical_accuracy: 0.1769 - top_5_categorical_accuracy: 0.5559 - top_10_categorical_accuracy: 0.7184 - top_20_categorical_accuracy: 0.8558 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0961 - top_5_categorical_accuracy_cp2: 0.7837 - top_5_categorical_accuracy_cp3: 0.9716 - top_5_categorical_accuracy_cp4: 0.9125 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6369 - top_10_categorical_accuracy_cp0: 0.0057 - top_10_categorical_accuracy_cp1: 0.5970 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9983 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0094 - top_10_categorical_accuracy_p4: 0.8221 - top_20_categorical_accuracy_cp0: 0.2920 - top_20_categorical_accuracy_cp1: 0.9852 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0122 - top_20_categorical_accuracy_p3: 0.1925 - top_20_categorical_accuracy_p4: 0.96217/7 [==============================] - ETA: 0s - loss: 0.1320 - categorical_accuracy: 0.1748 - top_5_categorical_accuracy: 0.5643 - top_10_categorical_accuracy: 0.7250 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1009 - top_5_categorical_accuracy_cp2: 0.7819 - top_5_categorical_accuracy_cp3: 0.9734 - top_5_categorical_accuracy_cp4: 0.9216 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6431 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.6024 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8255 - top_20_categorical_accuracy_cp0: 0.2934 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.9628DEBUG:root:Model metric val_loss improved from 0.177542 to 0.172543
7/7 [==============================] - 1s 110ms/step - loss: 0.1320 - categorical_accuracy: 0.1748 - top_5_categorical_accuracy: 0.5643 - top_10_categorical_accuracy: 0.7250 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1009 - top_5_categorical_accuracy_cp2: 0.7819 - top_5_categorical_accuracy_cp3: 0.9734 - top_5_categorical_accuracy_cp4: 0.9216 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6431 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.6024 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8255 - top_20_categorical_accuracy_cp0: 0.2934 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.9628 - val_loss: 0.1725 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2620 - val_top_10_categorical_accuracy: 0.3183 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2917 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4794 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0435 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5825 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.1733 - top_5_categorical_accuracy: 0.5273 - top_10_categorical_accuracy: 0.7024 - top_20_categorical_accuracy: 0.8512 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1339 - top_5_categorical_accuracy_cp2: 0.7258 - top_5_categorical_accuracy_cp3: 0.9649 - top_5_categorical_accuracy_cp4: 0.9474 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5970 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.6457 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0244 - top_10_categorical_accuracy_p4: 0.7932 - top_20_categorical_accuracy_cp0: 0.3421 - top_20_categorical_accuracy_cp1: 0.9685 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2439 - top_20_categorical_accuracy_p4: 0.94243/7 [===========>..................] - ETA: 0s - loss: 0.1277 - categorical_accuracy: 0.1747 - top_5_categorical_accuracy: 0.5646 - top_10_categorical_accuracy: 0.7247 - top_20_categorical_accuracy: 0.8658 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1265 - top_5_categorical_accuracy_cp2: 0.7336 - top_5_categorical_accuracy_cp3: 0.9703 - top_5_categorical_accuracy_cp4: 0.9699 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6371 - top_10_categorical_accuracy_cp0: 0.0129 - top_10_categorical_accuracy_cp1: 0.6294 - top_10_categorical_accuracy_cp2: 0.9825 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0263 - top_10_categorical_accuracy_p4: 0.8157 - top_20_categorical_accuracy_cp0: 0.3495 - top_20_categorical_accuracy_cp1: 0.9676 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2193 - top_20_categorical_accuracy_p4: 0.95935/7 [====================>.........] - ETA: 0s - loss: 0.1262 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.5744 - top_10_categorical_accuracy: 0.7324 - top_20_categorical_accuracy: 0.8668 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1347 - top_5_categorical_accuracy_cp2: 0.7074 - top_5_categorical_accuracy_cp3: 0.9749 - top_5_categorical_accuracy_cp4: 0.9793 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6535 - top_10_categorical_accuracy_cp0: 0.0079 - top_10_categorical_accuracy_cp1: 0.6402 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0143 - top_10_categorical_accuracy_p4: 0.8320 - top_20_categorical_accuracy_cp0: 0.3353 - top_20_categorical_accuracy_cp1: 0.9760 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2095 - top_20_categorical_accuracy_p4: 0.96717/7 [==============================] - ETA: 0s - loss: 0.1263 - categorical_accuracy: 0.1824 - top_5_categorical_accuracy: 0.5738 - top_10_categorical_accuracy: 0.7294 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1407 - top_5_categorical_accuracy_cp2: 0.6934 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9814 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6538 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.6269 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8301 - top_20_categorical_accuracy_cp0: 0.3290 - top_20_categorical_accuracy_cp1: 0.9755 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.9667DEBUG:root:Model metric val_loss improved from 0.172543 to 0.169445
7/7 [==============================] - 1s 114ms/step - loss: 0.1263 - categorical_accuracy: 0.1824 - top_5_categorical_accuracy: 0.5738 - top_10_categorical_accuracy: 0.7294 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1407 - top_5_categorical_accuracy_cp2: 0.6934 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9814 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6538 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.6269 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8301 - top_20_categorical_accuracy_cp0: 0.3290 - top_20_categorical_accuracy_cp1: 0.9755 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2078 - top_20_categorical_accuracy_p4: 0.9667 - val_loss: 0.1694 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3099 - val_top_10_categorical_accuracy: 0.3408 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5670 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1594 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6237 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.6195 - top_10_categorical_accuracy: 0.7380 - top_20_categorical_accuracy: 0.8738 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1827 - top_5_categorical_accuracy_cp2: 0.7931 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7013 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.5673 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8355 - top_20_categorical_accuracy_cp0: 0.3261 - top_20_categorical_accuracy_cp1: 0.9615 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1702 - top_20_categorical_accuracy_p4: 0.97193/7 [===========>..................] - ETA: 0s - loss: 0.1216 - categorical_accuracy: 0.2125 - top_5_categorical_accuracy: 0.6279 - top_10_categorical_accuracy: 0.7455 - top_20_categorical_accuracy: 0.8601 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2075 - top_5_categorical_accuracy_cp2: 0.8240 - top_5_categorical_accuracy_cp3: 0.9879 - top_5_categorical_accuracy_cp4: 0.9769 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7199 - top_10_categorical_accuracy_cp0: 0.0068 - top_10_categorical_accuracy_cp1: 0.6361 - top_10_categorical_accuracy_cp2: 0.9888 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0071 - top_10_categorical_accuracy_p4: 0.8541 - top_20_categorical_accuracy_cp0: 0.2637 - top_20_categorical_accuracy_cp1: 0.9830 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1286 - top_20_categorical_accuracy_p4: 0.9730        5/7 [====================>.........] - ETA: 0s - loss: 0.1231 - categorical_accuracy: 0.2120 - top_5_categorical_accuracy: 0.6178 - top_10_categorical_accuracy: 0.7423 - top_20_categorical_accuracy: 0.8633 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2377 - top_5_categorical_accuracy_cp2: 0.8345 - top_5_categorical_accuracy_cp3: 0.9838 - top_5_categorical_accuracy_cp4: 0.9775 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7057 - top_10_categorical_accuracy_cp0: 0.0138 - top_10_categorical_accuracy_cp1: 0.6774 - top_10_categorical_accuracy_cp2: 0.9903 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0094 - top_10_categorical_accuracy_p4: 0.8470 - top_20_categorical_accuracy_cp0: 0.3045 - top_20_categorical_accuracy_cp1: 0.9906 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1549 - top_20_categorical_accuracy_p4: 0.97177/7 [==============================] - ETA: 0s - loss: 0.1227 - categorical_accuracy: 0.2119 - top_5_categorical_accuracy: 0.6180 - top_10_categorical_accuracy: 0.7426 - top_20_categorical_accuracy: 0.8672 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2508 - top_5_categorical_accuracy_cp2: 0.8395 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7042 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.6804 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8444 - top_20_categorical_accuracy_cp0: 0.3290 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9721DEBUG:root:Model metric val_loss improved from 0.169445 to 0.163213
7/7 [==============================] - 1s 111ms/step - loss: 0.1227 - categorical_accuracy: 0.2119 - top_5_categorical_accuracy: 0.6180 - top_10_categorical_accuracy: 0.7426 - top_20_categorical_accuracy: 0.8672 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2508 - top_5_categorical_accuracy_cp2: 0.8395 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9734 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7042 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.6804 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8444 - top_20_categorical_accuracy_cp0: 0.3290 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9721 - val_loss: 0.1632 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2930 - val_top_10_categorical_accuracy: 0.5014 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5361 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9855 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9175 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1266 - categorical_accuracy: 0.2060 - top_5_categorical_accuracy: 0.5974 - top_10_categorical_accuracy: 0.7353 - top_20_categorical_accuracy: 0.8563 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3644 - top_5_categorical_accuracy_cp2: 0.8608 - top_5_categorical_accuracy_cp3: 0.9810 - top_5_categorical_accuracy_cp4: 0.9444 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6945 - top_10_categorical_accuracy_cp0: 0.0756 - top_10_categorical_accuracy_cp1: 0.7797 - top_10_categorical_accuracy_cp2: 0.9620 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9907 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8527 - top_20_categorical_accuracy_cp0: 0.3782 - top_20_categorical_accuracy_cp1: 0.9831 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.97363/7 [===========>..................] - ETA: 0s - loss: 0.1220 - categorical_accuracy: 0.2079 - top_5_categorical_accuracy: 0.6217 - top_10_categorical_accuracy: 0.7611 - top_20_categorical_accuracy: 0.8701 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.3413 - top_5_categorical_accuracy_cp2: 0.8320 - top_5_categorical_accuracy_cp3: 0.9848 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7104 - top_10_categorical_accuracy_cp0: 0.0889 - top_10_categorical_accuracy_cp1: 0.7725 - top_10_categorical_accuracy_cp2: 0.9672 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9831 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0417 - top_10_categorical_accuracy_p4: 0.8660 - top_20_categorical_accuracy_cp0: 0.3651 - top_20_categorical_accuracy_cp1: 0.9850 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2167 - top_20_categorical_accuracy_p4: 0.9754    5/7 [====================>.........] - ETA: 0s - loss: 0.1208 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6346 - top_10_categorical_accuracy: 0.7726 - top_20_categorical_accuracy: 0.8753 - top_5_categorical_accuracy_cp0: 0.0039 - top_5_categorical_accuracy_cp1: 0.3780 - top_5_categorical_accuracy_cp2: 0.8346 - top_5_categorical_accuracy_cp3: 0.9767 - top_5_categorical_accuracy_cp4: 0.9510 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7247 - top_10_categorical_accuracy_cp0: 0.0932 - top_10_categorical_accuracy_cp1: 0.7982 - top_10_categorical_accuracy_cp2: 0.9724 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 0.9853 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0476 - top_10_categorical_accuracy_p4: 0.8780 - top_20_categorical_accuracy_cp0: 0.3786 - top_20_categorical_accuracy_cp1: 0.9872 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2476 - top_20_categorical_accuracy_p4: 0.97707/7 [==============================] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.2084 - top_5_categorical_accuracy: 0.6390 - top_10_categorical_accuracy: 0.7753 - top_20_categorical_accuracy: 0.8776 - top_5_categorical_accuracy_cp0: 0.0081 - top_5_categorical_accuracy_cp1: 0.3746 - top_5_categorical_accuracy_cp2: 0.8498 - top_5_categorical_accuracy_cp3: 0.9734 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7278 - top_10_categorical_accuracy_cp0: 0.0972 - top_10_categorical_accuracy_cp1: 0.7997 - top_10_categorical_accuracy_cp2: 0.9712 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0510 - top_10_categorical_accuracy_p4: 0.8788 - top_20_categorical_accuracy_cp0: 0.3890 - top_20_categorical_accuracy_cp1: 0.9832 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9775    DEBUG:root:Model metric val_loss improved from 0.163213 to 0.162526
7/7 [==============================] - 1s 112ms/step - loss: 0.1199 - categorical_accuracy: 0.2084 - top_5_categorical_accuracy: 0.6390 - top_10_categorical_accuracy: 0.7753 - top_20_categorical_accuracy: 0.8776 - top_5_categorical_accuracy_cp0: 0.0081 - top_5_categorical_accuracy_cp1: 0.3746 - top_5_categorical_accuracy_cp2: 0.8498 - top_5_categorical_accuracy_cp3: 0.9734 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7278 - top_10_categorical_accuracy_cp0: 0.0972 - top_10_categorical_accuracy_cp1: 0.7997 - top_10_categorical_accuracy_cp2: 0.9712 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0510 - top_10_categorical_accuracy_p4: 0.8788 - top_20_categorical_accuracy_cp0: 0.3890 - top_20_categorical_accuracy_cp1: 0.9832 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9775 - val_loss: 0.1625 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3324 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6082 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0323 - val_top_20_categorical_accuracy_p4: 0.9639
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.1985 - top_5_categorical_accuracy: 0.6333 - top_10_categorical_accuracy: 0.7694 - top_20_categorical_accuracy: 0.8885 - top_5_categorical_accuracy_cp0: 0.0090 - top_5_categorical_accuracy_cp1: 0.4732 - top_5_categorical_accuracy_cp2: 0.8519 - top_5_categorical_accuracy_cp3: 0.9381 - top_5_categorical_accuracy_cp4: 0.9464 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7220 - top_10_categorical_accuracy_cp0: 0.1892 - top_10_categorical_accuracy_cp1: 0.8304 - top_10_categorical_accuracy_cp2: 0.9383 - top_10_categorical_accuracy_cp3: 0.9735 - top_10_categorical_accuracy_cp4: 0.9554 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.8685 - top_20_categorical_accuracy_cp0: 0.5045 - top_20_categorical_accuracy_cp1: 0.9732 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2619 - top_20_categorical_accuracy_p4: 0.98923/7 [===========>..................] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.2044 - top_5_categorical_accuracy: 0.6397 - top_10_categorical_accuracy: 0.7779 - top_20_categorical_accuracy: 0.8852 - top_5_categorical_accuracy_cp0: 0.0278 - top_5_categorical_accuracy_cp1: 0.4576 - top_5_categorical_accuracy_cp2: 0.8478 - top_5_categorical_accuracy_cp3: 0.9529 - top_5_categorical_accuracy_cp4: 0.9280 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7295 - top_10_categorical_accuracy_cp0: 0.1852 - top_10_categorical_accuracy_cp1: 0.8333 - top_10_categorical_accuracy_cp2: 0.9609 - top_10_categorical_accuracy_cp3: 0.9794 - top_10_categorical_accuracy_cp4: 0.9529 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0992 - top_10_categorical_accuracy_p4: 0.8777 - top_20_categorical_accuracy_cp0: 0.4784 - top_20_categorical_accuracy_cp1: 0.9727 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9889 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2443 - top_20_categorical_accuracy_p4: 0.98635/7 [====================>.........] - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.2038 - top_5_categorical_accuracy: 0.6498 - top_10_categorical_accuracy: 0.7878 - top_20_categorical_accuracy: 0.8882 - top_5_categorical_accuracy_cp0: 0.0292 - top_5_categorical_accuracy_cp1: 0.4459 - top_5_categorical_accuracy_cp2: 0.8438 - top_5_categorical_accuracy_cp3: 0.9585 - top_5_categorical_accuracy_cp4: 0.9420 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7414 - top_10_categorical_accuracy_cp0: 0.1871 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9521 - top_10_categorical_accuracy_cp3: 0.9838 - top_10_categorical_accuracy_cp4: 0.9630 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1168 - top_10_categorical_accuracy_p4: 0.8881 - top_20_categorical_accuracy_cp0: 0.4659 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2804 - top_20_categorical_accuracy_p4: 0.98747/7 [==============================] - ETA: 0s - loss: 0.1178 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6513 - top_10_categorical_accuracy: 0.7910 - top_20_categorical_accuracy: 0.8911 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4419 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9482 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7421 - top_10_categorical_accuracy_cp0: 0.1896 - top_10_categorical_accuracy_cp1: 0.8410 - top_10_categorical_accuracy_cp2: 0.9547 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9655 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1255 - top_10_categorical_accuracy_p4: 0.8898 - top_20_categorical_accuracy_cp0: 0.4749 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3020 - top_20_categorical_accuracy_p4: 0.98787/7 [==============================] - 1s 111ms/step - loss: 0.1178 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6513 - top_10_categorical_accuracy: 0.7910 - top_20_categorical_accuracy: 0.8911 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4419 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9482 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7421 - top_10_categorical_accuracy_cp0: 0.1896 - top_10_categorical_accuracy_cp1: 0.8410 - top_10_categorical_accuracy_cp2: 0.9547 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9655 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1255 - top_10_categorical_accuracy_p4: 0.8898 - top_20_categorical_accuracy_cp0: 0.4749 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3020 - top_20_categorical_accuracy_p4: 0.9878 - val_loss: 0.1633 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3523 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9794
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.1981 - top_5_categorical_accuracy: 0.6743 - top_10_categorical_accuracy: 0.8133 - top_20_categorical_accuracy: 0.9238 - top_5_categorical_accuracy_cp0: 0.0120 - top_5_categorical_accuracy_cp1: 0.4561 - top_5_categorical_accuracy_cp2: 0.8077 - top_5_categorical_accuracy_cp3: 0.9469 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7453 - top_10_categorical_accuracy_cp0: 0.1566 - top_10_categorical_accuracy_cp1: 0.8947 - top_10_categorical_accuracy_cp2: 0.9359 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9562 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1389 - top_10_categorical_accuracy_p4: 0.8884 - top_20_categorical_accuracy_cp0: 0.5542 - top_20_categorical_accuracy_cp1: 0.9737 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3889 - top_20_categorical_accuracy_p4: 0.99163/7 [===========>..................] - ETA: 0s - loss: 0.1171 - categorical_accuracy: 0.1958 - top_5_categorical_accuracy: 0.6521 - top_10_categorical_accuracy: 0.7928 - top_20_categorical_accuracy: 0.9043 - top_5_categorical_accuracy_cp0: 0.0199 - top_5_categorical_accuracy_cp1: 0.4639 - top_5_categorical_accuracy_cp2: 0.8158 - top_5_categorical_accuracy_cp3: 0.9444 - top_5_categorical_accuracy_cp4: 0.9626 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7414 - top_10_categorical_accuracy_cp0: 0.1821 - top_10_categorical_accuracy_cp1: 0.8614 - top_10_categorical_accuracy_cp2: 0.9474 - top_10_categorical_accuracy_cp3: 0.9649 - top_10_categorical_accuracy_cp4: 0.9733 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1240 - top_10_categorical_accuracy_p4: 0.8898 - top_20_categorical_accuracy_cp0: 0.5430 - top_20_categorical_accuracy_cp1: 0.9699 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9942 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4109 - top_20_categorical_accuracy_p4: 0.98995/7 [====================>.........] - ETA: 0s - loss: 0.1173 - categorical_accuracy: 0.1971 - top_5_categorical_accuracy: 0.6469 - top_10_categorical_accuracy: 0.7949 - top_20_categorical_accuracy: 0.9007 - top_5_categorical_accuracy_cp0: 0.0139 - top_5_categorical_accuracy_cp1: 0.4577 - top_5_categorical_accuracy_cp2: 0.8117 - top_5_categorical_accuracy_cp3: 0.9394 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7366 - top_10_categorical_accuracy_cp0: 0.2012 - top_10_categorical_accuracy_cp1: 0.8695 - top_10_categorical_accuracy_cp2: 0.9338 - top_10_categorical_accuracy_cp3: 0.9643 - top_10_categorical_accuracy_cp4: 0.9666 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1462 - top_10_categorical_accuracy_p4: 0.8917 - top_20_categorical_accuracy_cp0: 0.5359 - top_20_categorical_accuracy_cp1: 0.9651 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9947 - top_20_categorical_accuracy_cp4: 0.9904 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4198 - top_20_categorical_accuracy_p4: 0.98707/7 [==============================] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.1965 - top_5_categorical_accuracy: 0.6444 - top_10_categorical_accuracy: 0.7928 - top_20_categorical_accuracy: 0.8983 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.4541 - top_5_categorical_accuracy_cp2: 0.8107 - top_5_categorical_accuracy_cp3: 0.9438 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7343 - top_10_categorical_accuracy_cp0: 0.2075 - top_10_categorical_accuracy_cp1: 0.8654 - top_10_categorical_accuracy_cp2: 0.9362 - top_10_categorical_accuracy_cp3: 0.9675 - top_10_categorical_accuracy_cp4: 0.9602 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8902 - top_20_categorical_accuracy_cp0: 0.5332 - top_20_categorical_accuracy_cp1: 0.9648 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9867 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4078 - top_20_categorical_accuracy_p4: 0.98647/7 [==============================] - 1s 112ms/step - loss: 0.1175 - categorical_accuracy: 0.1965 - top_5_categorical_accuracy: 0.6444 - top_10_categorical_accuracy: 0.7928 - top_20_categorical_accuracy: 0.8983 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.4541 - top_5_categorical_accuracy_cp2: 0.8107 - top_5_categorical_accuracy_cp3: 0.9438 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7343 - top_10_categorical_accuracy_cp0: 0.2075 - top_10_categorical_accuracy_cp1: 0.8654 - top_10_categorical_accuracy_cp2: 0.9362 - top_10_categorical_accuracy_cp3: 0.9675 - top_10_categorical_accuracy_cp4: 0.9602 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.8902 - top_20_categorical_accuracy_cp0: 0.5332 - top_20_categorical_accuracy_cp1: 0.9648 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9867 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4078 - top_20_categorical_accuracy_p4: 0.9864 - val_loss: 0.1626 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6789 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3580 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9845
INFO:root:Restoring best model weights with val_loss: 0.162526 from epoch 7
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.14it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1657.45it/s]
INFO:root:Finished run 235d27e6e22d4e6590d93396f7925255
2023-05-24 20:17:58.520996: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:17:59.031337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:17:59.031397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:17:59.031403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 0664b8f19ce34f10b8d6dfdebba19475
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12171.09it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13203.93it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13066.24it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24132.93it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:18:01.343673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.343862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.344636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.344781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.344912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.345047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.345431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:18:01.482285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.482506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.482667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.482803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.482932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:01.483062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.047757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:18:03.048107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:18:03.048213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12735.92it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13397.65it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13187.30it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24528.09it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 30/154 [00:00<00:00, 290.23it/s]Loading hierarchy for column coarse_log_cluster_path:  39%|███▉      | 60/154 [00:00<00:00, 289.69it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 90/154 [00:00<00:00, 290.80it/s]Loading hierarchy for column coarse_log_cluster_path:  78%|███████▊  | 120/154 [00:00<00:00, 291.56it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 150/154 [00:00<00:00, 292.62it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 291.63it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:52,  7.66it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5173.99it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1338it [00:00, 40316.81it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/174 [00:00<?, ?it/s]Initializing gram_embedding connections:  47%|████▋     | 82/174 [00:00<00:00, 812.32it/s]Initializing gram_embedding connections:  94%|█████████▍| 164/174 [00:00<00:00, 386.65it/s]Initializing gram_embedding connections: 100%|██████████| 174/174 [00:00<00:00, 396.28it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.09it/s]Calculating percentile frequencies...: 7it [00:00,  7.59it/s]
2023-05-24 20:18:07.563612: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:18:40.042585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:18:40.602244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:18:40.715355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:18:41.115022: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f2eac012dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:18:41.115049: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:18:41.115055: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:18:41.119425: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:18:41.205291: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1928 - categorical_accuracy: 0.0057 - top_5_categorical_accuracy: 0.0479 - top_10_categorical_accuracy: 0.1149 - top_20_categorical_accuracy: 0.1935 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.1010 - top_5_categorical_accuracy_cp2: 0.0952 - top_5_categorical_accuracy_cp3: 0.0085 - top_5_categorical_accuracy_cp4: 0.0164 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.1250 - top_5_categorical_accuracy_p3: 0.0513 - top_5_categorical_accuracy_p4: 0.0458 - top_10_categorical_accuracy_cp0: 0.1414 - top_10_categorical_accuracy_cp1: 0.1616 - top_10_categorical_accuracy_cp2: 0.1905 - top_10_categorical_accuracy_cp3: 0.0678 - top_10_categorical_accuracy_cp4: 0.0492 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1667 - top_10_categorical_accuracy_p2: 0.3125 - top_10_categorical_accuracy_p3: 0.1282 - top_10_categorical_accuracy_p4: 0.1068 - top_20_categorical_accuracy_cp0: 0.2727 - top_20_categorical_accuracy_cp1: 0.2323 - top_20_categorical_accuracy_cp2: 0.2619 - top_20_categorical_accuracy_cp3: 0.1525 - top_20_categorical_accuracy_cp4: 0.0902 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1667 - top_20_categorical_accuracy_p2: 0.5000 - top_20_categorical_accuracy_p3: 0.3077 - top_20_categorical_accuracy_p4: 0.1743      3/Unknown - 34s 34ms/step - loss: 0.1931 - categorical_accuracy: 0.0502 - top_5_categorical_accuracy: 0.2003 - top_10_categorical_accuracy: 0.3198 - top_20_categorical_accuracy: 0.4539 - top_5_categorical_accuracy_cp0: 0.0341 - top_5_categorical_accuracy_cp1: 0.0769 - top_5_categorical_accuracy_cp2: 0.2594 - top_5_categorical_accuracy_cp3: 0.2538 - top_5_categorical_accuracy_cp4: 0.3481 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0455 - top_5_categorical_accuracy_p3: 0.0168 - top_5_categorical_accuracy_p4: 0.2241 - top_10_categorical_accuracy_cp0: 0.0887 - top_10_categorical_accuracy_cp1: 0.1723 - top_10_categorical_accuracy_cp2: 0.4226 - top_10_categorical_accuracy_cp3: 0.4290 - top_10_categorical_accuracy_cp4: 0.4623 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1250 - top_10_categorical_accuracy_p2: 0.1136 - top_10_categorical_accuracy_p3: 0.0672 - top_10_categorical_accuracy_p4: 0.3516 - top_20_categorical_accuracy_cp0: 0.1741 - top_20_categorical_accuracy_cp1: 0.3200 - top_20_categorical_accuracy_cp2: 0.5732 - top_20_categorical_accuracy_cp3: 0.5740 - top_20_categorical_accuracy_cp4: 0.6026 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1875 - top_20_categorical_accuracy_p2: 0.2727 - top_20_categorical_accuracy_p3: 0.1345 - top_20_categorical_accuracy_p4: 0.4921      5/Unknown - 34s 35ms/step - loss: 0.1932 - categorical_accuracy: 0.0908 - top_5_categorical_accuracy: 0.3280 - top_10_categorical_accuracy: 0.4405 - top_20_categorical_accuracy: 0.5572 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.1071 - top_5_categorical_accuracy_cp2: 0.4204 - top_5_categorical_accuracy_cp3: 0.5000 - top_5_categorical_accuracy_cp4: 0.5710 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0270 - top_5_categorical_accuracy_p3: 0.0094 - top_5_categorical_accuracy_p4: 0.3733 - top_10_categorical_accuracy_cp0: 0.0576 - top_10_categorical_accuracy_cp1: 0.2359 - top_10_categorical_accuracy_cp2: 0.5953 - top_10_categorical_accuracy_cp3: 0.6475 - top_10_categorical_accuracy_cp4: 0.6629 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0690 - top_10_categorical_accuracy_p2: 0.0811 - top_10_categorical_accuracy_p3: 0.0376 - top_10_categorical_accuracy_p4: 0.4967 - top_20_categorical_accuracy_cp0: 0.1420 - top_20_categorical_accuracy_cp1: 0.4247 - top_20_categorical_accuracy_cp2: 0.7258 - top_20_categorical_accuracy_cp3: 0.7428 - top_20_categorical_accuracy_cp4: 0.7532 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1379 - top_20_categorical_accuracy_p2: 0.2027 - top_20_categorical_accuracy_p3: 0.1080 - top_20_categorical_accuracy_p4: 0.6189      7/Unknown - 34s 34ms/step - loss: 0.1926 - categorical_accuracy: 0.1051 - top_5_categorical_accuracy: 0.3754 - top_10_categorical_accuracy: 0.4887 - top_20_categorical_accuracy: 0.5960 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.1055 - top_5_categorical_accuracy_cp2: 0.4959 - top_5_categorical_accuracy_cp3: 0.5769 - top_5_categorical_accuracy_cp4: 0.6441 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0235 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.4263 - top_10_categorical_accuracy_cp0: 0.0583 - top_10_categorical_accuracy_cp1: 0.2630 - top_10_categorical_accuracy_cp2: 0.6687 - top_10_categorical_accuracy_cp3: 0.7101 - top_10_categorical_accuracy_cp4: 0.7224 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0882 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.5501 - top_20_categorical_accuracy_cp0: 0.1442 - top_20_categorical_accuracy_cp1: 0.4572 - top_20_categorical_accuracy_cp2: 0.7778 - top_20_categorical_accuracy_cp3: 0.7885 - top_20_categorical_accuracy_cp4: 0.7968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1882 - top_20_categorical_accuracy_p3: 0.1059 - top_20_categorical_accuracy_p4: 0.66202023-05-24 20:18:42.196887: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195333
7/7 [==============================] - 53s 3s/step - loss: 0.1926 - categorical_accuracy: 0.1051 - top_5_categorical_accuracy: 0.3754 - top_10_categorical_accuracy: 0.4887 - top_20_categorical_accuracy: 0.5960 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.1055 - top_5_categorical_accuracy_cp2: 0.4959 - top_5_categorical_accuracy_cp3: 0.5769 - top_5_categorical_accuracy_cp4: 0.6441 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0235 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.4263 - top_10_categorical_accuracy_cp0: 0.0583 - top_10_categorical_accuracy_cp1: 0.2630 - top_10_categorical_accuracy_cp2: 0.6687 - top_10_categorical_accuracy_cp3: 0.7101 - top_10_categorical_accuracy_cp4: 0.7224 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0882 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.5501 - top_20_categorical_accuracy_cp0: 0.1442 - top_20_categorical_accuracy_cp1: 0.4572 - top_20_categorical_accuracy_cp2: 0.7778 - top_20_categorical_accuracy_cp3: 0.7885 - top_20_categorical_accuracy_cp4: 0.7968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1882 - top_20_categorical_accuracy_p3: 0.1059 - top_20_categorical_accuracy_p4: 0.6620 - val_loss: 0.1953 - val_categorical_accuracy: 0.2197 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.4113 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2029 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.0909 - val_top_20_categorical_accuracy_cp1: 0.2899 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0090 - val_top_20_categorical_accuracy_p4: 0.7474
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1892 - categorical_accuracy: 0.1594 - top_5_categorical_accuracy: 0.5655 - top_10_categorical_accuracy: 0.6888 - top_20_categorical_accuracy: 0.7837 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0631 - top_5_categorical_accuracy_cp2: 0.7662 - top_5_categorical_accuracy_cp3: 0.9487 - top_5_categorical_accuracy_cp4: 0.9680 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6395 - top_10_categorical_accuracy_cp0: 0.0103 - top_10_categorical_accuracy_cp1: 0.4234 - top_10_categorical_accuracy_cp2: 0.9610 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0625 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7768 - top_20_categorical_accuracy_cp0: 0.1237 - top_20_categorical_accuracy_cp1: 0.7387 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.0857 - top_20_categorical_accuracy_p4: 0.87553/7 [===========>..................] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.1447 - top_5_categorical_accuracy: 0.5412 - top_10_categorical_accuracy: 0.6720 - top_20_categorical_accuracy: 0.7671 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0577 - top_5_categorical_accuracy_cp2: 0.6667 - top_5_categorical_accuracy_cp3: 0.9531 - top_5_categorical_accuracy_cp4: 0.9777 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6263 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.4103 - top_10_categorical_accuracy_cp2: 0.9292 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0200 - top_10_categorical_accuracy_p3: 0.0301 - top_10_categorical_accuracy_p4: 0.7739 - top_20_categorical_accuracy_cp0: 0.1354 - top_20_categorical_accuracy_cp1: 0.7276 - top_20_categorical_accuracy_cp2: 0.9958 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0435 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.1053 - top_20_categorical_accuracy_p4: 0.8730        5/7 [====================>.........] - ETA: 0s - loss: 0.1847 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5522 - top_10_categorical_accuracy: 0.6893 - top_20_categorical_accuracy: 0.7875 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0417 - top_5_categorical_accuracy_cp2: 0.6788 - top_5_categorical_accuracy_cp3: 0.9658 - top_5_categorical_accuracy_cp4: 0.9839 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6304 - top_10_categorical_accuracy_cp0: 0.0236 - top_10_categorical_accuracy_cp1: 0.4356 - top_10_categorical_accuracy_cp2: 0.9513 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0135 - top_10_categorical_accuracy_p3: 0.0190 - top_10_categorical_accuracy_p4: 0.7848 - top_20_categorical_accuracy_cp0: 0.1532 - top_20_categorical_accuracy_cp1: 0.7614 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.0357 - top_20_categorical_accuracy_p2: 0.1081 - top_20_categorical_accuracy_p3: 0.1190 - top_20_categorical_accuracy_p4: 0.8835    7/7 [==============================] - ETA: 0s - loss: 0.1833 - categorical_accuracy: 0.1488 - top_5_categorical_accuracy: 0.5493 - top_10_categorical_accuracy: 0.6883 - top_20_categorical_accuracy: 0.7932 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0413 - top_5_categorical_accuracy_cp2: 0.6728 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6259 - top_10_categorical_accuracy_cp0: 0.0243 - top_10_categorical_accuracy_cp1: 0.4404 - top_10_categorical_accuracy_cp2: 0.9506 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.7822 - top_20_categorical_accuracy_cp0: 0.1653 - top_20_categorical_accuracy_cp1: 0.7813 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.1255 - top_20_categorical_accuracy_p4: 0.8877DEBUG:root:Model metric val_loss improved from 0.195333 to 0.187119
7/7 [==============================] - 1s 113ms/step - loss: 0.1833 - categorical_accuracy: 0.1488 - top_5_categorical_accuracy: 0.5493 - top_10_categorical_accuracy: 0.6883 - top_20_categorical_accuracy: 0.7932 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0413 - top_5_categorical_accuracy_cp2: 0.6728 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6259 - top_10_categorical_accuracy_cp0: 0.0243 - top_10_categorical_accuracy_cp1: 0.4404 - top_10_categorical_accuracy_cp2: 0.9506 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.7822 - top_20_categorical_accuracy_cp0: 0.1653 - top_20_categorical_accuracy_cp1: 0.7813 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.1255 - top_20_categorical_accuracy_p4: 0.8877 - val_loss: 0.1871 - val_categorical_accuracy: 0.0169 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3465 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1884 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6340 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1636 - categorical_accuracy: 0.1407 - top_5_categorical_accuracy: 0.5665 - top_10_categorical_accuracy: 0.7110 - top_20_categorical_accuracy: 0.8403 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0099 - top_5_categorical_accuracy_cp2: 0.6905 - top_5_categorical_accuracy_cp3: 0.9569 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6354 - top_10_categorical_accuracy_cp0: 0.0417 - top_10_categorical_accuracy_cp1: 0.4455 - top_10_categorical_accuracy_cp2: 0.9524 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0541 - top_10_categorical_accuracy_p4: 0.7932 - top_20_categorical_accuracy_cp0: 0.2396 - top_20_categorical_accuracy_cp1: 0.8911 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.3333 - top_20_categorical_accuracy_p2: 0.0769 - top_20_categorical_accuracy_p3: 0.2432 - top_20_categorical_accuracy_p4: 0.91903/7 [===========>..................] - ETA: 0s - loss: 0.1563 - categorical_accuracy: 0.1206 - top_5_categorical_accuracy: 0.5289 - top_10_categorical_accuracy: 0.6895 - top_20_categorical_accuracy: 0.8171 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0122 - top_5_categorical_accuracy_cp2: 0.5976 - top_5_categorical_accuracy_cp3: 0.9790 - top_5_categorical_accuracy_cp4: 0.9944 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6036 - top_10_categorical_accuracy_cp0: 0.0193 - top_10_categorical_accuracy_cp1: 0.4771 - top_10_categorical_accuracy_cp2: 0.9472 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0526 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0156 - top_10_categorical_accuracy_p4: 0.7848 - top_20_categorical_accuracy_cp0: 0.1672 - top_20_categorical_accuracy_cp1: 0.9174 - top_20_categorical_accuracy_cp2: 0.9919 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1053 - top_20_categorical_accuracy_p2: 0.0732 - top_20_categorical_accuracy_p3: 0.1484 - top_20_categorical_accuracy_p4: 0.9152    5/7 [====================>.........] - ETA: 0s - loss: 0.1502 - categorical_accuracy: 0.1185 - top_5_categorical_accuracy: 0.5347 - top_10_categorical_accuracy: 0.7008 - top_20_categorical_accuracy: 0.8300 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0128 - top_5_categorical_accuracy_cp2: 0.6005 - top_5_categorical_accuracy_cp3: 0.9712 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6071 - top_10_categorical_accuracy_cp0: 0.0199 - top_10_categorical_accuracy_cp1: 0.4991 - top_10_categorical_accuracy_cp2: 0.9523 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0333 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0100 - top_10_categorical_accuracy_p4: 0.7945 - top_20_categorical_accuracy_cp0: 0.1889 - top_20_categorical_accuracy_cp1: 0.9339 - top_20_categorical_accuracy_cp2: 0.9950 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0667 - top_20_categorical_accuracy_p2: 0.0725 - top_20_categorical_accuracy_p3: 0.1294 - top_20_categorical_accuracy_p4: 0.92827/7 [==============================] - ETA: 0s - loss: 0.1502 - categorical_accuracy: 0.1183 - top_5_categorical_accuracy: 0.5339 - top_10_categorical_accuracy: 0.7028 - top_20_categorical_accuracy: 0.8302 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0138 - top_5_categorical_accuracy_cp2: 0.5926 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6084 - top_10_categorical_accuracy_cp0: 0.0162 - top_10_categorical_accuracy_cp1: 0.5122 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7997 - top_20_categorical_accuracy_cp0: 0.1961 - top_20_categorical_accuracy_cp1: 0.9343 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0706 - top_20_categorical_accuracy_p3: 0.1333 - top_20_categorical_accuracy_p4: 0.9306    7/7 [==============================] - 1s 112ms/step - loss: 0.1502 - categorical_accuracy: 0.1183 - top_5_categorical_accuracy: 0.5339 - top_10_categorical_accuracy: 0.7028 - top_20_categorical_accuracy: 0.8302 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0138 - top_5_categorical_accuracy_cp2: 0.5926 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6084 - top_10_categorical_accuracy_cp0: 0.0162 - top_10_categorical_accuracy_cp1: 0.5122 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.7997 - top_20_categorical_accuracy_cp0: 0.1961 - top_20_categorical_accuracy_cp1: 0.9343 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0706 - top_20_categorical_accuracy_p3: 0.1333 - top_20_categorical_accuracy_p4: 0.9306 - val_loss: 0.1964 - val_categorical_accuracy: 0.0169 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3183 - val_top_20_categorical_accuracy: 0.5437 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0435 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5825 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.1226 - top_5_categorical_accuracy: 0.5690 - top_10_categorical_accuracy: 0.7414 - top_20_categorical_accuracy: 0.8621 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.6471 - top_5_categorical_accuracy_cp3: 0.9286 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6415 - top_10_categorical_accuracy_cp0: 0.0220 - top_10_categorical_accuracy_cp1: 0.5169 - top_10_categorical_accuracy_cp2: 0.9706 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8359 - top_20_categorical_accuracy_cp0: 0.2637 - top_20_categorical_accuracy_cp1: 0.9438 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1750 - top_20_categorical_accuracy_p4: 0.95683/7 [===========>..................] - ETA: 0s - loss: 0.1376 - categorical_accuracy: 0.1233 - top_5_categorical_accuracy: 0.5360 - top_10_categorical_accuracy: 0.7162 - top_20_categorical_accuracy: 0.8521 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0197 - top_5_categorical_accuracy_cp2: 0.6274 - top_5_categorical_accuracy_cp3: 0.9534 - top_5_categorical_accuracy_cp4: 0.9722 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6088 - top_10_categorical_accuracy_cp0: 0.0064 - top_10_categorical_accuracy_cp1: 0.5592 - top_10_categorical_accuracy_cp2: 0.9810 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8134 - top_20_categorical_accuracy_cp0: 0.2853 - top_20_categorical_accuracy_cp1: 0.9638 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1488 - top_20_categorical_accuracy_p4: 0.9548    5/7 [====================>.........] - ETA: 0s - loss: 0.1358 - categorical_accuracy: 0.1303 - top_5_categorical_accuracy: 0.5373 - top_10_categorical_accuracy: 0.7149 - top_20_categorical_accuracy: 0.8567 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0226 - top_5_categorical_accuracy_cp2: 0.6449 - top_5_categorical_accuracy_cp3: 0.9495 - top_5_categorical_accuracy_cp4: 0.9727 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6120 - top_10_categorical_accuracy_cp0: 0.0040 - top_10_categorical_accuracy_cp1: 0.5461 - top_10_categorical_accuracy_cp2: 0.9855 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8142 - top_20_categorical_accuracy_cp0: 0.2823 - top_20_categorical_accuracy_cp1: 0.9718 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0290 - top_20_categorical_accuracy_p3: 0.1498 - top_20_categorical_accuracy_p4: 0.9614    7/7 [==============================] - ETA: 0s - loss: 0.1362 - categorical_accuracy: 0.1296 - top_5_categorical_accuracy: 0.5339 - top_10_categorical_accuracy: 0.7131 - top_20_categorical_accuracy: 0.8562 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0245 - top_5_categorical_accuracy_cp2: 0.6420 - top_5_categorical_accuracy_cp3: 0.9497 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6084 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5535 - top_10_categorical_accuracy_cp2: 0.9835 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8126 - top_20_categorical_accuracy_cp0: 0.2869 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.1412 - top_20_categorical_accuracy_p4: 0.9621DEBUG:root:Model metric val_loss improved from 0.187119 to 0.177052
7/7 [==============================] - 1s 110ms/step - loss: 0.1362 - categorical_accuracy: 0.1296 - top_5_categorical_accuracy: 0.5339 - top_10_categorical_accuracy: 0.7131 - top_20_categorical_accuracy: 0.8562 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0245 - top_5_categorical_accuracy_cp2: 0.6420 - top_5_categorical_accuracy_cp3: 0.9497 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6084 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5535 - top_10_categorical_accuracy_cp2: 0.9835 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8126 - top_20_categorical_accuracy_cp0: 0.2869 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.1412 - top_20_categorical_accuracy_p4: 0.9621 - val_loss: 0.1771 - val_categorical_accuracy: 0.0197 - val_top_5_categorical_accuracy: 0.2817 - val_top_10_categorical_accuracy: 0.3268 - val_top_20_categorical_accuracy: 0.5352 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.5833 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5155 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0870 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5979 - val_top_20_categorical_accuracy_cp0: 0.0625 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9794
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1359 - categorical_accuracy: 0.1331 - top_5_categorical_accuracy: 0.5285 - top_10_categorical_accuracy: 0.7186 - top_20_categorical_accuracy: 0.8612 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0345 - top_5_categorical_accuracy_cp2: 0.7013 - top_5_categorical_accuracy_cp3: 0.9167 - top_5_categorical_accuracy_cp4: 0.9453 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5953 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.5603 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8094 - top_20_categorical_accuracy_cp0: 0.2784 - top_20_categorical_accuracy_cp1: 0.9741 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0500 - top_20_categorical_accuracy_p4: 0.96573/7 [===========>..................] - ETA: 0s - loss: 0.1365 - categorical_accuracy: 0.1305 - top_5_categorical_accuracy: 0.5171 - top_10_categorical_accuracy: 0.6965 - top_20_categorical_accuracy: 0.8536 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0495 - top_5_categorical_accuracy_cp2: 0.6653 - top_5_categorical_accuracy_cp3: 0.9006 - top_5_categorical_accuracy_cp4: 0.9609 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5956 - top_10_categorical_accuracy_cp0: 0.0061 - top_10_categorical_accuracy_cp1: 0.5325 - top_10_categorical_accuracy_cp2: 0.9958 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8022 - top_20_categorical_accuracy_cp0: 0.3191 - top_20_categorical_accuracy_cp1: 0.9783 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1765 - top_20_categorical_accuracy_p4: 0.9657    5/7 [====================>.........] - ETA: 0s - loss: 0.1344 - categorical_accuracy: 0.1313 - top_5_categorical_accuracy: 0.5270 - top_10_categorical_accuracy: 0.7093 - top_20_categorical_accuracy: 0.8573 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0407 - top_5_categorical_accuracy_cp2: 0.6794 - top_5_categorical_accuracy_cp3: 0.9043 - top_5_categorical_accuracy_cp4: 0.9670 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6037 - top_10_categorical_accuracy_cp0: 0.0057 - top_10_categorical_accuracy_cp1: 0.5527 - top_10_categorical_accuracy_cp2: 0.9975 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8126 - top_20_categorical_accuracy_cp0: 0.3053 - top_20_categorical_accuracy_cp1: 0.9797 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1542 - top_20_categorical_accuracy_p4: 0.96777/7 [==============================] - ETA: 0s - loss: 0.1330 - categorical_accuracy: 0.1328 - top_5_categorical_accuracy: 0.5361 - top_10_categorical_accuracy: 0.7169 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0413 - top_5_categorical_accuracy_cp2: 0.6934 - top_5_categorical_accuracy_cp3: 0.9068 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6109 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5612 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8169 - top_20_categorical_accuracy_cp0: 0.2998 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1451 - top_20_categorical_accuracy_p4: 0.9671DEBUG:root:Model metric val_loss improved from 0.177052 to 0.176255
7/7 [==============================] - 1s 114ms/step - loss: 0.1330 - categorical_accuracy: 0.1328 - top_5_categorical_accuracy: 0.5361 - top_10_categorical_accuracy: 0.7169 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0413 - top_5_categorical_accuracy_cp2: 0.6934 - top_5_categorical_accuracy_cp3: 0.9068 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6109 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5612 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8169 - top_20_categorical_accuracy_cp0: 0.2998 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1451 - top_20_categorical_accuracy_p4: 0.9671 - val_loss: 0.1763 - val_categorical_accuracy: 0.0225 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3239 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0725 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5928 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9845
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1365 - categorical_accuracy: 0.1243 - top_5_categorical_accuracy: 0.5047 - top_10_categorical_accuracy: 0.6685 - top_20_categorical_accuracy: 0.8606 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0630 - top_5_categorical_accuracy_cp2: 0.7581 - top_5_categorical_accuracy_cp3: 0.8772 - top_5_categorical_accuracy_cp4: 0.9912 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5714 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5039 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7569 - top_20_categorical_accuracy_cp0: 0.3684 - top_20_categorical_accuracy_cp1: 0.9843 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1538 - top_20_categorical_accuracy_p4: 0.96163/7 [===========>..................] - ETA: 0s - loss: 0.1309 - categorical_accuracy: 0.1316 - top_5_categorical_accuracy: 0.5449 - top_10_categorical_accuracy: 0.7038 - top_20_categorical_accuracy: 0.8658 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0618 - top_5_categorical_accuracy_cp2: 0.7729 - top_5_categorical_accuracy_cp3: 0.8902 - top_5_categorical_accuracy_cp4: 0.9945 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6150 - top_10_categorical_accuracy_cp0: 0.0032 - top_10_categorical_accuracy_cp1: 0.5324 - top_10_categorical_accuracy_cp2: 0.9956 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7943 - top_20_categorical_accuracy_cp0: 0.3333 - top_20_categorical_accuracy_cp1: 0.9824 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1429 - top_20_categorical_accuracy_p4: 0.96575/7 [====================>.........] - ETA: 0s - loss: 0.1292 - categorical_accuracy: 0.1401 - top_5_categorical_accuracy: 0.5634 - top_10_categorical_accuracy: 0.7130 - top_20_categorical_accuracy: 0.8645 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0720 - top_5_categorical_accuracy_cp2: 0.7761 - top_5_categorical_accuracy_cp3: 0.9210 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6410 - top_10_categorical_accuracy_cp0: 0.0020 - top_10_categorical_accuracy_cp1: 0.5461 - top_10_categorical_accuracy_cp2: 0.9949 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8112 - top_20_categorical_accuracy_cp0: 0.3176 - top_20_categorical_accuracy_cp1: 0.9815 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1476 - top_20_categorical_accuracy_p4: 0.97017/7 [==============================] - ETA: 0s - loss: 0.1291 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5665 - top_10_categorical_accuracy: 0.7116 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0703 - top_5_categorical_accuracy_cp2: 0.7840 - top_5_categorical_accuracy_cp3: 0.9320 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6456 - top_10_categorical_accuracy_cp0: 0.0016 - top_10_categorical_accuracy_cp1: 0.5398 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8108 - top_20_categorical_accuracy_cp0: 0.3160 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1451 - top_20_categorical_accuracy_p4: 0.9703DEBUG:root:Model metric val_loss improved from 0.176255 to 0.170068
7/7 [==============================] - 1s 112ms/step - loss: 0.1291 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5665 - top_10_categorical_accuracy: 0.7116 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0703 - top_5_categorical_accuracy_cp2: 0.7840 - top_5_categorical_accuracy_cp3: 0.9320 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6456 - top_10_categorical_accuracy_cp0: 0.0016 - top_10_categorical_accuracy_cp1: 0.5398 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8108 - top_20_categorical_accuracy_cp0: 0.3160 - top_20_categorical_accuracy_cp1: 0.9786 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1451 - top_20_categorical_accuracy_p4: 0.9703 - val_loss: 0.1701 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.3268 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0870 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5979 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9845
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1216 - categorical_accuracy: 0.1950 - top_5_categorical_accuracy: 0.6367 - top_10_categorical_accuracy: 0.7495 - top_20_categorical_accuracy: 0.8719 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1731 - top_5_categorical_accuracy_cp2: 0.9080 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7208 - top_10_categorical_accuracy_cp0: 0.0109 - top_10_categorical_accuracy_cp1: 0.6154 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8485 - top_20_categorical_accuracy_cp0: 0.2935 - top_20_categorical_accuracy_cp1: 0.9808 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1458 - top_20_categorical_accuracy_p4: 0.97193/7 [===========>..................] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.1959 - top_5_categorical_accuracy: 0.6279 - top_10_categorical_accuracy: 0.7405 - top_20_categorical_accuracy: 0.8639 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1190 - top_5_categorical_accuracy_cp2: 0.9139 - top_5_categorical_accuracy_cp3: 0.9848 - top_5_categorical_accuracy_cp4: 0.9846 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7199 - top_10_categorical_accuracy_cp0: 0.0068 - top_10_categorical_accuracy_cp1: 0.6020 - top_10_categorical_accuracy_cp2: 0.9963 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8490 - top_20_categorical_accuracy_cp0: 0.2911 - top_20_categorical_accuracy_cp1: 0.9762 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1631 - top_20_categorical_accuracy_p4: 0.97375/7 [====================>.........] - ETA: 0s - loss: 0.1252 - categorical_accuracy: 0.1976 - top_5_categorical_accuracy: 0.6106 - top_10_categorical_accuracy: 0.7335 - top_20_categorical_accuracy: 0.8633 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1245 - top_5_categorical_accuracy_cp2: 0.9294 - top_5_categorical_accuracy_cp3: 0.9856 - top_5_categorical_accuracy_cp4: 0.9791 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6974 - top_10_categorical_accuracy_cp0: 0.0118 - top_10_categorical_accuracy_cp1: 0.6340 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8378 - top_20_categorical_accuracy_cp0: 0.3183 - top_20_categorical_accuracy_cp1: 0.9774 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1690 - top_20_categorical_accuracy_p4: 0.97047/7 [==============================] - ETA: 0s - loss: 0.1250 - categorical_accuracy: 0.1996 - top_5_categorical_accuracy: 0.6086 - top_10_categorical_accuracy: 0.7320 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1223 - top_5_categorical_accuracy_cp2: 0.9362 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6935 - top_10_categorical_accuracy_cp0: 0.0130 - top_10_categorical_accuracy_cp1: 0.6315 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8337 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1647 - top_20_categorical_accuracy_p4: 0.9685    DEBUG:root:Model metric val_loss improved from 0.170068 to 0.163176
7/7 [==============================] - 1s 110ms/step - loss: 0.1250 - categorical_accuracy: 0.1996 - top_5_categorical_accuracy: 0.6086 - top_10_categorical_accuracy: 0.7320 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1223 - top_5_categorical_accuracy_cp2: 0.9362 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6935 - top_10_categorical_accuracy_cp0: 0.0130 - top_10_categorical_accuracy_cp1: 0.6315 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8337 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1647 - top_20_categorical_accuracy_p4: 0.9685 - val_loss: 0.1632 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3127 - val_top_10_categorical_accuracy: 0.3521 - val_top_20_categorical_accuracy: 0.5634 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0290 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5722 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6443 - val_top_20_categorical_accuracy_cp0: 0.1193 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.1351 - val_top_20_categorical_accuracy_p4: 0.9536
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1280 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.5784 - top_10_categorical_accuracy: 0.7202 - top_20_categorical_accuracy: 0.8563 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2119 - top_5_categorical_accuracy_cp2: 0.9494 - top_5_categorical_accuracy_cp3: 0.9810 - top_5_categorical_accuracy_cp4: 0.9537 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6725 - top_10_categorical_accuracy_cp0: 0.0252 - top_10_categorical_accuracy_cp1: 0.7373 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0192 - top_10_categorical_accuracy_p4: 0.8352 - top_20_categorical_accuracy_cp0: 0.3697 - top_20_categorical_accuracy_cp1: 0.9915 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1731 - top_20_categorical_accuracy_p4: 0.97583/7 [===========>..................] - ETA: 0s - loss: 0.1230 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.6172 - top_10_categorical_accuracy: 0.7440 - top_20_categorical_accuracy: 0.8676 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2425 - top_5_categorical_accuracy_cp2: 0.9385 - top_5_categorical_accuracy_cp3: 0.9848 - top_5_categorical_accuracy_cp4: 0.9551 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7053 - top_10_categorical_accuracy_cp0: 0.0254 - top_10_categorical_accuracy_cp1: 0.7186 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0085 - top_10_categorical_accuracy_p4: 0.8494 - top_20_categorical_accuracy_cp0: 0.3492 - top_20_categorical_accuracy_cp1: 0.9880 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2393 - top_20_categorical_accuracy_p4: 0.97105/7 [====================>.........] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.2087 - top_5_categorical_accuracy: 0.6274 - top_10_categorical_accuracy: 0.7532 - top_20_categorical_accuracy: 0.8703 - top_5_categorical_accuracy_cp0: 0.0019 - top_5_categorical_accuracy_cp1: 0.2789 - top_5_categorical_accuracy_cp2: 0.9098 - top_5_categorical_accuracy_cp3: 0.9803 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7165 - top_10_categorical_accuracy_cp0: 0.0350 - top_10_categorical_accuracy_cp1: 0.7394 - top_10_categorical_accuracy_cp2: 0.9875 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 0.9935 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0239 - top_10_categorical_accuracy_p4: 0.8580 - top_20_categorical_accuracy_cp0: 0.3534 - top_20_categorical_accuracy_cp1: 0.9853 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2584 - top_20_categorical_accuracy_p4: 0.9705    7/7 [==============================] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6337 - top_10_categorical_accuracy: 0.7602 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.2905 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9793 - top_5_categorical_accuracy_cp4: 0.9588 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7221 - top_10_categorical_accuracy_cp0: 0.0421 - top_10_categorical_accuracy_cp1: 0.7538 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.8637 - top_20_categorical_accuracy_cp0: 0.3614 - top_20_categorical_accuracy_cp1: 0.9847 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2549 - top_20_categorical_accuracy_p4: 0.9717DEBUG:root:Model metric val_loss improved from 0.163176 to 0.162296
7/7 [==============================] - 1s 112ms/step - loss: 0.1206 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6337 - top_10_categorical_accuracy: 0.7602 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.2905 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9793 - top_5_categorical_accuracy_cp4: 0.9588 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7221 - top_10_categorical_accuracy_cp0: 0.0421 - top_10_categorical_accuracy_cp1: 0.7538 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.8637 - top_20_categorical_accuracy_cp0: 0.3614 - top_20_categorical_accuracy_cp1: 0.9847 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2549 - top_20_categorical_accuracy_p4: 0.9717 - val_loss: 0.1623 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5155 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0227 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0360 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1224 - categorical_accuracy: 0.2079 - top_5_categorical_accuracy: 0.6238 - top_10_categorical_accuracy: 0.7505 - top_20_categorical_accuracy: 0.8715 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3929 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9204 - top_5_categorical_accuracy_cp4: 0.9643 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7112 - top_10_categorical_accuracy_cp0: 0.0360 - top_10_categorical_accuracy_cp1: 0.8304 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0238 - top_10_categorical_accuracy_p4: 0.8534 - top_20_categorical_accuracy_cp0: 0.4144 - top_20_categorical_accuracy_cp1: 0.9911 - top_20_categorical_accuracy_cp2: 0.9877 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3095 - top_20_categorical_accuracy_p4: 0.96554/7 [================>.............] - ETA: 0s - loss: 0.1201 - categorical_accuracy: 0.2066 - top_5_categorical_accuracy: 0.6412 - top_10_categorical_accuracy: 0.7716 - top_20_categorical_accuracy: 0.8787 - top_5_categorical_accuracy_cp0: 0.0024 - top_5_categorical_accuracy_cp1: 0.4098 - top_5_categorical_accuracy_cp2: 0.8947 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9497 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7298 - top_10_categorical_accuracy_cp0: 0.0865 - top_10_categorical_accuracy_cp1: 0.8374 - top_10_categorical_accuracy_cp2: 0.9934 - top_10_categorical_accuracy_cp3: 0.9910 - top_10_categorical_accuracy_cp4: 0.9537 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0588 - top_10_categorical_accuracy_p4: 0.8727 - top_20_categorical_accuracy_cp0: 0.4111 - top_20_categorical_accuracy_cp1: 0.9844 - top_20_categorical_accuracy_cp2: 0.9967 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9940 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3118 - top_20_categorical_accuracy_p4: 0.9714    6/7 [========================>.....] - ETA: 0s - loss: 0.1182 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6529 - top_10_categorical_accuracy: 0.7833 - top_20_categorical_accuracy: 0.8807 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.4096 - top_5_categorical_accuracy_cp2: 0.9002 - top_5_categorical_accuracy_cp3: 0.9626 - top_5_categorical_accuracy_cp4: 0.9545 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7440 - top_10_categorical_accuracy_cp0: 0.1003 - top_10_categorical_accuracy_cp1: 0.8516 - top_10_categorical_accuracy_cp2: 0.9917 - top_10_categorical_accuracy_cp3: 0.9895 - top_10_categorical_accuracy_cp4: 0.9612 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0909 - top_10_categorical_accuracy_p4: 0.8843 - top_20_categorical_accuracy_cp0: 0.4128 - top_20_categorical_accuracy_cp1: 0.9815 - top_20_categorical_accuracy_cp2: 0.9958 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3202 - top_20_categorical_accuracy_p4: 0.9743DEBUG:root:Model metric val_loss improved from 0.162296 to 0.161281
7/7 [==============================] - 1s 108ms/step - loss: 0.1184 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6525 - top_10_categorical_accuracy: 0.7834 - top_20_categorical_accuracy: 0.8801 - top_5_categorical_accuracy_cp0: 0.0049 - top_5_categorical_accuracy_cp1: 0.4113 - top_5_categorical_accuracy_cp2: 0.8992 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7436 - top_10_categorical_accuracy_cp0: 0.1021 - top_10_categorical_accuracy_cp1: 0.8532 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9896 - top_10_categorical_accuracy_cp4: 0.9615 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8845 - top_20_categorical_accuracy_cp0: 0.4117 - top_20_categorical_accuracy_cp1: 0.9817 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3176 - top_20_categorical_accuracy_p4: 0.9739 - val_loss: 0.1613 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.6366 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.2670 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4144 - val_top_20_categorical_accuracy_p4: 0.9278
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.2076 - top_5_categorical_accuracy: 0.6857 - top_10_categorical_accuracy: 0.8248 - top_20_categorical_accuracy: 0.9181 - top_5_categorical_accuracy_cp0: 0.0120 - top_5_categorical_accuracy_cp1: 0.4298 - top_5_categorical_accuracy_cp2: 0.9103 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7579 - top_10_categorical_accuracy_cp0: 0.1446 - top_10_categorical_accuracy_cp1: 0.9123 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1111 - top_10_categorical_accuracy_p4: 0.9032 - top_20_categorical_accuracy_cp0: 0.5301 - top_20_categorical_accuracy_cp1: 0.9825 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9854 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4444 - top_20_categorical_accuracy_p4: 0.98114/7 [================>.............] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.2058 - top_5_categorical_accuracy: 0.6587 - top_10_categorical_accuracy: 0.7975 - top_20_categorical_accuracy: 0.8888 - top_5_categorical_accuracy_cp0: 0.0075 - top_5_categorical_accuracy_cp1: 0.4289 - top_5_categorical_accuracy_cp2: 0.9060 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9643 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7496 - top_10_categorical_accuracy_cp0: 0.1533 - top_10_categorical_accuracy_cp1: 0.8778 - top_10_categorical_accuracy_cp2: 0.9732 - top_10_categorical_accuracy_cp3: 0.9714 - top_10_categorical_accuracy_cp4: 0.9742 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1272 - top_10_categorical_accuracy_p4: 0.8956 - top_20_categorical_accuracy_cp0: 0.4447 - top_20_categorical_accuracy_cp1: 0.9778 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9940 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3121 - top_20_categorical_accuracy_p4: 0.98226/7 [========================>.....] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.2070 - top_5_categorical_accuracy: 0.6525 - top_10_categorical_accuracy: 0.7961 - top_20_categorical_accuracy: 0.8897 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.4241 - top_5_categorical_accuracy_cp2: 0.8944 - top_5_categorical_accuracy_cp3: 0.9537 - top_5_categorical_accuracy_cp4: 0.9530 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7435 - top_10_categorical_accuracy_cp0: 0.1751 - top_10_categorical_accuracy_cp1: 0.8762 - top_10_categorical_accuracy_cp2: 0.9752 - top_10_categorical_accuracy_cp3: 0.9716 - top_10_categorical_accuracy_cp4: 0.9624 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1260 - top_10_categorical_accuracy_p4: 0.8956 - top_20_categorical_accuracy_cp0: 0.4697 - top_20_categorical_accuracy_cp1: 0.9768 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9879 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3504 - top_20_categorical_accuracy_p4: 0.98167/7 [==============================] - 1s 106ms/step - loss: 0.1175 - categorical_accuracy: 0.2068 - top_5_categorical_accuracy: 0.6522 - top_10_categorical_accuracy: 0.7966 - top_20_categorical_accuracy: 0.8898 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.4220 - top_5_categorical_accuracy_cp2: 0.8951 - top_5_categorical_accuracy_cp3: 0.9541 - top_5_categorical_accuracy_cp4: 0.9535 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7432 - top_10_categorical_accuracy_cp0: 0.1783 - top_10_categorical_accuracy_cp1: 0.8746 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9628 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1294 - top_10_categorical_accuracy_p4: 0.8959 - top_20_categorical_accuracy_cp0: 0.4700 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9880 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3529 - top_20_categorical_accuracy_p4: 0.9818 - val_loss: 0.1623 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3352 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.8750 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6134 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3580 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 0.0000e+00 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4505 - val_top_20_categorical_accuracy_p4: 0.9794
INFO:root:Restoring best model weights with val_loss: 0.161281 from epoch 8
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.43it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1488.55it/s]
INFO:root:Finished run 0664b8f19ce34f10b8d6dfdebba19475
2023-05-24 20:19:16.008546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:19:16.523789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:19:16.523847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:19:16.523852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 06ab6aa45c924a1b9063ff2e8b56b526
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12116.90it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13375.79it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13247.20it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24614.46it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:19:18.856424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.856630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.857419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.857567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.857697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.857828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.858209: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:19:18.999537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.999761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:18.999915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:19.000050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:19.000177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:19.000300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.552676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.552871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.553019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.553154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.553283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.553402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:19:20.553816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:19:20.553920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12826.13it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13587.70it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13390.02it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24842.87it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 288.45it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 58/154 [00:00<00:00, 288.75it/s]Loading hierarchy for column coarse_log_cluster_path:  57%|█████▋    | 88/154 [00:00<00:00, 290.42it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 118/154 [00:00<00:00, 291.68it/s]Loading hierarchy for column coarse_log_cluster_path:  96%|█████████▌| 148/154 [00:00<00:00, 293.34it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 291.94it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:52,  7.69it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5169.71it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1298it [00:00, 38924.45it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/154 [00:00<?, ?it/s]Initializing gram_embedding connections:  51%|█████▏    | 79/154 [00:00<00:00, 789.41it/s]Initializing gram_embedding connections: 100%|██████████| 154/154 [00:00<00:00, 429.16it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:01,  1.16s/it]Calculating percentile frequencies...: 7it [00:01,  6.03it/s]
2023-05-24 20:19:25.191587: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:19:57.711667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:19:58.290877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:19:58.391777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:19:58.845353: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7371f1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:19:58.845388: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:19:58.845397: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:19:58.849260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:19:58.931190: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1927 - categorical_accuracy: 0.0172 - top_5_categorical_accuracy: 0.1015 - top_10_categorical_accuracy: 0.1820 - top_20_categorical_accuracy: 0.3084 - top_5_categorical_accuracy_cp0: 0.0808 - top_5_categorical_accuracy_cp1: 0.0808 - top_5_categorical_accuracy_cp2: 0.0000e+00 - top_5_categorical_accuracy_cp3: 0.2119 - top_5_categorical_accuracy_cp4: 0.0984 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.1579 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.1089 - top_10_categorical_accuracy_cp0: 0.1717 - top_10_categorical_accuracy_cp1: 0.1616 - top_10_categorical_accuracy_cp2: 0.0000e+00 - top_10_categorical_accuracy_cp3: 0.3136 - top_10_categorical_accuracy_cp4: 0.2049 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.6667 - top_10_categorical_accuracy_p2: 0.2105 - top_10_categorical_accuracy_p3: 0.0526 - top_10_categorical_accuracy_p4: 0.1895 - top_20_categorical_accuracy_cp0: 0.2727 - top_20_categorical_accuracy_cp1: 0.3030 - top_20_categorical_accuracy_cp2: 0.0476 - top_20_categorical_accuracy_cp3: 0.4746 - top_20_categorical_accuracy_cp4: 0.3607 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.6667 - top_20_categorical_accuracy_p2: 0.2105 - top_20_categorical_accuracy_p3: 0.2632 - top_20_categorical_accuracy_p4: 0.3159      3/Unknown - 34s 37ms/step - loss: 0.1929 - categorical_accuracy: 0.0852 - top_5_categorical_accuracy: 0.3229 - top_10_categorical_accuracy: 0.4228 - top_20_categorical_accuracy: 0.5493 - top_5_categorical_accuracy_cp0: 0.0512 - top_5_categorical_accuracy_cp1: 0.1138 - top_5_categorical_accuracy_cp2: 0.1548 - top_5_categorical_accuracy_cp3: 0.6193 - top_5_categorical_accuracy_cp4: 0.5558 - top_5_categorical_accuracy_p0: 0.1429 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0638 - top_5_categorical_accuracy_p3: 0.0259 - top_5_categorical_accuracy_p4: 0.3610 - top_10_categorical_accuracy_cp0: 0.1126 - top_10_categorical_accuracy_cp1: 0.2123 - top_10_categorical_accuracy_cp2: 0.3013 - top_10_categorical_accuracy_cp3: 0.7009 - top_10_categorical_accuracy_cp4: 0.6727 - top_10_categorical_accuracy_p0: 0.1429 - top_10_categorical_accuracy_p1: 0.2000 - top_10_categorical_accuracy_p2: 0.1064 - top_10_categorical_accuracy_p3: 0.0776 - top_10_categorical_accuracy_p4: 0.4661 - top_20_categorical_accuracy_cp0: 0.2628 - top_20_categorical_accuracy_cp1: 0.3846 - top_20_categorical_accuracy_cp2: 0.4477 - top_20_categorical_accuracy_cp3: 0.7946 - top_20_categorical_accuracy_cp4: 0.7584 - top_20_categorical_accuracy_p0: 0.1429 - top_20_categorical_accuracy_p1: 0.2667 - top_20_categorical_accuracy_p2: 0.1915 - top_20_categorical_accuracy_p3: 0.2672 - top_20_categorical_accuracy_p4: 0.5901                             5/Unknown - 34s 37ms/step - loss: 0.1929 - categorical_accuracy: 0.1064 - top_5_categorical_accuracy: 0.4044 - top_10_categorical_accuracy: 0.5089 - top_20_categorical_accuracy: 0.6245 - top_5_categorical_accuracy_cp0: 0.0365 - top_5_categorical_accuracy_cp1: 0.1034 - top_5_categorical_accuracy_cp2: 0.3342 - top_5_categorical_accuracy_cp3: 0.7446 - top_5_categorical_accuracy_cp4: 0.7194 - top_5_categorical_accuracy_p0: 0.0769 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0526 - top_5_categorical_accuracy_p3: 0.0237 - top_5_categorical_accuracy_p4: 0.4581 - top_10_categorical_accuracy_cp0: 0.0864 - top_10_categorical_accuracy_cp1: 0.2704 - top_10_categorical_accuracy_cp2: 0.5144 - top_10_categorical_accuracy_cp3: 0.8165 - top_10_categorical_accuracy_cp4: 0.7968 - top_10_categorical_accuracy_p0: 0.0769 - top_10_categorical_accuracy_p1: 0.1333 - top_10_categorical_accuracy_p2: 0.0789 - top_10_categorical_accuracy_p3: 0.0806 - top_10_categorical_accuracy_p4: 0.5698 - top_20_categorical_accuracy_cp0: 0.2418 - top_20_categorical_accuracy_cp1: 0.4610 - top_20_categorical_accuracy_cp2: 0.6475 - top_20_categorical_accuracy_cp3: 0.8777 - top_20_categorical_accuracy_cp4: 0.8500 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.2000 - top_20_categorical_accuracy_p2: 0.1711 - top_20_categorical_accuracy_p3: 0.2607 - top_20_categorical_accuracy_p4: 0.6814      7/Unknown - 34s 36ms/step - loss: 0.1922 - categorical_accuracy: 0.1139 - top_5_categorical_accuracy: 0.4369 - top_10_categorical_accuracy: 0.5446 - top_20_categorical_accuracy: 0.6551 - top_5_categorical_accuracy_cp0: 0.0308 - top_5_categorical_accuracy_cp1: 0.0994 - top_5_categorical_accuracy_cp2: 0.4053 - top_5_categorical_accuracy_cp3: 0.7885 - top_5_categorical_accuracy_cp4: 0.7676 - top_5_categorical_accuracy_p0: 0.0625 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0471 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.4943 - top_10_categorical_accuracy_cp0: 0.0875 - top_10_categorical_accuracy_cp1: 0.2783 - top_10_categorical_accuracy_cp2: 0.6132 - top_10_categorical_accuracy_cp3: 0.8491 - top_10_categorical_accuracy_cp4: 0.8327 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.6091 - top_20_categorical_accuracy_cp0: 0.2464 - top_20_categorical_accuracy_cp1: 0.4832 - top_20_categorical_accuracy_cp2: 0.7222 - top_20_categorical_accuracy_cp3: 0.8994 - top_20_categorical_accuracy_cp4: 0.8765 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.2059 - top_20_categorical_accuracy_p2: 0.1529 - top_20_categorical_accuracy_p3: 0.2510 - top_20_categorical_accuracy_p4: 0.71602023-05-24 20:19:59.923727: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195440
7/7 [==============================] - 53s 3s/step - loss: 0.1922 - categorical_accuracy: 0.1139 - top_5_categorical_accuracy: 0.4369 - top_10_categorical_accuracy: 0.5446 - top_20_categorical_accuracy: 0.6551 - top_5_categorical_accuracy_cp0: 0.0308 - top_5_categorical_accuracy_cp1: 0.0994 - top_5_categorical_accuracy_cp2: 0.4053 - top_5_categorical_accuracy_cp3: 0.7885 - top_5_categorical_accuracy_cp4: 0.7676 - top_5_categorical_accuracy_p0: 0.0625 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0471 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.4943 - top_10_categorical_accuracy_cp0: 0.0875 - top_10_categorical_accuracy_cp1: 0.2783 - top_10_categorical_accuracy_cp2: 0.6132 - top_10_categorical_accuracy_cp3: 0.8491 - top_10_categorical_accuracy_cp4: 0.8327 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.6091 - top_20_categorical_accuracy_cp0: 0.2464 - top_20_categorical_accuracy_cp1: 0.4832 - top_20_categorical_accuracy_cp2: 0.7222 - top_20_categorical_accuracy_cp3: 0.8994 - top_20_categorical_accuracy_cp4: 0.8765 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.2059 - top_20_categorical_accuracy_p2: 0.1529 - top_20_categorical_accuracy_p3: 0.2510 - top_20_categorical_accuracy_p4: 0.7160 - val_loss: 0.1954 - val_categorical_accuracy: 0.0113 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3746 - val_top_20_categorical_accuracy: 0.5070 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.3333 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6856 - val_top_20_categorical_accuracy_cp0: 0.0057 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0625 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1883 - categorical_accuracy: 0.1480 - top_5_categorical_accuracy: 0.5579 - top_10_categorical_accuracy: 0.7097 - top_20_categorical_accuracy: 0.7951 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0721 - top_5_categorical_accuracy_cp2: 0.6753 - top_5_categorical_accuracy_cp3: 0.9402 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6309 - top_10_categorical_accuracy_cp0: 0.0619 - top_10_categorical_accuracy_cp1: 0.4414 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1250 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0811 - top_10_categorical_accuracy_p4: 0.7940 - top_20_categorical_accuracy_cp0: 0.2577 - top_20_categorical_accuracy_cp1: 0.6757 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2162 - top_20_categorical_accuracy_p4: 0.87773/7 [===========>..................] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.1339 - top_5_categorical_accuracy: 0.5406 - top_10_categorical_accuracy: 0.6885 - top_20_categorical_accuracy: 0.7659 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0449 - top_5_categorical_accuracy_cp2: 0.6833 - top_5_categorical_accuracy_cp3: 0.9326 - top_5_categorical_accuracy_cp4: 0.9944 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6256 - top_10_categorical_accuracy_cp0: 0.0554 - top_10_categorical_accuracy_cp1: 0.4199 - top_10_categorical_accuracy_cp2: 0.9875 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0455 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0448 - top_10_categorical_accuracy_p4: 0.7915 - top_20_categorical_accuracy_cp0: 0.2277 - top_20_categorical_accuracy_cp1: 0.6218 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0909 - top_20_categorical_accuracy_p2: 0.0200 - top_20_categorical_accuracy_p3: 0.2090 - top_20_categorical_accuracy_p4: 0.8634    5/7 [====================>.........] - ETA: 0s - loss: 0.1833 - categorical_accuracy: 0.1306 - top_5_categorical_accuracy: 0.5514 - top_10_categorical_accuracy: 0.6980 - top_20_categorical_accuracy: 0.7814 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0379 - top_5_categorical_accuracy_cp2: 0.7324 - top_5_categorical_accuracy_cp3: 0.9137 - top_5_categorical_accuracy_cp4: 0.9952 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6296 - top_10_categorical_accuracy_cp0: 0.0648 - top_10_categorical_accuracy_cp1: 0.4072 - top_10_categorical_accuracy_cp2: 0.9903 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0345 - top_10_categorical_accuracy_p2: 0.0133 - top_10_categorical_accuracy_p3: 0.0577 - top_10_categorical_accuracy_p4: 0.7909 - top_20_categorical_accuracy_cp0: 0.2515 - top_20_categorical_accuracy_cp1: 0.6345 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.1034 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.2212 - top_20_categorical_accuracy_p4: 0.8683        7/7 [==============================] - ETA: 0s - loss: 0.1815 - categorical_accuracy: 0.1306 - top_5_categorical_accuracy: 0.5446 - top_10_categorical_accuracy: 0.6974 - top_20_categorical_accuracy: 0.7859 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0321 - top_5_categorical_accuracy_cp2: 0.7181 - top_5_categorical_accuracy_cp3: 0.9098 - top_5_categorical_accuracy_cp4: 0.9960 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6205 - top_10_categorical_accuracy_cp0: 0.0600 - top_10_categorical_accuracy_cp1: 0.4190 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0588 - top_10_categorical_accuracy_p4: 0.7886 - top_20_categorical_accuracy_cp0: 0.2577 - top_20_categorical_accuracy_cp1: 0.6575 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.2235 - top_20_categorical_accuracy_p4: 0.8720DEBUG:root:Model metric val_loss improved from 0.195440 to 0.187854
7/7 [==============================] - 1s 114ms/step - loss: 0.1815 - categorical_accuracy: 0.1306 - top_5_categorical_accuracy: 0.5446 - top_10_categorical_accuracy: 0.6974 - top_20_categorical_accuracy: 0.7859 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0321 - top_5_categorical_accuracy_cp2: 0.7181 - top_5_categorical_accuracy_cp3: 0.9098 - top_5_categorical_accuracy_cp4: 0.9960 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6205 - top_10_categorical_accuracy_cp0: 0.0600 - top_10_categorical_accuracy_cp1: 0.4190 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0588 - top_10_categorical_accuracy_p4: 0.7886 - top_20_categorical_accuracy_cp0: 0.2577 - top_20_categorical_accuracy_cp1: 0.6575 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.2235 - top_20_categorical_accuracy_p4: 0.8720 - val_loss: 0.1879 - val_categorical_accuracy: 0.0056 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4958 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9565 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9072 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1582 - categorical_accuracy: 0.1236 - top_5_categorical_accuracy: 0.5627 - top_10_categorical_accuracy: 0.7129 - top_20_categorical_accuracy: 0.7966 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0396 - top_5_categorical_accuracy_cp2: 0.7381 - top_5_categorical_accuracy_cp3: 0.8707 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6311 - top_10_categorical_accuracy_cp0: 0.0521 - top_10_categorical_accuracy_cp1: 0.4059 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7996 - top_20_categorical_accuracy_cp0: 0.2292 - top_20_categorical_accuracy_cp1: 0.6733 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1622 - top_20_categorical_accuracy_p4: 0.87853/7 [===========>..................] - ETA: 0s - loss: 0.1519 - categorical_accuracy: 0.1105 - top_5_categorical_accuracy: 0.5219 - top_10_categorical_accuracy: 0.6902 - top_20_categorical_accuracy: 0.7943 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0214 - top_5_categorical_accuracy_cp2: 0.7195 - top_5_categorical_accuracy_cp3: 0.8473 - top_5_categorical_accuracy_cp4: 0.9944 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5957 - top_10_categorical_accuracy_cp0: 0.0354 - top_10_categorical_accuracy_cp1: 0.4251 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0476 - top_10_categorical_accuracy_p4: 0.7833 - top_20_categorical_accuracy_cp0: 0.2605 - top_20_categorical_accuracy_cp1: 0.7125 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2381 - top_20_categorical_accuracy_p4: 0.8841    5/7 [====================>.........] - ETA: 0s - loss: 0.1477 - categorical_accuracy: 0.1139 - top_5_categorical_accuracy: 0.5271 - top_10_categorical_accuracy: 0.6978 - top_20_categorical_accuracy: 0.8125 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0165 - top_5_categorical_accuracy_cp2: 0.7211 - top_5_categorical_accuracy_cp3: 0.8435 - top_5_categorical_accuracy_cp4: 0.9936 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5984 - top_10_categorical_accuracy_cp0: 0.0239 - top_10_categorical_accuracy_cp1: 0.4459 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0348 - top_10_categorical_accuracy_p4: 0.7893 - top_20_categorical_accuracy_cp0: 0.2763 - top_20_categorical_accuracy_cp1: 0.7651 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.0385 - top_20_categorical_accuracy_p2: 0.0137 - top_20_categorical_accuracy_p3: 0.2438 - top_20_categorical_accuracy_p4: 0.9000        7/7 [==============================] - ETA: 0s - loss: 0.1478 - categorical_accuracy: 0.1121 - top_5_categorical_accuracy: 0.5273 - top_10_categorical_accuracy: 0.7012 - top_20_categorical_accuracy: 0.8132 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0153 - top_5_categorical_accuracy_cp2: 0.7325 - top_5_categorical_accuracy_cp3: 0.8373 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6009 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.4618 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0353 - top_10_categorical_accuracy_p4: 0.7958 - top_20_categorical_accuracy_cp0: 0.2723 - top_20_categorical_accuracy_cp1: 0.7768 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.90347/7 [==============================] - 1s 105ms/step - loss: 0.1478 - categorical_accuracy: 0.1121 - top_5_categorical_accuracy: 0.5273 - top_10_categorical_accuracy: 0.7012 - top_20_categorical_accuracy: 0.8132 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0153 - top_5_categorical_accuracy_cp2: 0.7325 - top_5_categorical_accuracy_cp3: 0.8373 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6009 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.4618 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0353 - top_10_categorical_accuracy_p4: 0.7958 - top_20_categorical_accuracy_cp0: 0.2723 - top_20_categorical_accuracy_cp1: 0.7768 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.9034 - val_loss: 0.1887 - val_categorical_accuracy: 0.0141 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4958 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9565 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9072 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1318 - categorical_accuracy: 0.1073 - top_5_categorical_accuracy: 0.5728 - top_10_categorical_accuracy: 0.7395 - top_20_categorical_accuracy: 0.8506 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0112 - top_5_categorical_accuracy_cp2: 0.7157 - top_5_categorical_accuracy_cp3: 0.8750 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6458 - top_10_categorical_accuracy_cp0: 0.0330 - top_10_categorical_accuracy_cp1: 0.4607 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0244 - top_10_categorical_accuracy_p4: 0.8315 - top_20_categorical_accuracy_cp0: 0.2857 - top_20_categorical_accuracy_cp1: 0.8539 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.2683 - top_20_categorical_accuracy_p4: 0.93304/7 [================>.............] - ETA: 0s - loss: 0.1352 - categorical_accuracy: 0.1283 - top_5_categorical_accuracy: 0.5428 - top_10_categorical_accuracy: 0.7087 - top_20_categorical_accuracy: 0.8394 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0121 - top_5_categorical_accuracy_cp2: 0.7117 - top_5_categorical_accuracy_cp3: 0.9161 - top_5_categorical_accuracy_cp4: 0.9939 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6186 - top_10_categorical_accuracy_cp0: 0.0216 - top_10_categorical_accuracy_cp1: 0.5024 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0122 - top_10_categorical_accuracy_p4: 0.8066 - top_20_categorical_accuracy_cp0: 0.2957 - top_20_categorical_accuracy_cp1: 0.8913 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0351 - top_20_categorical_accuracy_p3: 0.2256 - top_20_categorical_accuracy_p4: 0.93556/7 [========================>.....] - ETA: 0s - loss: 0.1349 - categorical_accuracy: 0.1345 - top_5_categorical_accuracy: 0.5419 - top_10_categorical_accuracy: 0.7116 - top_20_categorical_accuracy: 0.8445 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0156 - top_5_categorical_accuracy_cp2: 0.7033 - top_5_categorical_accuracy_cp3: 0.9193 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6175 - top_10_categorical_accuracy_cp0: 0.0230 - top_10_categorical_accuracy_cp1: 0.5101 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0120 - top_10_categorical_accuracy_p4: 0.8098 - top_20_categorical_accuracy_cp0: 0.2977 - top_20_categorical_accuracy_cp1: 0.9020 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.2351 - top_20_categorical_accuracy_p4: 0.9403DEBUG:root:Model metric val_loss improved from 0.187854 to 0.176303
7/7 [==============================] - 1s 105ms/step - loss: 0.1351 - categorical_accuracy: 0.1340 - top_5_categorical_accuracy: 0.5402 - top_10_categorical_accuracy: 0.7100 - top_20_categorical_accuracy: 0.8446 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0153 - top_5_categorical_accuracy_cp2: 0.7037 - top_5_categorical_accuracy_cp3: 0.9201 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6155 - top_10_categorical_accuracy_cp0: 0.0227 - top_10_categorical_accuracy_cp1: 0.5092 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8079 - top_20_categorical_accuracy_cp0: 0.2998 - top_20_categorical_accuracy_cp1: 0.9037 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.2314 - top_20_categorical_accuracy_p4: 0.9406 - val_loss: 0.1763 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.1673 - top_5_categorical_accuracy: 0.5475 - top_10_categorical_accuracy: 0.7281 - top_20_categorical_accuracy: 0.8688 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0259 - top_5_categorical_accuracy_cp2: 0.7403 - top_5_categorical_accuracy_cp3: 0.9259 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6167 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.6034 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8201 - top_20_categorical_accuracy_cp0: 0.3814 - top_20_categorical_accuracy_cp1: 0.9224 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2105 - top_20_categorical_accuracy_p4: 0.96153/7 [===========>..................] - ETA: 0s - loss: 0.1355 - categorical_accuracy: 0.1711 - top_5_categorical_accuracy: 0.5463 - top_10_categorical_accuracy: 0.7015 - top_20_categorical_accuracy: 0.8517 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0310 - top_5_categorical_accuracy_cp2: 0.7373 - top_5_categorical_accuracy_cp3: 0.9669 - top_5_categorical_accuracy_cp4: 0.9972 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6292 - top_10_categorical_accuracy_cp0: 0.0122 - top_10_categorical_accuracy_cp1: 0.5542 - top_10_categorical_accuracy_cp2: 0.9915 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8080 - top_20_categorical_accuracy_cp0: 0.3495 - top_20_categorical_accuracy_cp1: 0.9381 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2353 - top_20_categorical_accuracy_p4: 0.9577    5/7 [====================>.........] - ETA: 0s - loss: 0.1330 - categorical_accuracy: 0.1777 - top_5_categorical_accuracy: 0.5567 - top_10_categorical_accuracy: 0.7127 - top_20_categorical_accuracy: 0.8539 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0499 - top_5_categorical_accuracy_cp2: 0.7328 - top_5_categorical_accuracy_cp3: 0.9699 - top_5_categorical_accuracy_cp4: 0.9917 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6378 - top_10_categorical_accuracy_cp0: 0.0095 - top_10_categorical_accuracy_cp1: 0.5712 - top_10_categorical_accuracy_cp2: 0.9898 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8165 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9464 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2019 - top_20_categorical_accuracy_p4: 0.95957/7 [==============================] - ETA: 0s - loss: 0.1317 - categorical_accuracy: 0.1761 - top_5_categorical_accuracy: 0.5634 - top_10_categorical_accuracy: 0.7185 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0627 - top_5_categorical_accuracy_cp2: 0.7263 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6420 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5703 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8187 - top_20_categorical_accuracy_cp0: 0.3306 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9617DEBUG:root:Model metric val_loss improved from 0.176303 to 0.172752
7/7 [==============================] - 1s 109ms/step - loss: 0.1317 - categorical_accuracy: 0.1761 - top_5_categorical_accuracy: 0.5634 - top_10_categorical_accuracy: 0.7185 - top_20_categorical_accuracy: 0.8603 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0627 - top_5_categorical_accuracy_cp2: 0.7263 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9934 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6420 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.5703 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8187 - top_20_categorical_accuracy_cp0: 0.3306 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9617 - val_loss: 0.1728 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3324 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1159 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6082 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.1733 - top_5_categorical_accuracy: 0.5066 - top_10_categorical_accuracy: 0.6911 - top_20_categorical_accuracy: 0.8493 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0709 - top_5_categorical_accuracy_cp2: 0.6452 - top_5_categorical_accuracy_cp3: 0.9561 - top_5_categorical_accuracy_cp4: 0.9737 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5736 - top_10_categorical_accuracy_cp0: 0.0175 - top_10_categorical_accuracy_cp1: 0.6220 - top_10_categorical_accuracy_cp2: 0.9355 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7825 - top_20_categorical_accuracy_cp0: 0.3421 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2195 - top_20_categorical_accuracy_p4: 0.94243/7 [===========>..................] - ETA: 0s - loss: 0.1288 - categorical_accuracy: 0.1734 - top_5_categorical_accuracy: 0.5405 - top_10_categorical_accuracy: 0.7171 - top_20_categorical_accuracy: 0.8639 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0794 - top_5_categorical_accuracy_cp2: 0.6201 - top_5_categorical_accuracy_cp3: 0.9674 - top_5_categorical_accuracy_cp4: 0.9836 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6100 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.6206 - top_10_categorical_accuracy_cp2: 0.9520 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8093 - top_20_categorical_accuracy_cp0: 0.3495 - top_20_categorical_accuracy_cp1: 0.9588 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2018 - top_20_categorical_accuracy_p4: 0.95865/7 [====================>.........] - ETA: 0s - loss: 0.1273 - categorical_accuracy: 0.1755 - top_5_categorical_accuracy: 0.5554 - top_10_categorical_accuracy: 0.7263 - top_20_categorical_accuracy: 0.8675 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0923 - top_5_categorical_accuracy_cp2: 0.6336 - top_5_categorical_accuracy_cp3: 0.9731 - top_5_categorical_accuracy_cp4: 0.9841 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6319 - top_10_categorical_accuracy_cp0: 0.0079 - top_10_categorical_accuracy_cp1: 0.6310 - top_10_categorical_accuracy_cp2: 0.9593 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8263 - top_20_categorical_accuracy_cp0: 0.3511 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2476 - top_20_categorical_accuracy_p4: 0.96457/7 [==============================] - ETA: 0s - loss: 0.1272 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.5562 - top_10_categorical_accuracy: 0.7269 - top_20_categorical_accuracy: 0.8657 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0887 - top_5_categorical_accuracy_cp2: 0.6399 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9867 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6338 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.6315 - top_10_categorical_accuracy_cp2: 0.9650 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8280 - top_20_categorical_accuracy_cp0: 0.3485 - top_20_categorical_accuracy_cp1: 0.9602 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9639    DEBUG:root:Model metric val_loss improved from 0.172752 to 0.170271
7/7 [==============================] - 1s 111ms/step - loss: 0.1272 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.5562 - top_10_categorical_accuracy: 0.7269 - top_20_categorical_accuracy: 0.8657 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0887 - top_5_categorical_accuracy_cp2: 0.6399 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9867 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6338 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.6315 - top_10_categorical_accuracy_cp2: 0.9650 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.8280 - top_20_categorical_accuracy_cp0: 0.3485 - top_20_categorical_accuracy_cp1: 0.9602 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9639 - val_loss: 0.1703 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2986 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.8333 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5464 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.2046 - top_5_categorical_accuracy: 0.6176 - top_10_categorical_accuracy: 0.7495 - top_20_categorical_accuracy: 0.8642 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1250 - top_5_categorical_accuracy_cp2: 0.8391 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6991 - top_10_categorical_accuracy_cp0: 0.0109 - top_10_categorical_accuracy_cp1: 0.6346 - top_10_categorical_accuracy_cp2: 0.9770 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8485 - top_20_categorical_accuracy_cp0: 0.2935 - top_20_categorical_accuracy_cp1: 0.9423 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1915 - top_20_categorical_accuracy_p4: 0.95893/7 [===========>..................] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.2055 - top_5_categorical_accuracy: 0.6221 - top_10_categorical_accuracy: 0.7500 - top_20_categorical_accuracy: 0.8632 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1667 - top_5_categorical_accuracy_cp2: 0.8427 - top_5_categorical_accuracy_cp3: 0.9788 - top_5_categorical_accuracy_cp4: 0.9794 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7133 - top_10_categorical_accuracy_cp0: 0.0103 - top_10_categorical_accuracy_cp1: 0.6531 - top_10_categorical_accuracy_cp2: 0.9925 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8600 - top_20_categorical_accuracy_cp0: 0.3048 - top_20_categorical_accuracy_cp1: 0.9592 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2143 - top_20_categorical_accuracy_p4: 0.96795/7 [====================>.........] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.2029 - top_5_categorical_accuracy: 0.6132 - top_10_categorical_accuracy: 0.7472 - top_20_categorical_accuracy: 0.8645 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2151 - top_5_categorical_accuracy_cp2: 0.8443 - top_5_categorical_accuracy_cp3: 0.9802 - top_5_categorical_accuracy_cp4: 0.9742 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7004 - top_10_categorical_accuracy_cp0: 0.0177 - top_10_categorical_accuracy_cp1: 0.7000 - top_10_categorical_accuracy_cp2: 0.9903 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0047 - top_10_categorical_accuracy_p4: 0.8530 - top_20_categorical_accuracy_cp0: 0.3379 - top_20_categorical_accuracy_cp1: 0.9642 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2347 - top_20_categorical_accuracy_p4: 0.9657    7/7 [==============================] - ETA: 0s - loss: 0.1226 - categorical_accuracy: 0.2050 - top_5_categorical_accuracy: 0.6161 - top_10_categorical_accuracy: 0.7439 - top_20_categorical_accuracy: 0.8694 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2248 - top_5_categorical_accuracy_cp2: 0.8621 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7021 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.6911 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9973 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8469 - top_20_categorical_accuracy_cp0: 0.3598 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.9685DEBUG:root:Model metric val_loss improved from 0.170271 to 0.164233
7/7 [==============================] - 1s 114ms/step - loss: 0.1226 - categorical_accuracy: 0.2050 - top_5_categorical_accuracy: 0.6161 - top_10_categorical_accuracy: 0.7439 - top_20_categorical_accuracy: 0.8694 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2248 - top_5_categorical_accuracy_cp2: 0.8621 - top_5_categorical_accuracy_cp3: 0.9837 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7021 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.6911 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9973 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8469 - top_20_categorical_accuracy_cp0: 0.3598 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.9685 - val_loss: 0.1642 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3042 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5567 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1254 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.5917 - top_10_categorical_accuracy: 0.7410 - top_20_categorical_accuracy: 0.8733 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3136 - top_5_categorical_accuracy_cp2: 0.9367 - top_5_categorical_accuracy_cp3: 0.9619 - top_5_categorical_accuracy_cp4: 0.9352 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6879 - top_10_categorical_accuracy_cp0: 0.0672 - top_10_categorical_accuracy_cp1: 0.7966 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9905 - top_10_categorical_accuracy_cp4: 0.9907 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8571 - top_20_categorical_accuracy_cp0: 0.4454 - top_20_categorical_accuracy_cp1: 0.9915 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2745 - top_20_categorical_accuracy_p4: 0.98463/7 [===========>..................] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.2142 - top_5_categorical_accuracy: 0.6293 - top_10_categorical_accuracy: 0.7598 - top_20_categorical_accuracy: 0.8758 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3293 - top_5_categorical_accuracy_cp2: 0.9262 - top_5_categorical_accuracy_cp3: 0.9666 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7190 - top_10_categorical_accuracy_cp0: 0.0698 - top_10_categorical_accuracy_cp1: 0.7605 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9939 - top_10_categorical_accuracy_cp4: 0.9916 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0500 - top_10_categorical_accuracy_p4: 0.8639 - top_20_categorical_accuracy_cp0: 0.4000 - top_20_categorical_accuracy_cp1: 0.9790 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3083 - top_20_categorical_accuracy_p4: 0.97395/7 [====================>.........] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2133 - top_5_categorical_accuracy: 0.6369 - top_10_categorical_accuracy: 0.7711 - top_20_categorical_accuracy: 0.8776 - top_5_categorical_accuracy_cp0: 0.0039 - top_5_categorical_accuracy_cp1: 0.3505 - top_5_categorical_accuracy_cp2: 0.9023 - top_5_categorical_accuracy_cp3: 0.9606 - top_5_categorical_accuracy_cp4: 0.9559 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0048 - top_5_categorical_accuracy_p4: 0.7269 - top_10_categorical_accuracy_cp0: 0.1029 - top_10_categorical_accuracy_cp1: 0.7706 - top_10_categorical_accuracy_cp2: 0.9950 - top_10_categorical_accuracy_cp3: 0.9875 - top_10_categorical_accuracy_cp4: 0.9902 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1000 - top_10_categorical_accuracy_p4: 0.8715 - top_20_categorical_accuracy_cp0: 0.4078 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3000 - top_20_categorical_accuracy_p4: 0.9748        7/7 [==============================] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.2134 - top_5_categorical_accuracy: 0.6416 - top_10_categorical_accuracy: 0.7765 - top_20_categorical_accuracy: 0.8807 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.3609 - top_5_categorical_accuracy_cp2: 0.8971 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.7303 - top_10_categorical_accuracy_cp0: 0.1135 - top_10_categorical_accuracy_cp1: 0.7768 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9867 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1176 - top_10_categorical_accuracy_p4: 0.8741 - top_20_categorical_accuracy_cp0: 0.4165 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.9764DEBUG:root:Model metric val_loss improved from 0.164233 to 0.163574
7/7 [==============================] - 1s 111ms/step - loss: 0.1197 - categorical_accuracy: 0.2134 - top_5_categorical_accuracy: 0.6416 - top_10_categorical_accuracy: 0.7765 - top_20_categorical_accuracy: 0.8807 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.3609 - top_5_categorical_accuracy_cp2: 0.8971 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.7303 - top_10_categorical_accuracy_cp0: 0.1135 - top_10_categorical_accuracy_cp1: 0.7768 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9867 - top_10_categorical_accuracy_cp4: 0.9894 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1176 - top_10_categorical_accuracy_p4: 0.8741 - top_20_categorical_accuracy_cp0: 0.4165 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.9764 - val_loss: 0.1636 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3577 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6546 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1222 - categorical_accuracy: 0.2079 - top_5_categorical_accuracy: 0.6276 - top_10_categorical_accuracy: 0.7524 - top_20_categorical_accuracy: 0.8790 - top_5_categorical_accuracy_cp0: 0.0180 - top_5_categorical_accuracy_cp1: 0.4464 - top_5_categorical_accuracy_cp2: 0.8395 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7155 - top_10_categorical_accuracy_cp0: 0.1441 - top_10_categorical_accuracy_cp1: 0.7768 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9469 - top_10_categorical_accuracy_cp4: 0.9732 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0476 - top_10_categorical_accuracy_p4: 0.8534 - top_20_categorical_accuracy_cp0: 0.4505 - top_20_categorical_accuracy_cp1: 0.9821 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2857 - top_20_categorical_accuracy_p4: 0.97633/7 [===========>..................] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.2132 - top_5_categorical_accuracy: 0.6404 - top_10_categorical_accuracy: 0.7760 - top_20_categorical_accuracy: 0.8826 - top_5_categorical_accuracy_cp0: 0.0216 - top_5_categorical_accuracy_cp1: 0.4515 - top_5_categorical_accuracy_cp2: 0.8565 - top_5_categorical_accuracy_cp3: 0.9500 - top_5_categorical_accuracy_cp4: 0.9391 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0229 - top_5_categorical_accuracy_p4: 0.7281 - top_10_categorical_accuracy_cp0: 0.2099 - top_10_categorical_accuracy_cp1: 0.7879 - top_10_categorical_accuracy_cp2: 0.9739 - top_10_categorical_accuracy_cp3: 0.9735 - top_10_categorical_accuracy_cp4: 0.9612 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1221 - top_10_categorical_accuracy_p4: 0.8734 - top_20_categorical_accuracy_cp0: 0.4660 - top_20_categorical_accuracy_cp1: 0.9697 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9917 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2901 - top_20_categorical_accuracy_p4: 0.9791    5/7 [====================>.........] - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.2110 - top_5_categorical_accuracy: 0.6502 - top_10_categorical_accuracy: 0.7882 - top_20_categorical_accuracy: 0.8829 - top_5_categorical_accuracy_cp0: 0.0214 - top_5_categorical_accuracy_cp1: 0.4385 - top_5_categorical_accuracy_cp2: 0.8589 - top_5_categorical_accuracy_cp3: 0.9531 - top_5_categorical_accuracy_cp4: 0.9517 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0187 - top_5_categorical_accuracy_p4: 0.7401 - top_10_categorical_accuracy_cp0: 0.1988 - top_10_categorical_accuracy_cp1: 0.8037 - top_10_categorical_accuracy_cp2: 0.9773 - top_10_categorical_accuracy_cp3: 0.9783 - top_10_categorical_accuracy_cp4: 0.9710 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1495 - top_10_categorical_accuracy_p4: 0.8855 - top_20_categorical_accuracy_cp0: 0.4503 - top_20_categorical_accuracy_cp1: 0.9615 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9919 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3084 - top_20_categorical_accuracy_p4: 0.97877/7 [==============================] - ETA: 0s - loss: 0.1179 - categorical_accuracy: 0.2112 - top_5_categorical_accuracy: 0.6522 - top_10_categorical_accuracy: 0.7919 - top_20_categorical_accuracy: 0.8867 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4343 - top_5_categorical_accuracy_cp2: 0.8580 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0157 - top_5_categorical_accuracy_p4: 0.7418 - top_10_categorical_accuracy_cp0: 0.2026 - top_10_categorical_accuracy_cp1: 0.8119 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9734 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.8888 - top_20_categorical_accuracy_cp0: 0.4603 - top_20_categorical_accuracy_cp1: 0.9664 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.9810DEBUG:root:Model metric val_loss improved from 0.163574 to 0.163350
7/7 [==============================] - 1s 109ms/step - loss: 0.1179 - categorical_accuracy: 0.2112 - top_5_categorical_accuracy: 0.6522 - top_10_categorical_accuracy: 0.7919 - top_20_categorical_accuracy: 0.8867 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4343 - top_5_categorical_accuracy_cp2: 0.8580 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0157 - top_5_categorical_accuracy_p4: 0.7418 - top_10_categorical_accuracy_cp0: 0.2026 - top_10_categorical_accuracy_cp1: 0.8119 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9734 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.8888 - top_20_categorical_accuracy_cp0: 0.4603 - top_20_categorical_accuracy_cp1: 0.9664 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.9810 - val_loss: 0.1634 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6535 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3068 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3145 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1130 - categorical_accuracy: 0.1943 - top_5_categorical_accuracy: 0.6914 - top_10_categorical_accuracy: 0.8362 - top_20_categorical_accuracy: 0.9257 - top_5_categorical_accuracy_cp0: 0.0241 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.8462 - top_5_categorical_accuracy_cp3: 0.9469 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7642 - top_10_categorical_accuracy_cp0: 0.2410 - top_10_categorical_accuracy_cp1: 0.8947 - top_10_categorical_accuracy_cp2: 0.9744 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2222 - top_10_categorical_accuracy_p4: 0.9074 - top_20_categorical_accuracy_cp0: 0.5542 - top_20_categorical_accuracy_cp1: 0.9825 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3611 - top_20_categorical_accuracy_p4: 0.99584/7 [================>.............] - ETA: 0s - loss: 0.1171 - categorical_accuracy: 0.2034 - top_5_categorical_accuracy: 0.6621 - top_10_categorical_accuracy: 0.7975 - top_20_categorical_accuracy: 0.8969 - top_5_categorical_accuracy_cp0: 0.0201 - top_5_categorical_accuracy_cp1: 0.4578 - top_5_categorical_accuracy_cp2: 0.8658 - top_5_categorical_accuracy_cp3: 0.9581 - top_5_categorical_accuracy_cp4: 0.9643 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0059 - top_5_categorical_accuracy_p4: 0.7528 - top_10_categorical_accuracy_cp0: 0.2286 - top_10_categorical_accuracy_cp1: 0.8044 - top_10_categorical_accuracy_cp2: 0.9765 - top_10_categorical_accuracy_cp3: 0.9736 - top_10_categorical_accuracy_cp4: 0.9762 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1882 - top_10_categorical_accuracy_p4: 0.8902 - top_20_categorical_accuracy_cp0: 0.5000 - top_20_categorical_accuracy_cp1: 0.9711 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9940 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3529 - top_20_categorical_accuracy_p4: 0.9881    6/7 [========================>.....] - ETA: 0s - loss: 0.1176 - categorical_accuracy: 0.2026 - top_5_categorical_accuracy: 0.6528 - top_10_categorical_accuracy: 0.7939 - top_20_categorical_accuracy: 0.8973 - top_5_categorical_accuracy_cp0: 0.0262 - top_5_categorical_accuracy_cp1: 0.4303 - top_5_categorical_accuracy_cp2: 0.8654 - top_5_categorical_accuracy_cp3: 0.9567 - top_5_categorical_accuracy_cp4: 0.9490 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7435 - top_10_categorical_accuracy_cp0: 0.2357 - top_10_categorical_accuracy_cp1: 0.8111 - top_10_categorical_accuracy_cp2: 0.9710 - top_10_categorical_accuracy_cp3: 0.9701 - top_10_categorical_accuracy_cp4: 0.9638 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1969 - top_10_categorical_accuracy_p4: 0.8866 - top_20_categorical_accuracy_cp0: 0.5188 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9879 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3898 - top_20_categorical_accuracy_p4: 0.98667/7 [==============================] - 1s 103ms/step - loss: 0.1176 - categorical_accuracy: 0.2021 - top_5_categorical_accuracy: 0.6529 - top_10_categorical_accuracy: 0.7944 - top_20_categorical_accuracy: 0.8974 - top_5_categorical_accuracy_cp0: 0.0259 - top_5_categorical_accuracy_cp1: 0.4312 - top_5_categorical_accuracy_cp2: 0.8663 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7436 - top_10_categorical_accuracy_cp0: 0.2366 - top_10_categorical_accuracy_cp1: 0.8119 - top_10_categorical_accuracy_cp2: 0.9712 - top_10_categorical_accuracy_cp3: 0.9704 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2000 - top_10_categorical_accuracy_p4: 0.8870 - top_20_categorical_accuracy_cp0: 0.5186 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9880 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3922 - top_20_categorical_accuracy_p4: 0.9868 - val_loss: 0.1640 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6845 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3693 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.163350 from epoch 8
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.85it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1525.91it/s]
INFO:root:Finished run 06ab6aa45c924a1b9063ff2e8b56b526
2023-05-24 20:20:33.744630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:20:34.263626: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:20:34.263694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:20:34.263701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 45645b6d0b584b14a28d21f154b1c282
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12083.24it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13410.73it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13206.34it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24319.51it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:20:36.580340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.580531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.581352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.581496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.581628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.581766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.582169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:20:36.705791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.706005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.706158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.706289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.706416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:36.706542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.279312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.279504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.279660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.279816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.279947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.280063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:20:38.280398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:20:38.280504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12686.67it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13485.15it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13468.95it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24808.58it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 286.78it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 58/154 [00:00<00:00, 287.53it/s]Loading hierarchy for column coarse_log_cluster_path:  57%|█████▋    | 88/154 [00:00<00:00, 290.53it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 118/154 [00:00<00:00, 290.41it/s]Loading hierarchy for column coarse_log_cluster_path:  96%|█████████▌| 148/154 [00:00<00:00, 290.33it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 289.81it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:52,  7.65it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5171.03it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 40170.69it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/198 [00:00<?, ?it/s]Initializing gram_embedding connections:  41%|████▏     | 82/198 [00:00<00:00, 808.42it/s]Initializing gram_embedding connections:  82%|████████▏ | 163/198 [00:00<00:00, 395.07it/s]Initializing gram_embedding connections: 100%|██████████| 198/198 [00:00<00:00, 354.95it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.09it/s]Calculating percentile frequencies...: 7it [00:00,  7.62it/s]
2023-05-24 20:20:42.930146: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:21:15.909969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:21:16.501550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:21:16.616369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:21:17.046164: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f9328009ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:21:17.046223: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:21:17.046233: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:21:17.051866: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:21:17.159501: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 35s 35s/step - loss: 0.1928 - categorical_accuracy: 0.0057 - top_5_categorical_accuracy: 0.0421 - top_10_categorical_accuracy: 0.1015 - top_20_categorical_accuracy: 0.2107 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.0505 - top_5_categorical_accuracy_cp2: 0.0119 - top_5_categorical_accuracy_cp3: 0.0424 - top_5_categorical_accuracy_cp4: 0.0574 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.1053 - top_5_categorical_accuracy_p3: 0.0526 - top_5_categorical_accuracy_p4: 0.0392 - top_10_categorical_accuracy_cp0: 0.0808 - top_10_categorical_accuracy_cp1: 0.0606 - top_10_categorical_accuracy_cp2: 0.1071 - top_10_categorical_accuracy_cp3: 0.0763 - top_10_categorical_accuracy_cp4: 0.1721 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.1053 - top_10_categorical_accuracy_p3: 0.1316 - top_10_categorical_accuracy_p4: 0.1002 - top_20_categorical_accuracy_cp0: 0.1414 - top_20_categorical_accuracy_cp1: 0.1414 - top_20_categorical_accuracy_cp2: 0.2619 - top_20_categorical_accuracy_cp3: 0.1610 - top_20_categorical_accuracy_cp4: 0.3361 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2632 - top_20_categorical_accuracy_p3: 0.1842 - top_20_categorical_accuracy_p4: 0.2135      3/Unknown - 35s 32ms/step - loss: 0.1930 - categorical_accuracy: 0.0737 - top_5_categorical_accuracy: 0.2511 - top_10_categorical_accuracy: 0.3497 - top_20_categorical_accuracy: 0.4647 - top_5_categorical_accuracy_cp0: 0.0239 - top_5_categorical_accuracy_cp1: 0.0585 - top_5_categorical_accuracy_cp2: 0.2552 - top_5_categorical_accuracy_cp3: 0.3625 - top_5_categorical_accuracy_cp4: 0.4883 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0426 - top_5_categorical_accuracy_p3: 0.0345 - top_5_categorical_accuracy_p4: 0.2803 - top_10_categorical_accuracy_cp0: 0.0751 - top_10_categorical_accuracy_cp1: 0.1046 - top_10_categorical_accuracy_cp2: 0.4310 - top_10_categorical_accuracy_cp3: 0.4924 - top_10_categorical_accuracy_cp4: 0.5922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1250 - top_10_categorical_accuracy_p2: 0.0851 - top_10_categorical_accuracy_p3: 0.1121 - top_10_categorical_accuracy_p4: 0.3826 - top_20_categorical_accuracy_cp0: 0.1672 - top_20_categorical_accuracy_cp1: 0.1908 - top_20_categorical_accuracy_cp2: 0.5983 - top_20_categorical_accuracy_cp3: 0.5982 - top_20_categorical_accuracy_cp4: 0.7247 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1250 - top_20_categorical_accuracy_p2: 0.2340 - top_20_categorical_accuracy_p3: 0.2069 - top_20_categorical_accuracy_p4: 0.5000             5/Unknown - 35s 35ms/step - loss: 0.1930 - categorical_accuracy: 0.1034 - top_5_categorical_accuracy: 0.3599 - top_10_categorical_accuracy: 0.4496 - top_20_categorical_accuracy: 0.5538 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.0399 - top_5_categorical_accuracy_cp2: 0.4491 - top_5_categorical_accuracy_cp3: 0.5881 - top_5_categorical_accuracy_cp4: 0.6694 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0395 - top_5_categorical_accuracy_p3: 0.0332 - top_5_categorical_accuracy_p4: 0.4072 - top_10_categorical_accuracy_cp0: 0.0595 - top_10_categorical_accuracy_cp1: 0.1198 - top_10_categorical_accuracy_cp2: 0.6266 - top_10_categorical_accuracy_cp3: 0.6906 - top_10_categorical_accuracy_cp4: 0.7452 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0714 - top_10_categorical_accuracy_p2: 0.0921 - top_10_categorical_accuracy_p3: 0.0900 - top_10_categorical_accuracy_p4: 0.5020 - top_20_categorical_accuracy_cp0: 0.1536 - top_20_categorical_accuracy_cp1: 0.2777 - top_20_categorical_accuracy_cp2: 0.7493 - top_20_categorical_accuracy_cp3: 0.7608 - top_20_categorical_accuracy_cp4: 0.8290 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.2368 - top_20_categorical_accuracy_p3: 0.1896 - top_20_categorical_accuracy_p4: 0.6063      7/Unknown - 35s 35ms/step - loss: 0.1923 - categorical_accuracy: 0.1142 - top_5_categorical_accuracy: 0.4011 - top_10_categorical_accuracy: 0.4912 - top_20_categorical_accuracy: 0.5876 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.0398 - top_5_categorical_accuracy_cp2: 0.5226 - top_5_categorical_accuracy_cp3: 0.6509 - top_5_categorical_accuracy_cp4: 0.7238 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0353 - top_5_categorical_accuracy_p4: 0.4528 - top_10_categorical_accuracy_cp0: 0.0632 - top_10_categorical_accuracy_cp1: 0.1330 - top_10_categorical_accuracy_cp2: 0.6996 - top_10_categorical_accuracy_cp3: 0.7456 - top_10_categorical_accuracy_cp4: 0.7902 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0824 - top_10_categorical_accuracy_p3: 0.0980 - top_10_categorical_accuracy_p4: 0.5476 - top_20_categorical_accuracy_cp0: 0.1588 - top_20_categorical_accuracy_cp1: 0.2966 - top_20_categorical_accuracy_cp2: 0.8025 - top_20_categorical_accuracy_cp3: 0.8033 - top_20_categorical_accuracy_cp4: 0.8592 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.2353 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.64232023-05-24 20:21:18.171807: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column fine_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.194963
7/7 [==============================] - 53s 3s/step - loss: 0.1923 - categorical_accuracy: 0.1142 - top_5_categorical_accuracy: 0.4011 - top_10_categorical_accuracy: 0.4912 - top_20_categorical_accuracy: 0.5876 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.0398 - top_5_categorical_accuracy_cp2: 0.5226 - top_5_categorical_accuracy_cp3: 0.6509 - top_5_categorical_accuracy_cp4: 0.7238 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0353 - top_5_categorical_accuracy_p4: 0.4528 - top_10_categorical_accuracy_cp0: 0.0632 - top_10_categorical_accuracy_cp1: 0.1330 - top_10_categorical_accuracy_cp2: 0.6996 - top_10_categorical_accuracy_cp3: 0.7456 - top_10_categorical_accuracy_cp4: 0.7902 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0824 - top_10_categorical_accuracy_p3: 0.0980 - top_10_categorical_accuracy_p4: 0.5476 - top_20_categorical_accuracy_cp0: 0.1588 - top_20_categorical_accuracy_cp1: 0.2966 - top_20_categorical_accuracy_cp2: 0.8025 - top_20_categorical_accuracy_cp3: 0.8033 - top_20_categorical_accuracy_cp4: 0.8592 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.2353 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.6423 - val_loss: 0.1950 - val_categorical_accuracy: 0.1070 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4169 - val_top_20_categorical_accuracy: 0.6225 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0568 - val_top_10_categorical_accuracy_cp1: 0.4058 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0806 - val_top_10_categorical_accuracy_p4: 0.7113 - val_top_20_categorical_accuracy_cp0: 0.2727 - val_top_20_categorical_accuracy_cp1: 0.9130 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.4583 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.2984 - val_top_20_categorical_accuracy_p4: 0.8918
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1883 - categorical_accuracy: 0.1499 - top_5_categorical_accuracy: 0.5712 - top_10_categorical_accuracy: 0.6509 - top_20_categorical_accuracy: 0.7495 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0090 - top_5_categorical_accuracy_cp2: 0.8052 - top_5_categorical_accuracy_cp3: 0.9658 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6459 - top_10_categorical_accuracy_cp0: 0.0206 - top_10_categorical_accuracy_cp1: 0.1982 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7339 - top_20_categorical_accuracy_cp0: 0.1649 - top_20_categorical_accuracy_cp1: 0.5405 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1250 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.1892 - top_20_categorical_accuracy_p4: 0.82833/7 [===========>..................] - ETA: 0s - loss: 0.1862 - categorical_accuracy: 0.1459 - top_5_categorical_accuracy: 0.5514 - top_10_categorical_accuracy: 0.6428 - top_20_categorical_accuracy: 0.7367 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0032 - top_5_categorical_accuracy_cp2: 0.7458 - top_5_categorical_accuracy_cp3: 0.9707 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6380 - top_10_categorical_accuracy_cp0: 0.0369 - top_10_categorical_accuracy_cp1: 0.2051 - top_10_categorical_accuracy_cp2: 0.9917 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.1000 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0448 - top_10_categorical_accuracy_p4: 0.7386 - top_20_categorical_accuracy_cp0: 0.1846 - top_20_categorical_accuracy_cp1: 0.5192 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1000 - top_20_categorical_accuracy_p1: 0.1500 - top_20_categorical_accuracy_p2: 0.0400 - top_20_categorical_accuracy_p3: 0.1866 - top_20_categorical_accuracy_p4: 0.8297        5/7 [====================>.........] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.1443 - top_5_categorical_accuracy: 0.5579 - top_10_categorical_accuracy: 0.6588 - top_20_categorical_accuracy: 0.7563 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0019 - top_5_categorical_accuracy_cp2: 0.7299 - top_5_categorical_accuracy_cp3: 0.9748 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6370 - top_10_categorical_accuracy_cp0: 0.0334 - top_10_categorical_accuracy_cp1: 0.2424 - top_10_categorical_accuracy_cp2: 0.9903 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0667 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0133 - top_10_categorical_accuracy_p3: 0.0337 - top_10_categorical_accuracy_p4: 0.7483 - top_20_categorical_accuracy_cp0: 0.1729 - top_20_categorical_accuracy_cp1: 0.5852 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.2000 - top_20_categorical_accuracy_p1: 0.1071 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.1635 - top_20_categorical_accuracy_p4: 0.8439    7/7 [==============================] - ETA: 0s - loss: 0.1809 - categorical_accuracy: 0.1403 - top_5_categorical_accuracy: 0.5518 - top_10_categorical_accuracy: 0.6623 - top_20_categorical_accuracy: 0.7637 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0046 - top_5_categorical_accuracy_cp2: 0.7099 - top_5_categorical_accuracy_cp3: 0.9719 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6288 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.2661 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0235 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7507 - top_20_categorical_accuracy_cp0: 0.1864 - top_20_categorical_accuracy_cp1: 0.6162 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1875 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.1647 - top_20_categorical_accuracy_p4: 0.8498    DEBUG:root:Model metric val_loss improved from 0.194963 to 0.184972
7/7 [==============================] - 1s 112ms/step - loss: 0.1809 - categorical_accuracy: 0.1403 - top_5_categorical_accuracy: 0.5518 - top_10_categorical_accuracy: 0.6623 - top_20_categorical_accuracy: 0.7637 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0046 - top_5_categorical_accuracy_cp2: 0.7099 - top_5_categorical_accuracy_cp3: 0.9719 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6288 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.2661 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0235 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7507 - top_20_categorical_accuracy_cp0: 0.1864 - top_20_categorical_accuracy_cp1: 0.6162 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1875 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.1647 - top_20_categorical_accuracy_p4: 0.8498 - val_loss: 0.1850 - val_categorical_accuracy: 0.0085 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4141 - val_top_20_categorical_accuracy: 0.6648 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5362 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7577 - val_top_20_categorical_accuracy_cp0: 0.3239 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.3333 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3952 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.1274 - top_5_categorical_accuracy: 0.5627 - top_10_categorical_accuracy: 0.7034 - top_20_categorical_accuracy: 0.8080 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0099 - top_5_categorical_accuracy_cp2: 0.6429 - top_5_categorical_accuracy_cp3: 0.9655 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6311 - top_10_categorical_accuracy_cp0: 0.0208 - top_10_categorical_accuracy_cp1: 0.3960 - top_10_categorical_accuracy_cp2: 0.9881 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0909 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7846 - top_20_categorical_accuracy_cp0: 0.2292 - top_20_categorical_accuracy_cp1: 0.7327 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1818 - top_20_categorical_accuracy_p3: 0.2432 - top_20_categorical_accuracy_p4: 0.88273/7 [===========>..................] - ETA: 0s - loss: 0.1499 - categorical_accuracy: 0.1181 - top_5_categorical_accuracy: 0.5276 - top_10_categorical_accuracy: 0.6737 - top_20_categorical_accuracy: 0.7778 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0061 - top_5_categorical_accuracy_cp2: 0.6016 - top_5_categorical_accuracy_cp3: 0.9701 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6022 - top_10_categorical_accuracy_cp0: 0.0161 - top_10_categorical_accuracy_cp1: 0.3731 - top_10_categorical_accuracy_cp2: 0.9878 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0233 - top_10_categorical_accuracy_p3: 0.0159 - top_10_categorical_accuracy_p4: 0.7667 - top_20_categorical_accuracy_cp0: 0.1865 - top_20_categorical_accuracy_cp1: 0.7034 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0465 - top_20_categorical_accuracy_p3: 0.1905 - top_20_categorical_accuracy_p4: 0.8674        5/7 [====================>.........] - ETA: 0s - loss: 0.1470 - categorical_accuracy: 0.1231 - top_5_categorical_accuracy: 0.5373 - top_10_categorical_accuracy: 0.6867 - top_20_categorical_accuracy: 0.7954 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0055 - top_5_categorical_accuracy_cp2: 0.6106 - top_5_categorical_accuracy_cp3: 0.9748 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6101 - top_10_categorical_accuracy_cp0: 0.0199 - top_10_categorical_accuracy_cp1: 0.4055 - top_10_categorical_accuracy_cp2: 0.9874 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0137 - top_10_categorical_accuracy_p3: 0.0249 - top_10_categorical_accuracy_p4: 0.7772 - top_20_categorical_accuracy_cp0: 0.1909 - top_20_categorical_accuracy_cp1: 0.7615 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0667 - top_20_categorical_accuracy_p1: 0.0833 - top_20_categorical_accuracy_p2: 0.0548 - top_20_categorical_accuracy_p3: 0.1542 - top_20_categorical_accuracy_p4: 0.88667/7 [==============================] - ETA: 0s - loss: 0.1472 - categorical_accuracy: 0.1205 - top_5_categorical_accuracy: 0.5367 - top_10_categorical_accuracy: 0.6871 - top_20_categorical_accuracy: 0.8016 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0046 - top_5_categorical_accuracy_cp2: 0.6049 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6116 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.4098 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.7808 - top_20_categorical_accuracy_cp0: 0.2075 - top_20_categorical_accuracy_cp1: 0.7813 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.1686 - top_20_categorical_accuracy_p4: 0.8948DEBUG:root:Model metric val_loss improved from 0.184972 to 0.179417
7/7 [==============================] - 1s 110ms/step - loss: 0.1472 - categorical_accuracy: 0.1205 - top_5_categorical_accuracy: 0.5367 - top_10_categorical_accuracy: 0.6871 - top_20_categorical_accuracy: 0.8016 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0046 - top_5_categorical_accuracy_cp2: 0.6049 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6116 - top_10_categorical_accuracy_cp0: 0.0178 - top_10_categorical_accuracy_cp1: 0.4098 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.7808 - top_20_categorical_accuracy_cp0: 0.2075 - top_20_categorical_accuracy_cp1: 0.7813 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.1686 - top_20_categorical_accuracy_p4: 0.8948 - val_loss: 0.1794 - val_categorical_accuracy: 0.0197 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1301 - categorical_accuracy: 0.1322 - top_5_categorical_accuracy: 0.5862 - top_10_categorical_accuracy: 0.7356 - top_20_categorical_accuracy: 0.8410 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0112 - top_5_categorical_accuracy_cp2: 0.6569 - top_5_categorical_accuracy_cp3: 0.9821 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6609 - top_10_categorical_accuracy_cp0: 0.0110 - top_10_categorical_accuracy_cp1: 0.4607 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8294 - top_20_categorical_accuracy_cp0: 0.2198 - top_20_categorical_accuracy_cp1: 0.8652 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1951 - top_20_categorical_accuracy_p4: 0.93093/7 [===========>..................] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.1340 - top_5_categorical_accuracy: 0.5487 - top_10_categorical_accuracy: 0.7016 - top_20_categorical_accuracy: 0.8306 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0033 - top_5_categorical_accuracy_cp2: 0.6502 - top_5_categorical_accuracy_cp3: 0.9883 - top_5_categorical_accuracy_cp4: 0.9917 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6231 - top_10_categorical_accuracy_cp0: 0.0064 - top_10_categorical_accuracy_cp1: 0.4704 - top_10_categorical_accuracy_cp2: 0.9962 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7968 - top_20_categorical_accuracy_cp0: 0.2564 - top_20_categorical_accuracy_cp1: 0.8816 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1570 - top_20_categorical_accuracy_p4: 0.92965/7 [====================>.........] - ETA: 0s - loss: 0.1346 - categorical_accuracy: 0.1391 - top_5_categorical_accuracy: 0.5480 - top_10_categorical_accuracy: 0.7127 - top_20_categorical_accuracy: 0.8392 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0056 - top_5_categorical_accuracy_cp2: 0.6618 - top_5_categorical_accuracy_cp3: 0.9874 - top_5_categorical_accuracy_cp4: 0.9871 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6241 - top_10_categorical_accuracy_cp0: 0.0139 - top_10_categorical_accuracy_cp1: 0.5160 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8116 - top_20_categorical_accuracy_cp0: 0.2624 - top_20_categorical_accuracy_cp1: 0.9040 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1675 - top_20_categorical_accuracy_p4: 0.94057/7 [==============================] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.1428 - top_5_categorical_accuracy: 0.5474 - top_10_categorical_accuracy: 0.7106 - top_20_categorical_accuracy: 0.8418 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0076 - top_5_categorical_accuracy_cp2: 0.6790 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9841 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6237 - top_10_categorical_accuracy_cp0: 0.0146 - top_10_categorical_accuracy_cp1: 0.5214 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8097 - top_20_categorical_accuracy_cp0: 0.2674 - top_20_categorical_accuracy_cp1: 0.9205 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1490 - top_20_categorical_accuracy_p4: 0.9456DEBUG:root:Model metric val_loss improved from 0.179417 to 0.176380
7/7 [==============================] - 1s 113ms/step - loss: 0.1350 - categorical_accuracy: 0.1428 - top_5_categorical_accuracy: 0.5474 - top_10_categorical_accuracy: 0.7106 - top_20_categorical_accuracy: 0.8418 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0076 - top_5_categorical_accuracy_cp2: 0.6790 - top_5_categorical_accuracy_cp3: 0.9882 - top_5_categorical_accuracy_cp4: 0.9841 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6237 - top_10_categorical_accuracy_cp0: 0.0146 - top_10_categorical_accuracy_cp1: 0.5214 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8097 - top_20_categorical_accuracy_cp0: 0.2674 - top_20_categorical_accuracy_cp1: 0.9205 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1490 - top_20_categorical_accuracy_p4: 0.9456 - val_loss: 0.1764 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5268 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0455 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9639
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1347 - categorical_accuracy: 0.1578 - top_5_categorical_accuracy: 0.5608 - top_10_categorical_accuracy: 0.7167 - top_20_categorical_accuracy: 0.8365 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.8182 - top_5_categorical_accuracy_cp3: 0.9722 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6317 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.5517 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8073 - top_20_categorical_accuracy_cp0: 0.2371 - top_20_categorical_accuracy_cp1: 0.8966 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0789 - top_20_categorical_accuracy_p4: 0.93583/7 [===========>..................] - ETA: 0s - loss: 0.1352 - categorical_accuracy: 0.1546 - top_5_categorical_accuracy: 0.5482 - top_10_categorical_accuracy: 0.6996 - top_20_categorical_accuracy: 0.8346 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0402 - top_5_categorical_accuracy_cp2: 0.7966 - top_5_categorical_accuracy_cp3: 0.9548 - top_5_categorical_accuracy_cp4: 0.9693 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6314 - top_10_categorical_accuracy_cp0: 0.0030 - top_10_categorical_accuracy_cp1: 0.5480 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8058 - top_20_categorical_accuracy_cp0: 0.3009 - top_20_categorical_accuracy_cp1: 0.9040 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1838 - top_20_categorical_accuracy_p4: 0.9431        5/7 [====================>.........] - ETA: 0s - loss: 0.1325 - categorical_accuracy: 0.1564 - top_5_categorical_accuracy: 0.5597 - top_10_categorical_accuracy: 0.7078 - top_20_categorical_accuracy: 0.8489 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0647 - top_5_categorical_accuracy_cp2: 0.7837 - top_5_categorical_accuracy_cp3: 0.9539 - top_5_categorical_accuracy_cp4: 0.9736 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6412 - top_10_categorical_accuracy_cp0: 0.0038 - top_10_categorical_accuracy_cp1: 0.5453 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8108 - top_20_categorical_accuracy_cp0: 0.3168 - top_20_categorical_accuracy_cp1: 0.9279 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1972 - top_20_categorical_accuracy_p4: 0.95427/7 [==============================] - ETA: 0s - loss: 0.1310 - categorical_accuracy: 0.1551 - top_5_categorical_accuracy: 0.5675 - top_10_categorical_accuracy: 0.7153 - top_20_categorical_accuracy: 0.8559 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0810 - top_5_categorical_accuracy_cp2: 0.7757 - top_5_categorical_accuracy_cp3: 0.9512 - top_5_categorical_accuracy_cp4: 0.9761 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6466 - top_10_categorical_accuracy_cp0: 0.0032 - top_10_categorical_accuracy_cp1: 0.5535 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8151 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9373 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9578DEBUG:root:Model metric val_loss improved from 0.176380 to 0.174530
7/7 [==============================] - 1s 109ms/step - loss: 0.1310 - categorical_accuracy: 0.1551 - top_5_categorical_accuracy: 0.5675 - top_10_categorical_accuracy: 0.7153 - top_20_categorical_accuracy: 0.8559 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0810 - top_5_categorical_accuracy_cp2: 0.7757 - top_5_categorical_accuracy_cp3: 0.9512 - top_5_categorical_accuracy_cp4: 0.9761 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6466 - top_10_categorical_accuracy_cp0: 0.0032 - top_10_categorical_accuracy_cp1: 0.5535 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8151 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9373 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9578 - val_loss: 0.1745 - val_categorical_accuracy: 0.0901 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3155 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0290 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5773 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1347 - categorical_accuracy: 0.1337 - top_5_categorical_accuracy: 0.5104 - top_10_categorical_accuracy: 0.6798 - top_20_categorical_accuracy: 0.8512 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1102 - top_5_categorical_accuracy_cp2: 0.6129 - top_5_categorical_accuracy_cp3: 0.9211 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5778 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5591 - top_10_categorical_accuracy_cp2: 0.9839 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7697 - top_20_categorical_accuracy_cp0: 0.3772 - top_20_categorical_accuracy_cp1: 0.9370 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1951 - top_20_categorical_accuracy_p4: 0.94673/7 [===========>..................] - ETA: 0s - loss: 0.1289 - categorical_accuracy: 0.1430 - top_5_categorical_accuracy: 0.5500 - top_10_categorical_accuracy: 0.7101 - top_20_categorical_accuracy: 0.8633 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1088 - top_5_categorical_accuracy_cp2: 0.6681 - top_5_categorical_accuracy_cp3: 0.9407 - top_5_categorical_accuracy_cp4: 0.9918 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6207 - top_10_categorical_accuracy_cp0: 0.0129 - top_10_categorical_accuracy_cp1: 0.5559 - top_10_categorical_accuracy_cp2: 0.9913 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0088 - top_10_categorical_accuracy_p4: 0.8007 - top_20_categorical_accuracy_cp0: 0.3560 - top_20_categorical_accuracy_cp1: 0.9500 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1842 - top_20_categorical_accuracy_p4: 0.9593    5/7 [====================>.........] - ETA: 0s - loss: 0.1272 - categorical_accuracy: 0.1545 - top_5_categorical_accuracy: 0.5679 - top_10_categorical_accuracy: 0.7229 - top_20_categorical_accuracy: 0.8622 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1199 - top_5_categorical_accuracy_cp2: 0.6921 - top_5_categorical_accuracy_cp3: 0.9551 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6462 - top_10_categorical_accuracy_cp0: 0.0099 - top_10_categorical_accuracy_cp1: 0.5867 - top_10_categorical_accuracy_cp2: 0.9949 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0095 - top_10_categorical_accuracy_p4: 0.8216 - top_20_categorical_accuracy_cp0: 0.3373 - top_20_categorical_accuracy_cp1: 0.9520 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1952 - top_20_categorical_accuracy_p4: 0.96327/7 [==============================] - ETA: 0s - loss: 0.1273 - categorical_accuracy: 0.1620 - top_5_categorical_accuracy: 0.5687 - top_10_categorical_accuracy: 0.7219 - top_20_categorical_accuracy: 0.8600 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1131 - top_5_categorical_accuracy_cp2: 0.7078 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6481 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5856 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8219 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1843 - top_20_categorical_accuracy_p4: 0.9632DEBUG:root:Model metric val_loss improved from 0.174530 to 0.169182
7/7 [==============================] - 1s 105ms/step - loss: 0.1273 - categorical_accuracy: 0.1620 - top_5_categorical_accuracy: 0.5687 - top_10_categorical_accuracy: 0.7219 - top_20_categorical_accuracy: 0.8600 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1131 - top_5_categorical_accuracy_cp2: 0.7078 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6481 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5856 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8219 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1843 - top_20_categorical_accuracy_p4: 0.9632 - val_loss: 0.1692 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3099 - val_top_10_categorical_accuracy: 0.3324 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5670 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1159 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6082 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1203 - categorical_accuracy: 0.2008 - top_5_categorical_accuracy: 0.6214 - top_10_categorical_accuracy: 0.7323 - top_20_categorical_accuracy: 0.8834 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1250 - top_5_categorical_accuracy_cp2: 0.8851 - top_5_categorical_accuracy_cp3: 0.9730 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7035 - top_10_categorical_accuracy_cp0: 0.0109 - top_10_categorical_accuracy_cp1: 0.5385 - top_10_categorical_accuracy_cp2: 0.9885 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0213 - top_10_categorical_accuracy_p4: 0.8268 - top_20_categorical_accuracy_cp0: 0.3696 - top_20_categorical_accuracy_cp1: 0.9712 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2553 - top_20_categorical_accuracy_p4: 0.97404/7 [================>.............] - ETA: 0s - loss: 0.1228 - categorical_accuracy: 0.2004 - top_5_categorical_accuracy: 0.6188 - top_10_categorical_accuracy: 0.7343 - top_20_categorical_accuracy: 0.8655 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1407 - top_5_categorical_accuracy_cp2: 0.9167 - top_5_categorical_accuracy_cp3: 0.9751 - top_5_categorical_accuracy_cp4: 0.9722 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7091 - top_10_categorical_accuracy_cp0: 0.0076 - top_10_categorical_accuracy_cp1: 0.6074 - top_10_categorical_accuracy_cp2: 0.9914 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9980 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0056 - top_10_categorical_accuracy_p4: 0.8409 - top_20_categorical_accuracy_cp0: 0.3149 - top_20_categorical_accuracy_cp1: 0.9753 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1977 - top_20_categorical_accuracy_p4: 0.97276/7 [========================>.....] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.2023 - top_5_categorical_accuracy: 0.6138 - top_10_categorical_accuracy: 0.7321 - top_20_categorical_accuracy: 0.8675 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1824 - top_5_categorical_accuracy_cp2: 0.9272 - top_5_categorical_accuracy_cp3: 0.9776 - top_5_categorical_accuracy_cp4: 0.9650 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7002 - top_10_categorical_accuracy_cp0: 0.0131 - top_10_categorical_accuracy_cp1: 0.6414 - top_10_categorical_accuracy_cp2: 0.9917 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8333 - top_20_categorical_accuracy_cp0: 0.3361 - top_20_categorical_accuracy_cp1: 0.9830 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9718DEBUG:root:Model metric val_loss improved from 0.169182 to 0.163766
7/7 [==============================] - 1s 99ms/step - loss: 0.1234 - categorical_accuracy: 0.2021 - top_5_categorical_accuracy: 0.6146 - top_10_categorical_accuracy: 0.7329 - top_20_categorical_accuracy: 0.8685 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1850 - top_5_categorical_accuracy_cp2: 0.9259 - top_5_categorical_accuracy_cp3: 0.9763 - top_5_categorical_accuracy_cp4: 0.9655 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7003 - top_10_categorical_accuracy_cp0: 0.0130 - top_10_categorical_accuracy_cp1: 0.6422 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8333 - top_20_categorical_accuracy_cp0: 0.3387 - top_20_categorical_accuracy_cp1: 0.9832 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9721 - val_loss: 0.1638 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3380 - val_top_10_categorical_accuracy: 0.3859 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1884 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6186 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.3913 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7062 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.2023 - top_5_categorical_accuracy: 0.5917 - top_10_categorical_accuracy: 0.7316 - top_20_categorical_accuracy: 0.8526 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3305 - top_5_categorical_accuracy_cp2: 0.9241 - top_5_categorical_accuracy_cp3: 0.9905 - top_5_categorical_accuracy_cp4: 0.8981 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6879 - top_10_categorical_accuracy_cp0: 0.0252 - top_10_categorical_accuracy_cp1: 0.7966 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9815 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8505 - top_20_categorical_accuracy_cp0: 0.3613 - top_20_categorical_accuracy_cp1: 0.9831 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.96924/7 [================>.............] - ETA: 0s - loss: 0.1205 - categorical_accuracy: 0.2095 - top_5_categorical_accuracy: 0.6451 - top_10_categorical_accuracy: 0.7701 - top_20_categorical_accuracy: 0.8698 - top_5_categorical_accuracy_cp0: 0.0025 - top_5_categorical_accuracy_cp1: 0.3571 - top_5_categorical_accuracy_cp2: 0.9190 - top_5_categorical_accuracy_cp3: 0.9777 - top_5_categorical_accuracy_cp4: 0.9475 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7352 - top_10_categorical_accuracy_cp0: 0.0442 - top_10_categorical_accuracy_cp1: 0.7926 - top_10_categorical_accuracy_cp2: 0.9969 - top_10_categorical_accuracy_cp3: 0.9978 - top_10_categorical_accuracy_cp4: 0.9939 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0552 - top_10_categorical_accuracy_p4: 0.8728 - top_20_categorical_accuracy_cp0: 0.3366 - top_20_categorical_accuracy_cp1: 0.9908 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2209 - top_20_categorical_accuracy_p4: 0.9718        6/7 [========================>.....] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6511 - top_10_categorical_accuracy: 0.7761 - top_20_categorical_accuracy: 0.8763 - top_5_categorical_accuracy_cp0: 0.0033 - top_5_categorical_accuracy_cp1: 0.3960 - top_5_categorical_accuracy_cp2: 0.9042 - top_5_categorical_accuracy_cp3: 0.9731 - top_5_categorical_accuracy_cp4: 0.9517 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7417 - top_10_categorical_accuracy_cp0: 0.0656 - top_10_categorical_accuracy_cp1: 0.8043 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9919 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0438 - top_10_categorical_accuracy_p4: 0.8801 - top_20_categorical_accuracy_cp0: 0.3689 - top_20_categorical_accuracy_cp1: 0.9923 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2351 - top_20_categorical_accuracy_p4: 0.9769DEBUG:root:Model metric val_loss improved from 0.163766 to 0.163678
7/7 [==============================] - 1s 107ms/step - loss: 0.1196 - categorical_accuracy: 0.2100 - top_5_categorical_accuracy: 0.6516 - top_10_categorical_accuracy: 0.7759 - top_20_categorical_accuracy: 0.8757 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.3976 - top_5_categorical_accuracy_cp2: 0.9033 - top_5_categorical_accuracy_cp3: 0.9734 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7425 - top_10_categorical_accuracy_cp0: 0.0648 - top_10_categorical_accuracy_cp1: 0.8043 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.8802 - top_20_categorical_accuracy_cp0: 0.3663 - top_20_categorical_accuracy_cp1: 0.9924 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2314 - top_20_categorical_accuracy_p4: 0.9768 - val_loss: 0.1637 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.4423 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.6957 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8093 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1225 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6219 - top_10_categorical_accuracy: 0.7694 - top_20_categorical_accuracy: 0.8866 - top_5_categorical_accuracy_cp0: 0.0180 - top_5_categorical_accuracy_cp1: 0.4286 - top_5_categorical_accuracy_cp2: 0.8272 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7091 - top_10_categorical_accuracy_cp0: 0.1261 - top_10_categorical_accuracy_cp1: 0.8571 - top_10_categorical_accuracy_cp2: 0.9630 - top_10_categorical_accuracy_cp3: 0.9735 - top_10_categorical_accuracy_cp4: 0.9732 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.8685 - top_20_categorical_accuracy_cp0: 0.4685 - top_20_categorical_accuracy_cp1: 0.9911 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2381 - top_20_categorical_accuracy_p4: 0.98923/7 [===========>..................] - ETA: 0s - loss: 0.1211 - categorical_accuracy: 0.2120 - top_5_categorical_accuracy: 0.6303 - top_10_categorical_accuracy: 0.7754 - top_20_categorical_accuracy: 0.8789 - top_5_categorical_accuracy_cp0: 0.0185 - top_5_categorical_accuracy_cp1: 0.4061 - top_5_categorical_accuracy_cp2: 0.8609 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9307 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7187 - top_10_categorical_accuracy_cp0: 0.1420 - top_10_categorical_accuracy_cp1: 0.8424 - top_10_categorical_accuracy_cp2: 0.9783 - top_10_categorical_accuracy_cp3: 0.9853 - top_10_categorical_accuracy_cp4: 0.9557 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1069 - top_10_categorical_accuracy_p4: 0.8741 - top_20_categorical_accuracy_cp0: 0.4228 - top_20_categorical_accuracy_cp1: 0.9909 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2443 - top_20_categorical_accuracy_p4: 0.97915/7 [====================>.........] - ETA: 0s - loss: 0.1195 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6437 - top_10_categorical_accuracy: 0.7856 - top_20_categorical_accuracy: 0.8798 - top_5_categorical_accuracy_cp0: 0.0156 - top_5_categorical_accuracy_cp1: 0.4073 - top_5_categorical_accuracy_cp2: 0.8640 - top_5_categorical_accuracy_cp3: 0.9603 - top_5_categorical_accuracy_cp4: 0.9469 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7345 - top_10_categorical_accuracy_cp0: 0.1404 - top_10_categorical_accuracy_cp1: 0.8459 - top_10_categorical_accuracy_cp2: 0.9798 - top_10_categorical_accuracy_cp3: 0.9838 - top_10_categorical_accuracy_cp4: 0.9646 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1028 - top_10_categorical_accuracy_p4: 0.8868 - top_20_categorical_accuracy_cp0: 0.4055 - top_20_categorical_accuracy_cp1: 0.9853 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2617 - top_20_categorical_accuracy_p4: 0.97967/7 [==============================] - ETA: 0s - loss: 0.1189 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6469 - top_10_categorical_accuracy: 0.7894 - top_20_categorical_accuracy: 0.8832 - top_5_categorical_accuracy_cp0: 0.0146 - top_5_categorical_accuracy_cp1: 0.4128 - top_5_categorical_accuracy_cp2: 0.8642 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7371 - top_10_categorical_accuracy_cp0: 0.1491 - top_10_categorical_accuracy_cp1: 0.8486 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9668 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1020 - top_10_categorical_accuracy_p4: 0.8902 - top_20_categorical_accuracy_cp0: 0.4182 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2706 - top_20_categorical_accuracy_p4: 0.9818DEBUG:root:Model metric val_loss improved from 0.163678 to 0.163330
7/7 [==============================] - 1s 111ms/step - loss: 0.1189 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6469 - top_10_categorical_accuracy: 0.7894 - top_20_categorical_accuracy: 0.8832 - top_5_categorical_accuracy_cp0: 0.0146 - top_5_categorical_accuracy_cp1: 0.4128 - top_5_categorical_accuracy_cp2: 0.8642 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9495 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7371 - top_10_categorical_accuracy_cp0: 0.1491 - top_10_categorical_accuracy_cp1: 0.8486 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9668 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1020 - top_10_categorical_accuracy_p4: 0.8902 - top_20_categorical_accuracy_cp0: 0.4182 - top_20_categorical_accuracy_cp1: 0.9862 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2706 - top_20_categorical_accuracy_p4: 0.9818 - val_loss: 0.1633 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.4056 - val_top_20_categorical_accuracy: 0.5239 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5072 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7423 - val_top_20_categorical_accuracy_cp0: 0.0398 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9588
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.2000 - top_5_categorical_accuracy: 0.6743 - top_10_categorical_accuracy: 0.8305 - top_20_categorical_accuracy: 0.9105 - top_5_categorical_accuracy_cp0: 0.0241 - top_5_categorical_accuracy_cp1: 0.4035 - top_5_categorical_accuracy_cp2: 0.8590 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7453 - top_10_categorical_accuracy_cp0: 0.2048 - top_10_categorical_accuracy_cp1: 0.8860 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1667 - top_10_categorical_accuracy_p4: 0.9053 - top_20_categorical_accuracy_cp0: 0.4819 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3611 - top_20_categorical_accuracy_p4: 0.97893/7 [===========>..................] - ETA: 0s - loss: 0.1171 - categorical_accuracy: 0.2034 - top_5_categorical_accuracy: 0.6553 - top_10_categorical_accuracy: 0.7978 - top_20_categorical_accuracy: 0.8897 - top_5_categorical_accuracy_cp0: 0.0166 - top_5_categorical_accuracy_cp1: 0.4488 - top_5_categorical_accuracy_cp2: 0.8465 - top_5_categorical_accuracy_cp3: 0.9474 - top_5_categorical_accuracy_cp4: 0.9706 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.7442 - top_10_categorical_accuracy_cp0: 0.1854 - top_10_categorical_accuracy_cp1: 0.8675 - top_10_categorical_accuracy_cp2: 0.9561 - top_10_categorical_accuracy_cp3: 0.9708 - top_10_categorical_accuracy_cp4: 0.9759 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1240 - top_10_categorical_accuracy_p4: 0.8955 - top_20_categorical_accuracy_cp0: 0.4570 - top_20_categorical_accuracy_cp1: 0.9759 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3178 - top_20_categorical_accuracy_p4: 0.9820    5/7 [====================>.........] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.2009 - top_5_categorical_accuracy: 0.6492 - top_10_categorical_accuracy: 0.7983 - top_20_categorical_accuracy: 0.8900 - top_5_categorical_accuracy_cp0: 0.0159 - top_5_categorical_accuracy_cp1: 0.4320 - top_5_categorical_accuracy_cp2: 0.8422 - top_5_categorical_accuracy_cp3: 0.9465 - top_5_categorical_accuracy_cp4: 0.9570 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7387 - top_10_categorical_accuracy_cp0: 0.2032 - top_10_categorical_accuracy_cp1: 0.8695 - top_10_categorical_accuracy_cp2: 0.9517 - top_10_categorical_accuracy_cp3: 0.9679 - top_10_categorical_accuracy_cp4: 0.9650 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1557 - top_10_categorical_accuracy_p4: 0.8947 - top_20_categorical_accuracy_cp0: 0.4622 - top_20_categorical_accuracy_cp1: 0.9724 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 0.9952 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3160 - top_20_categorical_accuracy_p4: 0.98447/7 [==============================] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6485 - top_10_categorical_accuracy: 0.7979 - top_20_categorical_accuracy: 0.8901 - top_5_categorical_accuracy_cp0: 0.0227 - top_5_categorical_accuracy_cp1: 0.4297 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9512 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7386 - top_10_categorical_accuracy_cp0: 0.2042 - top_10_categorical_accuracy_cp1: 0.8716 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 0.9689 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1412 - top_10_categorical_accuracy_p4: 0.8963 - top_20_categorical_accuracy_cp0: 0.4668 - top_20_categorical_accuracy_cp1: 0.9755 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.98507/7 [==============================] - 1s 113ms/step - loss: 0.1175 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6485 - top_10_categorical_accuracy: 0.7979 - top_20_categorical_accuracy: 0.8901 - top_5_categorical_accuracy_cp0: 0.0227 - top_5_categorical_accuracy_cp1: 0.4297 - top_5_categorical_accuracy_cp2: 0.8457 - top_5_categorical_accuracy_cp3: 0.9512 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7386 - top_10_categorical_accuracy_cp0: 0.2042 - top_10_categorical_accuracy_cp1: 0.8716 - top_10_categorical_accuracy_cp2: 0.9568 - top_10_categorical_accuracy_cp3: 0.9689 - top_10_categorical_accuracy_cp4: 0.9641 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1412 - top_10_categorical_accuracy_p4: 0.8963 - top_20_categorical_accuracy_cp0: 0.4668 - top_20_categorical_accuracy_cp1: 0.9755 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.9850 - val_loss: 0.1643 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.5408 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.0739 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9897
INFO:root:Restoring best model weights with val_loss: 0.163330 from epoch 8
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.26it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 2158.20it/s]
INFO:root:Finished run 45645b6d0b584b14a28d21f154b1c282
2023-05-24 20:21:52.152123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:21:52.681401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:21:52.681472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:21:52.681478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 7ca2df5cf497418ba38a1de23e6468f6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12082.65it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13310.69it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13211.22it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24499.44it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:21:55.041129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.041337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.042135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.042297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.042441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.042584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.042992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:21:55.178697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.178921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.179076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.179208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.179336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:55.179462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.745469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.745665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.745823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.745955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.746088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.746206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:21:56.746541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:21:56.746647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12906.23it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13725.55it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13354.93it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24798.80it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 30/154 [00:00<00:00, 290.20it/s]Loading hierarchy for column coarse_log_cluster_path:  39%|███▉      | 60/154 [00:00<00:00, 291.96it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 90/154 [00:00<00:00, 293.11it/s]Loading hierarchy for column coarse_log_cluster_path:  78%|███████▊  | 120/154 [00:00<00:00, 293.43it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 150/154 [00:00<00:00, 293.35it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 292.88it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:51,  7.72it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5207.08it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1338it [00:00, 40034.66it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/174 [00:00<?, ?it/s]Initializing gram_embedding connections:  47%|████▋     | 81/174 [00:00<00:00, 804.22it/s]Initializing gram_embedding connections:  93%|█████████▎| 162/174 [00:00<00:00, 392.55it/s]Initializing gram_embedding connections: 100%|██████████| 174/174 [00:00<00:00, 396.47it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.03it/s]Calculating percentile frequencies...: 7it [00:00,  7.17it/s]
2023-05-24 20:22:01.288594: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:22:33.953510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:22:34.529520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:22:34.631314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:22:35.004088: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fa874004770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:22:35.004130: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:22:35.004140: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:22:35.010122: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:22:35.092826: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1929 - categorical_accuracy: 0.0019 - top_5_categorical_accuracy: 0.0326 - top_10_categorical_accuracy: 0.0747 - top_20_categorical_accuracy: 0.1590 - top_5_categorical_accuracy_cp0: 0.0606 - top_5_categorical_accuracy_cp1: 0.0606 - top_5_categorical_accuracy_cp2: 0.0000e+00 - top_5_categorical_accuracy_cp3: 0.0424 - top_5_categorical_accuracy_cp4: 0.0000e+00 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0789 - top_5_categorical_accuracy_p4: 0.0305 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.1515 - top_10_categorical_accuracy_cp2: 0.0238 - top_10_categorical_accuracy_cp3: 0.0763 - top_10_categorical_accuracy_cp4: 0.0000e+00 - top_10_categorical_accuracy_p0: 0.5000 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0588 - top_10_categorical_accuracy_p3: 0.1316 - top_10_categorical_accuracy_p4: 0.0697 - top_20_categorical_accuracy_cp0: 0.2626 - top_20_categorical_accuracy_cp1: 0.2020 - top_20_categorical_accuracy_cp2: 0.0595 - top_20_categorical_accuracy_cp3: 0.2034 - top_20_categorical_accuracy_cp4: 0.0656 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.2353 - top_20_categorical_accuracy_p3: 0.2895 - top_20_categorical_accuracy_p4: 0.1460      3/Unknown - 34s 28ms/step - loss: 0.1932 - categorical_accuracy: 0.0540 - top_5_categorical_accuracy: 0.1799 - top_10_categorical_accuracy: 0.2759 - top_20_categorical_accuracy: 0.4050 - top_5_categorical_accuracy_cp0: 0.0273 - top_5_categorical_accuracy_cp1: 0.0615 - top_5_categorical_accuracy_cp2: 0.1172 - top_5_categorical_accuracy_cp3: 0.3958 - top_5_categorical_accuracy_cp4: 0.2494 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0213 - top_5_categorical_accuracy_p3: 0.0259 - top_5_categorical_accuracy_p4: 0.2010 - top_10_categorical_accuracy_cp0: 0.0922 - top_10_categorical_accuracy_cp1: 0.1323 - top_10_categorical_accuracy_cp2: 0.2259 - top_10_categorical_accuracy_cp3: 0.4955 - top_10_categorical_accuracy_cp4: 0.3792 - top_10_categorical_accuracy_p0: 0.2000 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0426 - top_10_categorical_accuracy_p3: 0.0948 - top_10_categorical_accuracy_p4: 0.3019 - top_20_categorical_accuracy_cp0: 0.1877 - top_20_categorical_accuracy_cp1: 0.2923 - top_20_categorical_accuracy_cp2: 0.3556 - top_20_categorical_accuracy_cp3: 0.6012 - top_20_categorical_accuracy_cp4: 0.5273 - top_20_categorical_accuracy_p0: 0.2000 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.1489 - top_20_categorical_accuracy_p3: 0.2328 - top_20_categorical_accuracy_p4: 0.4323                             5/Unknown - 34s 30ms/step - loss: 0.1933 - categorical_accuracy: 0.0962 - top_5_categorical_accuracy: 0.3048 - top_10_categorical_accuracy: 0.4090 - top_20_categorical_accuracy: 0.5279 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.0780 - top_5_categorical_accuracy_cp2: 0.2663 - top_5_categorical_accuracy_cp3: 0.6205 - top_5_categorical_accuracy_cp4: 0.4855 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0132 - top_5_categorical_accuracy_p3: 0.0237 - top_5_categorical_accuracy_p4: 0.3459 - top_10_categorical_accuracy_cp0: 0.0806 - top_10_categorical_accuracy_cp1: 0.2105 - top_10_categorical_accuracy_cp2: 0.4204 - top_10_categorical_accuracy_cp3: 0.6978 - top_10_categorical_accuracy_cp4: 0.5952 - top_10_categorical_accuracy_p0: 0.0833 - top_10_categorical_accuracy_p1: 0.0323 - top_10_categorical_accuracy_p2: 0.0395 - top_10_categorical_accuracy_p3: 0.0900 - top_10_categorical_accuracy_p4: 0.4572 - top_20_categorical_accuracy_cp0: 0.1843 - top_20_categorical_accuracy_cp1: 0.4047 - top_20_categorical_accuracy_cp2: 0.5561 - top_20_categorical_accuracy_cp3: 0.7626 - top_20_categorical_accuracy_cp4: 0.6984 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0968 - top_20_categorical_accuracy_p2: 0.1316 - top_20_categorical_accuracy_p3: 0.2275 - top_20_categorical_accuracy_p4: 0.5758      7/Unknown - 34s 31ms/step - loss: 0.1927 - categorical_accuracy: 0.1086 - top_5_categorical_accuracy: 0.3490 - top_10_categorical_accuracy: 0.4548 - top_20_categorical_accuracy: 0.5703 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.0749 - top_5_categorical_accuracy_cp2: 0.3292 - top_5_categorical_accuracy_cp3: 0.6879 - top_5_categorical_accuracy_cp4: 0.5671 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.3956 - top_10_categorical_accuracy_cp0: 0.0713 - top_10_categorical_accuracy_cp1: 0.2202 - top_10_categorical_accuracy_cp2: 0.5165 - top_10_categorical_accuracy_cp3: 0.7515 - top_10_categorical_accuracy_cp4: 0.6667 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0353 - top_10_categorical_accuracy_p3: 0.0784 - top_10_categorical_accuracy_p4: 0.5093 - top_20_categorical_accuracy_cp0: 0.1718 - top_20_categorical_accuracy_cp1: 0.4419 - top_20_categorical_accuracy_cp2: 0.6420 - top_20_categorical_accuracy_cp3: 0.8047 - top_20_categorical_accuracy_cp4: 0.7517 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.62482023-05-24 20:22:36.102826: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column medium_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.194919
7/7 [==============================] - 53s 3s/step - loss: 0.1927 - categorical_accuracy: 0.1086 - top_5_categorical_accuracy: 0.3490 - top_10_categorical_accuracy: 0.4548 - top_20_categorical_accuracy: 0.5703 - top_5_categorical_accuracy_cp0: 0.0178 - top_5_categorical_accuracy_cp1: 0.0749 - top_5_categorical_accuracy_cp2: 0.3292 - top_5_categorical_accuracy_cp3: 0.6879 - top_5_categorical_accuracy_cp4: 0.5671 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.3956 - top_10_categorical_accuracy_cp0: 0.0713 - top_10_categorical_accuracy_cp1: 0.2202 - top_10_categorical_accuracy_cp2: 0.5165 - top_10_categorical_accuracy_cp3: 0.7515 - top_10_categorical_accuracy_cp4: 0.6667 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0353 - top_10_categorical_accuracy_p3: 0.0784 - top_10_categorical_accuracy_p4: 0.5093 - top_20_categorical_accuracy_cp0: 0.1718 - top_20_categorical_accuracy_cp1: 0.4419 - top_20_categorical_accuracy_cp2: 0.6420 - top_20_categorical_accuracy_cp3: 0.8047 - top_20_categorical_accuracy_cp4: 0.7517 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.0882 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.6248 - val_loss: 0.1949 - val_categorical_accuracy: 0.2310 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.4507 - val_top_20_categorical_accuracy: 0.6479 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.1364 - val_top_10_categorical_accuracy_cp1: 0.3768 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1935 - val_top_10_categorical_accuracy_p4: 0.7010 - val_top_20_categorical_accuracy_cp0: 0.2898 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4113 - val_top_20_categorical_accuracy_p4: 0.9227
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1894 - categorical_accuracy: 0.1784 - top_5_categorical_accuracy: 0.5560 - top_10_categorical_accuracy: 0.6736 - top_20_categorical_accuracy: 0.7970 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0360 - top_5_categorical_accuracy_cp2: 0.6753 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9600 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6288 - top_10_categorical_accuracy_cp0: 0.0722 - top_10_categorical_accuracy_cp1: 0.2973 - top_10_categorical_accuracy_cp2: 0.9481 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0714 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7575 - top_20_categorical_accuracy_cp0: 0.2268 - top_20_categorical_accuracy_cp1: 0.7117 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1000 - top_20_categorical_accuracy_p2: 0.2143 - top_20_categorical_accuracy_p3: 0.1892 - top_20_categorical_accuracy_p4: 0.87773/7 [===========>..................] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.1745 - top_5_categorical_accuracy: 0.5476 - top_10_categorical_accuracy: 0.6681 - top_20_categorical_accuracy: 0.7728 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0385 - top_5_categorical_accuracy_cp2: 0.6792 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9693 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6336 - top_10_categorical_accuracy_cp0: 0.0431 - top_10_categorical_accuracy_cp1: 0.3654 - top_10_categorical_accuracy_cp2: 0.9417 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0196 - top_10_categorical_accuracy_p3: 0.0149 - top_10_categorical_accuracy_p4: 0.7709 - top_20_categorical_accuracy_cp0: 0.1692 - top_20_categorical_accuracy_cp1: 0.7212 - top_20_categorical_accuracy_cp2: 0.9958 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1111 - top_20_categorical_accuracy_p1: 0.1000 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.1194 - top_20_categorical_accuracy_p4: 0.8759    6/7 [========================>.....] - ETA: 0s - loss: 0.1835 - categorical_accuracy: 0.1693 - top_5_categorical_accuracy: 0.5507 - top_10_categorical_accuracy: 0.6810 - top_20_categorical_accuracy: 0.7917 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0293 - top_5_categorical_accuracy_cp2: 0.6722 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9784 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6280 - top_10_categorical_accuracy_cp0: 0.0391 - top_10_categorical_accuracy_cp1: 0.3843 - top_10_categorical_accuracy_cp2: 0.9647 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0119 - top_10_categorical_accuracy_p3: 0.0197 - top_10_categorical_accuracy_p4: 0.7744 - top_20_categorical_accuracy_cp0: 0.1906 - top_20_categorical_accuracy_cp1: 0.7546 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.1190 - top_20_categorical_accuracy_p3: 0.1260 - top_20_categorical_accuracy_p4: 0.8858DEBUG:root:Model metric val_loss improved from 0.194919 to 0.185621
7/7 [==============================] - 1s 102ms/step - loss: 0.1833 - categorical_accuracy: 0.1695 - top_5_categorical_accuracy: 0.5518 - top_10_categorical_accuracy: 0.6824 - top_20_categorical_accuracy: 0.7925 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0291 - top_5_categorical_accuracy_cp2: 0.6708 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9788 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6288 - top_10_categorical_accuracy_cp0: 0.0389 - top_10_categorical_accuracy_cp1: 0.3853 - top_10_categorical_accuracy_cp2: 0.9650 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.7754 - top_20_categorical_accuracy_cp0: 0.1896 - top_20_categorical_accuracy_cp1: 0.7554 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.1255 - top_20_categorical_accuracy_p4: 0.8863 - val_loss: 0.1856 - val_categorical_accuracy: 0.0141 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.6451 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.2841 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1624 - categorical_accuracy: 0.1521 - top_5_categorical_accuracy: 0.5703 - top_10_categorical_accuracy: 0.7205 - top_20_categorical_accuracy: 0.8156 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.6786 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6397 - top_10_categorical_accuracy_cp0: 0.0417 - top_10_categorical_accuracy_cp1: 0.4554 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0541 - top_10_categorical_accuracy_p4: 0.8038 - top_20_categorical_accuracy_cp0: 0.1771 - top_20_categorical_accuracy_cp1: 0.8218 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1892 - top_20_categorical_accuracy_p4: 0.89983/7 [===========>..................] - ETA: 0s - loss: 0.1549 - categorical_accuracy: 0.1308 - top_5_categorical_accuracy: 0.5289 - top_10_categorical_accuracy: 0.6971 - top_20_categorical_accuracy: 0.8013 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.5976 - top_5_categorical_accuracy_cp3: 0.9970 - top_5_categorical_accuracy_cp4: 0.9888 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6036 - top_10_categorical_accuracy_cp0: 0.0289 - top_10_categorical_accuracy_cp1: 0.4740 - top_10_categorical_accuracy_cp2: 0.9878 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0317 - top_10_categorical_accuracy_p4: 0.7928 - top_20_categorical_accuracy_cp0: 0.1833 - top_20_categorical_accuracy_cp1: 0.8196 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1111 - top_20_categorical_accuracy_p2: 0.0227 - top_20_categorical_accuracy_p3: 0.1429 - top_20_categorical_accuracy_p4: 0.8993        5/7 [====================>.........] - ETA: 0s - loss: 0.1495 - categorical_accuracy: 0.1284 - top_5_categorical_accuracy: 0.5377 - top_10_categorical_accuracy: 0.7077 - top_20_categorical_accuracy: 0.8136 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0018 - top_5_categorical_accuracy_cp2: 0.6030 - top_5_categorical_accuracy_cp3: 0.9964 - top_5_categorical_accuracy_cp4: 0.9904 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6106 - top_10_categorical_accuracy_cp0: 0.0239 - top_10_categorical_accuracy_cp1: 0.5046 - top_10_categorical_accuracy_cp2: 0.9849 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0249 - top_10_categorical_accuracy_p4: 0.8014 - top_20_categorical_accuracy_cp0: 0.1889 - top_20_categorical_accuracy_cp1: 0.8514 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0741 - top_20_categorical_accuracy_p2: 0.0417 - top_20_categorical_accuracy_p3: 0.1294 - top_20_categorical_accuracy_p4: 0.9104    7/7 [==============================] - ETA: 0s - loss: 0.1494 - categorical_accuracy: 0.1274 - top_5_categorical_accuracy: 0.5364 - top_10_categorical_accuracy: 0.7062 - top_20_categorical_accuracy: 0.8142 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0015 - top_5_categorical_accuracy_cp2: 0.5967 - top_5_categorical_accuracy_cp3: 0.9941 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6112 - top_10_categorical_accuracy_cp0: 0.0211 - top_10_categorical_accuracy_cp1: 0.5061 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8029 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.8639 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1176 - top_20_categorical_accuracy_p4: 0.9145    DEBUG:root:Model metric val_loss improved from 0.185621 to 0.183433
7/7 [==============================] - 1s 107ms/step - loss: 0.1494 - categorical_accuracy: 0.1274 - top_5_categorical_accuracy: 0.5364 - top_10_categorical_accuracy: 0.7062 - top_20_categorical_accuracy: 0.8142 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0015 - top_5_categorical_accuracy_cp2: 0.5967 - top_5_categorical_accuracy_cp3: 0.9941 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6112 - top_10_categorical_accuracy_cp0: 0.0211 - top_10_categorical_accuracy_cp1: 0.5061 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8029 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.8639 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1176 - top_20_categorical_accuracy_p4: 0.9145 - val_loss: 0.1834 - val_categorical_accuracy: 0.0141 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3324 - val_top_20_categorical_accuracy: 0.6451 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1159 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6082 - val_top_20_categorical_accuracy_cp0: 0.2841 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1315 - categorical_accuracy: 0.1284 - top_5_categorical_accuracy: 0.5728 - top_10_categorical_accuracy: 0.7452 - top_20_categorical_accuracy: 0.8467 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.6078 - top_5_categorical_accuracy_cp3: 0.9732 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6458 - top_10_categorical_accuracy_cp0: 0.0110 - top_10_categorical_accuracy_cp1: 0.5281 - top_10_categorical_accuracy_cp2: 0.9902 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8402 - top_20_categorical_accuracy_cp0: 0.2418 - top_20_categorical_accuracy_cp1: 0.8764 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1463 - top_20_categorical_accuracy_p4: 0.94174/7 [================>.............] - ETA: 0s - loss: 0.1349 - categorical_accuracy: 0.1212 - top_5_categorical_accuracy: 0.5442 - top_10_categorical_accuracy: 0.7129 - top_20_categorical_accuracy: 0.8460 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0217 - top_5_categorical_accuracy_cp2: 0.6366 - top_5_categorical_accuracy_cp3: 0.9691 - top_5_categorical_accuracy_cp4: 0.9939 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6203 - top_10_categorical_accuracy_cp0: 0.0096 - top_10_categorical_accuracy_cp1: 0.5435 - top_10_categorical_accuracy_cp2: 0.9910 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8126 - top_20_categorical_accuracy_cp0: 0.2764 - top_20_categorical_accuracy_cp1: 0.9444 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1646 - top_20_categorical_accuracy_p4: 0.9496    6/7 [========================>.....] - ETA: 0s - loss: 0.1343 - categorical_accuracy: 0.1247 - top_5_categorical_accuracy: 0.5460 - top_10_categorical_accuracy: 0.7167 - top_20_categorical_accuracy: 0.8487 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0264 - top_5_categorical_accuracy_cp2: 0.6680 - top_5_categorical_accuracy_cp3: 0.9596 - top_5_categorical_accuracy_cp4: 0.9867 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6222 - top_10_categorical_accuracy_cp0: 0.0082 - top_10_categorical_accuracy_cp1: 0.5537 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8167 - top_20_categorical_accuracy_cp0: 0.2632 - top_20_categorical_accuracy_cp1: 0.9549 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1673 - top_20_categorical_accuracy_p4: 0.9519DEBUG:root:Model metric val_loss improved from 0.183433 to 0.176589
7/7 [==============================] - 1s 101ms/step - loss: 0.1346 - categorical_accuracy: 0.1240 - top_5_categorical_accuracy: 0.5436 - top_10_categorical_accuracy: 0.7159 - top_20_categorical_accuracy: 0.8484 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0260 - top_5_categorical_accuracy_cp2: 0.6667 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9867 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6195 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5566 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8158 - top_20_categorical_accuracy_cp0: 0.2642 - top_20_categorical_accuracy_cp1: 0.9557 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1647 - top_20_categorical_accuracy_p4: 0.9517 - val_loss: 0.1766 - val_categorical_accuracy: 0.1127 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.3324 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.9583 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1159 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6082 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1332 - categorical_accuracy: 0.1559 - top_5_categorical_accuracy: 0.5684 - top_10_categorical_accuracy: 0.7262 - top_20_categorical_accuracy: 0.8669 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0603 - top_5_categorical_accuracy_cp2: 0.8831 - top_5_categorical_accuracy_cp3: 0.9537 - top_5_categorical_accuracy_cp4: 0.9453 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6403 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.6034 - top_10_categorical_accuracy_cp2: 0.9870 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8180 - top_20_categorical_accuracy_cp0: 0.2990 - top_20_categorical_accuracy_cp1: 0.9828 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1579 - top_20_categorical_accuracy_p4: 0.96364/7 [================>.............] - ETA: 0s - loss: 0.1340 - categorical_accuracy: 0.1634 - top_5_categorical_accuracy: 0.5631 - top_10_categorical_accuracy: 0.7084 - top_20_categorical_accuracy: 0.8533 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0903 - top_5_categorical_accuracy_cp2: 0.8594 - top_5_categorical_accuracy_cp3: 0.9180 - top_5_categorical_accuracy_cp4: 0.9664 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6459 - top_10_categorical_accuracy_cp0: 0.0070 - top_10_categorical_accuracy_cp1: 0.5741 - top_10_categorical_accuracy_cp2: 0.9936 - top_10_categorical_accuracy_cp3: 0.9956 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8126 - top_20_categorical_accuracy_cp0: 0.2951 - top_20_categorical_accuracy_cp1: 0.9838 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1676 - top_20_categorical_accuracy_p4: 0.9628    6/7 [========================>.....] - ETA: 0s - loss: 0.1316 - categorical_accuracy: 0.1675 - top_5_categorical_accuracy: 0.5758 - top_10_categorical_accuracy: 0.7224 - top_20_categorical_accuracy: 0.8610 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1111 - top_5_categorical_accuracy_cp2: 0.8568 - top_5_categorical_accuracy_cp3: 0.9088 - top_5_categorical_accuracy_cp4: 0.9704 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6562 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5910 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8232 - top_20_categorical_accuracy_cp0: 0.2923 - top_20_categorical_accuracy_cp1: 0.9892 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1587 - top_20_categorical_accuracy_p4: 0.9667DEBUG:root:Model metric val_loss improved from 0.176589 to 0.172139
7/7 [==============================] - 1s 108ms/step - loss: 0.1316 - categorical_accuracy: 0.1679 - top_5_categorical_accuracy: 0.5756 - top_10_categorical_accuracy: 0.7222 - top_20_categorical_accuracy: 0.8606 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1116 - top_5_categorical_accuracy_cp2: 0.8539 - top_5_categorical_accuracy_cp3: 0.9098 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6559 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5917 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8230 - top_20_categorical_accuracy_cp0: 0.2917 - top_20_categorical_accuracy_cp1: 0.9893 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1569 - top_20_categorical_accuracy_p4: 0.9664 - val_loss: 0.1721 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2930 - val_top_10_categorical_accuracy: 0.3211 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5361 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0580 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5876 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1326 - categorical_accuracy: 0.1733 - top_5_categorical_accuracy: 0.5367 - top_10_categorical_accuracy: 0.6836 - top_20_categorical_accuracy: 0.8588 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1102 - top_5_categorical_accuracy_cp2: 0.8065 - top_5_categorical_accuracy_cp3: 0.9561 - top_5_categorical_accuracy_cp4: 0.9825 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6077 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5669 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7740 - top_20_categorical_accuracy_cp0: 0.3421 - top_20_categorical_accuracy_cp1: 1.0000 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1951 - top_20_categorical_accuracy_p4: 0.95523/7 [===========>..................] - ETA: 0s - loss: 0.1278 - categorical_accuracy: 0.1665 - top_5_categorical_accuracy: 0.5734 - top_10_categorical_accuracy: 0.7234 - top_20_categorical_accuracy: 0.8671 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1235 - top_5_categorical_accuracy_cp2: 0.8035 - top_5_categorical_accuracy_cp3: 0.9585 - top_5_categorical_accuracy_cp4: 0.9781 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6471 - top_10_categorical_accuracy_cp0: 0.0162 - top_10_categorical_accuracy_cp1: 0.6088 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8164 - top_20_categorical_accuracy_cp0: 0.3236 - top_20_categorical_accuracy_cp1: 0.9971 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1491 - top_20_categorical_accuracy_p4: 0.96645/7 [====================>.........] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.1747 - top_5_categorical_accuracy: 0.5832 - top_10_categorical_accuracy: 0.7309 - top_20_categorical_accuracy: 0.8679 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1292 - top_5_categorical_accuracy_cp2: 0.7863 - top_5_categorical_accuracy_cp3: 0.9659 - top_5_categorical_accuracy_cp4: 0.9793 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6635 - top_10_categorical_accuracy_cp0: 0.0118 - top_10_categorical_accuracy_cp1: 0.6218 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8315 - top_20_categorical_accuracy_cp0: 0.3254 - top_20_categorical_accuracy_cp1: 0.9908 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2190 - top_20_categorical_accuracy_p4: 0.96757/7 [==============================] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.5869 - top_10_categorical_accuracy: 0.7294 - top_20_categorical_accuracy: 0.8663 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1269 - top_5_categorical_accuracy_cp2: 0.8045 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6688 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.6177 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8312 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9924 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9685DEBUG:root:Model metric val_loss improved from 0.172139 to 0.168141
7/7 [==============================] - 1s 113ms/step - loss: 0.1264 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.5869 - top_10_categorical_accuracy: 0.7294 - top_20_categorical_accuracy: 0.8663 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1269 - top_5_categorical_accuracy_cp2: 0.8045 - top_5_categorical_accuracy_cp3: 0.9704 - top_5_categorical_accuracy_cp4: 0.9827 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6688 - top_10_categorical_accuracy_cp0: 0.0097 - top_10_categorical_accuracy_cp1: 0.6177 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8312 - top_20_categorical_accuracy_cp0: 0.3177 - top_20_categorical_accuracy_cp1: 0.9924 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9685 - val_loss: 0.1681 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3099 - val_top_10_categorical_accuracy: 0.3549 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5670 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2319 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6495 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.2008 - top_5_categorical_accuracy: 0.6119 - top_10_categorical_accuracy: 0.7495 - top_20_categorical_accuracy: 0.8815 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1154 - top_5_categorical_accuracy_cp2: 0.8851 - top_5_categorical_accuracy_cp3: 0.9640 - top_5_categorical_accuracy_cp4: 0.9612 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6926 - top_10_categorical_accuracy_cp0: 0.0109 - top_10_categorical_accuracy_cp1: 0.6154 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8485 - top_20_categorical_accuracy_cp0: 0.3478 - top_20_categorical_accuracy_cp1: 0.9808 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2128 - top_20_categorical_accuracy_p4: 0.97623/7 [===========>..................] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.2067 - top_5_categorical_accuracy: 0.6272 - top_10_categorical_accuracy: 0.7494 - top_20_categorical_accuracy: 0.8664 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1361 - top_5_categorical_accuracy_cp2: 0.9326 - top_5_categorical_accuracy_cp3: 0.9697 - top_5_categorical_accuracy_cp4: 0.9692 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7192 - top_10_categorical_accuracy_cp0: 0.0137 - top_10_categorical_accuracy_cp1: 0.6395 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8592 - top_20_categorical_accuracy_cp0: 0.2945 - top_20_categorical_accuracy_cp1: 0.9864 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1929 - top_20_categorical_accuracy_p4: 0.97375/7 [====================>.........] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.2048 - top_5_categorical_accuracy: 0.6171 - top_10_categorical_accuracy: 0.7408 - top_20_categorical_accuracy: 0.8694 - top_5_categorical_accuracy_cp0: 0.0020 - top_5_categorical_accuracy_cp1: 0.1642 - top_5_categorical_accuracy_cp2: 0.9392 - top_5_categorical_accuracy_cp3: 0.9784 - top_5_categorical_accuracy_cp4: 0.9710 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7048 - top_10_categorical_accuracy_cp0: 0.0295 - top_10_categorical_accuracy_cp1: 0.6472 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0094 - top_10_categorical_accuracy_p4: 0.8452 - top_20_categorical_accuracy_cp0: 0.3399 - top_20_categorical_accuracy_cp1: 0.9868 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2300 - top_20_categorical_accuracy_p4: 0.9717        7/7 [==============================] - ETA: 0s - loss: 0.1224 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6177 - top_10_categorical_accuracy: 0.7448 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.1774 - top_5_categorical_accuracy_cp2: 0.9444 - top_5_categorical_accuracy_cp3: 0.9808 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7039 - top_10_categorical_accuracy_cp0: 0.0389 - top_10_categorical_accuracy_cp1: 0.6651 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0235 - top_10_categorical_accuracy_p4: 0.8466 - top_20_categorical_accuracy_cp0: 0.3582 - top_20_categorical_accuracy_cp1: 0.9878 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.9728DEBUG:root:Model metric val_loss improved from 0.168141 to 0.162743
7/7 [==============================] - 1s 112ms/step - loss: 0.1224 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6177 - top_10_categorical_accuracy: 0.7448 - top_20_categorical_accuracy: 0.8732 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.1774 - top_5_categorical_accuracy_cp2: 0.9444 - top_5_categorical_accuracy_cp3: 0.9808 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7039 - top_10_categorical_accuracy_cp0: 0.0389 - top_10_categorical_accuracy_cp1: 0.6651 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0235 - top_10_categorical_accuracy_p4: 0.8466 - top_20_categorical_accuracy_cp0: 0.3582 - top_20_categorical_accuracy_cp1: 0.9878 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2431 - top_20_categorical_accuracy_p4: 0.9728 - val_loss: 0.1627 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3324 - val_top_10_categorical_accuracy: 0.3577 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1449 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9882 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6082 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6546 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.2060 - top_5_categorical_accuracy: 0.6049 - top_10_categorical_accuracy: 0.7297 - top_20_categorical_accuracy: 0.8658 - top_5_categorical_accuracy_cp0: 0.0252 - top_5_categorical_accuracy_cp1: 0.2966 - top_5_categorical_accuracy_cp2: 0.9873 - top_5_categorical_accuracy_cp3: 0.9905 - top_5_categorical_accuracy_cp4: 0.9259 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7033 - top_10_categorical_accuracy_cp0: 0.1176 - top_10_categorical_accuracy_cp1: 0.6949 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9815 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0196 - top_10_categorical_accuracy_p4: 0.8462 - top_20_categorical_accuracy_cp0: 0.4202 - top_20_categorical_accuracy_cp1: 0.9831 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2745 - top_20_categorical_accuracy_p4: 0.97583/7 [===========>..................] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.6324 - top_10_categorical_accuracy: 0.7611 - top_20_categorical_accuracy: 0.8707 - top_5_categorical_accuracy_cp0: 0.0222 - top_5_categorical_accuracy_cp1: 0.3114 - top_5_categorical_accuracy_cp2: 0.9426 - top_5_categorical_accuracy_cp3: 0.9757 - top_5_categorical_accuracy_cp4: 0.9438 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7227 - top_10_categorical_accuracy_cp0: 0.0952 - top_10_categorical_accuracy_cp1: 0.7485 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9878 - top_10_categorical_accuracy_cp4: 0.9888 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0500 - top_10_categorical_accuracy_p4: 0.8653 - top_20_categorical_accuracy_cp0: 0.3810 - top_20_categorical_accuracy_cp1: 0.9731 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2917 - top_20_categorical_accuracy_p4: 0.96965/7 [====================>.........] - ETA: 0s - loss: 0.1205 - categorical_accuracy: 0.2076 - top_5_categorical_accuracy: 0.6395 - top_10_categorical_accuracy: 0.7673 - top_20_categorical_accuracy: 0.8741 - top_5_categorical_accuracy_cp0: 0.0175 - top_5_categorical_accuracy_cp1: 0.3284 - top_5_categorical_accuracy_cp2: 0.9223 - top_5_categorical_accuracy_cp3: 0.9696 - top_5_categorical_accuracy_cp4: 0.9542 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7304 - top_10_categorical_accuracy_cp0: 0.1029 - top_10_categorical_accuracy_cp1: 0.7651 - top_10_categorical_accuracy_cp2: 0.9950 - top_10_categorical_accuracy_cp3: 0.9839 - top_10_categorical_accuracy_cp4: 0.9820 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0810 - top_10_categorical_accuracy_p4: 0.8689 - top_20_categorical_accuracy_cp0: 0.3864 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2905 - top_20_categorical_accuracy_p4: 0.97187/7 [==============================] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.2081 - top_5_categorical_accuracy: 0.6441 - top_10_categorical_accuracy: 0.7750 - top_20_categorical_accuracy: 0.8782 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.3379 - top_5_categorical_accuracy_cp2: 0.9156 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7335 - top_10_categorical_accuracy_cp0: 0.1232 - top_10_categorical_accuracy_cp1: 0.7768 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9822 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8748 - top_20_categorical_accuracy_cp0: 0.4052 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2941 - top_20_categorical_accuracy_p4: 0.9739    7/7 [==============================] - 1s 108ms/step - loss: 0.1194 - categorical_accuracy: 0.2081 - top_5_categorical_accuracy: 0.6441 - top_10_categorical_accuracy: 0.7750 - top_20_categorical_accuracy: 0.8782 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.3379 - top_5_categorical_accuracy_cp2: 0.9156 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7335 - top_10_categorical_accuracy_cp0: 0.1232 - top_10_categorical_accuracy_cp1: 0.7768 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9822 - top_10_categorical_accuracy_cp4: 0.9814 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8748 - top_20_categorical_accuracy_cp0: 0.4052 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2941 - top_20_categorical_accuracy_p4: 0.9739 - val_loss: 0.1631 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.5296 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.0511 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9691
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1216 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6219 - top_10_categorical_accuracy: 0.7637 - top_20_categorical_accuracy: 0.8790 - top_5_categorical_accuracy_cp0: 0.0180 - top_5_categorical_accuracy_cp1: 0.4375 - top_5_categorical_accuracy_cp2: 0.8395 - top_5_categorical_accuracy_cp3: 0.9204 - top_5_categorical_accuracy_cp4: 0.9464 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7091 - top_10_categorical_accuracy_cp0: 0.1532 - top_10_categorical_accuracy_cp1: 0.8393 - top_10_categorical_accuracy_cp2: 0.9506 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1190 - top_10_categorical_accuracy_p4: 0.8599 - top_20_categorical_accuracy_cp0: 0.4955 - top_20_categorical_accuracy_cp1: 0.9554 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9735 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3333 - top_20_categorical_accuracy_p4: 0.97203/7 [===========>..................] - ETA: 0s - loss: 0.1202 - categorical_accuracy: 0.2082 - top_5_categorical_accuracy: 0.6265 - top_10_categorical_accuracy: 0.7722 - top_20_categorical_accuracy: 0.8864 - top_5_categorical_accuracy_cp0: 0.0093 - top_5_categorical_accuracy_cp1: 0.4061 - top_5_categorical_accuracy_cp2: 0.8478 - top_5_categorical_accuracy_cp3: 0.9471 - top_5_categorical_accuracy_cp4: 0.9391 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7144 - top_10_categorical_accuracy_cp0: 0.1852 - top_10_categorical_accuracy_cp1: 0.8182 - top_10_categorical_accuracy_cp2: 0.9739 - top_10_categorical_accuracy_cp3: 0.9647 - top_10_categorical_accuracy_cp4: 0.9474 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1603 - top_10_categorical_accuracy_p4: 0.8655 - top_20_categorical_accuracy_cp0: 0.5031 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9945 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3664 - top_20_categorical_accuracy_p4: 0.97635/7 [====================>.........] - ETA: 0s - loss: 0.1189 - categorical_accuracy: 0.2061 - top_5_categorical_accuracy: 0.6418 - top_10_categorical_accuracy: 0.7852 - top_20_categorical_accuracy: 0.8859 - top_5_categorical_accuracy_cp0: 0.0195 - top_5_categorical_accuracy_cp1: 0.4092 - top_5_categorical_accuracy_cp2: 0.8438 - top_5_categorical_accuracy_cp3: 0.9549 - top_5_categorical_accuracy_cp4: 0.9517 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7323 - top_10_categorical_accuracy_cp0: 0.1813 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9673 - top_10_categorical_accuracy_cp3: 0.9711 - top_10_categorical_accuracy_cp4: 0.9581 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1542 - top_10_categorical_accuracy_p4: 0.8816 - top_20_categorical_accuracy_cp0: 0.4756 - top_20_categorical_accuracy_cp1: 0.9615 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9928 - top_20_categorical_accuracy_cp4: 0.9919 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3551 - top_20_categorical_accuracy_p4: 0.97797/7 [==============================] - ETA: 0s - loss: 0.1184 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6428 - top_10_categorical_accuracy: 0.7903 - top_20_categorical_accuracy: 0.8898 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4037 - top_5_categorical_accuracy_cp2: 0.8333 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7321 - top_10_categorical_accuracy_cp0: 0.1994 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9671 - top_10_categorical_accuracy_cp3: 0.9689 - top_10_categorical_accuracy_cp4: 0.9615 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1569 - top_10_categorical_accuracy_p4: 0.8863 - top_20_categorical_accuracy_cp0: 0.4878 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3725 - top_20_categorical_accuracy_p4: 0.9800    7/7 [==============================] - 1s 107ms/step - loss: 0.1184 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6428 - top_10_categorical_accuracy: 0.7903 - top_20_categorical_accuracy: 0.8898 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4037 - top_5_categorical_accuracy_cp2: 0.8333 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7321 - top_10_categorical_accuracy_cp0: 0.1994 - top_10_categorical_accuracy_cp1: 0.8349 - top_10_categorical_accuracy_cp2: 0.9671 - top_10_categorical_accuracy_cp3: 0.9689 - top_10_categorical_accuracy_cp4: 0.9615 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1569 - top_10_categorical_accuracy_p4: 0.8863 - top_20_categorical_accuracy_cp0: 0.4878 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3725 - top_20_categorical_accuracy_p4: 0.9800 - val_loss: 0.1634 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3523 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9794
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1119 - categorical_accuracy: 0.2171 - top_5_categorical_accuracy: 0.6800 - top_10_categorical_accuracy: 0.8248 - top_20_categorical_accuracy: 0.9200 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.4737 - top_5_categorical_accuracy_cp2: 0.8205 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7516 - top_10_categorical_accuracy_cp0: 0.1928 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9359 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9562 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1667 - top_10_categorical_accuracy_p4: 0.8989 - top_20_categorical_accuracy_cp0: 0.5542 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4167 - top_20_categorical_accuracy_p4: 0.98533/7 [===========>..................] - ETA: 0s - loss: 0.1166 - categorical_accuracy: 0.2022 - top_5_categorical_accuracy: 0.6610 - top_10_categorical_accuracy: 0.7985 - top_20_categorical_accuracy: 0.8986 - top_5_categorical_accuracy_cp0: 0.0265 - top_5_categorical_accuracy_cp1: 0.4729 - top_5_categorical_accuracy_cp2: 0.8246 - top_5_categorical_accuracy_cp3: 0.9561 - top_5_categorical_accuracy_cp4: 0.9706 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.7507 - top_10_categorical_accuracy_cp0: 0.2219 - top_10_categorical_accuracy_cp1: 0.8584 - top_10_categorical_accuracy_cp2: 0.9386 - top_10_categorical_accuracy_cp3: 0.9678 - top_10_categorical_accuracy_cp4: 0.9706 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1550 - top_10_categorical_accuracy_p4: 0.8934 - top_20_categorical_accuracy_cp0: 0.5166 - top_20_categorical_accuracy_cp1: 0.9699 - top_20_categorical_accuracy_cp2: 0.9956 - top_20_categorical_accuracy_cp3: 0.9971 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3876 - top_20_categorical_accuracy_p4: 0.9856        5/7 [====================>.........] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.2024 - top_5_categorical_accuracy: 0.6575 - top_10_categorical_accuracy: 0.7976 - top_20_categorical_accuracy: 0.8976 - top_5_categorical_accuracy_cp0: 0.0239 - top_5_categorical_accuracy_cp1: 0.4559 - top_5_categorical_accuracy_cp2: 0.8397 - top_5_categorical_accuracy_cp3: 0.9519 - top_5_categorical_accuracy_cp4: 0.9618 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7483 - top_10_categorical_accuracy_cp0: 0.2291 - top_10_categorical_accuracy_cp1: 0.8493 - top_10_categorical_accuracy_cp2: 0.9466 - top_10_categorical_accuracy_cp3: 0.9643 - top_10_categorical_accuracy_cp4: 0.9650 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1604 - top_10_categorical_accuracy_p4: 0.8934 - top_20_categorical_accuracy_cp0: 0.5219 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9929 - top_20_categorical_accuracy_cp4: 0.9873 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4057 - top_20_categorical_accuracy_p4: 0.98487/7 [==============================] - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.2031 - top_5_categorical_accuracy: 0.6541 - top_10_categorical_accuracy: 0.7969 - top_20_categorical_accuracy: 0.8955 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4526 - top_5_categorical_accuracy_cp2: 0.8436 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7450 - top_10_categorical_accuracy_cp0: 0.2350 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9547 - top_10_categorical_accuracy_cp3: 0.9645 - top_10_categorical_accuracy_cp4: 0.9575 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.8945 - top_20_categorical_accuracy_cp0: 0.5186 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9867 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3961 - top_20_categorical_accuracy_p4: 0.98437/7 [==============================] - 1s 111ms/step - loss: 0.1170 - categorical_accuracy: 0.2031 - top_5_categorical_accuracy: 0.6541 - top_10_categorical_accuracy: 0.7969 - top_20_categorical_accuracy: 0.8955 - top_5_categorical_accuracy_cp0: 0.0243 - top_5_categorical_accuracy_cp1: 0.4526 - top_5_categorical_accuracy_cp2: 0.8436 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7450 - top_10_categorical_accuracy_cp0: 0.2350 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9547 - top_10_categorical_accuracy_cp3: 0.9645 - top_10_categorical_accuracy_cp4: 0.9575 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.8945 - top_20_categorical_accuracy_cp0: 0.5186 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9867 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3961 - top_20_categorical_accuracy_p4: 0.9843 - val_loss: 0.1645 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3324 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6845 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2464 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6082 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3693 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4032 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.162743 from epoch 6
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.41it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 2072.87it/s]
INFO:root:Finished run 7ca2df5cf497418ba38a1de23e6468f6
2023-05-24 20:23:09.905556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:23:10.421414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:23:10.421478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 20:23:10.421484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 4c173f64c1d64f3b9287c1059537a787
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12260.62it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13302.50it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13209.92it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24653.04it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
2023-05-24 20:23:12.784191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.784380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.785163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.785307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.785437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.785566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.785971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 20:23:12.938531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.938742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.938896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.939031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.939157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:12.939280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.496661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.496861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.497013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.497149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.497276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.497391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 20:23:14.497802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 20:23:14.497908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12807.19it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13553.89it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13421.67it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24852.68it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 30/154 [00:00<00:00, 290.48it/s]Loading hierarchy for column coarse_log_cluster_path:  39%|███▉      | 60/154 [00:00<00:00, 291.07it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 90/154 [00:00<00:00, 292.00it/s]Loading hierarchy for column coarse_log_cluster_path:  78%|███████▊  | 120/154 [00:00<00:00, 292.85it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 150/154 [00:00<00:00, 294.19it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 293.07it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:48,  7.95it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5313.10it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1298it [00:00, 38058.33it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/154 [00:00<?, ?it/s]Initializing gram_embedding connections:  53%|█████▎    | 82/154 [00:00<00:00, 806.46it/s]Initializing gram_embedding connections: 100%|██████████| 154/154 [00:00<00:00, 446.15it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.12it/s]Calculating percentile frequencies...: 7it [00:00,  7.83it/s]
2023-05-24 20:23:18.883969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 20:23:51.263485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 20:23:51.818360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:23:51.973924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 20:23:52.428059: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f4bf0029230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 20:23:52.428107: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:23:52.428119: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 20:23:52.431991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 20:23:52.515609: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1928 - categorical_accuracy: 0.0249 - top_5_categorical_accuracy: 0.0843 - top_10_categorical_accuracy: 0.1628 - top_20_categorical_accuracy: 0.2816 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.0707 - top_5_categorical_accuracy_cp2: 0.0595 - top_5_categorical_accuracy_cp3: 0.1610 - top_5_categorical_accuracy_cp4: 0.0738 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0556 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.0937 - top_10_categorical_accuracy_cp0: 0.0707 - top_10_categorical_accuracy_cp1: 0.1717 - top_10_categorical_accuracy_cp2: 0.1071 - top_10_categorical_accuracy_cp3: 0.2542 - top_10_categorical_accuracy_cp4: 0.1803 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.1111 - top_10_categorical_accuracy_p3: 0.0263 - top_10_categorical_accuracy_p4: 0.1786 - top_20_categorical_accuracy_cp0: 0.1313 - top_20_categorical_accuracy_cp1: 0.3232 - top_20_categorical_accuracy_cp2: 0.1548 - top_20_categorical_accuracy_cp3: 0.4407 - top_20_categorical_accuracy_cp4: 0.3033 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.1667 - top_20_categorical_accuracy_p3: 0.1053 - top_20_categorical_accuracy_p4: 0.3028      3/Unknown - 34s 39ms/step - loss: 0.1931 - categorical_accuracy: 0.0865 - top_5_categorical_accuracy: 0.2784 - top_10_categorical_accuracy: 0.3789 - top_20_categorical_accuracy: 0.4997 - top_5_categorical_accuracy_cp0: 0.0239 - top_5_categorical_accuracy_cp1: 0.1138 - top_5_categorical_accuracy_cp2: 0.1423 - top_5_categorical_accuracy_cp3: 0.5287 - top_5_categorical_accuracy_cp4: 0.4805 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0217 - top_5_categorical_accuracy_p3: 0.0086 - top_5_categorical_accuracy_p4: 0.3141 - top_10_categorical_accuracy_cp0: 0.0580 - top_10_categorical_accuracy_cp1: 0.2092 - top_10_categorical_accuracy_cp2: 0.2845 - top_10_categorical_accuracy_cp3: 0.6224 - top_10_categorical_accuracy_cp4: 0.6156 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0526 - top_10_categorical_accuracy_p2: 0.0435 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.4236 - top_20_categorical_accuracy_cp0: 0.1297 - top_20_categorical_accuracy_cp1: 0.3631 - top_20_categorical_accuracy_cp2: 0.4184 - top_20_categorical_accuracy_cp3: 0.7462 - top_20_categorical_accuracy_cp4: 0.7351 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1053 - top_20_categorical_accuracy_p2: 0.1087 - top_20_categorical_accuracy_p3: 0.1638 - top_20_categorical_accuracy_p4: 0.5476             5/Unknown - 34s 38ms/step - loss: 0.1932 - categorical_accuracy: 0.1125 - top_5_categorical_accuracy: 0.3691 - top_10_categorical_accuracy: 0.4736 - top_20_categorical_accuracy: 0.5758 - top_5_categorical_accuracy_cp0: 0.0134 - top_5_categorical_accuracy_cp1: 0.0980 - top_5_categorical_accuracy_cp2: 0.2924 - top_5_categorical_accuracy_cp3: 0.6996 - top_5_categorical_accuracy_cp4: 0.6597 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0133 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.4211 - top_10_categorical_accuracy_cp0: 0.0422 - top_10_categorical_accuracy_cp1: 0.2541 - top_10_categorical_accuracy_cp2: 0.4935 - top_10_categorical_accuracy_cp3: 0.7680 - top_10_categorical_accuracy_cp4: 0.7548 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0323 - top_10_categorical_accuracy_p2: 0.0267 - top_10_categorical_accuracy_p3: 0.0427 - top_10_categorical_accuracy_p4: 0.5363 - top_20_categorical_accuracy_cp0: 0.1171 - top_20_categorical_accuracy_cp1: 0.4229 - top_20_categorical_accuracy_cp2: 0.6084 - top_20_categorical_accuracy_cp3: 0.8471 - top_20_categorical_accuracy_cp4: 0.8339 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0968 - top_20_categorical_accuracy_p2: 0.0933 - top_20_categorical_accuracy_p3: 0.1469 - top_20_categorical_accuracy_p4: 0.6406      7/Unknown - 34s 37ms/step - loss: 0.1925 - categorical_accuracy: 0.1221 - top_5_categorical_accuracy: 0.4068 - top_10_categorical_accuracy: 0.5119 - top_20_categorical_accuracy: 0.6111 - top_5_categorical_accuracy_cp0: 0.0113 - top_5_categorical_accuracy_cp1: 0.0887 - top_5_categorical_accuracy_cp2: 0.3807 - top_5_categorical_accuracy_cp3: 0.7500 - top_5_categorical_accuracy_cp4: 0.7158 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.4628 - top_10_categorical_accuracy_cp0: 0.0389 - top_10_categorical_accuracy_cp1: 0.2630 - top_10_categorical_accuracy_cp2: 0.5905 - top_10_categorical_accuracy_cp3: 0.8092 - top_10_categorical_accuracy_cp4: 0.7981 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0235 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.5783 - top_20_categorical_accuracy_cp0: 0.1264 - top_20_categorical_accuracy_cp1: 0.4480 - top_20_categorical_accuracy_cp2: 0.6893 - top_20_categorical_accuracy_cp3: 0.8743 - top_20_categorical_accuracy_cp4: 0.8632 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.1490 - top_20_categorical_accuracy_p4: 0.6781    2023-05-24 20:23:53.548737: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column coarse_log_cluster_template as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195631
7/7 [==============================] - 52s 3s/step - loss: 0.1925 - categorical_accuracy: 0.1221 - top_5_categorical_accuracy: 0.4068 - top_10_categorical_accuracy: 0.5119 - top_20_categorical_accuracy: 0.6111 - top_5_categorical_accuracy_cp0: 0.0113 - top_5_categorical_accuracy_cp1: 0.0887 - top_5_categorical_accuracy_cp2: 0.3807 - top_5_categorical_accuracy_cp3: 0.7500 - top_5_categorical_accuracy_cp4: 0.7158 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.4628 - top_10_categorical_accuracy_cp0: 0.0389 - top_10_categorical_accuracy_cp1: 0.2630 - top_10_categorical_accuracy_cp2: 0.5905 - top_10_categorical_accuracy_cp3: 0.8092 - top_10_categorical_accuracy_cp4: 0.7981 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0235 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.5783 - top_20_categorical_accuracy_cp0: 0.1264 - top_20_categorical_accuracy_cp1: 0.4480 - top_20_categorical_accuracy_cp2: 0.6893 - top_20_categorical_accuracy_cp3: 0.8743 - top_20_categorical_accuracy_cp4: 0.8632 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.1490 - top_20_categorical_accuracy_p4: 0.6781 - val_loss: 0.1956 - val_categorical_accuracy: 0.1831 - val_top_5_categorical_accuracy: 0.2958 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.4028 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.7917 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5412 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0170 - val_top_20_categorical_accuracy_cp1: 0.4348 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.7371
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.1575 - top_5_categorical_accuracy: 0.5769 - top_10_categorical_accuracy: 0.7021 - top_20_categorical_accuracy: 0.7970 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0270 - top_5_categorical_accuracy_cp2: 0.8052 - top_5_categorical_accuracy_cp3: 0.9829 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6524 - top_10_categorical_accuracy_cp0: 0.0515 - top_10_categorical_accuracy_cp1: 0.4144 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1081 - top_10_categorical_accuracy_p4: 0.7854 - top_20_categorical_accuracy_cp0: 0.2062 - top_20_categorical_accuracy_cp1: 0.7297 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0667 - top_20_categorical_accuracy_p3: 0.1892 - top_20_categorical_accuracy_p4: 0.88413/7 [===========>..................] - ETA: 0s - loss: 0.1873 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5622 - top_10_categorical_accuracy: 0.6764 - top_20_categorical_accuracy: 0.7709 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0353 - top_5_categorical_accuracy_cp2: 0.7792 - top_5_categorical_accuracy_cp3: 0.9736 - top_5_categorical_accuracy_cp4: 0.9944 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6505 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.3750 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0448 - top_10_categorical_accuracy_p4: 0.7783 - top_20_categorical_accuracy_cp0: 0.1785 - top_20_categorical_accuracy_cp1: 0.6987 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1020 - top_20_categorical_accuracy_p3: 0.1343 - top_20_categorical_accuracy_p4: 0.87525/7 [====================>.........] - ETA: 0s - loss: 0.1844 - categorical_accuracy: 0.1409 - top_5_categorical_accuracy: 0.5712 - top_10_categorical_accuracy: 0.6839 - top_20_categorical_accuracy: 0.7810 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0265 - top_5_categorical_accuracy_cp2: 0.8054 - top_5_categorical_accuracy_cp3: 0.9676 - top_5_categorical_accuracy_cp4: 0.9920 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6522 - top_10_categorical_accuracy_cp0: 0.0314 - top_10_categorical_accuracy_cp1: 0.3655 - top_10_categorical_accuracy_cp2: 0.9951 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0133 - top_10_categorical_accuracy_p3: 0.0337 - top_10_categorical_accuracy_p4: 0.7774 - top_20_categorical_accuracy_cp0: 0.1847 - top_20_categorical_accuracy_cp1: 0.6970 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0667 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0800 - top_20_categorical_accuracy_p3: 0.1394 - top_20_categorical_accuracy_p4: 0.8761        7/7 [==============================] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.1375 - top_5_categorical_accuracy: 0.5650 - top_10_categorical_accuracy: 0.6836 - top_20_categorical_accuracy: 0.7831 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0260 - top_5_categorical_accuracy_cp2: 0.7922 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6438 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.3761 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7761 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.7125 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0706 - top_20_categorical_accuracy_p3: 0.1373 - top_20_categorical_accuracy_p4: 0.8766    DEBUG:root:Model metric val_loss improved from 0.195631 to 0.189862
7/7 [==============================] - 1s 110ms/step - loss: 0.1828 - categorical_accuracy: 0.1375 - top_5_categorical_accuracy: 0.5650 - top_10_categorical_accuracy: 0.6836 - top_20_categorical_accuracy: 0.7831 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0260 - top_5_categorical_accuracy_cp2: 0.7922 - top_5_categorical_accuracy_cp3: 0.9660 - top_5_categorical_accuracy_cp4: 0.9894 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6438 - top_10_categorical_accuracy_cp0: 0.0308 - top_10_categorical_accuracy_cp1: 0.3761 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0275 - top_10_categorical_accuracy_p4: 0.7761 - top_20_categorical_accuracy_cp0: 0.1848 - top_20_categorical_accuracy_cp1: 0.7125 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0706 - top_20_categorical_accuracy_p3: 0.1373 - top_20_categorical_accuracy_p4: 0.8766 - val_loss: 0.1899 - val_categorical_accuracy: 0.0085 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5324 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0568 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9742
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.1236 - top_5_categorical_accuracy: 0.5722 - top_10_categorical_accuracy: 0.6863 - top_20_categorical_accuracy: 0.8042 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0297 - top_5_categorical_accuracy_cp2: 0.7738 - top_5_categorical_accuracy_cp3: 0.8966 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6418 - top_10_categorical_accuracy_cp0: 0.0104 - top_10_categorical_accuracy_cp1: 0.3069 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7697 - top_20_categorical_accuracy_cp0: 0.1562 - top_20_categorical_accuracy_cp1: 0.7822 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0833 - top_20_categorical_accuracy_p3: 0.1081 - top_20_categorical_accuracy_p4: 0.89133/7 [===========>..................] - ETA: 0s - loss: 0.1539 - categorical_accuracy: 0.1073 - top_5_categorical_accuracy: 0.5225 - top_10_categorical_accuracy: 0.6711 - top_20_categorical_accuracy: 0.7949 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0092 - top_5_categorical_accuracy_cp2: 0.6911 - top_5_categorical_accuracy_cp3: 0.8772 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5964 - top_10_categorical_accuracy_cp0: 0.0225 - top_10_categorical_accuracy_cp1: 0.3456 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0079 - top_10_categorical_accuracy_p4: 0.7652 - top_20_categorical_accuracy_cp0: 0.1768 - top_20_categorical_accuracy_cp1: 0.7951 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0500 - top_20_categorical_accuracy_p2: 0.0476 - top_20_categorical_accuracy_p3: 0.1270 - top_20_categorical_accuracy_p4: 0.8935        5/7 [====================>.........] - ETA: 0s - loss: 0.1481 - categorical_accuracy: 0.1117 - top_5_categorical_accuracy: 0.5286 - top_10_categorical_accuracy: 0.6917 - top_20_categorical_accuracy: 0.8079 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0092 - top_5_categorical_accuracy_cp2: 0.6809 - top_5_categorical_accuracy_cp3: 0.8813 - top_5_categorical_accuracy_cp4: 0.9984 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6002 - top_10_categorical_accuracy_cp0: 0.0239 - top_10_categorical_accuracy_cp1: 0.4202 - top_10_categorical_accuracy_cp2: 0.9975 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0050 - top_10_categorical_accuracy_p4: 0.7849 - top_20_categorical_accuracy_cp0: 0.1750 - top_20_categorical_accuracy_cp1: 0.8367 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0833 - top_20_categorical_accuracy_p1: 0.0333 - top_20_categorical_accuracy_p2: 0.0429 - top_20_categorical_accuracy_p3: 0.1244 - top_20_categorical_accuracy_p4: 0.9044    7/7 [==============================] - ETA: 0s - loss: 0.1480 - categorical_accuracy: 0.1099 - top_5_categorical_accuracy: 0.5267 - top_10_categorical_accuracy: 0.6933 - top_20_categorical_accuracy: 0.8098 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0092 - top_5_categorical_accuracy_cp2: 0.6770 - top_5_categorical_accuracy_cp3: 0.8743 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6001 - top_10_categorical_accuracy_cp0: 0.0227 - top_10_categorical_accuracy_cp1: 0.4312 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.7897 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.8440 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1294 - top_20_categorical_accuracy_p4: 0.9088DEBUG:root:Model metric val_loss improved from 0.189862 to 0.186611
7/7 [==============================] - 1s 114ms/step - loss: 0.1480 - categorical_accuracy: 0.1099 - top_5_categorical_accuracy: 0.5267 - top_10_categorical_accuracy: 0.6933 - top_20_categorical_accuracy: 0.8098 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0092 - top_5_categorical_accuracy_cp2: 0.6770 - top_5_categorical_accuracy_cp3: 0.8743 - top_5_categorical_accuracy_cp4: 0.9987 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6001 - top_10_categorical_accuracy_cp0: 0.0227 - top_10_categorical_accuracy_cp1: 0.4312 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0039 - top_10_categorical_accuracy_p4: 0.7897 - top_20_categorical_accuracy_cp0: 0.1831 - top_20_categorical_accuracy_cp1: 0.8440 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.1294 - top_20_categorical_accuracy_p4: 0.9088 - val_loss: 0.1866 - val_categorical_accuracy: 0.0113 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9845
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1314 - categorical_accuracy: 0.1264 - top_5_categorical_accuracy: 0.5824 - top_10_categorical_accuracy: 0.7318 - top_20_categorical_accuracy: 0.8487 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0000e+00 - top_5_categorical_accuracy_cp2: 0.7549 - top_5_categorical_accuracy_cp3: 0.9018 - top_5_categorical_accuracy_cp4: 0.9844 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6566 - top_10_categorical_accuracy_cp0: 0.0330 - top_10_categorical_accuracy_cp1: 0.4157 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8251 - top_20_categorical_accuracy_cp0: 0.2198 - top_20_categorical_accuracy_cp1: 0.9101 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.0976 - top_20_categorical_accuracy_p4: 0.94823/7 [===========>..................] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.1290 - top_5_categorical_accuracy: 0.5537 - top_10_categorical_accuracy: 0.6934 - top_20_categorical_accuracy: 0.8388 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0099 - top_5_categorical_accuracy_cp2: 0.7643 - top_5_categorical_accuracy_cp3: 0.9213 - top_5_categorical_accuracy_cp4: 0.9889 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6289 - top_10_categorical_accuracy_cp0: 0.0128 - top_10_categorical_accuracy_cp1: 0.4178 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.7875 - top_20_categorical_accuracy_cp0: 0.2564 - top_20_categorical_accuracy_cp1: 0.9243 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1240 - top_20_categorical_accuracy_p4: 0.9419    5/7 [====================>.........] - ETA: 0s - loss: 0.1338 - categorical_accuracy: 0.1372 - top_5_categorical_accuracy: 0.5568 - top_10_categorical_accuracy: 0.7073 - top_20_categorical_accuracy: 0.8491 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0132 - top_5_categorical_accuracy_cp2: 0.7971 - top_5_categorical_accuracy_cp3: 0.9242 - top_5_categorical_accuracy_cp4: 0.9839 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6341 - top_10_categorical_accuracy_cp0: 0.0080 - top_10_categorical_accuracy_cp1: 0.4934 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8056 - top_20_categorical_accuracy_cp0: 0.2704 - top_20_categorical_accuracy_cp1: 0.9454 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1722 - top_20_categorical_accuracy_p4: 0.95147/7 [==============================] - ETA: 0s - loss: 0.1341 - categorical_accuracy: 0.1428 - top_5_categorical_accuracy: 0.5512 - top_10_categorical_accuracy: 0.7065 - top_20_categorical_accuracy: 0.8506 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0138 - top_5_categorical_accuracy_cp2: 0.8025 - top_5_categorical_accuracy_cp3: 0.9157 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6280 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5061 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8051 - top_20_categorical_accuracy_cp0: 0.2804 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.9521DEBUG:root:Model metric val_loss improved from 0.186611 to 0.176927
7/7 [==============================] - 1s 111ms/step - loss: 0.1341 - categorical_accuracy: 0.1428 - top_5_categorical_accuracy: 0.5512 - top_10_categorical_accuracy: 0.7065 - top_20_categorical_accuracy: 0.8506 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0138 - top_5_categorical_accuracy_cp2: 0.8025 - top_5_categorical_accuracy_cp3: 0.9157 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6280 - top_10_categorical_accuracy_cp0: 0.0081 - top_10_categorical_accuracy_cp1: 0.5061 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8051 - top_20_categorical_accuracy_cp0: 0.2804 - top_20_categorical_accuracy_cp1: 0.9511 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.9521 - val_loss: 0.1769 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3042 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5465 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5567 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0852 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 1.0000
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1338 - categorical_accuracy: 0.1825 - top_5_categorical_accuracy: 0.5608 - top_10_categorical_accuracy: 0.7243 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0603 - top_5_categorical_accuracy_cp2: 0.8701 - top_5_categorical_accuracy_cp3: 0.9167 - top_5_categorical_accuracy_cp4: 0.9531 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6317 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.5862 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8158 - top_20_categorical_accuracy_cp0: 0.2990 - top_20_categorical_accuracy_cp1: 0.9741 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1579 - top_20_categorical_accuracy_p4: 0.96153/7 [===========>..................] - ETA: 0s - loss: 0.1349 - categorical_accuracy: 0.1800 - top_5_categorical_accuracy: 0.5539 - top_10_categorical_accuracy: 0.7041 - top_20_categorical_accuracy: 0.8549 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0805 - top_5_categorical_accuracy_cp2: 0.8390 - top_5_categorical_accuracy_cp3: 0.9428 - top_5_categorical_accuracy_cp4: 0.9413 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6380 - top_10_categorical_accuracy_cp0: 0.0061 - top_10_categorical_accuracy_cp1: 0.5697 - top_10_categorical_accuracy_cp2: 0.9958 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8109 - top_20_categorical_accuracy_cp0: 0.3252 - top_20_categorical_accuracy_cp1: 0.9783 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0200 - top_20_categorical_accuracy_p3: 0.2279 - top_20_categorical_accuracy_p4: 0.9613        5/7 [====================>.........] - ETA: 0s - loss: 0.1326 - categorical_accuracy: 0.1846 - top_5_categorical_accuracy: 0.5647 - top_10_categorical_accuracy: 0.7139 - top_20_categorical_accuracy: 0.8588 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0869 - top_5_categorical_accuracy_cp2: 0.8244 - top_5_categorical_accuracy_cp3: 0.9450 - top_5_categorical_accuracy_cp4: 0.9571 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6469 - top_10_categorical_accuracy_cp0: 0.0134 - top_10_categorical_accuracy_cp1: 0.5675 - top_10_categorical_accuracy_cp2: 0.9975 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0094 - top_10_categorical_accuracy_p4: 0.8169 - top_20_categorical_accuracy_cp0: 0.3130 - top_20_categorical_accuracy_cp1: 0.9797 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0122 - top_20_categorical_accuracy_p3: 0.1972 - top_20_categorical_accuracy_p4: 0.9651    7/7 [==============================] - ETA: 0s - loss: 0.1314 - categorical_accuracy: 0.1836 - top_5_categorical_accuracy: 0.5678 - top_10_categorical_accuracy: 0.7207 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0979 - top_5_categorical_accuracy_cp2: 0.8086 - top_5_categorical_accuracy_cp3: 0.9349 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6470 - top_10_categorical_accuracy_cp0: 0.0113 - top_10_categorical_accuracy_cp1: 0.5780 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8205 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9817 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9678DEBUG:root:Model metric val_loss improved from 0.176927 to 0.171925
7/7 [==============================] - 1s 110ms/step - loss: 0.1314 - categorical_accuracy: 0.1836 - top_5_categorical_accuracy: 0.5678 - top_10_categorical_accuracy: 0.7207 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.0979 - top_5_categorical_accuracy_cp2: 0.8086 - top_5_categorical_accuracy_cp3: 0.9349 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6470 - top_10_categorical_accuracy_cp0: 0.0113 - top_10_categorical_accuracy_cp1: 0.5780 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8205 - top_20_categorical_accuracy_cp0: 0.3225 - top_20_categorical_accuracy_cp1: 0.9817 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.1922 - top_20_categorical_accuracy_p4: 0.9678 - val_loss: 0.1719 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2592 - val_top_10_categorical_accuracy: 0.3127 - val_top_20_categorical_accuracy: 0.5437 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4742 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0145 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5722 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1322 - categorical_accuracy: 0.1902 - top_5_categorical_accuracy: 0.5405 - top_10_categorical_accuracy: 0.6798 - top_20_categorical_accuracy: 0.8512 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1811 - top_5_categorical_accuracy_cp2: 0.6613 - top_5_categorical_accuracy_cp3: 0.9737 - top_5_categorical_accuracy_cp4: 0.9825 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6119 - top_10_categorical_accuracy_cp0: 0.0088 - top_10_categorical_accuracy_cp1: 0.5591 - top_10_categorical_accuracy_cp2: 0.9839 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0244 - top_10_categorical_accuracy_p4: 0.7676 - top_20_categorical_accuracy_cp0: 0.3509 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1951 - top_20_categorical_accuracy_p4: 0.94673/7 [===========>..................] - ETA: 0s - loss: 0.1270 - categorical_accuracy: 0.1892 - top_5_categorical_accuracy: 0.5759 - top_10_categorical_accuracy: 0.7177 - top_20_categorical_accuracy: 0.8627 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1529 - top_5_categorical_accuracy_cp2: 0.7380 - top_5_categorical_accuracy_cp3: 0.9792 - top_5_categorical_accuracy_cp4: 0.9836 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6500 - top_10_categorical_accuracy_cp0: 0.0065 - top_10_categorical_accuracy_cp1: 0.5971 - top_10_categorical_accuracy_cp2: 0.9913 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0088 - top_10_categorical_accuracy_p4: 0.8093 - top_20_categorical_accuracy_cp0: 0.3398 - top_20_categorical_accuracy_cp1: 0.9618 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1754 - top_20_categorical_accuracy_p4: 0.95935/7 [====================>.........] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.1892 - top_5_categorical_accuracy: 0.5836 - top_10_categorical_accuracy: 0.7248 - top_20_categorical_accuracy: 0.8637 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1568 - top_5_categorical_accuracy_cp2: 0.7303 - top_5_categorical_accuracy_cp3: 0.9731 - top_5_categorical_accuracy_cp4: 0.9857 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6639 - top_10_categorical_accuracy_cp0: 0.0059 - top_10_categorical_accuracy_cp1: 0.6015 - top_10_categorical_accuracy_cp2: 0.9924 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0095 - top_10_categorical_accuracy_p4: 0.8237 - top_20_categorical_accuracy_cp0: 0.3314 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1952 - top_20_categorical_accuracy_p4: 0.96497/7 [==============================] - ETA: 0s - loss: 0.1260 - categorical_accuracy: 0.1921 - top_5_categorical_accuracy: 0.5810 - top_10_categorical_accuracy: 0.7225 - top_20_categorical_accuracy: 0.8610 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1560 - top_5_categorical_accuracy_cp2: 0.7160 - top_5_categorical_accuracy_cp3: 0.9749 - top_5_categorical_accuracy_cp4: 0.9854 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6620 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5917 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8226 - top_20_categorical_accuracy_cp0: 0.3274 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.9632DEBUG:root:Model metric val_loss improved from 0.171925 to 0.168682
7/7 [==============================] - 1s 110ms/step - loss: 0.1260 - categorical_accuracy: 0.1921 - top_5_categorical_accuracy: 0.5810 - top_10_categorical_accuracy: 0.7225 - top_20_categorical_accuracy: 0.8610 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1560 - top_5_categorical_accuracy_cp2: 0.7160 - top_5_categorical_accuracy_cp3: 0.9749 - top_5_categorical_accuracy_cp4: 0.9854 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6620 - top_10_categorical_accuracy_cp0: 0.0049 - top_10_categorical_accuracy_cp1: 0.5917 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0078 - top_10_categorical_accuracy_p4: 0.8226 - top_20_categorical_accuracy_cp0: 0.3274 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1961 - top_20_categorical_accuracy_p4: 0.9632 - val_loss: 0.1687 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3099 - val_top_10_categorical_accuracy: 0.4535 - val_top_20_categorical_accuracy: 0.5437 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5670 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7391 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8299 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1196 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6310 - top_10_categorical_accuracy: 0.7553 - top_20_categorical_accuracy: 0.8815 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2019 - top_5_categorical_accuracy_cp2: 0.8046 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7143 - top_10_categorical_accuracy_cp0: 0.0000e+00 - top_10_categorical_accuracy_cp1: 0.6538 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8550 - top_20_categorical_accuracy_cp0: 0.3478 - top_20_categorical_accuracy_cp1: 0.9808 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2128 - top_20_categorical_accuracy_p4: 0.97623/7 [===========>..................] - ETA: 0s - loss: 0.1208 - categorical_accuracy: 0.2106 - top_5_categorical_accuracy: 0.6330 - top_10_categorical_accuracy: 0.7475 - top_20_categorical_accuracy: 0.8645 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2143 - top_5_categorical_accuracy_cp2: 0.8464 - top_5_categorical_accuracy_cp3: 0.9818 - top_5_categorical_accuracy_cp4: 0.9820 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7257 - top_10_categorical_accuracy_cp0: 0.0171 - top_10_categorical_accuracy_cp1: 0.6293 - top_10_categorical_accuracy_cp2: 0.9963 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0071 - top_10_categorical_accuracy_p4: 0.8563 - top_20_categorical_accuracy_cp0: 0.2945 - top_20_categorical_accuracy_cp1: 0.9762 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2000 - top_20_categorical_accuracy_p4: 0.9708        5/7 [====================>.........] - ETA: 0s - loss: 0.1226 - categorical_accuracy: 0.2063 - top_5_categorical_accuracy: 0.6212 - top_10_categorical_accuracy: 0.7400 - top_20_categorical_accuracy: 0.8660 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2358 - top_5_categorical_accuracy_cp2: 0.8637 - top_5_categorical_accuracy_cp3: 0.9820 - top_5_categorical_accuracy_cp4: 0.9758 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7096 - top_10_categorical_accuracy_cp0: 0.0275 - top_10_categorical_accuracy_cp1: 0.6509 - top_10_categorical_accuracy_cp2: 0.9951 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0047 - top_10_categorical_accuracy_p4: 0.8448 - top_20_categorical_accuracy_cp0: 0.3360 - top_20_categorical_accuracy_cp1: 0.9736 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2394 - top_20_categorical_accuracy_p4: 0.96707/7 [==============================] - ETA: 0s - loss: 0.1223 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6227 - top_10_categorical_accuracy: 0.7423 - top_20_categorical_accuracy: 0.8685 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.2477 - top_5_categorical_accuracy_cp2: 0.8765 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7096 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.6560 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9973 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8444 - top_20_categorical_accuracy_cp0: 0.3452 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2549 - top_20_categorical_accuracy_p4: 0.9664    DEBUG:root:Model metric val_loss improved from 0.168682 to 0.162914
7/7 [==============================] - 1s 112ms/step - loss: 0.1223 - categorical_accuracy: 0.2059 - top_5_categorical_accuracy: 0.6227 - top_10_categorical_accuracy: 0.7423 - top_20_categorical_accuracy: 0.8685 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.2477 - top_5_categorical_accuracy_cp2: 0.8765 - top_5_categorical_accuracy_cp3: 0.9822 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7096 - top_10_categorical_accuracy_cp0: 0.0405 - top_10_categorical_accuracy_cp1: 0.6560 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9973 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0157 - top_10_categorical_accuracy_p4: 0.8444 - top_20_categorical_accuracy_cp0: 0.3452 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2549 - top_20_categorical_accuracy_p4: 0.9664 - val_loss: 0.1629 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3014 - val_top_10_categorical_accuracy: 0.4958 - val_top_20_categorical_accuracy: 0.5042 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5515 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9565 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9072 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9227
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.2004 - top_5_categorical_accuracy: 0.6030 - top_10_categorical_accuracy: 0.7297 - top_20_categorical_accuracy: 0.8620 - top_5_categorical_accuracy_cp0: 0.0084 - top_5_categorical_accuracy_cp1: 0.3136 - top_5_categorical_accuracy_cp2: 0.9367 - top_5_categorical_accuracy_cp3: 0.9714 - top_5_categorical_accuracy_cp4: 0.9722 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7011 - top_10_categorical_accuracy_cp0: 0.1092 - top_10_categorical_accuracy_cp1: 0.7119 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9815 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0784 - top_10_categorical_accuracy_p4: 0.8396 - top_20_categorical_accuracy_cp0: 0.4286 - top_20_categorical_accuracy_cp1: 0.9576 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2549 - top_20_categorical_accuracy_p4: 0.97363/7 [===========>..................] - ETA: 0s - loss: 0.1215 - categorical_accuracy: 0.2034 - top_5_categorical_accuracy: 0.6420 - top_10_categorical_accuracy: 0.7617 - top_20_categorical_accuracy: 0.8663 - top_5_categorical_accuracy_cp0: 0.0317 - top_5_categorical_accuracy_cp1: 0.3383 - top_5_categorical_accuracy_cp2: 0.9303 - top_5_categorical_accuracy_cp3: 0.9696 - top_5_categorical_accuracy_cp4: 0.9663 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0083 - top_5_categorical_accuracy_p4: 0.7328 - top_10_categorical_accuracy_cp0: 0.1175 - top_10_categorical_accuracy_cp1: 0.7395 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9939 - top_10_categorical_accuracy_cp4: 0.9831 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0667 - top_10_categorical_accuracy_p4: 0.8646 - top_20_categorical_accuracy_cp0: 0.3778 - top_20_categorical_accuracy_cp1: 0.9581 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2750 - top_20_categorical_accuracy_p4: 0.9660    5/7 [====================>.........] - ETA: 0s - loss: 0.1205 - categorical_accuracy: 0.2053 - top_5_categorical_accuracy: 0.6487 - top_10_categorical_accuracy: 0.7692 - top_20_categorical_accuracy: 0.8707 - top_5_categorical_accuracy_cp0: 0.0311 - top_5_categorical_accuracy_cp1: 0.3541 - top_5_categorical_accuracy_cp2: 0.9248 - top_5_categorical_accuracy_cp3: 0.9624 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0048 - top_5_categorical_accuracy_p4: 0.7403 - top_10_categorical_accuracy_cp0: 0.1204 - top_10_categorical_accuracy_cp1: 0.7688 - top_10_categorical_accuracy_cp2: 0.9799 - top_10_categorical_accuracy_cp3: 0.9839 - top_10_categorical_accuracy_cp4: 0.9820 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0857 - top_10_categorical_accuracy_p4: 0.8706 - top_20_categorical_accuracy_cp0: 0.3883 - top_20_categorical_accuracy_cp1: 0.9615 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 0.9967 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2857 - top_20_categorical_accuracy_p4: 0.96837/7 [==============================] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6532 - top_10_categorical_accuracy: 0.7772 - top_20_categorical_accuracy: 0.8757 - top_5_categorical_accuracy_cp0: 0.0324 - top_5_categorical_accuracy_cp1: 0.3685 - top_5_categorical_accuracy_cp2: 0.9156 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7439 - top_10_categorical_accuracy_cp0: 0.1345 - top_10_categorical_accuracy_cp1: 0.7813 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9852 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0941 - top_10_categorical_accuracy_p4: 0.8770 - top_20_categorical_accuracy_cp0: 0.4036 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9717DEBUG:root:Model metric val_loss improved from 0.162914 to 0.162329
7/7 [==============================] - 1s 111ms/step - loss: 0.1194 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6532 - top_10_categorical_accuracy: 0.7772 - top_20_categorical_accuracy: 0.8757 - top_5_categorical_accuracy_cp0: 0.0324 - top_5_categorical_accuracy_cp1: 0.3685 - top_5_categorical_accuracy_cp2: 0.9156 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9641 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7439 - top_10_categorical_accuracy_cp0: 0.1345 - top_10_categorical_accuracy_cp1: 0.7813 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9852 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0941 - top_10_categorical_accuracy_p4: 0.8770 - top_20_categorical_accuracy_cp0: 0.4036 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9717 - val_loss: 0.1623 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3380 - val_top_10_categorical_accuracy: 0.4930 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1884 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6186 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9855 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9021 - val_top_20_categorical_accuracy_cp0: 0.0739 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9845
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1215 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6408 - top_10_categorical_accuracy: 0.7561 - top_20_categorical_accuracy: 0.8809 - top_5_categorical_accuracy_cp0: 0.0450 - top_5_categorical_accuracy_cp1: 0.4643 - top_5_categorical_accuracy_cp2: 0.8765 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9464 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0238 - top_5_categorical_accuracy_p4: 0.7284 - top_10_categorical_accuracy_cp0: 0.1712 - top_10_categorical_accuracy_cp1: 0.7946 - top_10_categorical_accuracy_cp2: 0.9259 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9732 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1429 - top_10_categorical_accuracy_p4: 0.8491 - top_20_categorical_accuracy_cp0: 0.4685 - top_20_categorical_accuracy_cp1: 0.9732 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9912 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3095 - top_20_categorical_accuracy_p4: 0.97634/7 [================>.............] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6427 - top_10_categorical_accuracy: 0.7863 - top_20_categorical_accuracy: 0.8877 - top_5_categorical_accuracy_cp0: 0.0529 - top_5_categorical_accuracy_cp1: 0.4098 - top_5_categorical_accuracy_cp2: 0.8487 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9437 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.7303 - top_10_categorical_accuracy_cp0: 0.2500 - top_10_categorical_accuracy_cp1: 0.7973 - top_10_categorical_accuracy_cp2: 0.9408 - top_10_categorical_accuracy_cp3: 0.9707 - top_10_categorical_accuracy_cp4: 0.9658 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1765 - top_10_categorical_accuracy_p4: 0.8786 - top_20_categorical_accuracy_cp0: 0.4856 - top_20_categorical_accuracy_cp1: 0.9666 - top_20_categorical_accuracy_cp2: 0.9934 - top_20_categorical_accuracy_cp3: 0.9932 - top_20_categorical_accuracy_cp4: 0.9940 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3588 - top_20_categorical_accuracy_p4: 0.97736/7 [========================>.....] - ETA: 0s - loss: 0.1182 - categorical_accuracy: 0.2119 - top_5_categorical_accuracy: 0.6497 - top_10_categorical_accuracy: 0.7919 - top_20_categorical_accuracy: 0.8899 - top_5_categorical_accuracy_cp0: 0.0477 - top_5_categorical_accuracy_cp1: 0.4034 - top_5_categorical_accuracy_cp2: 0.8399 - top_5_categorical_accuracy_cp3: 0.9581 - top_5_categorical_accuracy_cp4: 0.9545 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0119 - top_5_categorical_accuracy_p4: 0.7393 - top_10_categorical_accuracy_cp0: 0.2418 - top_10_categorical_accuracy_cp1: 0.7991 - top_10_categorical_accuracy_cp2: 0.9459 - top_10_categorical_accuracy_cp3: 0.9746 - top_10_categorical_accuracy_cp4: 0.9706 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1779 - top_10_categorical_accuracy_p4: 0.8861 - top_20_categorical_accuracy_cp0: 0.4753 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 0.9958 - top_20_categorical_accuracy_cp3: 0.9955 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3676 - top_20_categorical_accuracy_p4: 0.98057/7 [==============================] - 1s 106ms/step - loss: 0.1183 - categorical_accuracy: 0.2122 - top_5_categorical_accuracy: 0.6507 - top_10_categorical_accuracy: 0.7919 - top_20_categorical_accuracy: 0.8901 - top_5_categorical_accuracy_cp0: 0.0502 - top_5_categorical_accuracy_cp1: 0.4067 - top_5_categorical_accuracy_cp2: 0.8416 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.7403 - top_10_categorical_accuracy_cp0: 0.2431 - top_10_categorical_accuracy_cp1: 0.7997 - top_10_categorical_accuracy_cp2: 0.9465 - top_10_categorical_accuracy_cp3: 0.9749 - top_10_categorical_accuracy_cp4: 0.9708 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1765 - top_10_categorical_accuracy_p4: 0.8863 - top_20_categorical_accuracy_cp0: 0.4781 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 0.9959 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3686 - top_20_categorical_accuracy_p4: 0.9807 - val_loss: 0.1629 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3268 - val_top_10_categorical_accuracy: 0.4930 - val_top_20_categorical_accuracy: 0.5408 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9855 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9021 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.2076 - top_5_categorical_accuracy: 0.6876 - top_10_categorical_accuracy: 0.8229 - top_20_categorical_accuracy: 0.9219 - top_5_categorical_accuracy_cp0: 0.0482 - top_5_categorical_accuracy_cp1: 0.4386 - top_5_categorical_accuracy_cp2: 0.8718 - top_5_categorical_accuracy_cp3: 0.9558 - top_5_categorical_accuracy_cp4: 0.9562 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7600 - top_10_categorical_accuracy_cp0: 0.2410 - top_10_categorical_accuracy_cp1: 0.8246 - top_10_categorical_accuracy_cp2: 0.9615 - top_10_categorical_accuracy_cp3: 0.9823 - top_10_categorical_accuracy_cp4: 0.9635 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2222 - top_10_categorical_accuracy_p4: 0.8926 - top_20_categorical_accuracy_cp0: 0.5663 - top_20_categorical_accuracy_cp1: 0.9737 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9854 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4722 - top_20_categorical_accuracy_p4: 0.98324/7 [================>.............] - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.2053 - top_5_categorical_accuracy: 0.6578 - top_10_categorical_accuracy: 0.7990 - top_20_categorical_accuracy: 0.8945 - top_5_categorical_accuracy_cp0: 0.0352 - top_5_categorical_accuracy_cp1: 0.4311 - top_5_categorical_accuracy_cp2: 0.8557 - top_5_categorical_accuracy_cp3: 0.9559 - top_5_categorical_accuracy_cp4: 0.9663 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0059 - top_5_categorical_accuracy_p4: 0.7480 - top_10_categorical_accuracy_cp0: 0.2111 - top_10_categorical_accuracy_cp1: 0.8356 - top_10_categorical_accuracy_cp2: 0.9664 - top_10_categorical_accuracy_cp3: 0.9758 - top_10_categorical_accuracy_cp4: 0.9722 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1353 - top_10_categorical_accuracy_p4: 0.8967 - top_20_categorical_accuracy_cp0: 0.4975 - top_20_categorical_accuracy_cp1: 0.9644 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9921 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3824 - top_20_categorical_accuracy_p4: 0.9827    6/7 [========================>.....] - ETA: 0s - loss: 0.1177 - categorical_accuracy: 0.2039 - top_5_categorical_accuracy: 0.6471 - top_10_categorical_accuracy: 0.7949 - top_20_categorical_accuracy: 0.8954 - top_5_categorical_accuracy_cp0: 0.0360 - top_5_categorical_accuracy_cp1: 0.4087 - top_5_categorical_accuracy_cp2: 0.8427 - top_5_categorical_accuracy_cp3: 0.9522 - top_5_categorical_accuracy_cp4: 0.9544 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7370 - top_10_categorical_accuracy_cp0: 0.2259 - top_10_categorical_accuracy_cp1: 0.8344 - top_10_categorical_accuracy_cp2: 0.9607 - top_10_categorical_accuracy_cp3: 0.9701 - top_10_categorical_accuracy_cp4: 0.9624 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1575 - top_10_categorical_accuracy_p4: 0.8913 - top_20_categorical_accuracy_cp0: 0.5106 - top_20_categorical_accuracy_cp1: 0.9659 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9906 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3858 - top_20_categorical_accuracy_p4: 0.98487/7 [==============================] - 1s 106ms/step - loss: 0.1176 - categorical_accuracy: 0.2040 - top_5_categorical_accuracy: 0.6475 - top_10_categorical_accuracy: 0.7950 - top_20_categorical_accuracy: 0.8955 - top_5_categorical_accuracy_cp0: 0.0373 - top_5_categorical_accuracy_cp1: 0.4083 - top_5_categorical_accuracy_cp2: 0.8436 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9548 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7375 - top_10_categorical_accuracy_cp0: 0.2269 - top_10_categorical_accuracy_cp1: 0.8333 - top_10_categorical_accuracy_cp2: 0.9609 - top_10_categorical_accuracy_cp3: 0.9704 - top_10_categorical_accuracy_cp4: 0.9628 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1608 - top_10_categorical_accuracy_p4: 0.8913 - top_20_categorical_accuracy_cp0: 0.5105 - top_20_categorical_accuracy_cp1: 0.9664 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3882 - top_20_categorical_accuracy_p4: 0.9850 - val_loss: 0.1639 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.3493 - val_top_20_categorical_accuracy: 0.6676 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 0.0000e+00 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6392 - val_top_20_categorical_accuracy_cp0: 0.3352 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3629 - val_top_20_categorical_accuracy_p4: 0.9897
INFO:root:Restoring best model weights with val_loss: 0.162329 from epoch 7
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00, 10.70it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 2325.00it/s]
INFO:root:Finished run 4c173f64c1d64f3b9287c1059537a787
for knowledge_type in gram gram gram ; do \
echo "Starting experiment for huawei_logs with knowledge type " $knowledge_type "....." ; \
	~/miniconda3/envs/lena/bin/python main.py \
		--experimentconfig_model_type $knowledge_type \
		--huaweipreprocessorconfig_min_causality 0.01 \
		--huaweipreprocessorconfig_relevant_log_column fine_log_cluster_template\
		--no-modelconfig_base_feature_embeddings_trainable \
		--no-modelconfig_base_hidden_embeddings_trainable \
		--sequenceconfig_y_sequence_column_name attributes \
		--sequenceconfig_max_window_size 10 \
		--sequenceconfig_min_window_size 10 \
		--experimentconfig_multilabel_classification \
		--sequenceconfig_flatten_y \
		--sequenceconfig_flatten_x \
		--huaweipreprocessorconfig_log_parser drain \
		 ; \
done ; \

Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 21:00:19.704767: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:00:20.220799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:00:20.220859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:00:20.220865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 8e7c70bcf1bc4f3ca7be321efc0d8260
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12053.68it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13169.93it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13099.90it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24160.74it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 21:00:22.560946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.561144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.562020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.562173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.562312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.562449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.562836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:00:22.684658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.684864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.685014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.685145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.685277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:22.685407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.251654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.251866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.252020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.252158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.252288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.252402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 21:00:24.252792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:00:24.252899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12691.29it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13372.05it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13160.68it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24494.67it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 289.26it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 59/154 [00:00<00:00, 292.16it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 89/154 [00:00<00:00, 293.15it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 119/154 [00:00<00:00, 294.29it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 149/154 [00:00<00:00, 294.23it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 293.51it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:50,  7.77it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5222.53it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 38147.99it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/526 [00:00<?, ?it/s]Initializing gram_embedding connections:  25%|██▌       | 134/526 [00:00<00:00, 1328.24it/s]Initializing gram_embedding connections:  51%|█████     | 267/526 [00:00<00:00, 618.24it/s] Initializing gram_embedding connections:  66%|██████▋   | 349/526 [00:00<00:00, 439.14it/s]Initializing gram_embedding connections:  77%|███████▋  | 406/526 [00:00<00:00, 355.85it/s]Initializing gram_embedding connections:  86%|████████▌ | 450/526 [00:01<00:00, 301.64it/s]Initializing gram_embedding connections:  92%|█████████▏| 485/526 [00:01<00:00, 263.83it/s]Initializing gram_embedding connections:  98%|█████████▊| 514/526 [00:01<00:00, 235.74it/s]Initializing gram_embedding connections: 100%|██████████| 526/526 [00:01<00:00, 324.58it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:01,  1.02s/it]Calculating percentile frequencies...: 7it [00:01,  6.83it/s]
2023-05-24 21:00:30.103213: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 21:01:02.783373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 21:01:03.341760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:01:03.486485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:01:03.891160: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f9a345cdfc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 21:01:03.891215: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:01:03.891230: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:01:03.898381: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 21:01:04.017823: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1926 - categorical_accuracy: 0.0096 - top_5_categorical_accuracy: 0.0575 - top_10_categorical_accuracy: 0.1341 - top_20_categorical_accuracy: 0.2356 - top_5_categorical_accuracy_cp0: 0.0707 - top_5_categorical_accuracy_cp1: 0.0202 - top_5_categorical_accuracy_cp2: 0.0238 - top_5_categorical_accuracy_cp3: 0.0508 - top_5_categorical_accuracy_cp4: 0.1066 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0526 - top_5_categorical_accuracy_p3: 0.0789 - top_5_categorical_accuracy_p4: 0.0566 - top_10_categorical_accuracy_cp0: 0.1414 - top_10_categorical_accuracy_cp1: 0.0707 - top_10_categorical_accuracy_cp2: 0.1071 - top_10_categorical_accuracy_cp3: 0.1271 - top_10_categorical_accuracy_cp4: 0.2049 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.2500 - top_10_categorical_accuracy_p2: 0.1053 - top_10_categorical_accuracy_p3: 0.1579 - top_10_categorical_accuracy_p4: 0.1329 - top_20_categorical_accuracy_cp0: 0.2020 - top_20_categorical_accuracy_cp1: 0.1414 - top_20_categorical_accuracy_cp2: 0.1905 - top_20_categorical_accuracy_cp3: 0.2542 - top_20_categorical_accuracy_cp4: 0.3525 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.1053 - top_20_categorical_accuracy_p3: 0.2105 - top_20_categorical_accuracy_p4: 0.2418      3/Unknown - 34s 36ms/step - loss: 0.1906 - categorical_accuracy: 0.0668 - top_5_categorical_accuracy: 0.2072 - top_10_categorical_accuracy: 0.3020 - top_20_categorical_accuracy: 0.4196 - top_5_categorical_accuracy_cp0: 0.0785 - top_5_categorical_accuracy_cp1: 0.0585 - top_5_categorical_accuracy_cp2: 0.0628 - top_5_categorical_accuracy_cp3: 0.3021 - top_5_categorical_accuracy_cp4: 0.4390 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0638 - top_5_categorical_accuracy_p3: 0.0948 - top_5_categorical_accuracy_p4: 0.2248 - top_10_categorical_accuracy_cp0: 0.1399 - top_10_categorical_accuracy_cp1: 0.1446 - top_10_categorical_accuracy_cp2: 0.1715 - top_10_categorical_accuracy_cp3: 0.3958 - top_10_categorical_accuracy_cp4: 0.5584 - top_10_categorical_accuracy_p0: 0.1667 - top_10_categorical_accuracy_p1: 0.0625 - top_10_categorical_accuracy_p2: 0.1277 - top_10_categorical_accuracy_p3: 0.1724 - top_10_categorical_accuracy_p4: 0.3220 - top_20_categorical_accuracy_cp0: 0.2594 - top_20_categorical_accuracy_cp1: 0.2338 - top_20_categorical_accuracy_cp2: 0.3305 - top_20_categorical_accuracy_cp3: 0.5106 - top_20_categorical_accuracy_cp4: 0.6753 - top_20_categorical_accuracy_p0: 0.5000 - top_20_categorical_accuracy_p1: 0.1875 - top_20_categorical_accuracy_p2: 0.1915 - top_20_categorical_accuracy_p3: 0.2586 - top_20_categorical_accuracy_p4: 0.4431         5/Unknown - 34s 37ms/step - loss: 0.1884 - categorical_accuracy: 0.0901 - top_5_categorical_accuracy: 0.2915 - top_10_categorical_accuracy: 0.3888 - top_20_categorical_accuracy: 0.5032 - top_5_categorical_accuracy_cp0: 0.0691 - top_5_categorical_accuracy_cp1: 0.0944 - top_5_categorical_accuracy_cp2: 0.1775 - top_5_categorical_accuracy_cp3: 0.4029 - top_5_categorical_accuracy_cp4: 0.6242 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0357 - top_5_categorical_accuracy_p2: 0.0395 - top_5_categorical_accuracy_p3: 0.0806 - top_5_categorical_accuracy_p4: 0.3242 - top_10_categorical_accuracy_cp0: 0.1286 - top_10_categorical_accuracy_cp1: 0.2123 - top_10_categorical_accuracy_cp2: 0.3342 - top_10_categorical_accuracy_cp3: 0.4874 - top_10_categorical_accuracy_cp4: 0.7097 - top_10_categorical_accuracy_p0: 0.1333 - top_10_categorical_accuracy_p1: 0.0714 - top_10_categorical_accuracy_p2: 0.0789 - top_10_categorical_accuracy_p3: 0.1564 - top_10_categorical_accuracy_p4: 0.4259 - top_20_categorical_accuracy_cp0: 0.2457 - top_20_categorical_accuracy_cp1: 0.3321 - top_20_categorical_accuracy_cp2: 0.4935 - top_20_categorical_accuracy_cp3: 0.6043 - top_20_categorical_accuracy_cp4: 0.7871 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.1786 - top_20_categorical_accuracy_p2: 0.1447 - top_20_categorical_accuracy_p3: 0.2796 - top_20_categorical_accuracy_p4: 0.5406          7/Unknown - 34s 37ms/step - loss: 0.1861 - categorical_accuracy: 0.1008 - top_5_categorical_accuracy: 0.3333 - top_10_categorical_accuracy: 0.4297 - top_20_categorical_accuracy: 0.5417 - top_5_categorical_accuracy_cp0: 0.0697 - top_5_categorical_accuracy_cp1: 0.1131 - top_5_categorical_accuracy_cp2: 0.2716 - top_5_categorical_accuracy_cp3: 0.4423 - top_5_categorical_accuracy_cp4: 0.6826 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0706 - top_5_categorical_accuracy_p4: 0.3720 - top_10_categorical_accuracy_cp0: 0.1248 - top_10_categorical_accuracy_cp1: 0.2309 - top_10_categorical_accuracy_cp2: 0.4342 - top_10_categorical_accuracy_cp3: 0.5340 - top_10_categorical_accuracy_cp4: 0.7556 - top_10_categorical_accuracy_p0: 0.1250 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.1373 - top_10_categorical_accuracy_p4: 0.4735 - top_20_categorical_accuracy_cp0: 0.2399 - top_20_categorical_accuracy_cp1: 0.3670 - top_20_categorical_accuracy_cp2: 0.5802 - top_20_categorical_accuracy_cp3: 0.6479 - top_20_categorical_accuracy_cp4: 0.8207 - top_20_categorical_accuracy_p0: 0.3125 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.2667 - top_20_categorical_accuracy_p4: 0.58552023-05-24 21:01:05.067391: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195143
7/7 [==============================] - 53s 3s/step - loss: 0.1861 - categorical_accuracy: 0.1008 - top_5_categorical_accuracy: 0.3333 - top_10_categorical_accuracy: 0.4297 - top_20_categorical_accuracy: 0.5417 - top_5_categorical_accuracy_cp0: 0.0697 - top_5_categorical_accuracy_cp1: 0.1131 - top_5_categorical_accuracy_cp2: 0.2716 - top_5_categorical_accuracy_cp3: 0.4423 - top_5_categorical_accuracy_cp4: 0.6826 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0706 - top_5_categorical_accuracy_p4: 0.3720 - top_10_categorical_accuracy_cp0: 0.1248 - top_10_categorical_accuracy_cp1: 0.2309 - top_10_categorical_accuracy_cp2: 0.4342 - top_10_categorical_accuracy_cp3: 0.5340 - top_10_categorical_accuracy_cp4: 0.7556 - top_10_categorical_accuracy_p0: 0.1250 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0706 - top_10_categorical_accuracy_p3: 0.1373 - top_10_categorical_accuracy_p4: 0.4735 - top_20_categorical_accuracy_cp0: 0.2399 - top_20_categorical_accuracy_cp1: 0.3670 - top_20_categorical_accuracy_cp2: 0.5802 - top_20_categorical_accuracy_cp3: 0.6479 - top_20_categorical_accuracy_cp4: 0.8207 - top_20_categorical_accuracy_p0: 0.3125 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1294 - top_20_categorical_accuracy_p3: 0.2667 - top_20_categorical_accuracy_p4: 0.5855 - val_loss: 0.1951 - val_categorical_accuracy: 0.0479 - val_top_5_categorical_accuracy: 0.2197 - val_top_10_categorical_accuracy: 0.3577 - val_top_20_categorical_accuracy: 0.5521 - val_top_5_categorical_accuracy_cp0: 0.0057 - val_top_5_categorical_accuracy_cp1: 0.1159 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 0.7294 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0081 - val_top_5_categorical_accuracy_p4: 0.3969 - val_top_10_categorical_accuracy_cp0: 0.0739 - val_top_10_categorical_accuracy_cp1: 0.4058 - val_top_10_categorical_accuracy_cp2: 0.5417 - val_top_10_categorical_accuracy_cp3: 0.8471 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1048 - val_top_10_categorical_accuracy_p4: 0.5876 - val_top_20_categorical_accuracy_cp0: 0.3409 - val_top_20_categorical_accuracy_cp1: 0.5797 - val_top_20_categorical_accuracy_cp2: 0.6667 - val_top_20_categorical_accuracy_cp3: 0.9294 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4758 - val_top_20_categorical_accuracy_p4: 0.7062
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.1594 - top_5_categorical_accuracy: 0.5655 - top_10_categorical_accuracy: 0.6584 - top_20_categorical_accuracy: 0.7609 - top_5_categorical_accuracy_cp0: 0.0928 - top_5_categorical_accuracy_cp1: 0.1982 - top_5_categorical_accuracy_cp2: 0.7403 - top_5_categorical_accuracy_cp3: 0.7521 - top_5_categorical_accuracy_cp4: 0.9760 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.1081 - top_5_categorical_accuracy_p4: 0.6309 - top_10_categorical_accuracy_cp0: 0.1443 - top_10_categorical_accuracy_cp1: 0.3964 - top_10_categorical_accuracy_cp2: 0.8571 - top_10_categorical_accuracy_cp3: 0.8547 - top_10_categorical_accuracy_cp4: 0.9840 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1000 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1892 - top_10_categorical_accuracy_p4: 0.7275 - top_20_categorical_accuracy_cp0: 0.2887 - top_20_categorical_accuracy_cp1: 0.6126 - top_20_categorical_accuracy_cp2: 0.8961 - top_20_categorical_accuracy_cp3: 0.9487 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 1.0000 - top_20_categorical_accuracy_p1: 0.3000 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4054 - top_20_categorical_accuracy_p4: 0.81973/7 [===========>..................] - ETA: 0s - loss: 0.1622 - categorical_accuracy: 0.1555 - top_5_categorical_accuracy: 0.5546 - top_10_categorical_accuracy: 0.6491 - top_20_categorical_accuracy: 0.7525 - top_5_categorical_accuracy_cp0: 0.0646 - top_5_categorical_accuracy_cp1: 0.1987 - top_5_categorical_accuracy_cp2: 0.7875 - top_5_categorical_accuracy_cp3: 0.7331 - top_5_categorical_accuracy_cp4: 0.9832 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0448 - top_5_categorical_accuracy_p4: 0.6373 - top_10_categorical_accuracy_cp0: 0.1138 - top_10_categorical_accuracy_cp1: 0.4455 - top_10_categorical_accuracy_cp2: 0.8833 - top_10_categorical_accuracy_cp3: 0.8240 - top_10_categorical_accuracy_cp4: 0.9888 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0435 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1194 - top_10_categorical_accuracy_p4: 0.7386 - top_20_categorical_accuracy_cp0: 0.2523 - top_20_categorical_accuracy_cp1: 0.6699 - top_20_categorical_accuracy_cp2: 0.9292 - top_20_categorical_accuracy_cp3: 0.9208 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1739 - top_20_categorical_accuracy_p2: 0.0408 - top_20_categorical_accuracy_p3: 0.3060 - top_20_categorical_accuracy_p4: 0.8355    5/7 [====================>.........] - ETA: 0s - loss: 0.1554 - categorical_accuracy: 0.1504 - top_5_categorical_accuracy: 0.5685 - top_10_categorical_accuracy: 0.6775 - top_20_categorical_accuracy: 0.7749 - top_5_categorical_accuracy_cp0: 0.0530 - top_5_categorical_accuracy_cp1: 0.2027 - top_5_categorical_accuracy_cp2: 0.7981 - top_5_categorical_accuracy_cp3: 0.7482 - top_5_categorical_accuracy_cp4: 0.9887 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0385 - top_5_categorical_accuracy_p4: 0.6457 - top_10_categorical_accuracy_cp0: 0.1041 - top_10_categorical_accuracy_cp1: 0.4886 - top_10_categorical_accuracy_cp2: 0.9100 - top_10_categorical_accuracy_cp3: 0.8561 - top_10_categorical_accuracy_cp4: 0.9936 - top_10_categorical_accuracy_p0: 0.0667 - top_10_categorical_accuracy_p1: 0.0357 - top_10_categorical_accuracy_p2: 0.0133 - top_10_categorical_accuracy_p3: 0.1154 - top_10_categorical_accuracy_p4: 0.7617 - top_20_categorical_accuracy_cp0: 0.2417 - top_20_categorical_accuracy_cp1: 0.7121 - top_20_categorical_accuracy_cp2: 0.9513 - top_20_categorical_accuracy_cp3: 0.9406 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1333 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.0533 - top_20_categorical_accuracy_p3: 0.3125 - top_20_categorical_accuracy_p4: 0.8522        7/7 [==============================] - ETA: 0s - loss: 0.1540 - categorical_accuracy: 0.1463 - top_5_categorical_accuracy: 0.5653 - top_10_categorical_accuracy: 0.6817 - top_20_categorical_accuracy: 0.7787 - top_5_categorical_accuracy_cp0: 0.0486 - top_5_categorical_accuracy_cp1: 0.1881 - top_5_categorical_accuracy_cp2: 0.8066 - top_5_categorical_accuracy_cp3: 0.7544 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0353 - top_5_categorical_accuracy_p4: 0.6409 - top_10_categorical_accuracy_cp0: 0.1005 - top_10_categorical_accuracy_cp1: 0.4924 - top_10_categorical_accuracy_cp2: 0.9218 - top_10_categorical_accuracy_cp3: 0.8743 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.1098 - top_10_categorical_accuracy_p4: 0.7657 - top_20_categorical_accuracy_cp0: 0.2334 - top_20_categorical_accuracy_cp1: 0.7263 - top_20_categorical_accuracy_cp2: 0.9588 - top_20_categorical_accuracy_cp3: 0.9512 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.8555DEBUG:root:Model metric val_loss improved from 0.195143 to 0.191700
7/7 [==============================] - 1s 113ms/step - loss: 0.1540 - categorical_accuracy: 0.1463 - top_5_categorical_accuracy: 0.5653 - top_10_categorical_accuracy: 0.6817 - top_20_categorical_accuracy: 0.7787 - top_5_categorical_accuracy_cp0: 0.0486 - top_5_categorical_accuracy_cp1: 0.1881 - top_5_categorical_accuracy_cp2: 0.8066 - top_5_categorical_accuracy_cp3: 0.7544 - top_5_categorical_accuracy_cp4: 0.9907 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0353 - top_5_categorical_accuracy_p4: 0.6409 - top_10_categorical_accuracy_cp0: 0.1005 - top_10_categorical_accuracy_cp1: 0.4924 - top_10_categorical_accuracy_cp2: 0.9218 - top_10_categorical_accuracy_cp3: 0.8743 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.1098 - top_10_categorical_accuracy_p4: 0.7657 - top_20_categorical_accuracy_cp0: 0.2334 - top_20_categorical_accuracy_cp1: 0.7263 - top_20_categorical_accuracy_cp2: 0.9588 - top_20_categorical_accuracy_cp3: 0.9512 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.1176 - top_20_categorical_accuracy_p2: 0.0824 - top_20_categorical_accuracy_p3: 0.2980 - top_20_categorical_accuracy_p4: 0.8555 - val_loss: 0.1917 - val_categorical_accuracy: 0.0141 - val_top_5_categorical_accuracy: 0.1662 - val_top_10_categorical_accuracy: 0.4507 - val_top_20_categorical_accuracy: 0.5521 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 0.6118 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.3041 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7536 - val_top_10_categorical_accuracy_cp2: 0.9583 - val_top_10_categorical_accuracy_cp3: 0.9882 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8247 - val_top_20_categorical_accuracy_cp0: 0.1875 - val_top_20_categorical_accuracy_cp1: 0.7681 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0667 - val_top_20_categorical_accuracy_p1: 0.0588 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.2500 - val_top_20_categorical_accuracy_p4: 0.8402
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1391 - categorical_accuracy: 0.1388 - top_5_categorical_accuracy: 0.5608 - top_10_categorical_accuracy: 0.7357 - top_20_categorical_accuracy: 0.8175 - top_5_categorical_accuracy_cp0: 0.0208 - top_5_categorical_accuracy_cp1: 0.1485 - top_5_categorical_accuracy_cp2: 0.7976 - top_5_categorical_accuracy_cp3: 0.7069 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0541 - top_5_categorical_accuracy_p4: 0.6247 - top_10_categorical_accuracy_cp0: 0.0833 - top_10_categorical_accuracy_cp1: 0.5842 - top_10_categorical_accuracy_cp2: 0.9643 - top_10_categorical_accuracy_cp3: 0.9483 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1351 - top_10_categorical_accuracy_p4: 0.8145 - top_20_categorical_accuracy_cp0: 0.2083 - top_20_categorical_accuracy_cp1: 0.8119 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9914 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.1429 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3514 - top_20_categorical_accuracy_p4: 0.88493/7 [===========>..................] - ETA: 0s - loss: 0.1430 - categorical_accuracy: 0.1302 - top_5_categorical_accuracy: 0.5308 - top_10_categorical_accuracy: 0.7206 - top_20_categorical_accuracy: 0.8152 - top_5_categorical_accuracy_cp0: 0.0064 - top_5_categorical_accuracy_cp1: 0.1407 - top_5_categorical_accuracy_cp2: 0.7967 - top_5_categorical_accuracy_cp3: 0.7036 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0159 - top_5_categorical_accuracy_p4: 0.6043 - top_10_categorical_accuracy_cp0: 0.0804 - top_10_categorical_accuracy_cp1: 0.5963 - top_10_categorical_accuracy_cp2: 0.9756 - top_10_categorical_accuracy_cp3: 0.9521 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.8138 - top_20_categorical_accuracy_cp0: 0.2251 - top_20_categorical_accuracy_cp1: 0.8502 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.1000 - top_20_categorical_accuracy_p1: 0.0667 - top_20_categorical_accuracy_p2: 0.0682 - top_20_categorical_accuracy_p3: 0.2937 - top_20_categorical_accuracy_p4: 0.9000    5/7 [====================>.........] - ETA: 0s - loss: 0.1399 - categorical_accuracy: 0.1326 - top_5_categorical_accuracy: 0.5480 - top_10_categorical_accuracy: 0.7313 - top_20_categorical_accuracy: 0.8274 - top_5_categorical_accuracy_cp0: 0.0040 - top_5_categorical_accuracy_cp1: 0.1450 - top_5_categorical_accuracy_cp2: 0.8015 - top_5_categorical_accuracy_cp3: 0.7482 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0100 - top_5_categorical_accuracy_p4: 0.6214 - top_10_categorical_accuracy_cp0: 0.0596 - top_10_categorical_accuracy_cp1: 0.6239 - top_10_categorical_accuracy_cp2: 0.9799 - top_10_categorical_accuracy_cp3: 0.9658 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0697 - top_10_categorical_accuracy_p4: 0.8243 - top_20_categorical_accuracy_cp0: 0.2306 - top_20_categorical_accuracy_cp1: 0.8807 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9982 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0417 - top_20_categorical_accuracy_p2: 0.0811 - top_20_categorical_accuracy_p3: 0.2886 - top_20_categorical_accuracy_p4: 0.91097/7 [==============================] - ETA: 0s - loss: 0.1395 - categorical_accuracy: 0.1359 - top_5_categorical_accuracy: 0.5496 - top_10_categorical_accuracy: 0.7310 - top_20_categorical_accuracy: 0.8271 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.1483 - top_5_categorical_accuracy_cp2: 0.7942 - top_5_categorical_accuracy_cp3: 0.7618 - top_5_categorical_accuracy_cp4: 0.9973 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.6255 - top_10_categorical_accuracy_cp0: 0.0551 - top_10_categorical_accuracy_cp1: 0.6269 - top_10_categorical_accuracy_cp2: 0.9774 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0706 - top_10_categorical_accuracy_p4: 0.8265 - top_20_categorical_accuracy_cp0: 0.2301 - top_20_categorical_accuracy_cp1: 0.8853 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0941 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9127DEBUG:root:Model metric val_loss improved from 0.191700 to 0.184573
7/7 [==============================] - 1s 117ms/step - loss: 0.1395 - categorical_accuracy: 0.1359 - top_5_categorical_accuracy: 0.5496 - top_10_categorical_accuracy: 0.7310 - top_20_categorical_accuracy: 0.8271 - top_5_categorical_accuracy_cp0: 0.0032 - top_5_categorical_accuracy_cp1: 0.1483 - top_5_categorical_accuracy_cp2: 0.7942 - top_5_categorical_accuracy_cp3: 0.7618 - top_5_categorical_accuracy_cp4: 0.9973 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.6255 - top_10_categorical_accuracy_cp0: 0.0551 - top_10_categorical_accuracy_cp1: 0.6269 - top_10_categorical_accuracy_cp2: 0.9774 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0706 - top_10_categorical_accuracy_p4: 0.8265 - top_20_categorical_accuracy_cp0: 0.2301 - top_20_categorical_accuracy_cp1: 0.8853 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9985 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0941 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9127 - val_loss: 0.1846 - val_categorical_accuracy: 0.0592 - val_top_5_categorical_accuracy: 0.2282 - val_top_10_categorical_accuracy: 0.4535 - val_top_20_categorical_accuracy: 0.5324 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.3750 - val_top_5_categorical_accuracy_cp3: 0.8353 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.4175 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7391 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8299 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 0.9710 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0667 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0887 - val_top_20_categorical_accuracy_p4: 0.9124
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1296 - categorical_accuracy: 0.1571 - top_5_categorical_accuracy: 0.6092 - top_10_categorical_accuracy: 0.7625 - top_20_categorical_accuracy: 0.8467 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1348 - top_5_categorical_accuracy_cp2: 0.8725 - top_5_categorical_accuracy_cp3: 0.8482 - top_5_categorical_accuracy_cp4: 0.9531 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6868 - top_10_categorical_accuracy_cp0: 0.0110 - top_10_categorical_accuracy_cp1: 0.6292 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9911 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0244 - top_10_categorical_accuracy_p4: 0.8575 - top_20_categorical_accuracy_cp0: 0.2088 - top_20_categorical_accuracy_cp1: 0.9101 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.1707 - top_20_categorical_accuracy_p4: 0.93743/7 [===========>..................] - ETA: 0s - loss: 0.1337 - categorical_accuracy: 0.1568 - top_5_categorical_accuracy: 0.5815 - top_10_categorical_accuracy: 0.7364 - top_20_categorical_accuracy: 0.8426 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1908 - top_5_categorical_accuracy_cp2: 0.8669 - top_5_categorical_accuracy_cp3: 0.8338 - top_5_categorical_accuracy_cp4: 0.9667 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6604 - top_10_categorical_accuracy_cp0: 0.0224 - top_10_categorical_accuracy_cp1: 0.6349 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9971 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0331 - top_10_categorical_accuracy_p4: 0.8335 - top_20_categorical_accuracy_cp0: 0.2821 - top_20_categorical_accuracy_cp1: 0.9178 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0625 - top_20_categorical_accuracy_p2: 0.0256 - top_20_categorical_accuracy_p3: 0.2810 - top_20_categorical_accuracy_p4: 0.9311    5/7 [====================>.........] - ETA: 0s - loss: 0.1307 - categorical_accuracy: 0.1658 - top_5_categorical_accuracy: 0.5938 - top_10_categorical_accuracy: 0.7485 - top_20_categorical_accuracy: 0.8525 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2072 - top_5_categorical_accuracy_cp2: 0.8744 - top_5_categorical_accuracy_cp3: 0.8736 - top_5_categorical_accuracy_cp4: 0.9678 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6762 - top_10_categorical_accuracy_cp0: 0.0258 - top_10_categorical_accuracy_cp1: 0.6836 - top_10_categorical_accuracy_cp2: 0.9976 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0383 - top_10_categorical_accuracy_p4: 0.8490 - top_20_categorical_accuracy_cp0: 0.3002 - top_20_categorical_accuracy_cp1: 0.9341 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0741 - top_20_categorical_accuracy_p2: 0.0290 - top_20_categorical_accuracy_p3: 0.3397 - top_20_categorical_accuracy_p4: 0.93847/7 [==============================] - ETA: 0s - loss: 0.1301 - categorical_accuracy: 0.1726 - top_5_categorical_accuracy: 0.5976 - top_10_categorical_accuracy: 0.7502 - top_20_categorical_accuracy: 0.8512 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2263 - top_5_categorical_accuracy_cp2: 0.8827 - top_5_categorical_accuracy_cp3: 0.8846 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6810 - top_10_categorical_accuracy_cp0: 0.0243 - top_10_categorical_accuracy_cp1: 0.7064 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8512 - top_20_categorical_accuracy_cp0: 0.2950 - top_20_categorical_accuracy_cp1: 0.9404 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.3294 - top_20_categorical_accuracy_p4: 0.9385DEBUG:root:Model metric val_loss improved from 0.184573 to 0.172656
7/7 [==============================] - 1s 115ms/step - loss: 0.1301 - categorical_accuracy: 0.1726 - top_5_categorical_accuracy: 0.5976 - top_10_categorical_accuracy: 0.7502 - top_20_categorical_accuracy: 0.8512 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2263 - top_5_categorical_accuracy_cp2: 0.8827 - top_5_categorical_accuracy_cp3: 0.8846 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6810 - top_10_categorical_accuracy_cp0: 0.0243 - top_10_categorical_accuracy_cp1: 0.7064 - top_10_categorical_accuracy_cp2: 0.9979 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8512 - top_20_categorical_accuracy_cp0: 0.2950 - top_20_categorical_accuracy_cp1: 0.9404 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.3294 - top_20_categorical_accuracy_p4: 0.9385 - val_loss: 0.1727 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3042 - val_top_10_categorical_accuracy: 0.4451 - val_top_20_categorical_accuracy: 0.5070 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.9167 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5567 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.6957 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8144 - val_top_20_categorical_accuracy_cp0: 0.0114 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0161 - val_top_20_categorical_accuracy_p4: 0.9175
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.2091 - top_5_categorical_accuracy: 0.6255 - top_10_categorical_accuracy: 0.7681 - top_20_categorical_accuracy: 0.8536 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3276 - top_5_categorical_accuracy_cp2: 0.8442 - top_5_categorical_accuracy_cp3: 0.9722 - top_5_categorical_accuracy_cp4: 0.9453 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7045 - top_10_categorical_accuracy_cp0: 0.0309 - top_10_categorical_accuracy_cp1: 0.7586 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0526 - top_10_categorical_accuracy_p4: 0.8608 - top_20_categorical_accuracy_cp0: 0.2680 - top_20_categorical_accuracy_cp1: 0.9483 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2368 - top_20_categorical_accuracy_p4: 0.94223/7 [===========>..................] - ETA: 0s - loss: 0.1261 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6141 - top_10_categorical_accuracy: 0.7459 - top_20_categorical_accuracy: 0.8542 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3437 - top_5_categorical_accuracy_cp2: 0.8051 - top_5_categorical_accuracy_cp3: 0.9729 - top_5_categorical_accuracy_cp4: 0.9637 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7073 - top_10_categorical_accuracy_cp0: 0.0304 - top_10_categorical_accuracy_cp1: 0.7554 - top_10_categorical_accuracy_cp2: 0.9915 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0368 - top_10_categorical_accuracy_p4: 0.8555 - top_20_categorical_accuracy_cp0: 0.3374 - top_20_categorical_accuracy_cp1: 0.9628 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3456 - top_20_categorical_accuracy_p4: 0.94965/7 [====================>.........] - ETA: 0s - loss: 0.1245 - categorical_accuracy: 0.2066 - top_5_categorical_accuracy: 0.6176 - top_10_categorical_accuracy: 0.7584 - top_20_categorical_accuracy: 0.8653 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3641 - top_5_categorical_accuracy_cp2: 0.7710 - top_5_categorical_accuracy_cp3: 0.9610 - top_5_categorical_accuracy_cp4: 0.9587 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7075 - top_10_categorical_accuracy_cp0: 0.0363 - top_10_categorical_accuracy_cp1: 0.7708 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0329 - top_10_categorical_accuracy_p4: 0.8657 - top_20_categorical_accuracy_cp0: 0.3531 - top_20_categorical_accuracy_cp1: 0.9723 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3333 - top_20_categorical_accuracy_p4: 0.96037/7 [==============================] - ETA: 0s - loss: 0.1234 - categorical_accuracy: 0.2050 - top_5_categorical_accuracy: 0.6224 - top_10_categorical_accuracy: 0.7699 - top_20_categorical_accuracy: 0.8745 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.3670 - top_5_categorical_accuracy_cp2: 0.7593 - top_5_categorical_accuracy_cp3: 0.9615 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7092 - top_10_categorical_accuracy_cp0: 0.0535 - top_10_categorical_accuracy_cp1: 0.7859 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8737 - top_20_categorical_accuracy_cp0: 0.3793 - top_20_categorical_accuracy_cp1: 0.9740 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3451 - top_20_categorical_accuracy_p4: 0.9649    DEBUG:root:Model metric val_loss improved from 0.172656 to 0.165310
7/7 [==============================] - 1s 113ms/step - loss: 0.1234 - categorical_accuracy: 0.2050 - top_5_categorical_accuracy: 0.6224 - top_10_categorical_accuracy: 0.7699 - top_20_categorical_accuracy: 0.8745 - top_5_categorical_accuracy_cp0: 0.0016 - top_5_categorical_accuracy_cp1: 0.3670 - top_5_categorical_accuracy_cp2: 0.7593 - top_5_categorical_accuracy_cp3: 0.9615 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7092 - top_10_categorical_accuracy_cp0: 0.0535 - top_10_categorical_accuracy_cp1: 0.7859 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 0.9987 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.8737 - top_20_categorical_accuracy_cp0: 0.3793 - top_20_categorical_accuracy_cp1: 0.9740 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3451 - top_20_categorical_accuracy_p4: 0.9649 - val_loss: 0.1653 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3155 - val_top_10_categorical_accuracy: 0.4986 - val_top_20_categorical_accuracy: 0.5408 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0870 - val_top_5_categorical_accuracy_cp2: 0.8333 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5773 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9710 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9124 - val_top_20_categorical_accuracy_cp0: 0.0739 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0968 - val_top_20_categorical_accuracy_p4: 0.9278
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1229 - categorical_accuracy: 0.2222 - top_5_categorical_accuracy: 0.6309 - top_10_categorical_accuracy: 0.7815 - top_20_categorical_accuracy: 0.8738 - top_5_categorical_accuracy_cp0: 0.0088 - top_5_categorical_accuracy_cp1: 0.5039 - top_5_categorical_accuracy_cp2: 0.7419 - top_5_categorical_accuracy_cp3: 0.9912 - top_5_categorical_accuracy_cp4: 0.9737 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7143 - top_10_categorical_accuracy_cp0: 0.1842 - top_10_categorical_accuracy_cp1: 0.8346 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9825 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0976 - top_10_categorical_accuracy_p4: 0.8763 - top_20_categorical_accuracy_cp0: 0.4386 - top_20_categorical_accuracy_cp1: 0.9764 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3171 - top_20_categorical_accuracy_p4: 0.96163/7 [===========>..................] - ETA: 0s - loss: 0.1189 - categorical_accuracy: 0.2133 - top_5_categorical_accuracy: 0.6563 - top_10_categorical_accuracy: 0.8019 - top_20_categorical_accuracy: 0.8899 - top_5_categorical_accuracy_cp0: 0.0259 - top_5_categorical_accuracy_cp1: 0.4912 - top_5_categorical_accuracy_cp2: 0.7948 - top_5_categorical_accuracy_cp3: 0.9703 - top_5_categorical_accuracy_cp4: 0.9671 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7407 - top_10_categorical_accuracy_cp0: 0.1845 - top_10_categorical_accuracy_cp1: 0.8412 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9852 - top_10_categorical_accuracy_cp4: 0.9945 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0702 - top_10_categorical_accuracy_p4: 0.8993 - top_20_categorical_accuracy_cp0: 0.4790 - top_20_categorical_accuracy_cp1: 0.9676 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3860 - top_20_categorical_accuracy_p4: 0.97295/7 [====================>.........] - ETA: 0s - loss: 0.1181 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6608 - top_10_categorical_accuracy: 0.8051 - top_20_categorical_accuracy: 0.8938 - top_5_categorical_accuracy_cp0: 0.0237 - top_5_categorical_accuracy_cp1: 0.4742 - top_5_categorical_accuracy_cp2: 0.8142 - top_5_categorical_accuracy_cp3: 0.9677 - top_5_categorical_accuracy_cp4: 0.9682 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7518 - top_10_categorical_accuracy_cp0: 0.1854 - top_10_categorical_accuracy_cp1: 0.8524 - top_10_categorical_accuracy_cp2: 0.9847 - top_10_categorical_accuracy_cp3: 0.9838 - top_10_categorical_accuracy_cp4: 0.9936 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1095 - top_10_categorical_accuracy_p4: 0.9060 - top_20_categorical_accuracy_cp0: 0.4990 - top_20_categorical_accuracy_cp1: 0.9631 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9946 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0429 - top_20_categorical_accuracy_p3: 0.4190 - top_20_categorical_accuracy_p4: 0.9775    7/7 [==============================] - ETA: 0s - loss: 0.1180 - categorical_accuracy: 0.2106 - top_5_categorical_accuracy: 0.6642 - top_10_categorical_accuracy: 0.8067 - top_20_categorical_accuracy: 0.8952 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4878 - top_5_categorical_accuracy_cp2: 0.8169 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7568 - top_10_categorical_accuracy_cp0: 0.1945 - top_10_categorical_accuracy_cp1: 0.8532 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9852 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1098 - top_10_categorical_accuracy_p4: 0.9092 - top_20_categorical_accuracy_cp0: 0.5057 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.4314 - top_20_categorical_accuracy_p4: 0.9793    DEBUG:root:Model metric val_loss improved from 0.165310 to 0.164171
7/7 [==============================] - 1s 109ms/step - loss: 0.1180 - categorical_accuracy: 0.2106 - top_5_categorical_accuracy: 0.6642 - top_10_categorical_accuracy: 0.8067 - top_20_categorical_accuracy: 0.8952 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4878 - top_5_categorical_accuracy_cp2: 0.8169 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7568 - top_10_categorical_accuracy_cp0: 0.1945 - top_10_categorical_accuracy_cp1: 0.8532 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9852 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1098 - top_10_categorical_accuracy_p4: 0.9092 - top_20_categorical_accuracy_cp0: 0.5057 - top_20_categorical_accuracy_cp1: 0.9633 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.4314 - top_20_categorical_accuracy_p4: 0.9793 - val_loss: 0.1642 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3437 - val_top_10_categorical_accuracy: 0.4986 - val_top_20_categorical_accuracy: 0.5577 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.2174 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6289 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9710 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9124 - val_top_20_categorical_accuracy_cp0: 0.1080 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0887 - val_top_20_categorical_accuracy_p4: 0.9639
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.2027 - top_5_categorical_accuracy: 0.6654 - top_10_categorical_accuracy: 0.8241 - top_20_categorical_accuracy: 0.9273 - top_5_categorical_accuracy_cp0: 0.0109 - top_5_categorical_accuracy_cp1: 0.4327 - top_5_categorical_accuracy_cp2: 0.8276 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9612 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7532 - top_10_categorical_accuracy_cp0: 0.2283 - top_10_categorical_accuracy_cp1: 0.8750 - top_10_categorical_accuracy_cp2: 0.9770 - top_10_categorical_accuracy_cp3: 0.9730 - top_10_categorical_accuracy_cp4: 0.9767 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1064 - top_10_categorical_accuracy_p4: 0.9221 - top_20_categorical_accuracy_cp0: 0.6413 - top_20_categorical_accuracy_cp1: 0.9615 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1000 - top_20_categorical_accuracy_p3: 0.5957 - top_20_categorical_accuracy_p4: 0.98703/7 [===========>..................] - ETA: 0s - loss: 0.1150 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6705 - top_10_categorical_accuracy: 0.8117 - top_20_categorical_accuracy: 0.9052 - top_5_categorical_accuracy_cp0: 0.0274 - top_5_categorical_accuracy_cp1: 0.4524 - top_5_categorical_accuracy_cp2: 0.8652 - top_5_categorical_accuracy_cp3: 0.9364 - top_5_categorical_accuracy_cp4: 0.9589 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0071 - top_5_categorical_accuracy_p4: 0.7681 - top_10_categorical_accuracy_cp0: 0.2123 - top_10_categorical_accuracy_cp1: 0.8401 - top_10_categorical_accuracy_cp2: 0.9813 - top_10_categorical_accuracy_cp3: 0.9818 - top_10_categorical_accuracy_cp4: 0.9794 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1000 - top_10_categorical_accuracy_p4: 0.9205 - top_20_categorical_accuracy_cp0: 0.5308 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9939 - top_20_categorical_accuracy_cp4: 0.9974 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0541 - top_20_categorical_accuracy_p3: 0.4643 - top_20_categorical_accuracy_p4: 0.9891    5/7 [====================>.........] - ETA: 0s - loss: 0.1161 - categorical_accuracy: 0.2033 - top_5_categorical_accuracy: 0.6692 - top_10_categorical_accuracy: 0.8158 - top_20_categorical_accuracy: 0.9064 - top_5_categorical_accuracy_cp0: 0.0373 - top_5_categorical_accuracy_cp1: 0.4774 - top_5_categorical_accuracy_cp2: 0.8881 - top_5_categorical_accuracy_cp3: 0.9424 - top_5_categorical_accuracy_cp4: 0.9614 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7639 - top_10_categorical_accuracy_cp0: 0.2534 - top_10_categorical_accuracy_cp1: 0.8642 - top_10_categorical_accuracy_cp2: 0.9830 - top_10_categorical_accuracy_cp3: 0.9784 - top_10_categorical_accuracy_cp4: 0.9791 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1315 - top_10_categorical_accuracy_p4: 0.9196 - top_20_categorical_accuracy_cp0: 0.5580 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0580 - top_20_categorical_accuracy_p3: 0.4883 - top_20_categorical_accuracy_p4: 0.98837/7 [==============================] - ETA: 0s - loss: 0.1157 - categorical_accuracy: 0.2043 - top_5_categorical_accuracy: 0.6695 - top_10_categorical_accuracy: 0.8202 - top_20_categorical_accuracy: 0.9074 - top_5_categorical_accuracy_cp0: 0.0373 - top_5_categorical_accuracy_cp1: 0.4755 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9497 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7625 - top_10_categorical_accuracy_cp0: 0.2674 - top_10_categorical_accuracy_cp1: 0.8716 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.9213 - top_20_categorical_accuracy_cp0: 0.5640 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.4863 - top_20_categorical_accuracy_p4: 0.9882DEBUG:root:Model metric val_loss improved from 0.164171 to 0.161466
7/7 [==============================] - 1s 112ms/step - loss: 0.1157 - categorical_accuracy: 0.2043 - top_5_categorical_accuracy: 0.6695 - top_10_categorical_accuracy: 0.8202 - top_20_categorical_accuracy: 0.9074 - top_5_categorical_accuracy_cp0: 0.0373 - top_5_categorical_accuracy_cp1: 0.4755 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9497 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7625 - top_10_categorical_accuracy_cp0: 0.2674 - top_10_categorical_accuracy_cp1: 0.8716 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.9213 - top_20_categorical_accuracy_cp0: 0.5640 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.4863 - top_20_categorical_accuracy_p4: 0.9882 - val_loss: 0.1615 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3352 - val_top_10_categorical_accuracy: 0.4958 - val_top_20_categorical_accuracy: 0.6423 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1739 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6134 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.9565 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.9072 - val_top_20_categorical_accuracy_cp0: 0.2784 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.2903 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.2004 - top_5_categorical_accuracy: 0.6352 - top_10_categorical_accuracy: 0.7940 - top_20_categorical_accuracy: 0.9036 - top_5_categorical_accuracy_cp0: 0.0420 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.9114 - top_5_categorical_accuracy_cp3: 0.9619 - top_5_categorical_accuracy_cp4: 0.9167 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7385 - top_10_categorical_accuracy_cp0: 0.2773 - top_10_categorical_accuracy_cp1: 0.8559 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9810 - top_10_categorical_accuracy_cp4: 0.9630 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0980 - top_10_categorical_accuracy_p4: 0.9121 - top_20_categorical_accuracy_cp0: 0.6387 - top_20_categorical_accuracy_cp1: 0.9492 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9815 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0714 - top_20_categorical_accuracy_p3: 0.5882 - top_20_categorical_accuracy_p4: 0.98243/7 [===========>..................] - ETA: 0s - loss: 0.1149 - categorical_accuracy: 0.2066 - top_5_categorical_accuracy: 0.6755 - top_10_categorical_accuracy: 0.8308 - top_20_categorical_accuracy: 0.9068 - top_5_categorical_accuracy_cp0: 0.0825 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.9016 - top_5_categorical_accuracy_cp3: 0.9635 - top_5_categorical_accuracy_cp4: 0.9438 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7719 - top_10_categorical_accuracy_cp0: 0.3206 - top_10_categorical_accuracy_cp1: 0.8952 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9848 - top_10_categorical_accuracy_cp4: 0.9719 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1333 - top_10_categorical_accuracy_p4: 0.9377 - top_20_categorical_accuracy_cp0: 0.5841 - top_20_categorical_accuracy_cp1: 0.9671 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9888 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0222 - top_20_categorical_accuracy_p3: 0.5417 - top_20_categorical_accuracy_p4: 0.98845/7 [====================>.........] - ETA: 0s - loss: 0.1134 - categorical_accuracy: 0.2076 - top_5_categorical_accuracy: 0.6882 - top_10_categorical_accuracy: 0.8388 - top_20_categorical_accuracy: 0.9095 - top_5_categorical_accuracy_cp0: 0.0835 - top_5_categorical_accuracy_cp1: 0.5284 - top_5_categorical_accuracy_cp2: 0.8947 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9592 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7859 - top_10_categorical_accuracy_cp0: 0.3320 - top_10_categorical_accuracy_cp1: 0.9064 - top_10_categorical_accuracy_cp2: 0.9875 - top_10_categorical_accuracy_cp3: 0.9821 - top_10_categorical_accuracy_cp4: 0.9771 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1762 - top_10_categorical_accuracy_p4: 0.9418 - top_20_categorical_accuracy_cp0: 0.5786 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9935 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0282 - top_20_categorical_accuracy_p3: 0.5190 - top_20_categorical_accuracy_p4: 0.99047/7 [==============================] - ETA: 0s - loss: 0.1126 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.6905 - top_10_categorical_accuracy: 0.8415 - top_20_categorical_accuracy: 0.9118 - top_5_categorical_accuracy_cp0: 0.0875 - top_5_categorical_accuracy_cp1: 0.5229 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7868 - top_10_categorical_accuracy_cp0: 0.3420 - top_10_categorical_accuracy_cp1: 0.9052 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9761 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1804 - top_10_categorical_accuracy_p4: 0.9424 - top_20_categorical_accuracy_cp0: 0.5867 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.5216 - top_20_categorical_accuracy_p4: 0.9903DEBUG:root:Model metric val_loss improved from 0.161466 to 0.159120
7/7 [==============================] - 1s 116ms/step - loss: 0.1126 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.6905 - top_10_categorical_accuracy: 0.8415 - top_20_categorical_accuracy: 0.9118 - top_5_categorical_accuracy_cp0: 0.0875 - top_5_categorical_accuracy_cp1: 0.5229 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7868 - top_10_categorical_accuracy_cp0: 0.3420 - top_10_categorical_accuracy_cp1: 0.9052 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9761 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1804 - top_10_categorical_accuracy_p4: 0.9424 - top_20_categorical_accuracy_cp0: 0.5867 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.5216 - top_20_categorical_accuracy_p4: 0.9903 - val_loss: 0.1591 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3380 - val_top_10_categorical_accuracy: 0.4789 - val_top_20_categorical_accuracy: 0.6817 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1884 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6186 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8696 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8763 - val_top_20_categorical_accuracy_cp0: 0.3580 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3952 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1149 - categorical_accuracy: 0.2136 - top_5_categorical_accuracy: 0.6749 - top_10_categorical_accuracy: 0.8166 - top_20_categorical_accuracy: 0.9112 - top_5_categorical_accuracy_cp0: 0.1171 - top_5_categorical_accuracy_cp1: 0.5268 - top_5_categorical_accuracy_cp2: 0.9012 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7694 - top_10_categorical_accuracy_cp0: 0.3604 - top_10_categorical_accuracy_cp1: 0.8750 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9469 - top_10_categorical_accuracy_cp4: 0.9554 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1667 - top_10_categorical_accuracy_p4: 0.9159 - top_20_categorical_accuracy_cp0: 0.6396 - top_20_categorical_accuracy_cp1: 0.9643 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9823 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0909 - top_20_categorical_accuracy_p3: 0.5714 - top_20_categorical_accuracy_p4: 0.98493/7 [===========>..................] - ETA: 0s - loss: 0.1127 - categorical_accuracy: 0.2132 - top_5_categorical_accuracy: 0.6820 - top_10_categorical_accuracy: 0.8347 - top_20_categorical_accuracy: 0.9129 - top_5_categorical_accuracy_cp0: 0.1049 - top_5_categorical_accuracy_cp1: 0.5303 - top_5_categorical_accuracy_cp2: 0.8870 - top_5_categorical_accuracy_cp3: 0.9588 - top_5_categorical_accuracy_cp4: 0.9474 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7777 - top_10_categorical_accuracy_cp0: 0.3580 - top_10_categorical_accuracy_cp1: 0.9000 - top_10_categorical_accuracy_cp2: 0.9957 - top_10_categorical_accuracy_cp3: 0.9765 - top_10_categorical_accuracy_cp4: 0.9668 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1450 - top_10_categorical_accuracy_p4: 0.9381 - top_20_categorical_accuracy_cp0: 0.6204 - top_20_categorical_accuracy_cp1: 0.9758 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9912 - top_20_categorical_accuracy_cp4: 0.9889 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0857 - top_20_categorical_accuracy_p3: 0.5344 - top_20_categorical_accuracy_p4: 0.98855/7 [====================>.........] - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.2125 - top_5_categorical_accuracy: 0.6970 - top_10_categorical_accuracy: 0.8399 - top_20_categorical_accuracy: 0.9103 - top_5_categorical_accuracy_cp0: 0.0975 - top_5_categorical_accuracy_cp1: 0.5284 - top_5_categorical_accuracy_cp2: 0.9144 - top_5_categorical_accuracy_cp3: 0.9657 - top_5_categorical_accuracy_cp4: 0.9614 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7952 - top_10_categorical_accuracy_cp0: 0.3450 - top_10_categorical_accuracy_cp1: 0.8972 - top_10_categorical_accuracy_cp2: 0.9950 - top_10_categorical_accuracy_cp3: 0.9783 - top_10_categorical_accuracy_cp4: 0.9758 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1589 - top_10_categorical_accuracy_p4: 0.9436 - top_20_categorical_accuracy_cp0: 0.5965 - top_20_categorical_accuracy_cp1: 0.9670 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 0.9903 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0448 - top_20_categorical_accuracy_p3: 0.5421 - top_20_categorical_accuracy_p4: 0.98707/7 [==============================] - ETA: 0s - loss: 0.1109 - categorical_accuracy: 0.2128 - top_5_categorical_accuracy: 0.7015 - top_10_categorical_accuracy: 0.8434 - top_20_categorical_accuracy: 0.9127 - top_5_categorical_accuracy_cp0: 0.1086 - top_5_categorical_accuracy_cp1: 0.5291 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9655 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7990 - top_10_categorical_accuracy_cp0: 0.3485 - top_10_categorical_accuracy_cp1: 0.9006 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1608 - top_10_categorical_accuracy_p4: 0.9464 - top_20_categorical_accuracy_cp0: 0.5981 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.5490 - top_20_categorical_accuracy_p4: 0.9889    DEBUG:root:Model metric val_loss improved from 0.159120 to 0.157284
7/7 [==============================] - 1s 113ms/step - loss: 0.1109 - categorical_accuracy: 0.2128 - top_5_categorical_accuracy: 0.7015 - top_10_categorical_accuracy: 0.8434 - top_20_categorical_accuracy: 0.9127 - top_5_categorical_accuracy_cp0: 0.1086 - top_5_categorical_accuracy_cp1: 0.5291 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9655 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7990 - top_10_categorical_accuracy_cp0: 0.3485 - top_10_categorical_accuracy_cp1: 0.9006 - top_10_categorical_accuracy_cp2: 0.9959 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1608 - top_10_categorical_accuracy_p4: 0.9464 - top_20_categorical_accuracy_cp0: 0.5981 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.5490 - top_20_categorical_accuracy_p4: 0.9889 - val_loss: 0.1573 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.4028 - val_top_10_categorical_accuracy: 0.4873 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.5217 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7371 - val_top_10_categorical_accuracy_cp0: 0.0057 - val_top_10_categorical_accuracy_cp1: 0.8986 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8918 - val_top_20_categorical_accuracy_cp0: 0.3466 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3790 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1055 - categorical_accuracy: 0.2038 - top_5_categorical_accuracy: 0.7352 - top_10_categorical_accuracy: 0.8819 - top_20_categorical_accuracy: 0.9371 - top_5_categorical_accuracy_cp0: 0.1205 - top_5_categorical_accuracy_cp1: 0.5439 - top_5_categorical_accuracy_cp2: 0.9359 - top_5_categorical_accuracy_cp3: 0.9646 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8126 - top_10_categorical_accuracy_cp0: 0.4337 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2222 - top_10_categorical_accuracy_p4: 0.9579 - top_20_categorical_accuracy_cp0: 0.6747 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9912 - top_20_categorical_accuracy_cp4: 0.9927 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6389 - top_20_categorical_accuracy_p4: 0.98743/7 [===========>..................] - ETA: 0s - loss: 0.1102 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.7136 - top_10_categorical_accuracy: 0.8517 - top_20_categorical_accuracy: 0.9176 - top_5_categorical_accuracy_cp0: 0.1126 - top_5_categorical_accuracy_cp1: 0.5542 - top_5_categorical_accuracy_cp2: 0.9211 - top_5_categorical_accuracy_cp3: 0.9766 - top_5_categorical_accuracy_cp4: 0.9733 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8112 - top_10_categorical_accuracy_cp0: 0.3642 - top_10_categorical_accuracy_cp1: 0.9157 - top_10_categorical_accuracy_cp2: 0.9912 - top_10_categorical_accuracy_cp3: 0.9766 - top_10_categorical_accuracy_cp4: 0.9893 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1550 - top_10_categorical_accuracy_p4: 0.9539 - top_20_categorical_accuracy_cp0: 0.6258 - top_20_categorical_accuracy_cp1: 0.9699 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9883 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0541 - top_20_categorical_accuracy_p3: 0.5814 - top_20_categorical_accuracy_p4: 0.9878    5/7 [====================>.........] - ETA: 0s - loss: 0.1103 - categorical_accuracy: 0.2112 - top_5_categorical_accuracy: 0.7112 - top_10_categorical_accuracy: 0.8478 - top_20_categorical_accuracy: 0.9151 - top_5_categorical_accuracy_cp0: 0.1175 - top_5_categorical_accuracy_cp1: 0.5368 - top_5_categorical_accuracy_cp2: 0.9288 - top_5_categorical_accuracy_cp3: 0.9679 - top_5_categorical_accuracy_cp4: 0.9713 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8098 - top_10_categorical_accuracy_cp0: 0.3645 - top_10_categorical_accuracy_cp1: 0.9044 - top_10_categorical_accuracy_cp2: 0.9898 - top_10_categorical_accuracy_cp3: 0.9750 - top_10_categorical_accuracy_cp4: 0.9825 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1509 - top_10_categorical_accuracy_p4: 0.9515 - top_20_categorical_accuracy_cp0: 0.6016 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9929 - top_20_categorical_accuracy_cp4: 0.9952 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0323 - top_20_categorical_accuracy_p2: 0.0462 - top_20_categorical_accuracy_p3: 0.5472 - top_20_categorical_accuracy_p4: 0.9900    7/7 [==============================] - ETA: 0s - loss: 0.1104 - categorical_accuracy: 0.2116 - top_5_categorical_accuracy: 0.7103 - top_10_categorical_accuracy: 0.8443 - top_20_categorical_accuracy: 0.9143 - top_5_categorical_accuracy_cp0: 0.1264 - top_5_categorical_accuracy_cp1: 0.5336 - top_5_categorical_accuracy_cp2: 0.9300 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8094 - top_10_categorical_accuracy_cp0: 0.3582 - top_10_categorical_accuracy_cp1: 0.9052 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.9485 - top_20_categorical_accuracy_cp0: 0.5997 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.5451 - top_20_categorical_accuracy_p4: 0.9903DEBUG:root:Model metric val_loss improved from 0.157284 to 0.154186
7/7 [==============================] - 1s 111ms/step - loss: 0.1104 - categorical_accuracy: 0.2116 - top_5_categorical_accuracy: 0.7103 - top_10_categorical_accuracy: 0.8443 - top_20_categorical_accuracy: 0.9143 - top_5_categorical_accuracy_cp0: 0.1264 - top_5_categorical_accuracy_cp1: 0.5336 - top_5_categorical_accuracy_cp2: 0.9300 - top_5_categorical_accuracy_cp3: 0.9689 - top_5_categorical_accuracy_cp4: 0.9681 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8094 - top_10_categorical_accuracy_cp0: 0.3582 - top_10_categorical_accuracy_cp1: 0.9052 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9774 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1490 - top_10_categorical_accuracy_p4: 0.9485 - top_20_categorical_accuracy_cp0: 0.5997 - top_20_categorical_accuracy_cp1: 0.9725 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0294 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.5451 - top_20_categorical_accuracy_p4: 0.9903 - val_loss: 0.1542 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.4197 - val_top_10_categorical_accuracy: 0.4873 - val_top_20_categorical_accuracy: 0.7606 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.6087 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7680 - val_top_10_categorical_accuracy_cp0: 0.0057 - val_top_10_categorical_accuracy_cp1: 0.8986 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8918 - val_top_20_categorical_accuracy_cp0: 0.5227 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.6210 - val_top_20_categorical_accuracy_p4: 0.9948
INFO:root:Restoring best model weights with val_loss: 0.154186 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  9.39it/s]Calculating prediction outputs...: 1it [00:00,  9.37it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1611.07it/s]
INFO:root:Finished run 8e7c70bcf1bc4f3ca7be321efc0d8260
Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 21:01:39.248381: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:01:39.771627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:01:39.771694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:01:39.771700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 20f0f98d2c1d41cfaac621bfc602d3c5
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12263.82it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13289.50it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13009.67it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24221.20it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 21:01:42.163543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.163736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.164538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.164680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.164809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.164935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.165341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:01:42.297557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.297774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.297929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.298064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.298192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:42.298319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.862886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.863076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.863232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.863364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.863490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.863606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 21:01:43.863977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:01:43.864083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12787.94it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13445.31it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13031.87it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24706.29it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 286.04it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 59/154 [00:00<00:00, 290.55it/s]Loading hierarchy for column coarse_log_cluster_path:  58%|█████▊    | 89/154 [00:00<00:00, 291.39it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 119/154 [00:00<00:00, 292.91it/s]Loading hierarchy for column coarse_log_cluster_path:  97%|█████████▋| 149/154 [00:00<00:00, 293.12it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 292.16it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:50,  7.81it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5246.10it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 39551.44it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/526 [00:00<?, ?it/s]Initializing gram_embedding connections:  23%|██▎       | 122/526 [00:00<00:00, 1206.37it/s]Initializing gram_embedding connections:  46%|████▌     | 243/526 [00:00<00:00, 567.48it/s] Initializing gram_embedding connections:  60%|██████    | 317/526 [00:00<00:00, 413.12it/s]Initializing gram_embedding connections:  70%|███████   | 370/526 [00:00<00:00, 337.22it/s]Initializing gram_embedding connections:  78%|███████▊  | 411/526 [00:01<00:00, 291.58it/s]Initializing gram_embedding connections:  85%|████████▍ | 445/526 [00:01<00:00, 260.37it/s]Initializing gram_embedding connections:  90%|█████████ | 474/526 [00:01<00:00, 236.38it/s]Initializing gram_embedding connections:  95%|█████████▍| 499/526 [00:01<00:00, 217.85it/s]Initializing gram_embedding connections:  99%|█████████▉| 522/526 [00:01<00:00, 202.57it/s]Initializing gram_embedding connections: 100%|██████████| 526/526 [00:01<00:00, 294.18it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.03it/s]Calculating percentile frequencies...: 7it [00:00,  7.20it/s]
2023-05-24 21:01:49.812549: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 21:02:22.343501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 21:02:22.964123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:02:23.042405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:02:23.473422: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f53a8008220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 21:02:23.473467: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:02:23.473478: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:02:23.477243: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 21:02:23.560552: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1935 - categorical_accuracy: 0.0019 - top_5_categorical_accuracy: 0.0345 - top_10_categorical_accuracy: 0.0709 - top_20_categorical_accuracy: 0.1590 - top_5_categorical_accuracy_cp0: 0.0505 - top_5_categorical_accuracy_cp1: 0.0808 - top_5_categorical_accuracy_cp2: 0.0119 - top_5_categorical_accuracy_cp3: 0.0085 - top_5_categorical_accuracy_cp4: 0.0246 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.1000 - top_5_categorical_accuracy_p3: 0.0286 - top_5_categorical_accuracy_p4: 0.0327 - top_10_categorical_accuracy_cp0: 0.1313 - top_10_categorical_accuracy_cp1: 0.1414 - top_10_categorical_accuracy_cp2: 0.0238 - top_10_categorical_accuracy_cp3: 0.0424 - top_10_categorical_accuracy_cp4: 0.0246 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.1000 - top_10_categorical_accuracy_p3: 0.1143 - top_10_categorical_accuracy_p4: 0.0675 - top_20_categorical_accuracy_cp0: 0.2121 - top_20_categorical_accuracy_cp1: 0.2929 - top_20_categorical_accuracy_cp2: 0.1071 - top_20_categorical_accuracy_cp3: 0.1610 - top_20_categorical_accuracy_cp4: 0.0410 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1500 - top_20_categorical_accuracy_p3: 0.2857 - top_20_categorical_accuracy_p4: 0.1525      3/Unknown - 34s 39ms/step - loss: 0.1921 - categorical_accuracy: 0.0451 - top_5_categorical_accuracy: 0.1545 - top_10_categorical_accuracy: 0.2308 - top_20_categorical_accuracy: 0.3484 - top_5_categorical_accuracy_cp0: 0.0614 - top_5_categorical_accuracy_cp1: 0.0923 - top_5_categorical_accuracy_cp2: 0.0335 - top_5_categorical_accuracy_cp3: 0.2326 - top_5_categorical_accuracy_cp4: 0.2857 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0870 - top_5_categorical_accuracy_p3: 0.0259 - top_5_categorical_accuracy_p4: 0.1700 - top_10_categorical_accuracy_cp0: 0.1195 - top_10_categorical_accuracy_cp1: 0.1723 - top_10_categorical_accuracy_cp2: 0.0879 - top_10_categorical_accuracy_cp3: 0.3082 - top_10_categorical_accuracy_cp4: 0.3870 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0500 - top_10_categorical_accuracy_p2: 0.1087 - top_10_categorical_accuracy_p3: 0.0948 - top_10_categorical_accuracy_p4: 0.2493 - top_20_categorical_accuracy_cp0: 0.2116 - top_20_categorical_accuracy_cp1: 0.3046 - top_20_categorical_accuracy_cp2: 0.2008 - top_20_categorical_accuracy_cp3: 0.4381 - top_20_categorical_accuracy_cp4: 0.5039 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.0500 - top_20_categorical_accuracy_p2: 0.1957 - top_20_categorical_accuracy_p3: 0.1983 - top_20_categorical_accuracy_p4: 0.3703                 5/Unknown - 34s 39ms/step - loss: 0.1905 - categorical_accuracy: 0.0798 - top_5_categorical_accuracy: 0.2509 - top_10_categorical_accuracy: 0.3390 - top_20_categorical_accuracy: 0.4527 - top_5_categorical_accuracy_cp0: 0.0557 - top_5_categorical_accuracy_cp1: 0.1162 - top_5_categorical_accuracy_cp2: 0.1175 - top_5_categorical_accuracy_cp3: 0.3579 - top_5_categorical_accuracy_cp4: 0.5210 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0658 - top_5_categorical_accuracy_p3: 0.0237 - top_5_categorical_accuracy_p4: 0.2825 - top_10_categorical_accuracy_cp0: 0.1171 - top_10_categorical_accuracy_cp1: 0.2214 - top_10_categorical_accuracy_cp2: 0.2376 - top_10_categorical_accuracy_cp3: 0.4406 - top_10_categorical_accuracy_cp4: 0.6016 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0333 - top_10_categorical_accuracy_p2: 0.1053 - top_10_categorical_accuracy_p3: 0.0900 - top_10_categorical_accuracy_p4: 0.3755 - top_20_categorical_accuracy_cp0: 0.2150 - top_20_categorical_accuracy_cp1: 0.3884 - top_20_categorical_accuracy_cp2: 0.3525 - top_20_categorical_accuracy_cp3: 0.5522 - top_20_categorical_accuracy_cp4: 0.6823 - top_20_categorical_accuracy_p0: 0.1538 - top_20_categorical_accuracy_p1: 0.0667 - top_20_categorical_accuracy_p2: 0.2105 - top_20_categorical_accuracy_p3: 0.1943 - top_20_categorical_accuracy_p4: 0.4911      7/Unknown - 34s 38ms/step - loss: 0.1889 - categorical_accuracy: 0.0926 - top_5_categorical_accuracy: 0.2969 - top_10_categorical_accuracy: 0.3892 - top_20_categorical_accuracy: 0.4978 - top_5_categorical_accuracy_cp0: 0.0600 - top_5_categorical_accuracy_cp1: 0.1422 - top_5_categorical_accuracy_cp2: 0.1708 - top_5_categorical_accuracy_cp3: 0.4201 - top_5_categorical_accuracy_cp4: 0.5963 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0588 - top_5_categorical_accuracy_p3: 0.0235 - top_5_categorical_accuracy_p4: 0.3344 - top_10_categorical_accuracy_cp0: 0.1216 - top_10_categorical_accuracy_cp1: 0.2676 - top_10_categorical_accuracy_cp2: 0.3086 - top_10_categorical_accuracy_cp3: 0.5015 - top_10_categorical_accuracy_cp4: 0.6653 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0941 - top_10_categorical_accuracy_p3: 0.0863 - top_10_categorical_accuracy_p4: 0.4320 - top_20_categorical_accuracy_cp0: 0.2188 - top_20_categorical_accuracy_cp1: 0.4327 - top_20_categorical_accuracy_cp2: 0.4300 - top_20_categorical_accuracy_cp3: 0.6036 - top_20_categorical_accuracy_cp4: 0.7317 - top_20_categorical_accuracy_p0: 0.1875 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1882 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.5426    2023-05-24 21:02:24.613433: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195998
7/7 [==============================] - 53s 3s/step - loss: 0.1889 - categorical_accuracy: 0.0926 - top_5_categorical_accuracy: 0.2969 - top_10_categorical_accuracy: 0.3892 - top_20_categorical_accuracy: 0.4978 - top_5_categorical_accuracy_cp0: 0.0600 - top_5_categorical_accuracy_cp1: 0.1422 - top_5_categorical_accuracy_cp2: 0.1708 - top_5_categorical_accuracy_cp3: 0.4201 - top_5_categorical_accuracy_cp4: 0.5963 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0588 - top_5_categorical_accuracy_p3: 0.0235 - top_5_categorical_accuracy_p4: 0.3344 - top_10_categorical_accuracy_cp0: 0.1216 - top_10_categorical_accuracy_cp1: 0.2676 - top_10_categorical_accuracy_cp2: 0.3086 - top_10_categorical_accuracy_cp3: 0.5015 - top_10_categorical_accuracy_cp4: 0.6653 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0941 - top_10_categorical_accuracy_p3: 0.0863 - top_10_categorical_accuracy_p4: 0.4320 - top_20_categorical_accuracy_cp0: 0.2188 - top_20_categorical_accuracy_cp1: 0.4327 - top_20_categorical_accuracy_cp2: 0.4300 - top_20_categorical_accuracy_cp3: 0.6036 - top_20_categorical_accuracy_cp4: 0.7317 - top_20_categorical_accuracy_p0: 0.1875 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.1882 - top_20_categorical_accuracy_p3: 0.1882 - top_20_categorical_accuracy_p4: 0.5426 - val_loss: 0.1960 - val_categorical_accuracy: 0.0225 - val_top_5_categorical_accuracy: 0.1521 - val_top_10_categorical_accuracy: 0.2732 - val_top_20_categorical_accuracy: 0.4254 - val_top_5_categorical_accuracy_cp0: 0.0114 - val_top_5_categorical_accuracy_cp1: 0.0145 - val_top_5_categorical_accuracy_cp2: 0.0833 - val_top_5_categorical_accuracy_cp3: 0.5647 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0161 - val_top_5_categorical_accuracy_p4: 0.2680 - val_top_10_categorical_accuracy_cp0: 0.0852 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 0.2083 - val_top_10_categorical_accuracy_cp3: 0.7176 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.1053 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.1048 - val_top_10_categorical_accuracy_p4: 0.4227 - val_top_20_categorical_accuracy_cp0: 0.2102 - val_top_20_categorical_accuracy_cp1: 0.5362 - val_top_20_categorical_accuracy_cp2: 0.2917 - val_top_20_categorical_accuracy_cp3: 0.8118 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.1579 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.2000 - val_top_20_categorical_accuracy_p3: 0.2661 - val_top_20_categorical_accuracy_p4: 0.5876
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1754 - categorical_accuracy: 0.1613 - top_5_categorical_accuracy: 0.5844 - top_10_categorical_accuracy: 0.6641 - top_20_categorical_accuracy: 0.7609 - top_5_categorical_accuracy_cp0: 0.0825 - top_5_categorical_accuracy_cp1: 0.3153 - top_5_categorical_accuracy_cp2: 0.6104 - top_5_categorical_accuracy_cp3: 0.8291 - top_5_categorical_accuracy_cp4: 0.9680 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0625 - top_5_categorical_accuracy_p3: 0.0556 - top_5_categorical_accuracy_p4: 0.6545 - top_10_categorical_accuracy_cp0: 0.1340 - top_10_categorical_accuracy_cp1: 0.5135 - top_10_categorical_accuracy_cp2: 0.7403 - top_10_categorical_accuracy_cp3: 0.8718 - top_10_categorical_accuracy_cp4: 0.9680 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0625 - top_10_categorical_accuracy_p3: 0.1667 - top_10_categorical_accuracy_p4: 0.7361 - top_20_categorical_accuracy_cp0: 0.2371 - top_20_categorical_accuracy_cp1: 0.7658 - top_20_categorical_accuracy_cp2: 0.8442 - top_20_categorical_accuracy_cp3: 0.9145 - top_20_categorical_accuracy_cp4: 0.9680 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.1250 - top_20_categorical_accuracy_p3: 0.2222 - top_20_categorical_accuracy_p4: 0.83483/7 [===========>..................] - ETA: 0s - loss: 0.1717 - categorical_accuracy: 0.1497 - top_5_categorical_accuracy: 0.5374 - top_10_categorical_accuracy: 0.6294 - top_20_categorical_accuracy: 0.7303 - top_5_categorical_accuracy_cp0: 0.0615 - top_5_categorical_accuracy_cp1: 0.2628 - top_5_categorical_accuracy_cp2: 0.5458 - top_5_categorical_accuracy_cp3: 0.7771 - top_5_categorical_accuracy_cp4: 0.9749 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0182 - top_5_categorical_accuracy_p3: 0.0385 - top_5_categorical_accuracy_p4: 0.6175 - top_10_categorical_accuracy_cp0: 0.1200 - top_10_categorical_accuracy_cp1: 0.4904 - top_10_categorical_accuracy_cp2: 0.6708 - top_10_categorical_accuracy_cp3: 0.8387 - top_10_categorical_accuracy_cp4: 0.9860 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0182 - top_10_categorical_accuracy_p3: 0.1000 - top_10_categorical_accuracy_p4: 0.7181 - top_20_categorical_accuracy_cp0: 0.2215 - top_20_categorical_accuracy_cp1: 0.7340 - top_20_categorical_accuracy_cp2: 0.7917 - top_20_categorical_accuracy_cp3: 0.9003 - top_20_categorical_accuracy_cp4: 0.9860 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0870 - top_20_categorical_accuracy_p2: 0.0545 - top_20_categorical_accuracy_p3: 0.1923 - top_20_categorical_accuracy_p4: 0.82315/7 [====================>.........] - ETA: 0s - loss: 0.1640 - categorical_accuracy: 0.1493 - top_5_categorical_accuracy: 0.5567 - top_10_categorical_accuracy: 0.6641 - top_20_categorical_accuracy: 0.7589 - top_5_categorical_accuracy_cp0: 0.0472 - top_5_categorical_accuracy_cp1: 0.2595 - top_5_categorical_accuracy_cp2: 0.5985 - top_5_categorical_accuracy_cp3: 0.7950 - top_5_categorical_accuracy_cp4: 0.9855 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0128 - top_5_categorical_accuracy_p3: 0.0242 - top_5_categorical_accuracy_p4: 0.6330 - top_10_categorical_accuracy_cp0: 0.1081 - top_10_categorical_accuracy_cp1: 0.5417 - top_10_categorical_accuracy_cp2: 0.7324 - top_10_categorical_accuracy_cp3: 0.8723 - top_10_categorical_accuracy_cp4: 0.9920 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0128 - top_10_categorical_accuracy_p3: 0.0966 - top_10_categorical_accuracy_p4: 0.7491 - top_20_categorical_accuracy_cp0: 0.2220 - top_20_categorical_accuracy_cp1: 0.7652 - top_20_categorical_accuracy_cp2: 0.8418 - top_20_categorical_accuracy_cp3: 0.9227 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0769 - top_20_categorical_accuracy_p1: 0.0714 - top_20_categorical_accuracy_p2: 0.0513 - top_20_categorical_accuracy_p3: 0.2029 - top_20_categorical_accuracy_p4: 0.8452    7/7 [==============================] - ETA: 0s - loss: 0.1614 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5527 - top_10_categorical_accuracy: 0.6714 - top_20_categorical_accuracy: 0.7699 - top_5_categorical_accuracy_cp0: 0.0389 - top_5_categorical_accuracy_cp1: 0.2416 - top_5_categorical_accuracy_cp2: 0.6008 - top_5_categorical_accuracy_cp3: 0.8033 - top_5_categorical_accuracy_cp4: 0.9880 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.6277 - top_10_categorical_accuracy_cp0: 0.1005 - top_10_categorical_accuracy_cp1: 0.5627 - top_10_categorical_accuracy_cp2: 0.7490 - top_10_categorical_accuracy_cp3: 0.8831 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0863 - top_10_categorical_accuracy_p4: 0.7568 - top_20_categorical_accuracy_cp0: 0.2269 - top_20_categorical_accuracy_cp1: 0.7859 - top_20_categorical_accuracy_cp2: 0.8621 - top_20_categorical_accuracy_cp3: 0.9349 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.8555DEBUG:root:Model metric val_loss improved from 0.195998 to 0.194326
7/7 [==============================] - 1s 114ms/step - loss: 0.1614 - categorical_accuracy: 0.1485 - top_5_categorical_accuracy: 0.5527 - top_10_categorical_accuracy: 0.6714 - top_20_categorical_accuracy: 0.7699 - top_5_categorical_accuracy_cp0: 0.0389 - top_5_categorical_accuracy_cp1: 0.2416 - top_5_categorical_accuracy_cp2: 0.6008 - top_5_categorical_accuracy_cp3: 0.8033 - top_5_categorical_accuracy_cp4: 0.9880 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0118 - top_5_categorical_accuracy_p3: 0.0196 - top_5_categorical_accuracy_p4: 0.6277 - top_10_categorical_accuracy_cp0: 0.1005 - top_10_categorical_accuracy_cp1: 0.5627 - top_10_categorical_accuracy_cp2: 0.7490 - top_10_categorical_accuracy_cp3: 0.8831 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0118 - top_10_categorical_accuracy_p3: 0.0863 - top_10_categorical_accuracy_p4: 0.7568 - top_20_categorical_accuracy_cp0: 0.2269 - top_20_categorical_accuracy_cp1: 0.7859 - top_20_categorical_accuracy_cp2: 0.8621 - top_20_categorical_accuracy_cp3: 0.9349 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.1250 - top_20_categorical_accuracy_p1: 0.0588 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.8555 - val_loss: 0.1943 - val_categorical_accuracy: 0.0028 - val_top_5_categorical_accuracy: 0.0535 - val_top_10_categorical_accuracy: 0.3915 - val_top_20_categorical_accuracy: 0.4986 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 0.1412 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.0979 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5652 - val_top_10_categorical_accuracy_cp2: 0.5833 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7165 - val_top_20_categorical_accuracy_cp0: 0.0170 - val_top_20_categorical_accuracy_cp1: 0.9420 - val_top_20_categorical_accuracy_cp2: 0.9583 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.1538 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0081 - val_top_20_categorical_accuracy_p4: 0.8969
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1397 - categorical_accuracy: 0.1369 - top_5_categorical_accuracy: 0.5570 - top_10_categorical_accuracy: 0.7091 - top_20_categorical_accuracy: 0.8099 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1485 - top_5_categorical_accuracy_cp2: 0.7262 - top_5_categorical_accuracy_cp3: 0.7586 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6247 - top_10_categorical_accuracy_cp0: 0.0521 - top_10_categorical_accuracy_cp1: 0.5842 - top_10_categorical_accuracy_cp2: 0.8452 - top_10_categorical_accuracy_cp3: 0.9397 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0270 - top_10_categorical_accuracy_p4: 0.7932 - top_20_categorical_accuracy_cp0: 0.2188 - top_20_categorical_accuracy_cp1: 0.8416 - top_20_categorical_accuracy_cp2: 0.9167 - top_20_categorical_accuracy_cp3: 0.9828 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0833 - top_20_categorical_accuracy_p3: 0.2162 - top_20_categorical_accuracy_p4: 0.88913/7 [===========>..................] - ETA: 0s - loss: 0.1435 - categorical_accuracy: 0.1257 - top_5_categorical_accuracy: 0.5067 - top_10_categorical_accuracy: 0.6895 - top_20_categorical_accuracy: 0.8070 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1376 - top_5_categorical_accuracy_cp2: 0.6301 - top_5_categorical_accuracy_cp3: 0.7216 - top_5_categorical_accuracy_cp4: 1.0000 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5783 - top_10_categorical_accuracy_cp0: 0.0482 - top_10_categorical_accuracy_cp1: 0.5902 - top_10_categorical_accuracy_cp2: 0.8577 - top_10_categorical_accuracy_cp3: 0.9281 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0236 - top_10_categorical_accuracy_p4: 0.7848 - top_20_categorical_accuracy_cp0: 0.2379 - top_20_categorical_accuracy_cp1: 0.8563 - top_20_categorical_accuracy_cp2: 0.9512 - top_20_categorical_accuracy_cp3: 0.9760 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0714 - top_20_categorical_accuracy_p3: 0.2126 - top_20_categorical_accuracy_p4: 0.89935/7 [====================>.........] - ETA: 0s - loss: 0.1405 - categorical_accuracy: 0.1258 - top_5_categorical_accuracy: 0.5198 - top_10_categorical_accuracy: 0.7107 - top_20_categorical_accuracy: 0.8194 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1541 - top_5_categorical_accuracy_cp2: 0.6256 - top_5_categorical_accuracy_cp3: 0.7374 - top_5_categorical_accuracy_cp4: 0.9984 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5902 - top_10_categorical_accuracy_cp0: 0.0477 - top_10_categorical_accuracy_cp1: 0.6440 - top_10_categorical_accuracy_cp2: 0.8769 - top_10_categorical_accuracy_cp3: 0.9335 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0498 - top_10_categorical_accuracy_p4: 0.8027 - top_20_categorical_accuracy_cp0: 0.2326 - top_20_categorical_accuracy_cp1: 0.8771 - top_20_categorical_accuracy_cp2: 0.9698 - top_20_categorical_accuracy_cp3: 0.9838 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0429 - top_20_categorical_accuracy_p3: 0.2090 - top_20_categorical_accuracy_p4: 0.91097/7 [==============================] - ETA: 0s - loss: 0.1402 - categorical_accuracy: 0.1249 - top_5_categorical_accuracy: 0.5223 - top_10_categorical_accuracy: 0.7112 - top_20_categorical_accuracy: 0.8198 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1514 - top_5_categorical_accuracy_cp2: 0.6296 - top_5_categorical_accuracy_cp3: 0.7530 - top_5_categorical_accuracy_cp4: 0.9960 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5951 - top_10_categorical_accuracy_cp0: 0.0421 - top_10_categorical_accuracy_cp1: 0.6361 - top_10_categorical_accuracy_cp2: 0.8909 - top_10_categorical_accuracy_cp3: 0.9438 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.8065 - top_20_categorical_accuracy_cp0: 0.2301 - top_20_categorical_accuracy_cp1: 0.8807 - top_20_categorical_accuracy_cp2: 0.9753 - top_20_categorical_accuracy_cp3: 0.9867 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9142DEBUG:root:Model metric val_loss improved from 0.194326 to 0.188641
7/7 [==============================] - 1s 114ms/step - loss: 0.1402 - categorical_accuracy: 0.1249 - top_5_categorical_accuracy: 0.5223 - top_10_categorical_accuracy: 0.7112 - top_20_categorical_accuracy: 0.8198 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1514 - top_5_categorical_accuracy_cp2: 0.6296 - top_5_categorical_accuracy_cp3: 0.7530 - top_5_categorical_accuracy_cp4: 0.9960 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.5951 - top_10_categorical_accuracy_cp0: 0.0421 - top_10_categorical_accuracy_cp1: 0.6361 - top_10_categorical_accuracy_cp2: 0.8909 - top_10_categorical_accuracy_cp3: 0.9438 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0431 - top_10_categorical_accuracy_p4: 0.8065 - top_20_categorical_accuracy_cp0: 0.2301 - top_20_categorical_accuracy_cp1: 0.8807 - top_20_categorical_accuracy_cp2: 0.9753 - top_20_categorical_accuracy_cp3: 0.9867 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0471 - top_20_categorical_accuracy_p3: 0.2039 - top_20_categorical_accuracy_p4: 0.9142 - val_loss: 0.1886 - val_categorical_accuracy: 0.0113 - val_top_5_categorical_accuracy: 0.1577 - val_top_10_categorical_accuracy: 0.4225 - val_top_20_categorical_accuracy: 0.4986 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 0.5765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.2887 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5797 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7732 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 0.9710 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9124
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1309 - categorical_accuracy: 0.1398 - top_5_categorical_accuracy: 0.5958 - top_10_categorical_accuracy: 0.7548 - top_20_categorical_accuracy: 0.8525 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1685 - top_5_categorical_accuracy_cp2: 0.6863 - top_5_categorical_accuracy_cp3: 0.8839 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6717 - top_10_categorical_accuracy_cp0: 0.0110 - top_10_categorical_accuracy_cp1: 0.6067 - top_10_categorical_accuracy_cp2: 0.9706 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8510 - top_20_categorical_accuracy_cp0: 0.2088 - top_20_categorical_accuracy_cp1: 0.9438 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1707 - top_20_categorical_accuracy_p4: 0.94603/7 [===========>..................] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.1416 - top_5_categorical_accuracy: 0.5556 - top_10_categorical_accuracy: 0.7269 - top_20_categorical_accuracy: 0.8432 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1908 - top_5_categorical_accuracy_cp2: 0.6806 - top_5_categorical_accuracy_cp3: 0.8513 - top_5_categorical_accuracy_cp4: 0.9722 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6310 - top_10_categorical_accuracy_cp0: 0.0224 - top_10_categorical_accuracy_cp1: 0.6184 - top_10_categorical_accuracy_cp2: 0.9696 - top_10_categorical_accuracy_cp3: 0.9913 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0161 - top_10_categorical_accuracy_p4: 0.8241 - top_20_categorical_accuracy_cp0: 0.2564 - top_20_categorical_accuracy_cp1: 0.9474 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0286 - top_20_categorical_accuracy_p3: 0.2177 - top_20_categorical_accuracy_p4: 0.9375        5/7 [====================>.........] - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.1494 - top_5_categorical_accuracy: 0.5648 - top_10_categorical_accuracy: 0.7401 - top_20_categorical_accuracy: 0.8533 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.1902 - top_5_categorical_accuracy_cp2: 0.7295 - top_5_categorical_accuracy_cp3: 0.8556 - top_5_categorical_accuracy_cp4: 0.9727 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6432 - top_10_categorical_accuracy_cp0: 0.0298 - top_10_categorical_accuracy_cp1: 0.6610 - top_10_categorical_accuracy_cp2: 0.9758 - top_10_categorical_accuracy_cp3: 0.9928 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0239 - top_10_categorical_accuracy_p4: 0.8407 - top_20_categorical_accuracy_cp0: 0.2823 - top_20_categorical_accuracy_cp1: 0.9548 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0303 - top_20_categorical_accuracy_p3: 0.2536 - top_20_categorical_accuracy_p4: 0.94797/7 [==============================] - ETA: 0s - loss: 0.1322 - categorical_accuracy: 0.1563 - top_5_categorical_accuracy: 0.5697 - top_10_categorical_accuracy: 0.7423 - top_20_categorical_accuracy: 0.8537 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2034 - top_5_categorical_accuracy_cp2: 0.7490 - top_5_categorical_accuracy_cp3: 0.8669 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6491 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.6850 - top_10_categorical_accuracy_cp2: 0.9774 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0235 - top_10_categorical_accuracy_p4: 0.8437 - top_20_categorical_accuracy_cp0: 0.2917 - top_20_categorical_accuracy_cp1: 0.9557 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9492DEBUG:root:Model metric val_loss improved from 0.188641 to 0.178109
7/7 [==============================] - 1s 119ms/step - loss: 0.1322 - categorical_accuracy: 0.1563 - top_5_categorical_accuracy: 0.5697 - top_10_categorical_accuracy: 0.7423 - top_20_categorical_accuracy: 0.8537 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.2034 - top_5_categorical_accuracy_cp2: 0.7490 - top_5_categorical_accuracy_cp3: 0.8669 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6491 - top_10_categorical_accuracy_cp0: 0.0276 - top_10_categorical_accuracy_cp1: 0.6850 - top_10_categorical_accuracy_cp2: 0.9774 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0235 - top_10_categorical_accuracy_p4: 0.8437 - top_20_categorical_accuracy_cp0: 0.2917 - top_20_categorical_accuracy_cp1: 0.9557 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.2471 - top_20_categorical_accuracy_p4: 0.9492 - val_loss: 0.1781 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3042 - val_top_10_categorical_accuracy: 0.3155 - val_top_20_categorical_accuracy: 0.5155 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5567 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.0290 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.5773 - val_top_20_categorical_accuracy_cp0: 0.0284 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9433
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1236 - categorical_accuracy: 0.2015 - top_5_categorical_accuracy: 0.6236 - top_10_categorical_accuracy: 0.7795 - top_20_categorical_accuracy: 0.8726 - top_5_categorical_accuracy_cp0: 0.0000e+00 - top_5_categorical_accuracy_cp1: 0.3448 - top_5_categorical_accuracy_cp2: 0.8961 - top_5_categorical_accuracy_cp3: 0.8889 - top_5_categorical_accuracy_cp4: 0.9609 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7024 - top_10_categorical_accuracy_cp0: 0.0206 - top_10_categorical_accuracy_cp1: 0.8276 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9907 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8779 - top_20_categorical_accuracy_cp0: 0.3299 - top_20_categorical_accuracy_cp1: 0.9828 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1282 - top_20_categorical_accuracy_p4: 0.97223/7 [===========>..................] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.2047 - top_5_categorical_accuracy: 0.6001 - top_10_categorical_accuracy: 0.7560 - top_20_categorical_accuracy: 0.8612 - top_5_categorical_accuracy_cp0: 0.0030 - top_5_categorical_accuracy_cp1: 0.3251 - top_5_categorical_accuracy_cp2: 0.8008 - top_5_categorical_accuracy_cp3: 0.9307 - top_5_categorical_accuracy_cp4: 0.9581 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6912 - top_10_categorical_accuracy_cp0: 0.0365 - top_10_categorical_accuracy_cp1: 0.8019 - top_10_categorical_accuracy_cp2: 0.9915 - top_10_categorical_accuracy_cp3: 0.9940 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0073 - top_10_categorical_accuracy_p4: 0.8701 - top_20_categorical_accuracy_cp0: 0.3587 - top_20_categorical_accuracy_cp1: 0.9752 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2409 - top_20_categorical_accuracy_p4: 0.9679        5/7 [====================>.........] - ETA: 0s - loss: 0.1247 - categorical_accuracy: 0.2085 - top_5_categorical_accuracy: 0.6134 - top_10_categorical_accuracy: 0.7671 - top_20_categorical_accuracy: 0.8680 - top_5_categorical_accuracy_cp0: 0.0076 - top_5_categorical_accuracy_cp1: 0.3697 - top_5_categorical_accuracy_cp2: 0.7761 - top_5_categorical_accuracy_cp3: 0.9291 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7027 - top_10_categorical_accuracy_cp0: 0.0515 - top_10_categorical_accuracy_cp1: 0.8115 - top_10_categorical_accuracy_cp2: 0.9898 - top_10_categorical_accuracy_cp3: 0.9840 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0141 - top_10_categorical_accuracy_p4: 0.8775 - top_20_categorical_accuracy_cp0: 0.3607 - top_20_categorical_accuracy_cp1: 0.9778 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2535 - top_20_categorical_accuracy_p4: 0.97087/7 [==============================] - ETA: 0s - loss: 0.1239 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6164 - top_10_categorical_accuracy: 0.7750 - top_20_categorical_accuracy: 0.8716 - top_5_categorical_accuracy_cp0: 0.0081 - top_5_categorical_accuracy_cp1: 0.3654 - top_5_categorical_accuracy_cp2: 0.7695 - top_5_categorical_accuracy_cp3: 0.9246 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7024 - top_10_categorical_accuracy_cp0: 0.0551 - top_10_categorical_accuracy_cp1: 0.8196 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9822 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8820 - top_20_categorical_accuracy_cp0: 0.3582 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2510 - top_20_categorical_accuracy_p4: 0.9703DEBUG:root:Model metric val_loss improved from 0.178109 to 0.170698
7/7 [==============================] - 1s 115ms/step - loss: 0.1239 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6164 - top_10_categorical_accuracy: 0.7750 - top_20_categorical_accuracy: 0.8716 - top_5_categorical_accuracy_cp0: 0.0081 - top_5_categorical_accuracy_cp1: 0.3654 - top_5_categorical_accuracy_cp2: 0.7695 - top_5_categorical_accuracy_cp3: 0.9246 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7024 - top_10_categorical_accuracy_cp0: 0.0551 - top_10_categorical_accuracy_cp1: 0.8196 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9822 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0118 - top_10_categorical_accuracy_p4: 0.8820 - top_20_categorical_accuracy_cp0: 0.3582 - top_20_categorical_accuracy_cp1: 0.9801 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.2510 - top_20_categorical_accuracy_p4: 0.9703 - val_loss: 0.1707 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2986 - val_top_10_categorical_accuracy: 0.3465 - val_top_20_categorical_accuracy: 0.5296 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.9167 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5464 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.1884 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6340 - val_top_20_categorical_accuracy_cp0: 0.0511 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9691
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1238 - categorical_accuracy: 0.2128 - top_5_categorical_accuracy: 0.6252 - top_10_categorical_accuracy: 0.7797 - top_20_categorical_accuracy: 0.8927 - top_5_categorical_accuracy_cp0: 0.0175 - top_5_categorical_accuracy_cp1: 0.4961 - top_5_categorical_accuracy_cp2: 0.7419 - top_5_categorical_accuracy_cp3: 0.9561 - top_5_categorical_accuracy_cp4: 0.9825 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7079 - top_10_categorical_accuracy_cp0: 0.1053 - top_10_categorical_accuracy_cp1: 0.8898 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 0.9912 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0000e+00 - top_10_categorical_accuracy_p4: 0.8827 - top_20_categorical_accuracy_cp0: 0.5088 - top_20_categorical_accuracy_cp1: 0.9921 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3846 - top_20_categorical_accuracy_p4: 0.97873/7 [===========>..................] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.2095 - top_5_categorical_accuracy: 0.6437 - top_10_categorical_accuracy: 0.7899 - top_20_categorical_accuracy: 0.8918 - top_5_categorical_accuracy_cp0: 0.0129 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.7380 - top_5_categorical_accuracy_cp3: 0.9466 - top_5_categorical_accuracy_cp4: 0.9726 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7264 - top_10_categorical_accuracy_cp0: 0.1230 - top_10_categorical_accuracy_cp1: 0.8441 - top_10_categorical_accuracy_cp2: 0.9956 - top_10_categorical_accuracy_cp3: 0.9792 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0268 - top_10_categorical_accuracy_p4: 0.8893 - top_20_categorical_accuracy_cp0: 0.4790 - top_20_categorical_accuracy_cp1: 0.9765 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3393 - top_20_categorical_accuracy_p4: 0.9793    5/7 [====================>.........] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6483 - top_10_categorical_accuracy: 0.7967 - top_20_categorical_accuracy: 0.8915 - top_5_categorical_accuracy_cp0: 0.0217 - top_5_categorical_accuracy_cp1: 0.4926 - top_5_categorical_accuracy_cp2: 0.7277 - top_5_categorical_accuracy_cp3: 0.9443 - top_5_categorical_accuracy_cp4: 0.9761 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0048 - top_5_categorical_accuracy_p4: 0.7371 - top_10_categorical_accuracy_cp0: 0.1479 - top_10_categorical_accuracy_cp1: 0.8506 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 0.9767 - top_10_categorical_accuracy_cp4: 0.9952 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0478 - top_10_categorical_accuracy_p4: 0.9021 - top_20_categorical_accuracy_cp0: 0.4734 - top_20_categorical_accuracy_cp1: 0.9760 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0137 - top_20_categorical_accuracy_p3: 0.3541 - top_20_categorical_accuracy_p4: 0.9818        7/7 [==============================] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6469 - top_10_categorical_accuracy: 0.7969 - top_20_categorical_accuracy: 0.8920 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4908 - top_5_categorical_accuracy_cp2: 0.7202 - top_5_categorical_accuracy_cp3: 0.9482 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7368 - top_10_categorical_accuracy_cp0: 0.1475 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9778 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.9045 - top_20_categorical_accuracy_cp0: 0.4830 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.3765 - top_20_categorical_accuracy_p4: 0.9814DEBUG:root:Model metric val_loss improved from 0.170698 to 0.169943
7/7 [==============================] - 1s 113ms/step - loss: 0.1198 - categorical_accuracy: 0.2109 - top_5_categorical_accuracy: 0.6469 - top_10_categorical_accuracy: 0.7969 - top_20_categorical_accuracy: 0.8920 - top_5_categorical_accuracy_cp0: 0.0211 - top_5_categorical_accuracy_cp1: 0.4908 - top_5_categorical_accuracy_cp2: 0.7202 - top_5_categorical_accuracy_cp3: 0.9482 - top_5_categorical_accuracy_cp4: 0.9774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7368 - top_10_categorical_accuracy_cp0: 0.1475 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9778 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0392 - top_10_categorical_accuracy_p4: 0.9045 - top_20_categorical_accuracy_cp0: 0.4830 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.3765 - top_20_categorical_accuracy_p4: 0.9814 - val_loss: 0.1699 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3211 - val_top_10_categorical_accuracy: 0.3606 - val_top_20_categorical_accuracy: 0.5239 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1014 - val_top_5_categorical_accuracy_cp2: 0.9583 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5876 - val_top_10_categorical_accuracy_cp0: 0.0170 - val_top_10_categorical_accuracy_cp1: 0.2464 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6598 - val_top_20_categorical_accuracy_cp0: 0.0682 - val_top_20_categorical_accuracy_cp1: 0.9275 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9588
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1139 - categorical_accuracy: 0.2084 - top_5_categorical_accuracy: 0.6711 - top_10_categorical_accuracy: 0.8222 - top_20_categorical_accuracy: 0.8987 - top_5_categorical_accuracy_cp0: 0.0435 - top_5_categorical_accuracy_cp1: 0.4423 - top_5_categorical_accuracy_cp2: 0.7931 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9767 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7597 - top_10_categorical_accuracy_cp0: 0.2391 - top_10_categorical_accuracy_cp1: 0.8462 - top_10_categorical_accuracy_cp2: 0.9770 - top_10_categorical_accuracy_cp3: 0.9640 - top_10_categorical_accuracy_cp4: 0.9922 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0833 - top_10_categorical_accuracy_p4: 0.9221 - top_20_categorical_accuracy_cp0: 0.5109 - top_20_categorical_accuracy_cp1: 0.9519 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9730 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3542 - top_20_categorical_accuracy_p4: 0.98054/7 [================>.............] - ETA: 0s - loss: 0.1164 - categorical_accuracy: 0.2037 - top_5_categorical_accuracy: 0.6737 - top_10_categorical_accuracy: 0.8144 - top_20_categorical_accuracy: 0.8941 - top_5_categorical_accuracy_cp0: 0.0252 - top_5_categorical_accuracy_cp1: 0.4815 - top_5_categorical_accuracy_cp2: 0.8534 - top_5_categorical_accuracy_cp3: 0.9457 - top_5_categorical_accuracy_cp4: 0.9762 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7720 - top_10_categorical_accuracy_cp0: 0.2191 - top_10_categorical_accuracy_cp1: 0.8593 - top_10_categorical_accuracy_cp2: 0.9885 - top_10_categorical_accuracy_cp3: 0.9706 - top_10_categorical_accuracy_cp4: 0.9901 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0847 - top_10_categorical_accuracy_p4: 0.9251 - top_20_categorical_accuracy_cp0: 0.4912 - top_20_categorical_accuracy_cp1: 0.9654 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9864 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0175 - top_20_categorical_accuracy_p3: 0.3729 - top_20_categorical_accuracy_p4: 0.9880    6/7 [========================>.....] - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.2036 - top_5_categorical_accuracy: 0.6718 - top_10_categorical_accuracy: 0.8171 - top_20_categorical_accuracy: 0.8957 - top_5_categorical_accuracy_cp0: 0.0277 - top_5_categorical_accuracy_cp1: 0.5023 - top_5_categorical_accuracy_cp2: 0.8711 - top_5_categorical_accuracy_cp3: 0.9493 - top_5_categorical_accuracy_cp4: 0.9717 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7664 - top_10_categorical_accuracy_cp0: 0.2496 - top_10_categorical_accuracy_cp1: 0.8717 - top_10_categorical_accuracy_cp2: 0.9896 - top_10_categorical_accuracy_cp3: 0.9731 - top_10_categorical_accuracy_cp4: 0.9852 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1137 - top_10_categorical_accuracy_p4: 0.9215 - top_20_categorical_accuracy_cp0: 0.5204 - top_20_categorical_accuracy_cp1: 0.9583 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9881 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0238 - top_20_categorical_accuracy_p3: 0.3843 - top_20_categorical_accuracy_p4: 0.9855DEBUG:root:Model metric val_loss improved from 0.169943 to 0.167273
7/7 [==============================] - 1s 109ms/step - loss: 0.1167 - categorical_accuracy: 0.2031 - top_5_categorical_accuracy: 0.6726 - top_10_categorical_accuracy: 0.8183 - top_20_categorical_accuracy: 0.8964 - top_5_categorical_accuracy_cp0: 0.0276 - top_5_categorical_accuracy_cp1: 0.5031 - top_5_categorical_accuracy_cp2: 0.8724 - top_5_categorical_accuracy_cp3: 0.9482 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7665 - top_10_categorical_accuracy_cp0: 0.2512 - top_10_categorical_accuracy_cp1: 0.8731 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9734 - top_10_categorical_accuracy_cp4: 0.9854 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1137 - top_10_categorical_accuracy_p4: 0.9220 - top_20_categorical_accuracy_cp0: 0.5219 - top_20_categorical_accuracy_cp1: 0.9587 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.3843 - top_20_categorical_accuracy_p4: 0.9857 - val_loss: 0.1673 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3324 - val_top_10_categorical_accuracy: 0.3521 - val_top_20_categorical_accuracy: 0.5380 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.1594 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.6082 - val_top_10_categorical_accuracy_cp0: 0.0114 - val_top_10_categorical_accuracy_cp1: 0.2174 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6443 - val_top_20_categorical_accuracy_cp0: 0.0739 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0081 - val_top_20_categorical_accuracy_p4: 0.9794
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.2098 - top_5_categorical_accuracy: 0.6219 - top_10_categorical_accuracy: 0.7788 - top_20_categorical_accuracy: 0.8847 - top_5_categorical_accuracy_cp0: 0.0588 - top_5_categorical_accuracy_cp1: 0.4831 - top_5_categorical_accuracy_cp2: 0.8101 - top_5_categorical_accuracy_cp3: 0.9429 - top_5_categorical_accuracy_cp4: 0.9444 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7231 - top_10_categorical_accuracy_cp0: 0.2521 - top_10_categorical_accuracy_cp1: 0.8390 - top_10_categorical_accuracy_cp2: 0.9620 - top_10_categorical_accuracy_cp3: 0.9810 - top_10_categorical_accuracy_cp4: 0.9630 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1346 - top_10_categorical_accuracy_p4: 0.8901 - top_20_categorical_accuracy_cp0: 0.5630 - top_20_categorical_accuracy_cp1: 0.9407 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9810 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4615 - top_20_categorical_accuracy_p4: 0.97583/7 [===========>..................] - ETA: 0s - loss: 0.1159 - categorical_accuracy: 0.2104 - top_5_categorical_accuracy: 0.6660 - top_10_categorical_accuracy: 0.8181 - top_20_categorical_accuracy: 0.9011 - top_5_categorical_accuracy_cp0: 0.0635 - top_5_categorical_accuracy_cp1: 0.4790 - top_5_categorical_accuracy_cp2: 0.8770 - top_5_categorical_accuracy_cp3: 0.9483 - top_5_categorical_accuracy_cp4: 0.9691 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0085 - top_5_categorical_accuracy_p4: 0.7603 - top_10_categorical_accuracy_cp0: 0.2825 - top_10_categorical_accuracy_cp1: 0.8832 - top_10_categorical_accuracy_cp2: 0.9836 - top_10_categorical_accuracy_cp3: 0.9696 - top_10_categorical_accuracy_cp4: 0.9775 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1525 - top_10_categorical_accuracy_p4: 0.9218 - top_20_categorical_accuracy_cp0: 0.5587 - top_20_categorical_accuracy_cp1: 0.9641 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9878 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0200 - top_20_categorical_accuracy_p3: 0.5000 - top_20_categorical_accuracy_p4: 0.9862        5/7 [====================>.........] - ETA: 0s - loss: 0.1147 - categorical_accuracy: 0.2080 - top_5_categorical_accuracy: 0.6757 - top_10_categorical_accuracy: 0.8240 - top_20_categorical_accuracy: 0.9030 - top_5_categorical_accuracy_cp0: 0.0563 - top_5_categorical_accuracy_cp1: 0.4917 - top_5_categorical_accuracy_cp2: 0.8897 - top_5_categorical_accuracy_cp3: 0.9445 - top_5_categorical_accuracy_cp4: 0.9755 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0048 - top_5_categorical_accuracy_p4: 0.7712 - top_10_categorical_accuracy_cp0: 0.2854 - top_10_categorical_accuracy_cp1: 0.8789 - top_10_categorical_accuracy_cp2: 0.9875 - top_10_categorical_accuracy_cp3: 0.9732 - top_10_categorical_accuracy_cp4: 0.9853 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1381 - top_10_categorical_accuracy_p4: 0.9284 - top_20_categorical_accuracy_cp0: 0.5515 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9875 - top_20_categorical_accuracy_cp4: 0.9984 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0143 - top_20_categorical_accuracy_p3: 0.4667 - top_20_categorical_accuracy_p4: 0.98837/7 [==============================] - ETA: 0s - loss: 0.1140 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6814 - top_10_categorical_accuracy: 0.8252 - top_20_categorical_accuracy: 0.9021 - top_5_categorical_accuracy_cp0: 0.0519 - top_5_categorical_accuracy_cp1: 0.5046 - top_5_categorical_accuracy_cp2: 0.8971 - top_5_categorical_accuracy_cp3: 0.9453 - top_5_categorical_accuracy_cp4: 0.9748 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7761 - top_10_categorical_accuracy_cp0: 0.2836 - top_10_categorical_accuracy_cp1: 0.8792 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9734 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1333 - top_10_categorical_accuracy_p4: 0.9281 - top_20_categorical_accuracy_cp0: 0.5494 - top_20_categorical_accuracy_cp1: 0.9618 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.4471 - top_20_categorical_accuracy_p4: 0.9864DEBUG:root:Model metric val_loss improved from 0.167273 to 0.164276
7/7 [==============================] - 1s 113ms/step - loss: 0.1140 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6814 - top_10_categorical_accuracy: 0.8252 - top_20_categorical_accuracy: 0.9021 - top_5_categorical_accuracy_cp0: 0.0519 - top_5_categorical_accuracy_cp1: 0.5046 - top_5_categorical_accuracy_cp2: 0.8971 - top_5_categorical_accuracy_cp3: 0.9453 - top_5_categorical_accuracy_cp4: 0.9748 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7761 - top_10_categorical_accuracy_cp0: 0.2836 - top_10_categorical_accuracy_cp1: 0.8792 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9734 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1333 - top_10_categorical_accuracy_p4: 0.9281 - top_20_categorical_accuracy_cp0: 0.5494 - top_20_categorical_accuracy_cp1: 0.9618 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.4471 - top_20_categorical_accuracy_p4: 0.9864 - val_loss: 0.1643 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3155 - val_top_10_categorical_accuracy: 0.3437 - val_top_20_categorical_accuracy: 0.5549 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0580 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5773 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.2029 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6289 - val_top_20_categorical_accuracy_cp0: 0.1080 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0645 - val_top_20_categorical_accuracy_p4: 0.9742
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1159 - categorical_accuracy: 0.2042 - top_5_categorical_accuracy: 0.6824 - top_10_categorical_accuracy: 0.8185 - top_20_categorical_accuracy: 0.8979 - top_5_categorical_accuracy_cp0: 0.0811 - top_5_categorical_accuracy_cp1: 0.5893 - top_5_categorical_accuracy_cp2: 0.9136 - top_5_categorical_accuracy_cp3: 0.9292 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7780 - top_10_categorical_accuracy_cp0: 0.3784 - top_10_categorical_accuracy_cp1: 0.8839 - top_10_categorical_accuracy_cp2: 0.9753 - top_10_categorical_accuracy_cp3: 0.9292 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1429 - top_10_categorical_accuracy_p4: 0.9203 - top_20_categorical_accuracy_cp0: 0.5856 - top_20_categorical_accuracy_cp1: 0.9732 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9646 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4524 - top_20_categorical_accuracy_p4: 0.98283/7 [===========>..................] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.2082 - top_5_categorical_accuracy: 0.6946 - top_10_categorical_accuracy: 0.8271 - top_20_categorical_accuracy: 0.9066 - top_5_categorical_accuracy_cp0: 0.0895 - top_5_categorical_accuracy_cp1: 0.5727 - top_5_categorical_accuracy_cp2: 0.9304 - top_5_categorical_accuracy_cp3: 0.9471 - top_5_categorical_accuracy_cp4: 0.9612 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7921 - top_10_categorical_accuracy_cp0: 0.3488 - top_10_categorical_accuracy_cp1: 0.8788 - top_10_categorical_accuracy_cp2: 0.9913 - top_10_categorical_accuracy_cp3: 0.9676 - top_10_categorical_accuracy_cp4: 0.9723 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1077 - top_10_categorical_accuracy_p4: 0.9331 - top_20_categorical_accuracy_cp0: 0.5864 - top_20_categorical_accuracy_cp1: 0.9727 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9972 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4692 - top_20_categorical_accuracy_p4: 0.98995/7 [====================>.........] - ETA: 0s - loss: 0.1121 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.7027 - top_10_categorical_accuracy: 0.8373 - top_20_categorical_accuracy: 0.9049 - top_5_categorical_accuracy_cp0: 0.0975 - top_5_categorical_accuracy_cp1: 0.5706 - top_5_categorical_accuracy_cp2: 0.8992 - top_5_categorical_accuracy_cp3: 0.9531 - top_5_categorical_accuracy_cp4: 0.9694 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.8013 - top_10_categorical_accuracy_cp0: 0.3431 - top_10_categorical_accuracy_cp1: 0.8881 - top_10_categorical_accuracy_cp2: 0.9924 - top_10_categorical_accuracy_cp3: 0.9729 - top_10_categorical_accuracy_cp4: 0.9807 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1355 - top_10_categorical_accuracy_p4: 0.9427 - top_20_categorical_accuracy_cp0: 0.5614 - top_20_categorical_accuracy_cp1: 0.9706 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9874 - top_20_categorical_accuracy_cp4: 0.9968 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0147 - top_20_categorical_accuracy_p3: 0.4626 - top_20_categorical_accuracy_p4: 0.9892        7/7 [==============================] - ETA: 0s - loss: 0.1117 - categorical_accuracy: 0.2128 - top_5_categorical_accuracy: 0.7046 - top_10_categorical_accuracy: 0.8393 - top_20_categorical_accuracy: 0.9058 - top_5_categorical_accuracy_cp0: 0.1053 - top_5_categorical_accuracy_cp1: 0.5688 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.8026 - top_10_categorical_accuracy_cp0: 0.3436 - top_10_categorical_accuracy_cp1: 0.8884 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1412 - top_10_categorical_accuracy_p4: 0.9435 - top_20_categorical_accuracy_cp0: 0.5624 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9896 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.4627 - top_20_categorical_accuracy_p4: 0.9893DEBUG:root:Model metric val_loss improved from 0.164276 to 0.161031
7/7 [==============================] - 1s 116ms/step - loss: 0.1117 - categorical_accuracy: 0.2128 - top_5_categorical_accuracy: 0.7046 - top_10_categorical_accuracy: 0.8393 - top_20_categorical_accuracy: 0.9058 - top_5_categorical_accuracy_cp0: 0.1053 - top_5_categorical_accuracy_cp1: 0.5688 - top_5_categorical_accuracy_cp2: 0.8909 - top_5_categorical_accuracy_cp3: 0.9527 - top_5_categorical_accuracy_cp4: 0.9708 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.8026 - top_10_categorical_accuracy_cp0: 0.3436 - top_10_categorical_accuracy_cp1: 0.8884 - top_10_categorical_accuracy_cp2: 0.9938 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1412 - top_10_categorical_accuracy_p4: 0.9435 - top_20_categorical_accuracy_cp0: 0.5624 - top_20_categorical_accuracy_cp1: 0.9679 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9896 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.4627 - top_20_categorical_accuracy_p4: 0.9893 - val_loss: 0.1610 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.3690 - val_top_20_categorical_accuracy: 0.6056 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0290 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.3333 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.6753 - val_top_20_categorical_accuracy_cp0: 0.2102 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.2177 - val_top_20_categorical_accuracy_p4: 0.9691
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1070 - categorical_accuracy: 0.2152 - top_5_categorical_accuracy: 0.7352 - top_10_categorical_accuracy: 0.8686 - top_20_categorical_accuracy: 0.9352 - top_5_categorical_accuracy_cp0: 0.1325 - top_5_categorical_accuracy_cp1: 0.5702 - top_5_categorical_accuracy_cp2: 0.9103 - top_5_categorical_accuracy_cp3: 0.9469 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8126 - top_10_categorical_accuracy_cp0: 0.3494 - top_10_categorical_accuracy_cp1: 0.9474 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9708 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1471 - top_10_categorical_accuracy_p4: 0.9495 - top_20_categorical_accuracy_cp0: 0.6747 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9735 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0909 - top_20_categorical_accuracy_p3: 0.6471 - top_20_categorical_accuracy_p4: 0.98533/7 [===========>..................] - ETA: 0s - loss: 0.1107 - categorical_accuracy: 0.2110 - top_5_categorical_accuracy: 0.7060 - top_10_categorical_accuracy: 0.8460 - top_20_categorical_accuracy: 0.9144 - top_5_categorical_accuracy_cp0: 0.1126 - top_5_categorical_accuracy_cp1: 0.5723 - top_5_categorical_accuracy_cp2: 0.8904 - top_5_categorical_accuracy_cp3: 0.9503 - top_5_categorical_accuracy_cp4: 0.9679 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8026 - top_10_categorical_accuracy_cp0: 0.3444 - top_10_categorical_accuracy_cp1: 0.9157 - top_10_categorical_accuracy_cp2: 0.9912 - top_10_categorical_accuracy_cp3: 0.9737 - top_10_categorical_accuracy_cp4: 0.9840 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1395 - top_10_categorical_accuracy_p4: 0.9488 - top_20_categorical_accuracy_cp0: 0.6159 - top_20_categorical_accuracy_cp1: 0.9578 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9883 - top_20_categorical_accuracy_cp4: 0.9973 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0833 - top_20_categorical_accuracy_p3: 0.5504 - top_20_categorical_accuracy_p4: 0.98635/7 [====================>.........] - ETA: 0s - loss: 0.1109 - categorical_accuracy: 0.2085 - top_5_categorical_accuracy: 0.7017 - top_10_categorical_accuracy: 0.8428 - top_20_categorical_accuracy: 0.9102 - top_5_categorical_accuracy_cp0: 0.1116 - top_5_categorical_accuracy_cp1: 0.5423 - top_5_categorical_accuracy_cp2: 0.8957 - top_5_categorical_accuracy_cp3: 0.9519 - top_5_categorical_accuracy_cp4: 0.9666 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7990 - top_10_categorical_accuracy_cp0: 0.3446 - top_10_categorical_accuracy_cp1: 0.9026 - top_10_categorical_accuracy_cp2: 0.9924 - top_10_categorical_accuracy_cp3: 0.9715 - top_10_categorical_accuracy_cp4: 0.9809 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1362 - top_10_categorical_accuracy_p4: 0.9471 - top_20_categorical_accuracy_cp0: 0.5976 - top_20_categorical_accuracy_cp1: 0.9577 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9875 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0606 - top_20_categorical_accuracy_p3: 0.5352 - top_20_categorical_accuracy_p4: 0.98537/7 [==============================] - ETA: 0s - loss: 0.1109 - categorical_accuracy: 0.2087 - top_5_categorical_accuracy: 0.7024 - top_10_categorical_accuracy: 0.8418 - top_20_categorical_accuracy: 0.9099 - top_5_categorical_accuracy_cp0: 0.1199 - top_5_categorical_accuracy_cp1: 0.5443 - top_5_categorical_accuracy_cp2: 0.8992 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8004 - top_10_categorical_accuracy_cp0: 0.3533 - top_10_categorical_accuracy_cp1: 0.9006 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1373 - top_10_categorical_accuracy_p4: 0.9467 - top_20_categorical_accuracy_cp0: 0.5948 - top_20_categorical_accuracy_cp1: 0.9618 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9896 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.5294 - top_20_categorical_accuracy_p4: 0.9868DEBUG:root:Model metric val_loss improved from 0.161031 to 0.158719
7/7 [==============================] - 1s 116ms/step - loss: 0.1109 - categorical_accuracy: 0.2087 - top_5_categorical_accuracy: 0.7024 - top_10_categorical_accuracy: 0.8418 - top_20_categorical_accuracy: 0.9099 - top_5_categorical_accuracy_cp0: 0.1199 - top_5_categorical_accuracy_cp1: 0.5443 - top_5_categorical_accuracy_cp2: 0.8992 - top_5_categorical_accuracy_cp3: 0.9556 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8004 - top_10_categorical_accuracy_cp0: 0.3533 - top_10_categorical_accuracy_cp1: 0.9006 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9719 - top_10_categorical_accuracy_cp4: 0.9788 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1373 - top_10_categorical_accuracy_p4: 0.9467 - top_20_categorical_accuracy_cp0: 0.5948 - top_20_categorical_accuracy_cp1: 0.9618 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9896 - top_20_categorical_accuracy_cp4: 0.9934 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0588 - top_20_categorical_accuracy_p3: 0.5294 - top_20_categorical_accuracy_p4: 0.9868 - val_loss: 0.1587 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.4423 - val_top_20_categorical_accuracy: 0.6761 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0290 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 0.9765 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7101 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 0.9765 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8093 - val_top_20_categorical_accuracy_cp0: 0.3523 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4194 - val_top_20_categorical_accuracy_p4: 0.9691
INFO:root:Restoring best model weights with val_loss: 0.158719 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  9.48it/s]Calculating prediction outputs...: 1it [00:00,  9.46it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1425.11it/s]
INFO:root:Finished run 20f0f98d2c1d41cfaac621bfc602d3c5
Starting experiment for huawei_logs with knowledge type  gram .....
2023-05-24 21:02:58.824263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:02:59.347277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:02:59.347349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/pacev/miniconda3/envs/lena/lib/
2023-05-24 21:02:59.347355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=None)
DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/i40/pacev/Domain-Guided-Monitoring, universal_newlines=False, shell=None, istream=<valid stream>)
INFO:root:Starting run 47827585b1634893b72464b3eef4a0a6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12201.18it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13293.65it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13174.27it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24437.58it/s]
DEBUG:root:Aggregating huawei data per grouper
DEBUG:root:Using subset of length 2000 instead total df of length 1
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
2023-05-24 21:03:01.691795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.691982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.692785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.692930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.693059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.693183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.693571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-24 21:03:01.828150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.828385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.828542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.828676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.828808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:01.828932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.394333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.394525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.394679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.394813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.394940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.395054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21863 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6
2023-05-24 21:03:03.395432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-05-24 21:03:03.395538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21863 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 12950.51it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13599.56it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/639 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 639/639 [00:00<00:00, 13473.76it/s]
Generating DRAIN clusters from log_df:   0%|          | 0/30 [00:00<?, ?it/s]Generating DRAIN clusters from log_df: 100%|██████████| 30/30 [00:00<00:00, 24489.90it/s]
Loading hierarchy for column coarse_log_cluster_path:   0%|          | 0/154 [00:00<?, ?it/s]Loading hierarchy for column coarse_log_cluster_path:  19%|█▉        | 29/154 [00:00<00:00, 286.11it/s]Loading hierarchy for column coarse_log_cluster_path:  38%|███▊      | 58/154 [00:00<00:00, 287.57it/s]Loading hierarchy for column coarse_log_cluster_path:  57%|█████▋    | 88/154 [00:00<00:00, 290.07it/s]Loading hierarchy for column coarse_log_cluster_path:  77%|███████▋  | 118/154 [00:00<00:00, 291.54it/s]Loading hierarchy for column coarse_log_cluster_path:  96%|█████████▌| 148/154 [00:00<00:00, 291.20it/s]Loading hierarchy for column coarse_log_cluster_path: 100%|██████████| 154/154 [00:00<00:00, 290.32it/s]
Adding huawei log hierarchy:   0%|          | 0/863 [00:00<?, ?it/s]Adding huawei log hierarchy:   0%|          | 1/863 [00:00<01:53,  7.61it/s]Adding huawei log hierarchy: 100%|██████████| 863/863 [00:00<00:00, 5152.14it/s]
Building Hierarchy from df: 0it [00:00, ?it/s]Building Hierarchy from df: 1410it [00:00, 38306.13it/s]
INFO:root:Built hierarchy with 1145 nodes
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
INFO:root:Using strategy with 2 workers
DEBUG:root:Regularization not enabled for attention
DEBUG:root:Regularization not enabled for attention
INFO:root:Initializing gram_embedding basic embedding variables
DEBUG:root:Regularization not enabled for base_embeddings
DEBUG:root:Regularization not enabled for base_embeddings
INFO:root:Initializing gram_embedding connection information
Initializing gram_embedding connections:   0%|          | 0/526 [00:00<?, ?it/s]Initializing gram_embedding connections:  25%|██▍       | 130/526 [00:00<00:00, 1288.25it/s]Initializing gram_embedding connections:  49%|████▉     | 259/526 [00:00<00:00, 613.75it/s] Initializing gram_embedding connections:  64%|██████▍   | 339/526 [00:00<00:00, 437.04it/s]Initializing gram_embedding connections:  75%|███████▌  | 395/526 [00:00<00:00, 353.06it/s]Initializing gram_embedding connections:  83%|████████▎ | 438/526 [00:01<00:00, 302.44it/s]Initializing gram_embedding connections:  90%|████████▉ | 473/526 [00:01<00:00, 265.76it/s]Initializing gram_embedding connections:  95%|█████████▌| 502/526 [00:01<00:00, 239.88it/s]Initializing gram_embedding connections: 100%|██████████| 526/526 [00:01<00:00, 319.03it/s]
DEBUG:root:Regularization not enabled for prediction_rnn
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:tensorflow:Layer gru will use cuDNN kernels when running on GPU.
DEBUG:root:Regularization not enabled for prediction_dense
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Calculating percentile frequencies...: 0it [00:00, ?it/s]DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
Calculating percentile frequencies...: 1it [00:00,  1.05it/s]Calculating percentile frequencies...: 7it [00:00,  7.32it/s]
2023-05-24 21:03:09.193742: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

Epoch 1/10
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
2023-05-24 21:03:42.040202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-05-24 21:03:42.610106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:03:42.750448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8500
2023-05-24 21:03:43.157562: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f1fa0007640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-05-24 21:03:43.157607: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:03:43.157615: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2023-05-24 21:03:43.161210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-24 21:03:43.241641: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
      1/Unknown - 34s 34s/step - loss: 0.1933 - categorical_accuracy: 0.0077 - top_5_categorical_accuracy: 0.0536 - top_10_categorical_accuracy: 0.1092 - top_20_categorical_accuracy: 0.1973 - top_5_categorical_accuracy_cp0: 0.0404 - top_5_categorical_accuracy_cp1: 0.0303 - top_5_categorical_accuracy_cp2: 0.0000e+00 - top_5_categorical_accuracy_cp3: 0.0254 - top_5_categorical_accuracy_cp4: 0.1475 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0556 - top_5_categorical_accuracy_p3: 0.0256 - top_5_categorical_accuracy_p4: 0.0566 - top_10_categorical_accuracy_cp0: 0.1414 - top_10_categorical_accuracy_cp1: 0.1010 - top_10_categorical_accuracy_cp2: 0.0357 - top_10_categorical_accuracy_cp3: 0.0508 - top_10_categorical_accuracy_cp4: 0.1967 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.1111 - top_10_categorical_accuracy_p3: 0.2051 - top_10_categorical_accuracy_p4: 0.1024 - top_20_categorical_accuracy_cp0: 0.1919 - top_20_categorical_accuracy_cp1: 0.2020 - top_20_categorical_accuracy_cp2: 0.1310 - top_20_categorical_accuracy_cp3: 0.1186 - top_20_categorical_accuracy_cp4: 0.3197 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.1667 - top_20_categorical_accuracy_p3: 0.2821 - top_20_categorical_accuracy_p4: 0.1939      3/Unknown - 34s 39ms/step - loss: 0.1920 - categorical_accuracy: 0.0642 - top_5_categorical_accuracy: 0.1697 - top_10_categorical_accuracy: 0.2352 - top_20_categorical_accuracy: 0.3382 - top_5_categorical_accuracy_cp0: 0.0614 - top_5_categorical_accuracy_cp1: 0.0338 - top_5_categorical_accuracy_cp2: 0.0293 - top_5_categorical_accuracy_cp3: 0.2387 - top_5_categorical_accuracy_cp4: 0.3948 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0526 - top_5_categorical_accuracy_p2: 0.0465 - top_5_categorical_accuracy_p3: 0.0252 - top_5_categorical_accuracy_p4: 0.1880 - top_10_categorical_accuracy_cp0: 0.1365 - top_10_categorical_accuracy_cp1: 0.0831 - top_10_categorical_accuracy_cp2: 0.0837 - top_10_categorical_accuracy_cp3: 0.3051 - top_10_categorical_accuracy_cp4: 0.4727 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1579 - top_10_categorical_accuracy_p2: 0.0698 - top_10_categorical_accuracy_p3: 0.1345 - top_10_categorical_accuracy_p4: 0.2507 - top_20_categorical_accuracy_cp0: 0.2116 - top_20_categorical_accuracy_cp1: 0.1815 - top_20_categorical_accuracy_cp2: 0.1925 - top_20_categorical_accuracy_cp3: 0.4260 - top_20_categorical_accuracy_cp4: 0.5818 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1579 - top_20_categorical_accuracy_p2: 0.1163 - top_20_categorical_accuracy_p3: 0.2269 - top_20_categorical_accuracy_p4: 0.3581                     5/Unknown - 35s 39ms/step - loss: 0.1905 - categorical_accuracy: 0.0905 - top_5_categorical_accuracy: 0.2497 - top_10_categorical_accuracy: 0.3292 - top_20_categorical_accuracy: 0.4432 - top_5_categorical_accuracy_cp0: 0.0653 - top_5_categorical_accuracy_cp1: 0.0635 - top_5_categorical_accuracy_cp2: 0.0574 - top_5_categorical_accuracy_cp3: 0.3741 - top_5_categorical_accuracy_cp4: 0.5774 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0323 - top_5_categorical_accuracy_p2: 0.0411 - top_5_categorical_accuracy_p3: 0.0376 - top_5_categorical_accuracy_p4: 0.2803 - top_10_categorical_accuracy_cp0: 0.1305 - top_10_categorical_accuracy_cp1: 0.1525 - top_10_categorical_accuracy_cp2: 0.1671 - top_10_categorical_accuracy_cp3: 0.4532 - top_10_categorical_accuracy_cp4: 0.6419 - top_10_categorical_accuracy_p0: 0.0769 - top_10_categorical_accuracy_p1: 0.0968 - top_10_categorical_accuracy_p2: 0.0548 - top_10_categorical_accuracy_p3: 0.1174 - top_10_categorical_accuracy_p4: 0.3620 - top_20_categorical_accuracy_cp0: 0.2188 - top_20_categorical_accuracy_cp1: 0.2958 - top_20_categorical_accuracy_cp2: 0.3342 - top_20_categorical_accuracy_cp3: 0.5612 - top_20_categorical_accuracy_cp4: 0.7242 - top_20_categorical_accuracy_p0: 0.1538 - top_20_categorical_accuracy_p1: 0.1290 - top_20_categorical_accuracy_p2: 0.0959 - top_20_categorical_accuracy_p3: 0.2066 - top_20_categorical_accuracy_p4: 0.4820              7/Unknown - 35s 39ms/step - loss: 0.1888 - categorical_accuracy: 0.1030 - top_5_categorical_accuracy: 0.2925 - top_10_categorical_accuracy: 0.3751 - top_20_categorical_accuracy: 0.4893 - top_5_categorical_accuracy_cp0: 0.0681 - top_5_categorical_accuracy_cp1: 0.0856 - top_5_categorical_accuracy_cp2: 0.1008 - top_5_categorical_accuracy_cp3: 0.4438 - top_5_categorical_accuracy_cp4: 0.6441 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0471 - top_5_categorical_accuracy_p4: 0.3276 - top_10_categorical_accuracy_cp0: 0.1264 - top_10_categorical_accuracy_cp1: 0.1820 - top_10_categorical_accuracy_cp2: 0.2366 - top_10_categorical_accuracy_cp3: 0.5237 - top_10_categorical_accuracy_cp4: 0.7025 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.1176 - top_10_categorical_accuracy_p4: 0.4134 - top_20_categorical_accuracy_cp0: 0.2366 - top_20_categorical_accuracy_cp1: 0.3226 - top_20_categorical_accuracy_cp2: 0.4198 - top_20_categorical_accuracy_cp3: 0.6169 - top_20_categorical_accuracy_cp4: 0.7716 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.1765 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2157 - top_20_categorical_accuracy_p4: 0.53112023-05-24 21:03:44.279876: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:6"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
DEBUG:root:Using only features in column  as inputs, and features from column attributes as prediction goals
DEBUG:root:Splitting values of df with only one row and 863 items as list
DEBUG:root:Model metric val_loss improved from inf to 0.195033
7/7 [==============================] - 53s 3s/step - loss: 0.1888 - categorical_accuracy: 0.1030 - top_5_categorical_accuracy: 0.2925 - top_10_categorical_accuracy: 0.3751 - top_20_categorical_accuracy: 0.4893 - top_5_categorical_accuracy_cp0: 0.0681 - top_5_categorical_accuracy_cp1: 0.0856 - top_5_categorical_accuracy_cp2: 0.1008 - top_5_categorical_accuracy_cp3: 0.4438 - top_5_categorical_accuracy_cp4: 0.6441 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0353 - top_5_categorical_accuracy_p3: 0.0471 - top_5_categorical_accuracy_p4: 0.3276 - top_10_categorical_accuracy_cp0: 0.1264 - top_10_categorical_accuracy_cp1: 0.1820 - top_10_categorical_accuracy_cp2: 0.2366 - top_10_categorical_accuracy_cp3: 0.5237 - top_10_categorical_accuracy_cp4: 0.7025 - top_10_categorical_accuracy_p0: 0.0625 - top_10_categorical_accuracy_p1: 0.1176 - top_10_categorical_accuracy_p2: 0.0471 - top_10_categorical_accuracy_p3: 0.1176 - top_10_categorical_accuracy_p4: 0.4134 - top_20_categorical_accuracy_cp0: 0.2366 - top_20_categorical_accuracy_cp1: 0.3226 - top_20_categorical_accuracy_cp2: 0.4198 - top_20_categorical_accuracy_cp3: 0.6169 - top_20_categorical_accuracy_cp4: 0.7716 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.1765 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2157 - top_20_categorical_accuracy_p4: 0.5311 - val_loss: 0.1950 - val_categorical_accuracy: 0.0394 - val_top_5_categorical_accuracy: 0.3296 - val_top_10_categorical_accuracy: 0.4225 - val_top_20_categorical_accuracy: 0.5099 - val_top_5_categorical_accuracy_cp0: 0.1705 - val_top_5_categorical_accuracy_cp1: 0.3188 - val_top_5_categorical_accuracy_cp2: 0.0000e+00 - val_top_5_categorical_accuracy_cp3: 0.7529 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0625 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.2613 - val_top_5_categorical_accuracy_p4: 0.4485 - val_top_10_categorical_accuracy_cp0: 0.2273 - val_top_10_categorical_accuracy_cp1: 0.5217 - val_top_10_categorical_accuracy_cp2: 0.1667 - val_top_10_categorical_accuracy_cp3: 0.8118 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0625 - val_top_10_categorical_accuracy_p2: 0.0556 - val_top_10_categorical_accuracy_p3: 0.3423 - val_top_10_categorical_accuracy_p4: 0.5670 - val_top_20_categorical_accuracy_cp0: 0.3011 - val_top_20_categorical_accuracy_cp1: 0.6232 - val_top_20_categorical_accuracy_cp2: 0.3333 - val_top_20_categorical_accuracy_cp3: 0.8941 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0625 - val_top_20_categorical_accuracy_p1: 0.1250 - val_top_20_categorical_accuracy_p2: 0.0556 - val_top_20_categorical_accuracy_p3: 0.4414 - val_top_20_categorical_accuracy_p4: 0.6598
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/keras/engine/training.py:2416: UserWarning: Metric MultilabelNestedMetric implements a `reset_states()` method; rename it to `reset_state()` (without the final "s"). The name `reset_states()` has been deprecated to improve API consistency.
  m.reset_state()
Epoch 2/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1756 - categorical_accuracy: 0.1689 - top_5_categorical_accuracy: 0.5294 - top_10_categorical_accuracy: 0.6224 - top_20_categorical_accuracy: 0.7287 - top_5_categorical_accuracy_cp0: 0.0722 - top_5_categorical_accuracy_cp1: 0.1712 - top_5_categorical_accuracy_cp2: 0.4286 - top_5_categorical_accuracy_cp3: 0.8547 - top_5_categorical_accuracy_cp4: 0.9600 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0286 - top_5_categorical_accuracy_p4: 0.5966 - top_10_categorical_accuracy_cp0: 0.1443 - top_10_categorical_accuracy_cp1: 0.3694 - top_10_categorical_accuracy_cp2: 0.6234 - top_10_categorical_accuracy_cp3: 0.8889 - top_10_categorical_accuracy_cp4: 0.9680 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.1250 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1143 - top_10_categorical_accuracy_p4: 0.6931 - top_20_categorical_accuracy_cp0: 0.3196 - top_20_categorical_accuracy_cp1: 0.5766 - top_20_categorical_accuracy_cp2: 0.7792 - top_20_categorical_accuracy_cp3: 0.9145 - top_20_categorical_accuracy_cp4: 0.9760 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2500 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.3143 - top_20_categorical_accuracy_p4: 0.79183/7 [===========>..................] - ETA: 0s - loss: 0.1718 - categorical_accuracy: 0.1662 - top_5_categorical_accuracy: 0.5305 - top_10_categorical_accuracy: 0.6275 - top_20_categorical_accuracy: 0.7360 - top_5_categorical_accuracy_cp0: 0.0708 - top_5_categorical_accuracy_cp1: 0.2083 - top_5_categorical_accuracy_cp2: 0.4875 - top_5_categorical_accuracy_cp3: 0.8299 - top_5_categorical_accuracy_cp4: 0.9721 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0435 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0677 - top_5_categorical_accuracy_p4: 0.6065 - top_10_categorical_accuracy_cp0: 0.1477 - top_10_categorical_accuracy_cp1: 0.4006 - top_10_categorical_accuracy_cp2: 0.7000 - top_10_categorical_accuracy_cp3: 0.8739 - top_10_categorical_accuracy_cp4: 0.9777 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0870 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1053 - top_10_categorical_accuracy_p4: 0.7144 - top_20_categorical_accuracy_cp0: 0.3015 - top_20_categorical_accuracy_cp1: 0.6346 - top_20_categorical_accuracy_cp2: 0.8125 - top_20_categorical_accuracy_cp3: 0.9267 - top_20_categorical_accuracy_cp4: 0.9860 - top_20_categorical_accuracy_p0: 0.2857 - top_20_categorical_accuracy_p1: 0.2174 - top_20_categorical_accuracy_p2: 0.1569 - top_20_categorical_accuracy_p3: 0.2481 - top_20_categorical_accuracy_p4: 0.8164        5/7 [====================>.........] - ETA: 0s - loss: 0.1643 - categorical_accuracy: 0.1759 - top_5_categorical_accuracy: 0.5586 - top_10_categorical_accuracy: 0.6626 - top_20_categorical_accuracy: 0.7616 - top_5_categorical_accuracy_cp0: 0.0688 - top_5_categorical_accuracy_cp1: 0.2292 - top_5_categorical_accuracy_cp2: 0.5450 - top_5_categorical_accuracy_cp3: 0.8597 - top_5_categorical_accuracy_cp4: 0.9791 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0345 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0524 - top_5_categorical_accuracy_p4: 0.6326 - top_10_categorical_accuracy_cp0: 0.1395 - top_10_categorical_accuracy_cp1: 0.4716 - top_10_categorical_accuracy_cp2: 0.7494 - top_10_categorical_accuracy_cp3: 0.9011 - top_10_categorical_accuracy_cp4: 0.9823 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0690 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0905 - top_10_categorical_accuracy_p4: 0.7474 - top_20_categorical_accuracy_cp0: 0.2967 - top_20_categorical_accuracy_cp1: 0.6742 - top_20_categorical_accuracy_cp2: 0.8564 - top_20_categorical_accuracy_cp3: 0.9442 - top_20_categorical_accuracy_cp4: 0.9904 - top_20_categorical_accuracy_p0: 0.3077 - top_20_categorical_accuracy_p1: 0.1724 - top_20_categorical_accuracy_p2: 0.1081 - top_20_categorical_accuracy_p3: 0.2190 - top_20_categorical_accuracy_p4: 0.84227/7 [==============================] - ETA: 0s - loss: 0.1616 - categorical_accuracy: 0.1755 - top_5_categorical_accuracy: 0.5640 - top_10_categorical_accuracy: 0.6711 - top_20_categorical_accuracy: 0.7684 - top_5_categorical_accuracy_cp0: 0.0665 - top_5_categorical_accuracy_cp1: 0.2416 - top_5_categorical_accuracy_cp2: 0.5576 - top_5_categorical_accuracy_cp3: 0.8713 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0471 - top_5_categorical_accuracy_p4: 0.6381 - top_10_categorical_accuracy_cp0: 0.1475 - top_10_categorical_accuracy_cp1: 0.4878 - top_10_categorical_accuracy_cp2: 0.7675 - top_10_categorical_accuracy_cp3: 0.9083 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0941 - top_10_categorical_accuracy_p4: 0.7554 - top_20_categorical_accuracy_cp0: 0.3079 - top_20_categorical_accuracy_cp1: 0.6896 - top_20_categorical_accuracy_cp2: 0.8663 - top_20_categorical_accuracy_cp3: 0.9467 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2353 - top_20_categorical_accuracy_p4: 0.8476DEBUG:root:Model metric val_loss improved from 0.195033 to 0.192344
7/7 [==============================] - 1s 113ms/step - loss: 0.1616 - categorical_accuracy: 0.1755 - top_5_categorical_accuracy: 0.5640 - top_10_categorical_accuracy: 0.6711 - top_20_categorical_accuracy: 0.7684 - top_5_categorical_accuracy_cp0: 0.0665 - top_5_categorical_accuracy_cp1: 0.2416 - top_5_categorical_accuracy_cp2: 0.5576 - top_5_categorical_accuracy_cp3: 0.8713 - top_5_categorical_accuracy_cp4: 0.9801 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0294 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0471 - top_5_categorical_accuracy_p4: 0.6381 - top_10_categorical_accuracy_cp0: 0.1475 - top_10_categorical_accuracy_cp1: 0.4878 - top_10_categorical_accuracy_cp2: 0.7675 - top_10_categorical_accuracy_cp3: 0.9083 - top_10_categorical_accuracy_cp4: 0.9841 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0588 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0941 - top_10_categorical_accuracy_p4: 0.7554 - top_20_categorical_accuracy_cp0: 0.3079 - top_20_categorical_accuracy_cp1: 0.6896 - top_20_categorical_accuracy_cp2: 0.8663 - top_20_categorical_accuracy_cp3: 0.9467 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.2500 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1059 - top_20_categorical_accuracy_p3: 0.2353 - top_20_categorical_accuracy_p4: 0.8476 - val_loss: 0.1923 - val_categorical_accuracy: 0.0085 - val_top_5_categorical_accuracy: 0.0704 - val_top_10_categorical_accuracy: 0.4789 - val_top_20_categorical_accuracy: 0.6169 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0290 - val_top_5_categorical_accuracy_cp2: 0.1667 - val_top_5_categorical_accuracy_cp3: 0.2118 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.1289 - val_top_10_categorical_accuracy_cp0: 0.1307 - val_top_10_categorical_accuracy_cp1: 0.7536 - val_top_10_categorical_accuracy_cp2: 0.6250 - val_top_10_categorical_accuracy_cp3: 0.9294 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.2072 - val_top_10_categorical_accuracy_p4: 0.7577 - val_top_20_categorical_accuracy_cp0: 0.2670 - val_top_20_categorical_accuracy_cp1: 0.9275 - val_top_20_categorical_accuracy_cp2: 0.9167 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4234 - val_top_20_categorical_accuracy_p4: 0.8866
Epoch 3/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1426 - categorical_accuracy: 0.1711 - top_5_categorical_accuracy: 0.6008 - top_10_categorical_accuracy: 0.7281 - top_20_categorical_accuracy: 0.8365 - top_5_categorical_accuracy_cp0: 0.0312 - top_5_categorical_accuracy_cp1: 0.2475 - top_5_categorical_accuracy_cp2: 0.7143 - top_5_categorical_accuracy_cp3: 0.8707 - top_5_categorical_accuracy_cp4: 0.9845 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0270 - top_5_categorical_accuracy_p4: 0.6716 - top_10_categorical_accuracy_cp0: 0.1562 - top_10_categorical_accuracy_cp1: 0.5743 - top_10_categorical_accuracy_cp2: 0.8690 - top_10_categorical_accuracy_cp3: 0.9483 - top_10_categorical_accuracy_cp4: 0.9845 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1081 - top_10_categorical_accuracy_p4: 0.8081 - top_20_categorical_accuracy_cp0: 0.4375 - top_20_categorical_accuracy_cp1: 0.7723 - top_20_categorical_accuracy_cp2: 0.9405 - top_20_categorical_accuracy_cp3: 0.9828 - top_20_categorical_accuracy_cp4: 0.9845 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1667 - top_20_categorical_accuracy_p2: 0.0909 - top_20_categorical_accuracy_p3: 0.4324 - top_20_categorical_accuracy_p4: 0.89983/7 [===========>..................] - ETA: 0s - loss: 0.1463 - categorical_accuracy: 0.1613 - top_5_categorical_accuracy: 0.5695 - top_10_categorical_accuracy: 0.7156 - top_20_categorical_accuracy: 0.8229 - top_5_categorical_accuracy_cp0: 0.0289 - top_5_categorical_accuracy_cp1: 0.2569 - top_5_categorical_accuracy_cp2: 0.6911 - top_5_categorical_accuracy_cp3: 0.8383 - top_5_categorical_accuracy_cp4: 0.9916 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0078 - top_5_categorical_accuracy_p4: 0.6493 - top_10_categorical_accuracy_cp0: 0.1286 - top_10_categorical_accuracy_cp1: 0.6177 - top_10_categorical_accuracy_cp2: 0.8862 - top_10_categorical_accuracy_cp3: 0.9371 - top_10_categorical_accuracy_cp4: 0.9916 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0556 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0938 - top_10_categorical_accuracy_p4: 0.8072 - top_20_categorical_accuracy_cp0: 0.3730 - top_20_categorical_accuracy_cp1: 0.7920 - top_20_categorical_accuracy_cp2: 0.9715 - top_20_categorical_accuracy_cp3: 0.9820 - top_20_categorical_accuracy_cp4: 0.9916 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.2778 - top_20_categorical_accuracy_p2: 0.1707 - top_20_categorical_accuracy_p3: 0.2969 - top_20_categorical_accuracy_p4: 0.9029    5/7 [====================>.........] - ETA: 0s - loss: 0.1424 - categorical_accuracy: 0.1665 - top_5_categorical_accuracy: 0.5842 - top_10_categorical_accuracy: 0.7321 - top_20_categorical_accuracy: 0.8350 - top_5_categorical_accuracy_cp0: 0.0258 - top_5_categorical_accuracy_cp1: 0.2679 - top_5_categorical_accuracy_cp2: 0.6960 - top_5_categorical_accuracy_cp3: 0.8615 - top_5_categorical_accuracy_cp4: 0.9936 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0100 - top_5_categorical_accuracy_p4: 0.6625 - top_10_categorical_accuracy_cp0: 0.1093 - top_10_categorical_accuracy_cp1: 0.6624 - top_10_categorical_accuracy_cp2: 0.8945 - top_10_categorical_accuracy_cp3: 0.9550 - top_10_categorical_accuracy_cp4: 0.9936 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0385 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0896 - top_10_categorical_accuracy_p4: 0.8230 - top_20_categorical_accuracy_cp0: 0.3618 - top_20_categorical_accuracy_cp1: 0.8275 - top_20_categorical_accuracy_cp2: 0.9824 - top_20_categorical_accuracy_cp3: 0.9874 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1923 - top_20_categorical_accuracy_p2: 0.1370 - top_20_categorical_accuracy_p3: 0.3035 - top_20_categorical_accuracy_p4: 0.91527/7 [==============================] - ETA: 0s - loss: 0.1420 - categorical_accuracy: 0.1667 - top_5_categorical_accuracy: 0.5898 - top_10_categorical_accuracy: 0.7357 - top_20_categorical_accuracy: 0.8362 - top_5_categorical_accuracy_cp0: 0.0276 - top_5_categorical_accuracy_cp1: 0.2768 - top_5_categorical_accuracy_cp2: 0.7058 - top_5_categorical_accuracy_cp3: 0.8713 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.6710 - top_10_categorical_accuracy_cp0: 0.1102 - top_10_categorical_accuracy_cp1: 0.6713 - top_10_categorical_accuracy_cp2: 0.9033 - top_10_categorical_accuracy_cp3: 0.9601 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8298 - top_20_categorical_accuracy_cp0: 0.3566 - top_20_categorical_accuracy_cp1: 0.8394 - top_20_categorical_accuracy_cp2: 0.9835 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.3137 - top_20_categorical_accuracy_p4: 0.9188DEBUG:root:Model metric val_loss improved from 0.192344 to 0.184840
7/7 [==============================] - 1s 118ms/step - loss: 0.1420 - categorical_accuracy: 0.1667 - top_5_categorical_accuracy: 0.5898 - top_10_categorical_accuracy: 0.7357 - top_20_categorical_accuracy: 0.8362 - top_5_categorical_accuracy_cp0: 0.0276 - top_5_categorical_accuracy_cp1: 0.2768 - top_5_categorical_accuracy_cp2: 0.7058 - top_5_categorical_accuracy_cp3: 0.8713 - top_5_categorical_accuracy_cp4: 0.9947 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.6710 - top_10_categorical_accuracy_cp0: 0.1102 - top_10_categorical_accuracy_cp1: 0.6713 - top_10_categorical_accuracy_cp2: 0.9033 - top_10_categorical_accuracy_cp3: 0.9601 - top_10_categorical_accuracy_cp4: 0.9947 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0294 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0902 - top_10_categorical_accuracy_p4: 0.8298 - top_20_categorical_accuracy_cp0: 0.3566 - top_20_categorical_accuracy_cp1: 0.8394 - top_20_categorical_accuracy_cp2: 0.9835 - top_20_categorical_accuracy_cp3: 0.9882 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.1471 - top_20_categorical_accuracy_p2: 0.1176 - top_20_categorical_accuracy_p3: 0.3137 - top_20_categorical_accuracy_p4: 0.9188 - val_loss: 0.1848 - val_categorical_accuracy: 0.0056 - val_top_5_categorical_accuracy: 0.1099 - val_top_10_categorical_accuracy: 0.4535 - val_top_20_categorical_accuracy: 0.6254 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0145 - val_top_5_categorical_accuracy_cp2: 0.2500 - val_top_5_categorical_accuracy_cp3: 0.3647 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.2010 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7536 - val_top_10_categorical_accuracy_cp2: 0.9583 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8299 - val_top_20_categorical_accuracy_cp0: 0.2557 - val_top_20_categorical_accuracy_cp1: 0.9710 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.4054 - val_top_20_categorical_accuracy_p4: 0.9124
Epoch 4/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1316 - categorical_accuracy: 0.1858 - top_5_categorical_accuracy: 0.6571 - top_10_categorical_accuracy: 0.7950 - top_20_categorical_accuracy: 0.8793 - top_5_categorical_accuracy_cp0: 0.0330 - top_5_categorical_accuracy_cp1: 0.3708 - top_5_categorical_accuracy_cp2: 0.7353 - top_5_categorical_accuracy_cp3: 0.9375 - top_5_categorical_accuracy_cp4: 0.9922 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7408 - top_10_categorical_accuracy_cp0: 0.1538 - top_10_categorical_accuracy_cp1: 0.7079 - top_10_categorical_accuracy_cp2: 0.9706 - top_10_categorical_accuracy_cp3: 0.9911 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1250 - top_10_categorical_accuracy_p4: 0.8855 - top_20_categorical_accuracy_cp0: 0.3956 - top_20_categorical_accuracy_cp1: 0.9101 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.3333 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3250 - top_20_categorical_accuracy_p4: 0.96113/7 [===========>..................] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.1713 - top_5_categorical_accuracy: 0.6144 - top_10_categorical_accuracy: 0.7630 - top_20_categorical_accuracy: 0.8496 - top_5_categorical_accuracy_cp0: 0.0096 - top_5_categorical_accuracy_cp1: 0.3191 - top_5_categorical_accuracy_cp2: 0.7567 - top_5_categorical_accuracy_cp3: 0.9271 - top_5_categorical_accuracy_cp4: 0.9861 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.6978 - top_10_categorical_accuracy_cp0: 0.1058 - top_10_categorical_accuracy_cp1: 0.7138 - top_10_categorical_accuracy_cp2: 0.9772 - top_10_categorical_accuracy_cp3: 0.9942 - top_10_categorical_accuracy_cp4: 0.9972 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0992 - top_10_categorical_accuracy_p4: 0.8579 - top_20_categorical_accuracy_cp0: 0.3365 - top_20_categorical_accuracy_cp1: 0.9013 - top_20_categorical_accuracy_cp2: 0.9962 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0909 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0256 - top_20_categorical_accuracy_p3: 0.2893 - top_20_categorical_accuracy_p4: 0.9383    5/7 [====================>.........] - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.1688 - top_5_categorical_accuracy: 0.6185 - top_10_categorical_accuracy: 0.7706 - top_20_categorical_accuracy: 0.8594 - top_5_categorical_accuracy_cp0: 0.0080 - top_5_categorical_accuracy_cp1: 0.3333 - top_5_categorical_accuracy_cp2: 0.7826 - top_5_categorical_accuracy_cp3: 0.9368 - top_5_categorical_accuracy_cp4: 0.9630 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7044 - top_10_categorical_accuracy_cp0: 0.0915 - top_10_categorical_accuracy_cp1: 0.7514 - top_10_categorical_accuracy_cp2: 0.9783 - top_10_categorical_accuracy_cp3: 0.9946 - top_10_categorical_accuracy_cp4: 0.9984 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0918 - top_10_categorical_accuracy_p4: 0.8694 - top_20_categorical_accuracy_cp0: 0.3598 - top_20_categorical_accuracy_cp1: 0.9134 - top_20_categorical_accuracy_cp2: 0.9976 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0714 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0429 - top_20_categorical_accuracy_p3: 0.3430 - top_20_categorical_accuracy_p4: 0.94627/7 [==============================] - ETA: 0s - loss: 0.1318 - categorical_accuracy: 0.1751 - top_5_categorical_accuracy: 0.6199 - top_10_categorical_accuracy: 0.7699 - top_20_categorical_accuracy: 0.8597 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.3532 - top_5_categorical_accuracy_cp2: 0.7922 - top_5_categorical_accuracy_cp3: 0.9349 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7064 - top_10_categorical_accuracy_cp0: 0.0891 - top_10_categorical_accuracy_cp1: 0.7630 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0784 - top_10_categorical_accuracy_p4: 0.8702 - top_20_categorical_accuracy_cp0: 0.3614 - top_20_categorical_accuracy_cp1: 0.9205 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.9489DEBUG:root:Model metric val_loss improved from 0.184840 to 0.171946
7/7 [==============================] - 1s 115ms/step - loss: 0.1318 - categorical_accuracy: 0.1751 - top_5_categorical_accuracy: 0.6199 - top_10_categorical_accuracy: 0.7699 - top_20_categorical_accuracy: 0.8597 - top_5_categorical_accuracy_cp0: 0.0065 - top_5_categorical_accuracy_cp1: 0.3532 - top_5_categorical_accuracy_cp2: 0.7922 - top_5_categorical_accuracy_cp3: 0.9349 - top_5_categorical_accuracy_cp4: 0.9602 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7064 - top_10_categorical_accuracy_cp0: 0.0891 - top_10_categorical_accuracy_cp1: 0.7630 - top_10_categorical_accuracy_cp2: 0.9815 - top_10_categorical_accuracy_cp3: 0.9941 - top_10_categorical_accuracy_cp4: 0.9960 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0784 - top_10_categorical_accuracy_p4: 0.8702 - top_20_categorical_accuracy_cp0: 0.3614 - top_20_categorical_accuracy_cp1: 0.9205 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0625 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.3216 - top_20_categorical_accuracy_p4: 0.9489 - val_loss: 0.1719 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.2761 - val_top_10_categorical_accuracy: 0.4535 - val_top_20_categorical_accuracy: 0.5493 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 0.5000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 1.0000 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5052 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7391 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8299 - val_top_20_categorical_accuracy_cp0: 0.0909 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0631 - val_top_20_categorical_accuracy_p4: 0.9691
Epoch 5/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1249 - categorical_accuracy: 0.1920 - top_5_categorical_accuracy: 0.6331 - top_10_categorical_accuracy: 0.7795 - top_20_categorical_accuracy: 0.8650 - top_5_categorical_accuracy_cp0: 0.0103 - top_5_categorical_accuracy_cp1: 0.3621 - top_5_categorical_accuracy_cp2: 0.8442 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9453 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7131 - top_10_categorical_accuracy_cp0: 0.1031 - top_10_categorical_accuracy_cp1: 0.7586 - top_10_categorical_accuracy_cp2: 0.9870 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0500 - top_10_categorical_accuracy_p4: 0.8737 - top_20_categorical_accuracy_cp0: 0.3299 - top_20_categorical_accuracy_cp1: 0.9483 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.1750 - top_20_categorical_accuracy_p4: 0.95933/7 [===========>..................] - ETA: 0s - loss: 0.1258 - categorical_accuracy: 0.2041 - top_5_categorical_accuracy: 0.6229 - top_10_categorical_accuracy: 0.7630 - top_20_categorical_accuracy: 0.8625 - top_5_categorical_accuracy_cp0: 0.0091 - top_5_categorical_accuracy_cp1: 0.3777 - top_5_categorical_accuracy_cp2: 0.8475 - top_5_categorical_accuracy_cp3: 0.9699 - top_5_categorical_accuracy_cp4: 0.9385 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7175 - top_10_categorical_accuracy_cp0: 0.0942 - top_10_categorical_accuracy_cp1: 0.7709 - top_10_categorical_accuracy_cp2: 0.9958 - top_10_categorical_accuracy_cp3: 0.9970 - top_10_categorical_accuracy_cp4: 1.0000 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0662 - top_10_categorical_accuracy_p4: 0.8723 - top_20_categorical_accuracy_cp0: 0.3951 - top_20_categorical_accuracy_cp1: 0.9443 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3015 - top_20_categorical_accuracy_p4: 0.96355/7 [====================>.........] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.2081 - top_5_categorical_accuracy: 0.6290 - top_10_categorical_accuracy: 0.7721 - top_20_categorical_accuracy: 0.8695 - top_5_categorical_accuracy_cp0: 0.0095 - top_5_categorical_accuracy_cp1: 0.4011 - top_5_categorical_accuracy_cp2: 0.7913 - top_5_categorical_accuracy_cp3: 0.9681 - top_5_categorical_accuracy_cp4: 0.9472 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7206 - top_10_categorical_accuracy_cp0: 0.1031 - top_10_categorical_accuracy_cp1: 0.7782 - top_10_categorical_accuracy_cp2: 0.9898 - top_10_categorical_accuracy_cp3: 0.9982 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0607 - top_10_categorical_accuracy_p4: 0.8788 - top_20_categorical_accuracy_cp0: 0.3969 - top_20_categorical_accuracy_cp1: 0.9501 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0123 - top_20_categorical_accuracy_p3: 0.2944 - top_20_categorical_accuracy_p4: 0.9682    7/7 [==============================] - ETA: 0s - loss: 0.1232 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6353 - top_10_categorical_accuracy: 0.7831 - top_20_categorical_accuracy: 0.8754 - top_5_categorical_accuracy_cp0: 0.0162 - top_5_categorical_accuracy_cp1: 0.4251 - top_5_categorical_accuracy_cp2: 0.7695 - top_5_categorical_accuracy_cp3: 0.9615 - top_5_categorical_accuracy_cp4: 0.9456 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7239 - top_10_categorical_accuracy_cp0: 0.1167 - top_10_categorical_accuracy_cp1: 0.7951 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0588 - top_10_categorical_accuracy_p4: 0.8870 - top_20_categorical_accuracy_cp0: 0.4036 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9710DEBUG:root:Model metric val_loss improved from 0.171946 to 0.167049
7/7 [==============================] - 1s 116ms/step - loss: 0.1232 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6353 - top_10_categorical_accuracy: 0.7831 - top_20_categorical_accuracy: 0.8754 - top_5_categorical_accuracy_cp0: 0.0162 - top_5_categorical_accuracy_cp1: 0.4251 - top_5_categorical_accuracy_cp2: 0.7695 - top_5_categorical_accuracy_cp3: 0.9615 - top_5_categorical_accuracy_cp4: 0.9456 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7239 - top_10_categorical_accuracy_cp0: 0.1167 - top_10_categorical_accuracy_cp1: 0.7951 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9985 - top_10_categorical_accuracy_cp4: 0.9934 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0588 - top_10_categorical_accuracy_p4: 0.8870 - top_20_categorical_accuracy_cp0: 0.4036 - top_20_categorical_accuracy_cp1: 0.9572 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9987 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.2863 - top_20_categorical_accuracy_p4: 0.9710 - val_loss: 0.1670 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3014 - val_top_10_categorical_accuracy: 0.4197 - val_top_20_categorical_accuracy: 0.5437 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0580 - val_top_5_categorical_accuracy_cp2: 0.7500 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5515 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5652 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7680 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 6/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.2090 - top_5_categorical_accuracy: 0.6234 - top_10_categorical_accuracy: 0.7985 - top_20_categorical_accuracy: 0.8870 - top_5_categorical_accuracy_cp0: 0.0263 - top_5_categorical_accuracy_cp1: 0.4961 - top_5_categorical_accuracy_cp2: 0.7097 - top_5_categorical_accuracy_cp3: 1.0000 - top_5_categorical_accuracy_cp4: 0.9386 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7058 - top_10_categorical_accuracy_cp0: 0.2632 - top_10_categorical_accuracy_cp1: 0.8346 - top_10_categorical_accuracy_cp2: 1.0000 - top_10_categorical_accuracy_cp3: 1.0000 - top_10_categorical_accuracy_cp4: 0.9825 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0256 - top_10_categorical_accuracy_p4: 0.9019 - top_20_categorical_accuracy_cp0: 0.5263 - top_20_categorical_accuracy_cp1: 0.9606 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 1.0000 - top_20_categorical_accuracy_cp4: 0.9912 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3590 - top_20_categorical_accuracy_p4: 0.97443/7 [===========>..................] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.2076 - top_5_categorical_accuracy: 0.6430 - top_10_categorical_accuracy: 0.8019 - top_20_categorical_accuracy: 0.8905 - top_5_categorical_accuracy_cp0: 0.0550 - top_5_categorical_accuracy_cp1: 0.5235 - top_5_categorical_accuracy_cp2: 0.6812 - top_5_categorical_accuracy_cp3: 0.9585 - top_5_categorical_accuracy_cp4: 0.9370 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7257 - top_10_categorical_accuracy_cp0: 0.2557 - top_10_categorical_accuracy_cp1: 0.8382 - top_10_categorical_accuracy_cp2: 0.9651 - top_10_categorical_accuracy_cp3: 0.9792 - top_10_categorical_accuracy_cp4: 0.9644 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0714 - top_10_categorical_accuracy_p4: 0.8993 - top_20_categorical_accuracy_cp0: 0.5243 - top_20_categorical_accuracy_cp1: 0.9412 - top_20_categorical_accuracy_cp2: 0.9956 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9918 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0400 - top_20_categorical_accuracy_p3: 0.3839 - top_20_categorical_accuracy_p4: 0.9729    5/7 [====================>.........] - ETA: 0s - loss: 0.1195 - categorical_accuracy: 0.2048 - top_5_categorical_accuracy: 0.6456 - top_10_categorical_accuracy: 0.8028 - top_20_categorical_accuracy: 0.8919 - top_5_categorical_accuracy_cp0: 0.0513 - top_5_categorical_accuracy_cp1: 0.4871 - top_5_categorical_accuracy_cp2: 0.7048 - top_5_categorical_accuracy_cp3: 0.9587 - top_5_categorical_accuracy_cp4: 0.9475 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7345 - top_10_categorical_accuracy_cp0: 0.2564 - top_10_categorical_accuracy_cp1: 0.8321 - top_10_categorical_accuracy_cp2: 0.9517 - top_10_categorical_accuracy_cp3: 0.9785 - top_10_categorical_accuracy_cp4: 0.9697 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0952 - top_10_categorical_accuracy_p4: 0.9047 - top_20_categorical_accuracy_cp0: 0.5207 - top_20_categorical_accuracy_cp1: 0.9446 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9928 - top_20_categorical_accuracy_cp4: 0.9904 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0282 - top_20_categorical_accuracy_p3: 0.4333 - top_20_categorical_accuracy_p4: 0.97447/7 [==============================] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.2056 - top_5_categorical_accuracy: 0.6472 - top_10_categorical_accuracy: 0.8032 - top_20_categorical_accuracy: 0.8936 - top_5_categorical_accuracy_cp0: 0.0502 - top_5_categorical_accuracy_cp1: 0.4847 - top_5_categorical_accuracy_cp2: 0.7202 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7375 - top_10_categorical_accuracy_cp0: 0.2561 - top_10_categorical_accuracy_cp1: 0.8303 - top_10_categorical_accuracy_cp2: 0.9527 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9734 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.9077 - top_20_categorical_accuracy_cp0: 0.5300 - top_20_categorical_accuracy_cp1: 0.9434 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.4549 - top_20_categorical_accuracy_p4: 0.97577/7 [==============================] - 1s 108ms/step - loss: 0.1194 - categorical_accuracy: 0.2056 - top_5_categorical_accuracy: 0.6472 - top_10_categorical_accuracy: 0.8032 - top_20_categorical_accuracy: 0.8936 - top_5_categorical_accuracy_cp0: 0.0502 - top_5_categorical_accuracy_cp1: 0.4847 - top_5_categorical_accuracy_cp2: 0.7202 - top_5_categorical_accuracy_cp3: 0.9571 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7375 - top_10_categorical_accuracy_cp0: 0.2561 - top_10_categorical_accuracy_cp1: 0.8303 - top_10_categorical_accuracy_cp2: 0.9527 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9734 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0824 - top_10_categorical_accuracy_p4: 0.9077 - top_20_categorical_accuracy_cp0: 0.5300 - top_20_categorical_accuracy_cp1: 0.9434 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0353 - top_20_categorical_accuracy_p3: 0.4549 - top_20_categorical_accuracy_p4: 0.9757 - val_loss: 0.1680 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3183 - val_top_10_categorical_accuracy: 0.4169 - val_top_20_categorical_accuracy: 0.5437 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0870 - val_top_5_categorical_accuracy_cp2: 0.9167 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5825 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.5507 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.7629 - val_top_20_categorical_accuracy_cp0: 0.0795 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9948
Epoch 7/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1150 - categorical_accuracy: 0.1969 - top_5_categorical_accuracy: 0.6673 - top_10_categorical_accuracy: 0.8164 - top_20_categorical_accuracy: 0.9140 - top_5_categorical_accuracy_cp0: 0.0217 - top_5_categorical_accuracy_cp1: 0.4615 - top_5_categorical_accuracy_cp2: 0.8046 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9535 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7554 - top_10_categorical_accuracy_cp0: 0.2717 - top_10_categorical_accuracy_cp1: 0.8654 - top_10_categorical_accuracy_cp2: 0.9080 - top_10_categorical_accuracy_cp3: 0.9640 - top_10_categorical_accuracy_cp4: 0.9767 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1250 - top_10_categorical_accuracy_p4: 0.9113 - top_20_categorical_accuracy_cp0: 0.5652 - top_20_categorical_accuracy_cp1: 0.9712 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 0.9922 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4583 - top_20_categorical_accuracy_p4: 0.98703/7 [===========>..................] - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.2017 - top_5_categorical_accuracy: 0.6679 - top_10_categorical_accuracy: 0.8085 - top_20_categorical_accuracy: 0.8969 - top_5_categorical_accuracy_cp0: 0.0274 - top_5_categorical_accuracy_cp1: 0.4524 - top_5_categorical_accuracy_cp2: 0.8315 - top_5_categorical_accuracy_cp3: 0.9545 - top_5_categorical_accuracy_cp4: 0.9563 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7659 - top_10_categorical_accuracy_cp0: 0.2432 - top_10_categorical_accuracy_cp1: 0.8537 - top_10_categorical_accuracy_cp2: 0.9438 - top_10_categorical_accuracy_cp3: 0.9667 - top_10_categorical_accuracy_cp4: 0.9717 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1064 - top_10_categorical_accuracy_p4: 0.9161 - top_20_categorical_accuracy_cp0: 0.5000 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9909 - top_20_categorical_accuracy_cp4: 0.9897 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4043 - top_20_categorical_accuracy_p4: 0.98695/7 [====================>.........] - ETA: 0s - loss: 0.1176 - categorical_accuracy: 0.2033 - top_5_categorical_accuracy: 0.6643 - top_10_categorical_accuracy: 0.8131 - top_20_categorical_accuracy: 0.8987 - top_5_categorical_accuracy_cp0: 0.0393 - top_5_categorical_accuracy_cp1: 0.4679 - top_5_categorical_accuracy_cp2: 0.8540 - top_5_categorical_accuracy_cp3: 0.9550 - top_5_categorical_accuracy_cp4: 0.9581 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7583 - top_10_categorical_accuracy_cp0: 0.2770 - top_10_categorical_accuracy_cp1: 0.8604 - top_10_categorical_accuracy_cp2: 0.9586 - top_10_categorical_accuracy_cp3: 0.9730 - top_10_categorical_accuracy_cp4: 0.9726 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1174 - top_10_categorical_accuracy_p4: 0.9178 - top_20_categorical_accuracy_cp0: 0.5285 - top_20_categorical_accuracy_cp1: 0.9736 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9910 - top_20_categorical_accuracy_cp4: 0.9887 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4413 - top_20_categorical_accuracy_p4: 0.9857    7/7 [==============================] - ETA: 0s - loss: 0.1172 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6632 - top_10_categorical_accuracy: 0.8126 - top_20_categorical_accuracy: 0.9018 - top_5_categorical_accuracy_cp0: 0.0340 - top_5_categorical_accuracy_cp1: 0.4648 - top_5_categorical_accuracy_cp2: 0.8601 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7554 - top_10_categorical_accuracy_cp0: 0.2804 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9609 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9721 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1216 - top_10_categorical_accuracy_p4: 0.9149 - top_20_categorical_accuracy_cp0: 0.5462 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9894 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4549 - top_20_categorical_accuracy_p4: 0.9857    DEBUG:root:Model metric val_loss improved from 0.167049 to 0.164550
7/7 [==============================] - 1s 116ms/step - loss: 0.1172 - categorical_accuracy: 0.2012 - top_5_categorical_accuracy: 0.6632 - top_10_categorical_accuracy: 0.8126 - top_20_categorical_accuracy: 0.9018 - top_5_categorical_accuracy_cp0: 0.0340 - top_5_categorical_accuracy_cp1: 0.4648 - top_5_categorical_accuracy_cp2: 0.8601 - top_5_categorical_accuracy_cp3: 0.9601 - top_5_categorical_accuracy_cp4: 0.9575 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0039 - top_5_categorical_accuracy_p4: 0.7554 - top_10_categorical_accuracy_cp0: 0.2804 - top_10_categorical_accuracy_cp1: 0.8517 - top_10_categorical_accuracy_cp2: 0.9609 - top_10_categorical_accuracy_cp3: 0.9763 - top_10_categorical_accuracy_cp4: 0.9721 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1216 - top_10_categorical_accuracy_p4: 0.9149 - top_20_categorical_accuracy_cp0: 0.5462 - top_20_categorical_accuracy_cp1: 0.9694 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9926 - top_20_categorical_accuracy_cp4: 0.9894 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4549 - top_20_categorical_accuracy_p4: 0.9857 - val_loss: 0.1646 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3070 - val_top_10_categorical_accuracy: 0.4676 - val_top_20_categorical_accuracy: 0.5408 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0000e+00 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5619 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8116 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8557 - val_top_20_categorical_accuracy_cp0: 0.0739 - val_top_20_categorical_accuracy_cp1: 1.0000 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9897
Epoch 8/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1210 - categorical_accuracy: 0.1966 - top_5_categorical_accuracy: 0.6276 - top_10_categorical_accuracy: 0.7864 - top_20_categorical_accuracy: 0.8847 - top_5_categorical_accuracy_cp0: 0.0252 - top_5_categorical_accuracy_cp1: 0.4831 - top_5_categorical_accuracy_cp2: 0.8734 - top_5_categorical_accuracy_cp3: 0.9714 - top_5_categorical_accuracy_cp4: 0.9352 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7297 - top_10_categorical_accuracy_cp0: 0.2521 - top_10_categorical_accuracy_cp1: 0.8644 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 0.9810 - top_10_categorical_accuracy_cp4: 0.9537 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0769 - top_10_categorical_accuracy_p4: 0.9055 - top_20_categorical_accuracy_cp0: 0.5714 - top_20_categorical_accuracy_cp1: 0.9492 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9905 - top_20_categorical_accuracy_cp4: 0.9722 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4423 - top_20_categorical_accuracy_p4: 0.97803/7 [===========>..................] - ETA: 0s - loss: 0.1162 - categorical_accuracy: 0.2072 - top_5_categorical_accuracy: 0.6559 - top_10_categorical_accuracy: 0.8150 - top_20_categorical_accuracy: 0.9011 - top_5_categorical_accuracy_cp0: 0.0476 - top_5_categorical_accuracy_cp1: 0.4222 - top_5_categorical_accuracy_cp2: 0.9221 - top_5_categorical_accuracy_cp3: 0.9574 - top_5_categorical_accuracy_cp4: 0.9522 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7495 - top_10_categorical_accuracy_cp0: 0.2698 - top_10_categorical_accuracy_cp1: 0.8683 - top_10_categorical_accuracy_cp2: 0.9918 - top_10_categorical_accuracy_cp3: 0.9848 - top_10_categorical_accuracy_cp4: 0.9691 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.0940 - top_10_categorical_accuracy_p4: 0.9232 - top_20_categorical_accuracy_cp0: 0.5556 - top_20_categorical_accuracy_cp1: 0.9701 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9939 - top_20_categorical_accuracy_cp4: 0.9888 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0204 - top_20_categorical_accuracy_p3: 0.4786 - top_20_categorical_accuracy_p4: 0.9884    5/7 [====================>.........] - ETA: 0s - loss: 0.1144 - categorical_accuracy: 0.2065 - top_5_categorical_accuracy: 0.6700 - top_10_categorical_accuracy: 0.8236 - top_20_categorical_accuracy: 0.9068 - top_5_categorical_accuracy_cp0: 0.0544 - top_5_categorical_accuracy_cp1: 0.4532 - top_5_categorical_accuracy_cp2: 0.9123 - top_5_categorical_accuracy_cp3: 0.9589 - top_5_categorical_accuracy_cp4: 0.9592 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7651 - top_10_categorical_accuracy_cp0: 0.2854 - top_10_categorical_accuracy_cp1: 0.8807 - top_10_categorical_accuracy_cp2: 0.9875 - top_10_categorical_accuracy_cp3: 0.9821 - top_10_categorical_accuracy_cp4: 0.9739 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1148 - top_10_categorical_accuracy_p4: 0.9301 - top_20_categorical_accuracy_cp0: 0.5670 - top_20_categorical_accuracy_cp1: 0.9743 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9902 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0141 - top_20_categorical_accuracy_p3: 0.4976 - top_20_categorical_accuracy_p4: 0.99007/7 [==============================] - ETA: 0s - loss: 0.1134 - categorical_accuracy: 0.2075 - top_5_categorical_accuracy: 0.6792 - top_10_categorical_accuracy: 0.8280 - top_20_categorical_accuracy: 0.9077 - top_5_categorical_accuracy_cp0: 0.0551 - top_5_categorical_accuracy_cp1: 0.4679 - top_5_categorical_accuracy_cp2: 0.9239 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7740 - top_10_categorical_accuracy_cp0: 0.2934 - top_10_categorical_accuracy_cp1: 0.8823 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9837 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1216 - top_10_categorical_accuracy_p4: 0.9324 - top_20_categorical_accuracy_cp0: 0.5673 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4824 - top_20_categorical_accuracy_p4: 0.9900DEBUG:root:Model metric val_loss improved from 0.164550 to 0.162089
7/7 [==============================] - 1s 118ms/step - loss: 0.1134 - categorical_accuracy: 0.2075 - top_5_categorical_accuracy: 0.6792 - top_10_categorical_accuracy: 0.8280 - top_20_categorical_accuracy: 0.9077 - top_5_categorical_accuracy_cp0: 0.0551 - top_5_categorical_accuracy_cp1: 0.4679 - top_5_categorical_accuracy_cp2: 0.9239 - top_5_categorical_accuracy_cp3: 0.9630 - top_5_categorical_accuracy_cp4: 0.9615 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7740 - top_10_categorical_accuracy_cp0: 0.2934 - top_10_categorical_accuracy_cp1: 0.8823 - top_10_categorical_accuracy_cp2: 0.9897 - top_10_categorical_accuracy_cp3: 0.9837 - top_10_categorical_accuracy_cp4: 0.9748 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1216 - top_10_categorical_accuracy_p4: 0.9324 - top_20_categorical_accuracy_cp0: 0.5673 - top_20_categorical_accuracy_cp1: 0.9709 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9970 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4824 - top_20_categorical_accuracy_p4: 0.9900 - val_loss: 0.1621 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.3211 - val_top_10_categorical_accuracy: 0.4592 - val_top_20_categorical_accuracy: 0.5014 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.0725 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.5876 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7681 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8402 - val_top_20_categorical_accuracy_cp0: 0.0000e+00 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0000e+00 - val_top_20_categorical_accuracy_p4: 0.9175
Epoch 9/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1164 - categorical_accuracy: 0.2136 - top_5_categorical_accuracy: 0.6673 - top_10_categorical_accuracy: 0.8261 - top_20_categorical_accuracy: 0.8960 - top_5_categorical_accuracy_cp0: 0.0541 - top_5_categorical_accuracy_cp1: 0.5446 - top_5_categorical_accuracy_cp2: 0.8889 - top_5_categorical_accuracy_cp3: 0.9469 - top_5_categorical_accuracy_cp4: 0.9554 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7608 - top_10_categorical_accuracy_cp0: 0.3153 - top_10_categorical_accuracy_cp1: 0.9464 - top_10_categorical_accuracy_cp2: 0.9877 - top_10_categorical_accuracy_cp3: 0.9558 - top_10_categorical_accuracy_cp4: 0.9643 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1190 - top_10_categorical_accuracy_p4: 0.9310 - top_20_categorical_accuracy_cp0: 0.5495 - top_20_categorical_accuracy_cp1: 0.9821 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9823 - top_20_categorical_accuracy_cp4: 0.9911 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.3810 - top_20_categorical_accuracy_p4: 0.98713/7 [===========>..................] - ETA: 0s - loss: 0.1143 - categorical_accuracy: 0.2088 - top_5_categorical_accuracy: 0.6763 - top_10_categorical_accuracy: 0.8290 - top_20_categorical_accuracy: 0.9054 - top_5_categorical_accuracy_cp0: 0.0617 - top_5_categorical_accuracy_cp1: 0.5030 - top_5_categorical_accuracy_cp2: 0.9217 - top_5_categorical_accuracy_cp3: 0.9676 - top_5_categorical_accuracy_cp4: 0.9557 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7712 - top_10_categorical_accuracy_cp0: 0.3272 - top_10_categorical_accuracy_cp1: 0.8939 - top_10_categorical_accuracy_cp2: 0.9913 - top_10_categorical_accuracy_cp3: 0.9824 - top_10_categorical_accuracy_cp4: 0.9723 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1288 - top_10_categorical_accuracy_p4: 0.9331 - top_20_categorical_accuracy_cp0: 0.5679 - top_20_categorical_accuracy_cp1: 0.9848 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9941 - top_20_categorical_accuracy_cp4: 0.9917 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4470 - top_20_categorical_accuracy_p4: 0.98995/7 [====================>.........] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.2099 - top_5_categorical_accuracy: 0.6829 - top_10_categorical_accuracy: 0.8361 - top_20_categorical_accuracy: 0.9053 - top_5_categorical_accuracy_cp0: 0.0702 - top_5_categorical_accuracy_cp1: 0.4954 - top_5_categorical_accuracy_cp2: 0.8967 - top_5_categorical_accuracy_cp3: 0.9657 - top_5_categorical_accuracy_cp4: 0.9646 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7792 - top_10_categorical_accuracy_cp0: 0.3158 - top_10_categorical_accuracy_cp1: 0.8991 - top_10_categorical_accuracy_cp2: 0.9924 - top_10_categorical_accuracy_cp3: 0.9838 - top_10_categorical_accuracy_cp4: 0.9791 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1449 - top_10_categorical_accuracy_p4: 0.9406 - top_20_categorical_accuracy_cp0: 0.5556 - top_20_categorical_accuracy_cp1: 0.9743 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9964 - top_20_categorical_accuracy_cp4: 0.9919 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.4720 - top_20_categorical_accuracy_p4: 0.98927/7 [==============================] - ETA: 0s - loss: 0.1128 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.6864 - top_10_categorical_accuracy: 0.8365 - top_20_categorical_accuracy: 0.9077 - top_5_categorical_accuracy_cp0: 0.0778 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.8889 - top_5_categorical_accuracy_cp3: 0.9645 - top_5_categorical_accuracy_cp4: 0.9668 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7822 - top_10_categorical_accuracy_cp0: 0.3241 - top_10_categorical_accuracy_cp1: 0.8945 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9801 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.9399 - top_20_categorical_accuracy_cp0: 0.5624 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4824 - top_20_categorical_accuracy_p4: 0.9900    DEBUG:root:Model metric val_loss improved from 0.162089 to 0.159896
7/7 [==============================] - 1s 112ms/step - loss: 0.1128 - categorical_accuracy: 0.2103 - top_5_categorical_accuracy: 0.6864 - top_10_categorical_accuracy: 0.8365 - top_20_categorical_accuracy: 0.9077 - top_5_categorical_accuracy_cp0: 0.0778 - top_5_categorical_accuracy_cp1: 0.5000 - top_5_categorical_accuracy_cp2: 0.8889 - top_5_categorical_accuracy_cp3: 0.9645 - top_5_categorical_accuracy_cp4: 0.9668 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.7822 - top_10_categorical_accuracy_cp0: 0.3241 - top_10_categorical_accuracy_cp1: 0.8945 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9808 - top_10_categorical_accuracy_cp4: 0.9801 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1451 - top_10_categorical_accuracy_p4: 0.9399 - top_20_categorical_accuracy_cp0: 0.5624 - top_20_categorical_accuracy_cp1: 0.9771 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9956 - top_20_categorical_accuracy_cp4: 0.9920 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0118 - top_20_categorical_accuracy_p3: 0.4824 - top_20_categorical_accuracy_p4: 0.9900 - val_loss: 0.1599 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.4028 - val_top_10_categorical_accuracy: 0.4563 - val_top_20_categorical_accuracy: 0.5155 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.4928 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7371 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.7536 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8351 - val_top_20_categorical_accuracy_cp0: 0.0284 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.0450 - val_top_20_categorical_accuracy_p4: 0.9175
Epoch 10/10
1/7 [===>..........................] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.2152 - top_5_categorical_accuracy: 0.7314 - top_10_categorical_accuracy: 0.8724 - top_20_categorical_accuracy: 0.9333 - top_5_categorical_accuracy_cp0: 0.1205 - top_5_categorical_accuracy_cp1: 0.5439 - top_5_categorical_accuracy_cp2: 0.9103 - top_5_categorical_accuracy_cp3: 0.9646 - top_5_categorical_accuracy_cp4: 0.9635 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0000e+00 - top_5_categorical_accuracy_p4: 0.8084 - top_10_categorical_accuracy_cp0: 0.3976 - top_10_categorical_accuracy_cp1: 0.9211 - top_10_categorical_accuracy_cp2: 0.9872 - top_10_categorical_accuracy_cp3: 0.9646 - top_10_categorical_accuracy_cp4: 0.9781 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.1944 - top_10_categorical_accuracy_p4: 0.9495 - top_20_categorical_accuracy_cp0: 0.6627 - top_20_categorical_accuracy_cp1: 0.9649 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9735 - top_20_categorical_accuracy_cp4: 1.0000 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6111 - top_20_categorical_accuracy_p4: 0.98533/7 [===========>..................] - ETA: 0s - loss: 0.1107 - categorical_accuracy: 0.2123 - top_5_categorical_accuracy: 0.7022 - top_10_categorical_accuracy: 0.8492 - top_20_categorical_accuracy: 0.9163 - top_5_categorical_accuracy_cp0: 0.0993 - top_5_categorical_accuracy_cp1: 0.5361 - top_5_categorical_accuracy_cp2: 0.9167 - top_5_categorical_accuracy_cp3: 0.9591 - top_5_categorical_accuracy_cp4: 0.9706 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0076 - top_5_categorical_accuracy_p4: 0.7976 - top_10_categorical_accuracy_cp0: 0.3874 - top_10_categorical_accuracy_cp1: 0.8916 - top_10_categorical_accuracy_cp2: 0.9868 - top_10_categorical_accuracy_cp3: 0.9766 - top_10_categorical_accuracy_cp4: 0.9840 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2214 - top_10_categorical_accuracy_p4: 0.9445 - top_20_categorical_accuracy_cp0: 0.6291 - top_20_categorical_accuracy_cp1: 0.9608 - top_20_categorical_accuracy_cp2: 1.0000 - top_20_categorical_accuracy_cp3: 0.9854 - top_20_categorical_accuracy_cp4: 0.9947 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0000e+00 - top_20_categorical_accuracy_p3: 0.6031 - top_20_categorical_accuracy_p4: 0.9849    5/7 [====================>.........] - ETA: 0s - loss: 0.1112 - categorical_accuracy: 0.2097 - top_5_categorical_accuracy: 0.6990 - top_10_categorical_accuracy: 0.8451 - top_20_categorical_accuracy: 0.9125 - top_5_categorical_accuracy_cp0: 0.0976 - top_5_categorical_accuracy_cp1: 0.5202 - top_5_categorical_accuracy_cp2: 0.9211 - top_5_categorical_accuracy_cp3: 0.9554 - top_5_categorical_accuracy_cp4: 0.9666 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0047 - top_5_categorical_accuracy_p4: 0.7955 - top_10_categorical_accuracy_cp0: 0.3685 - top_10_categorical_accuracy_cp1: 0.8897 - top_10_categorical_accuracy_cp2: 0.9873 - top_10_categorical_accuracy_cp3: 0.9768 - top_10_categorical_accuracy_cp4: 0.9809 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2056 - top_10_categorical_accuracy_p4: 0.9432 - top_20_categorical_accuracy_cp0: 0.6036 - top_20_categorical_accuracy_cp1: 0.9632 - top_20_categorical_accuracy_cp2: 0.9975 - top_20_categorical_accuracy_cp3: 0.9893 - top_20_categorical_accuracy_cp4: 0.9936 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0152 - top_20_categorical_accuracy_p3: 0.5654 - top_20_categorical_accuracy_p4: 0.9861    7/7 [==============================] - ETA: 0s - loss: 0.1111 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6996 - top_10_categorical_accuracy: 0.8456 - top_20_categorical_accuracy: 0.9127 - top_5_categorical_accuracy_cp0: 0.1037 - top_5_categorical_accuracy_cp1: 0.5260 - top_5_categorical_accuracy_cp2: 0.9218 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.7961 - top_10_categorical_accuracy_cp0: 0.3776 - top_10_categorical_accuracy_cp1: 0.8945 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9761 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2078 - top_10_categorical_accuracy_p4: 0.9446 - top_20_categorical_accuracy_cp0: 0.6078 - top_20_categorical_accuracy_cp1: 0.9664 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.5765 - top_20_categorical_accuracy_p4: 0.9868DEBUG:root:Model metric val_loss improved from 0.159896 to 0.156094
7/7 [==============================] - 1s 114ms/step - loss: 0.1111 - categorical_accuracy: 0.2094 - top_5_categorical_accuracy: 0.6996 - top_10_categorical_accuracy: 0.8456 - top_20_categorical_accuracy: 0.9127 - top_5_categorical_accuracy_cp0: 0.1037 - top_5_categorical_accuracy_cp1: 0.5260 - top_5_categorical_accuracy_cp2: 0.9218 - top_5_categorical_accuracy_cp3: 0.9586 - top_5_categorical_accuracy_cp4: 0.9628 - top_5_categorical_accuracy_p0: 0.0000e+00 - top_5_categorical_accuracy_p1: 0.0000e+00 - top_5_categorical_accuracy_p2: 0.0000e+00 - top_5_categorical_accuracy_p3: 0.0118 - top_5_categorical_accuracy_p4: 0.7961 - top_10_categorical_accuracy_cp0: 0.3776 - top_10_categorical_accuracy_cp1: 0.8945 - top_10_categorical_accuracy_cp2: 0.9856 - top_10_categorical_accuracy_cp3: 0.9793 - top_10_categorical_accuracy_cp4: 0.9761 - top_10_categorical_accuracy_p0: 0.0000e+00 - top_10_categorical_accuracy_p1: 0.0000e+00 - top_10_categorical_accuracy_p2: 0.0000e+00 - top_10_categorical_accuracy_p3: 0.2078 - top_10_categorical_accuracy_p4: 0.9446 - top_20_categorical_accuracy_cp0: 0.6078 - top_20_categorical_accuracy_cp1: 0.9664 - top_20_categorical_accuracy_cp2: 0.9979 - top_20_categorical_accuracy_cp3: 0.9911 - top_20_categorical_accuracy_cp4: 0.9907 - top_20_categorical_accuracy_p0: 0.0000e+00 - top_20_categorical_accuracy_p1: 0.0000e+00 - top_20_categorical_accuracy_p2: 0.0235 - top_20_categorical_accuracy_p3: 0.5765 - top_20_categorical_accuracy_p4: 0.9868 - val_loss: 0.1561 - val_categorical_accuracy: 0.2338 - val_top_5_categorical_accuracy: 0.4254 - val_top_10_categorical_accuracy: 0.4761 - val_top_20_categorical_accuracy: 0.6254 - val_top_5_categorical_accuracy_cp0: 0.0000e+00 - val_top_5_categorical_accuracy_cp1: 0.6087 - val_top_5_categorical_accuracy_cp2: 1.0000 - val_top_5_categorical_accuracy_cp3: 1.0000 - val_top_5_categorical_accuracy_cp4: 0.0000e+00 - val_top_5_categorical_accuracy_p0: 0.0000e+00 - val_top_5_categorical_accuracy_p1: 0.0000e+00 - val_top_5_categorical_accuracy_p2: 0.0000e+00 - val_top_5_categorical_accuracy_p3: 0.0000e+00 - val_top_5_categorical_accuracy_p4: 0.7784 - val_top_10_categorical_accuracy_cp0: 0.0000e+00 - val_top_10_categorical_accuracy_cp1: 0.8551 - val_top_10_categorical_accuracy_cp2: 1.0000 - val_top_10_categorical_accuracy_cp3: 1.0000 - val_top_10_categorical_accuracy_cp4: 1.0000 - val_top_10_categorical_accuracy_p0: 0.0000e+00 - val_top_10_categorical_accuracy_p1: 0.0000e+00 - val_top_10_categorical_accuracy_p2: 0.0000e+00 - val_top_10_categorical_accuracy_p3: 0.0000e+00 - val_top_10_categorical_accuracy_p4: 0.8711 - val_top_20_categorical_accuracy_cp0: 0.2500 - val_top_20_categorical_accuracy_cp1: 0.9855 - val_top_20_categorical_accuracy_cp2: 1.0000 - val_top_20_categorical_accuracy_cp3: 1.0000 - val_top_20_categorical_accuracy_cp4: 1.0000 - val_top_20_categorical_accuracy_p0: 0.0000e+00 - val_top_20_categorical_accuracy_p1: 0.0000e+00 - val_top_20_categorical_accuracy_p2: 0.0000e+00 - val_top_20_categorical_accuracy_p3: 0.3964 - val_top_20_categorical_accuracy_p4: 0.9175
INFO:root:Restoring best model weights with val_loss: 0.156094 from epoch 9
DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.
/home/i40/pacev/Domain-Guided-Monitoring/src/training/analysis/plotting.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(20, 10))
Calculating prediction outputs...: 0it [00:00, ?it/s]Calculating prediction outputs...: 1it [00:00,  9.72it/s]Calculating prediction outputs...: 1it [00:00,  9.70it/s]
Calculating x frequencies...: 0it [00:00, ?it/s]Calculating x frequencies...: 7it [00:00, 1664.22it/s]
INFO:root:Finished run 47827585b1634893b72464b3eef4a0a6
Starting Jupyter Notebook at port 8888
PATH="/home/i40/pacev/miniconda3/envs/lena/bin:/home/i40/pacev/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/home/i40/pacev/Domain-Guided-Monitoring/~/miniconda3/miniconda3/envs/lena/bin" ; \
~/miniconda3/envs/lena/bin/jupyter notebook notebooks/ --no-browser 
[W 2023-05-25 07:38:21.541 LabApp] 'notebook_dir' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2023-05-25 07:38:21.541 LabApp] 'notebook_dir' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2023-05-25 07:38:21.545 LabApp] JupyterLab extension loaded from /home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/jupyterlab
[I 2023-05-25 07:38:21.545 LabApp] JupyterLab application directory is /home/i40/pacev/miniconda3/envs/lena/share/jupyter/lab
[I 07:38:21.548 NotebookApp] Serving notebooks from local directory: /home/i40/pacev/Domain-Guided-Monitoring/notebooks
[I 07:38:21.548 NotebookApp] Jupyter Notebook 6.5.2 is running at:
[I 07:38:21.548 NotebookApp] http://localhost:8888/?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a
[I 07:38:21.548 NotebookApp]  or http://127.0.0.1:8888/?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a
[I 07:38:21.548 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 07:38:21.550 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///home/i40/pacev/.local/share/jupyter/runtime/nbserver-729245-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a
     or http://127.0.0.1:8888/?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a
[I 07:38:22.910 NotebookApp] 302 GET / (127.0.0.1) 0.400000ms
[W 07:38:22.931 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[W 07:38:22.932 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[I 07:38:22.932 NotebookApp] 302 GET /tree? (127.0.0.1) 1.560000ms
[W 07:38:23.916 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 9.620000ms referer=None
[I 07:38:32.312 NotebookApp] 302 GET /?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a (127.0.0.1) 0.570000ms
[W 07:38:33.308 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[W 07:38:36.894 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.490000ms referer=None
[W 07:38:36.951 NotebookApp] Notebook Attention based selection.ipynb is not trusted
[I 07:38:37.133 NotebookApp] Kernel started: a0beeaa2-3220-46bc-aca2-cea2ceb47add, name: python3
[W 07:38:38.078 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.570000ms referer=None
[W 07:38:38.420 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:38:39.130 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.220000ms referer=None
[I 07:38:39.248 NotebookApp] Kernel started: 3010a91d-2db2-4408-83b8-66780ca0384f, name: lena
[W 07:38:40.229 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.850000ms referer=None
[I 07:40:37.172 NotebookApp] Saving file at /Attention based selection.ipynb
[W 07:40:37.173 NotebookApp] Notebook Attention based selection.ipynb is not trusted
[W 07:40:38.127 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[I 08:12:26.855 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:de3d36bc36db48bb8869b4473ef6e227
[I 08:12:26.856 NotebookApp] Starting buffering for a0beeaa2-3220-46bc-aca2-cea2ceb47add:bfa0749ceb574f329fbde2d430ec7aba
[W 08:45:47.419 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[W 08:45:47.420 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[W 08:45:47.421 NotebookApp] Forbidden
[W 08:45:47.421 NotebookApp] 403 GET /api/sessions?_=1685004135510 (127.0.0.1) 2.320000ms referer=http://localhost:8888/tree
[W 08:45:47.421 NotebookApp] Forbidden
[W 08:45:47.422 NotebookApp] 403 GET /api/terminals?_=1685004135511 (127.0.0.1) 1.920000ms referer=http://localhost:8888/tree
[I 08:45:48.263 NotebookApp] 302 GET /tree (127.0.0.1) 0.760000ms
[W 08:45:48.412 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.320000ms referer=None
[W 08:45:49.447 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.310000ms referer=None
[I 08:46:08.467 NotebookApp] 302 GET /?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a (127.0.0.1) 0.640000ms
[W 08:46:09.470 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 08:46:13.679 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:46:14.161 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.290000ms referer=None
[W 08:46:15.800 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
2023-05-25 08:46:24.177815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-25 08:46:24.687531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 08:46:24.687588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 08:46:24.687592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[W 08:46:25.437 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 08:46:27.052 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[W 08:46:30.986 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.570000ms referer=None
[W 08:46:32.161 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 08:46:47.893 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.450000ms referer=None
[W 08:46:53.016 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.510000ms referer=None
[W 08:47:07.146 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.590000ms referer=None
[I 08:48:15.417 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 08:48:15.419 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:48:15.799 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.270000ms referer=None
[W 08:49:55.175 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.610000ms referer=None
[W 08:50:09.001 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[I 08:50:15.425 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 08:50:15.426 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:50:15.767 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[W 08:50:17.637 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[W 08:50:26.709 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[I 08:52:15.401 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 08:52:15.402 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:52:15.798 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.830000ms referer=None
[W 08:55:03.306 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.920000ms referer=None
[W 08:55:23.585 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[I 08:56:15.417 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 08:56:15.418 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:56:15.806 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.310000ms referer=None
[I 08:58:15.439 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 08:58:15.440 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 08:58:15.794 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.240000ms referer=None
[W 08:58:51.845 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.540000ms referer=None
[W 08:59:04.118 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 08:59:28.541 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[I 09:00:15.406 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:00:15.408 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:00:15.825 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.210000ms referer=None
[W 09:00:34.756 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.500000ms referer=None
[I 09:02:15.412 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:02:15.413 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:02:15.804 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[W 09:07:39.081 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.400000ms referer=None
[W 09:08:06.476 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.320000ms referer=None
[W 09:17:43.447 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.430000ms referer=None
[W 09:26:05.713 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.440000ms referer=None
[W 09:26:46.338 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[W 09:26:56.922 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[W 09:27:01.095 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[W 09:27:19.243 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 09:27:23.421 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.480000ms referer=None
[W 09:27:26.806 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[W 09:27:32.282 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[I 09:28:15.487 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:28:15.488 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:28:15.803 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.490000ms referer=None
[I 09:28:20.465 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:0b1e002e7bf0499b85471517c055da32
[W 09:28:21.493 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[I 09:28:21.605 NotebookApp] Kernel restarted: 3010a91d-2db2-4408-83b8-66780ca0384f
[I 09:28:21.646 NotebookApp] Restoring connection for 3010a91d-2db2-4408-83b8-66780ca0384f:0b1e002e7bf0499b85471517c055da32
[I 09:28:22.154 NotebookApp] Replaying 3 buffered messages
2023-05-25 09:28:27.398949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-25 09:28:27.891175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 09:28:27.891231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 09:28:27.891236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[W 09:28:28.699 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.950000ms referer=None
[W 09:28:30.223 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.000000ms referer=None
[W 09:28:35.330 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.020000ms referer=None
[W 09:28:38.554 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 09:28:41.885 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.810000ms referer=None
[W 09:28:47.482 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 09:29:05.634 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.450000ms referer=None
[W 09:29:22.398 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[I 09:30:15.430 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:30:15.431 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:30:15.806 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 09:30:55.511 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.230000ms referer=None
[W 09:32:16.523 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.120000ms referer=None
[I 09:34:15.428 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:34:15.430 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:34:16.227 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.530000ms referer=None
[I 09:36:15.432 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:36:15.434 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:36:15.806 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.190000ms referer=None
[W 09:40:41.958 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.040000ms referer=None
[W 09:41:49.466 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.390000ms referer=None
[W 09:47:25.323 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[W 09:48:13.250 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.940000ms referer=None
[I 09:48:15.400 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:48:15.401 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/nbformat/__init__.py:128: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
/home/i40/pacev/miniconda3/envs/lena/lib/python3.9/site-packages/notebook/services/contents/manager.py:353: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate_nb(model['content'])
[W 09:48:15.773 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.240000ms referer=None
[W 09:48:18.199 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.450000ms referer=None
[W 09:48:27.156 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[W 09:48:32.147 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 09:48:42.256 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.530000ms referer=None
[W 09:48:44.371 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.490000ms referer=None
[I 09:50:15.410 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:50:15.411 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:50:15.815 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 09:51:33.511 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 09:52:02.558 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.530000ms referer=None
[W 09:52:07.553 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[W 09:52:10.529 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.610000ms referer=None
[I 09:52:15.420 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:52:15.421 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:52:15.780 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.360000ms referer=None
[W 09:52:24.279 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 09:53:18.434 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.610000ms referer=None
[W 09:54:02.348 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.260000ms referer=None
[I 09:54:15.440 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:54:15.441 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:54:15.773 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 09:54:24.321 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 09:55:28.458 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[I 09:56:15.442 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:56:15.443 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:56:15.803 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[W 09:56:31.736 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.200000ms referer=None
[W 09:57:18.869 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.330000ms referer=None
[I 09:57:39.141 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:0b1e002e7bf0499b85471517c055da32
[W 09:57:40.152 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.980000ms referer=None
[I 09:57:40.387 NotebookApp] Kernel restarted: 3010a91d-2db2-4408-83b8-66780ca0384f
[I 09:57:40.430 NotebookApp] Restoring connection for 3010a91d-2db2-4408-83b8-66780ca0384f:0b1e002e7bf0499b85471517c055da32
[I 09:57:40.936 NotebookApp] Replaying 3 buffered messages
2023-05-25 09:57:44.034905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-25 09:57:44.538166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 09:57:44.538227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-05-25 09:57:44.538232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[W 09:57:45.319 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.170000ms referer=None
[W 09:57:46.849 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.250000ms referer=None
[W 09:57:51.463 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.730000ms referer=None
[W 09:57:55.517 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 09:58:10.106 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.060000ms referer=None
[W 09:58:12.226 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.200000ms referer=None
[I 09:58:15.437 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 09:58:15.439 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 09:58:15.782 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.240000ms referer=None
[I 10:00:15.491 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:00:15.492 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:00:15.843 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.300000ms referer=None
[W 10:01:06.839 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 10:01:13.104 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.540000ms referer=None
[W 10:01:15.894 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[W 10:01:17.617 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.450000ms referer=None
[I 10:02:15.449 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:02:15.450 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:02:15.807 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 10:03:52.079 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 10:03:54.991 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.180000ms referer=None
[I 10:04:15.438 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:04:15.440 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:04:15.796 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.400000ms referer=None
[W 10:04:25.823 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.150000ms referer=None
[W 10:04:30.591 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.440000ms referer=None
[W 10:05:04.251 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.510000ms referer=None
[W 10:05:37.012 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.340000ms referer=None
[W 10:06:13.377 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.160000ms referer=None
[I 10:06:16.520 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:06:16.521 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:06:16.589 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.260000ms referer=None
[W 10:12:33.058 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[W 10:12:40.925 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[W 10:14:40.431 NotebookApp] WebSocket ping timeout after 119981 ms.
[I 10:14:45.435 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:0b1e002e7bf0499b85471517c055da32
[W 13:14:07.776 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[W 13:14:10.768 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 13:14:12.182 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:14:13.071 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.440000ms referer=None
[W 13:14:14.490 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.350000ms referer=None
[W 13:14:38.706 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.960000ms referer=None
[W 13:14:41.916 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 13:15:06.539 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.850000ms referer=None
[W 13:15:09.607 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 13:15:22.273 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.590000ms referer=None
[W 13:16:14.675 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[I 13:16:15.346 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 13:16:15.347 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:16:36.466 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.670000ms referer=None
[W 13:16:38.814 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.330000ms referer=None
[I 13:18:14.293 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 13:18:14.294 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:18:14.525 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.290000ms referer=None
[W 13:27:29.842 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.430000ms referer=None
[W 13:30:41.208 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[I 13:30:44.220 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:2f8d828b1a03480ab33f3056750885b4
[I 12:14:48.502 NotebookApp] 302 GET /?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a (127.0.0.1) 0.600000ms
[W 12:14:49.488 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 12:14:53.120 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:14:53.312 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.290000ms referer=None
[W 12:14:54.878 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.340000ms referer=None
[I 12:15:43.138 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:752432e2331b4d0b9a14c88cfe40c3cd
[W 12:15:43.640 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:15:44.170 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.280000ms referer=None
[W 12:15:45.374 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[I 12:15:55.184 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:509aa35e83314166a62d30d491d2d208
[W 12:15:55.670 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:15:56.198 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.020000ms referer=None
[W 12:15:57.390 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.350000ms referer=None
[W 12:16:22.457 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.960000ms referer=None
[W 12:16:36.762 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 12:17:01.419 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.860000ms referer=None
[W 12:17:10.603 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[I 12:17:34.859 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:44780daf7c6a4200862f0f73786b57cd
[I 12:17:35.706 NotebookApp] Kernel restarted: 3010a91d-2db2-4408-83b8-66780ca0384f
[I 12:17:35.741 NotebookApp] Restoring connection for 3010a91d-2db2-4408-83b8-66780ca0384f:44780daf7c6a4200862f0f73786b57cd
[W 12:17:35.869 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.050000ms referer=None
[I 12:17:36.194 NotebookApp] Replaying 3 buffered messages
2023-06-12 12:17:39.261097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-12 12:17:39.838291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-06-12 12:17:39.838353: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH
2023-06-12 12:17:39.838357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[W 12:17:40.427 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.440000ms referer=None
[W 12:17:42.302 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[W 12:17:43.578 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.390000ms referer=None
[W 12:17:54.501 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.480000ms referer=None
[W 12:17:56.499 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[W 12:17:58.658 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.500000ms referer=None
[I 12:17:59.607 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:17:59.610 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:18:04.631 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[I 12:19:59.055 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:19:59.057 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:19:59.119 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 85.220000ms referer=None
[W 12:21:23.836 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.400000ms referer=None
[I 12:21:58.610 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:21:58.611 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:21:58.920 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[I 12:23:58.555 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:23:58.556 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:23:58.912 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[I 12:25:59.137 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:25:59.138 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:25:59.205 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.160000ms referer=None
[W 12:26:59.884 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[W 12:27:59.065 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.860000ms referer=None
[I 12:27:59.349 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:27:59.350 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:29:58.796 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:29:58.798 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 12:29:58.922 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.110000ms referer=None
[W 13:55:30.428 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.480000ms referer=None
[W 13:55:55.488 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.650000ms referer=None
[W 13:55:59.489 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 13:56:01.112 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.780000ms referer=None
[I 13:56:01.277 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 13:56:01.278 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:56:02.994 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.110000ms referer=None
[W 13:56:08.593 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.570000ms referer=None
[I 13:58:00.793 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 13:58:00.794 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:58:00.869 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.300000ms referer=None
[I 14:00:00.533 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 14:00:00.535 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 14:00:00.870 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.280000ms referer=None
[I 14:02:00.503 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 14:02:00.505 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 14:02:00.865 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.350000ms referer=None
[I 14:04:00.499 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 14:04:00.501 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 14:04:00.868 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.290000ms referer=None
[I 16:48:06.843 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:44780daf7c6a4200862f0f73786b57cd
[I 10:37:40.180 NotebookApp] 302 GET /?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a (127.0.0.1) 0.630000ms
[W 10:37:41.159 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[W 10:37:41.666 NotebookApp] Forbidden
[W 10:37:41.667 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.780000ms referer=None
[W 10:37:41.738 NotebookApp] 401 POST /login (127.0.0.1) 1.440000ms referer=None
[W 10:37:45.231 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:37:45.461 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.920000ms referer=None
[W 10:37:46.950 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.480000ms referer=None
[W 10:38:02.273 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.440000ms referer=None
[W 10:38:07.262 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 10:38:11.641 NotebookApp] Forbidden
[W 10:38:11.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.870000ms referer=None
[W 10:38:11.690 NotebookApp] 401 POST /login (127.0.0.1) 1.460000ms referer=None
[W 10:38:41.639 NotebookApp] Forbidden
[W 10:38:41.640 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:38:41.688 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:38:57.303 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 10:38:59.333 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.490000ms referer=None
[W 10:39:11.638 NotebookApp] Forbidden
[W 10:39:11.638 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.930000ms referer=None
[W 10:39:11.683 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:39:41.647 NotebookApp] Forbidden
[W 10:39:41.647 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:39:41.691 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[I 10:39:46.607 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:39:46.608 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:39:46.973 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 10:40:11.639 NotebookApp] Forbidden
[W 10:40:11.639 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:40:11.686 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:40:41.644 NotebookApp] Forbidden
[W 10:40:41.644 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.940000ms referer=None
[W 10:40:41.688 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 10:41:11.641 NotebookApp] Forbidden
[W 10:41:11.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.950000ms referer=None
[W 10:41:11.685 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:41:41.641 NotebookApp] Forbidden
[W 10:41:41.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.950000ms referer=None
[W 10:41:41.686 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 10:42:11.641 NotebookApp] Forbidden
[W 10:42:11.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:42:11.684 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:42:41.640 NotebookApp] Forbidden
[W 10:42:41.640 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 10:42:41.686 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:43:11.641 NotebookApp] Forbidden
[W 10:43:11.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:43:11.685 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:43:41.641 NotebookApp] Forbidden
[W 10:43:41.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 10:43:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[I 10:43:46.624 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:43:46.626 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:43:46.977 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.330000ms referer=None
[W 10:44:11.641 NotebookApp] Forbidden
[W 10:44:11.641 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.950000ms referer=None
[W 10:44:11.684 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:44:41.648 NotebookApp] Forbidden
[W 10:44:41.648 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 10:44:41.696 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:45:11.642 NotebookApp] Forbidden
[W 10:45:11.642 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:45:11.683 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 10:45:41.641 NotebookApp] Forbidden
[W 10:45:41.642 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 10:45:41.685 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[I 10:45:46.625 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:45:46.627 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 10:45:46.982 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.220000ms referer=None
[W 10:46:11.642 NotebookApp] Forbidden
[W 10:46:11.642 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:46:11.684 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:46:41.644 NotebookApp] Forbidden
[W 10:46:41.644 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:46:41.688 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 10:47:11.643 NotebookApp] Forbidden
[W 10:47:11.643 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:47:11.683 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:47:41.649 NotebookApp] Forbidden
[W 10:47:41.649 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:47:41.691 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:48:11.644 NotebookApp] Forbidden
[W 10:48:11.644 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:48:11.686 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:48:41.645 NotebookApp] Forbidden
[W 10:48:41.645 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:48:41.691 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:49:11.644 NotebookApp] Forbidden
[W 10:49:11.644 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:49:11.684 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 10:49:41.645 NotebookApp] Forbidden
[W 10:49:41.645 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:49:41.686 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:50:11.644 NotebookApp] Forbidden
[W 10:50:11.644 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:50:11.685 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:50:41.645 NotebookApp] Forbidden
[W 10:50:41.645 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:50:41.686 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:51:11.649 NotebookApp] Forbidden
[W 10:51:11.649 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:51:11.693 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:51:41.646 NotebookApp] Forbidden
[W 10:51:41.646 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 10:51:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:52:11.651 NotebookApp] Forbidden
[W 10:52:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 10:52:11.696 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:52:41.650 NotebookApp] Forbidden
[W 10:52:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:52:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.430000ms referer=None
[W 10:53:11.647 NotebookApp] Forbidden
[W 10:53:11.647 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 10:53:11.691 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:53:41.645 NotebookApp] Forbidden
[W 10:53:41.646 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 10:53:41.686 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:54:11.649 NotebookApp] Forbidden
[W 10:54:11.649 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:54:11.689 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:54:41.646 NotebookApp] Forbidden
[W 10:54:41.646 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 10:54:41.693 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:55:11.647 NotebookApp] Forbidden
[W 10:55:11.647 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:55:11.689 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:55:41.647 NotebookApp] Forbidden
[W 10:55:41.647 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:55:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:56:11.649 NotebookApp] Forbidden
[W 10:56:11.649 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 10:56:11.687 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:56:41.647 NotebookApp] Forbidden
[W 10:56:41.648 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:56:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 10:57:11.647 NotebookApp] Forbidden
[W 10:57:11.647 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 10:57:11.686 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:57:41.650 NotebookApp] Forbidden
[W 10:57:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:57:41.696 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 10:58:11.649 NotebookApp] Forbidden
[W 10:58:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.080000ms referer=None
[W 10:58:11.693 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 10:58:41.650 NotebookApp] Forbidden
[W 10:58:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.080000ms referer=None
[W 10:58:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 10:59:11.650 NotebookApp] Forbidden
[W 10:59:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:59:11.693 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 10:59:41.650 NotebookApp] Forbidden
[W 10:59:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 10:59:41.690 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:00:11.650 NotebookApp] Forbidden
[W 11:00:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:00:11.688 NotebookApp] 401 POST /login (127.0.0.1) 1.430000ms referer=None
[W 11:00:41.651 NotebookApp] Forbidden
[W 11:00:41.652 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.080000ms referer=None
[W 11:00:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:01:11.650 NotebookApp] Forbidden
[W 11:01:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:01:11.691 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:01:41.650 NotebookApp] Forbidden
[W 11:01:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:01:41.690 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:02:11.650 NotebookApp] Forbidden
[W 11:02:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:02:11.688 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:02:41.650 NotebookApp] Forbidden
[W 11:02:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:02:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:03:11.650 NotebookApp] Forbidden
[W 11:03:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:03:11.693 NotebookApp] 401 POST /login (127.0.0.1) 1.470000ms referer=None
[W 11:03:41.650 NotebookApp] Forbidden
[W 11:03:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:03:41.693 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:04:11.650 NotebookApp] Forbidden
[W 11:04:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:04:11.689 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:04:41.650 NotebookApp] Forbidden
[W 11:04:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:04:41.691 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:05:11.650 NotebookApp] Forbidden
[W 11:05:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:05:11.691 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:05:41.650 NotebookApp] Forbidden
[W 11:05:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:05:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:06:11.650 NotebookApp] Forbidden
[W 11:06:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:06:11.692 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:06:41.650 NotebookApp] Forbidden
[W 11:06:41.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:06:41.689 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:07:11.650 NotebookApp] Forbidden
[W 11:07:11.651 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:07:11.694 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:07:41.650 NotebookApp] Forbidden
[W 11:07:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 11:07:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:08:11.656 NotebookApp] Forbidden
[W 11:08:11.657 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 11:08:11.696 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:08:41.650 NotebookApp] Forbidden
[W 11:08:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:08:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:09:11.653 NotebookApp] Forbidden
[W 11:09:11.653 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.950000ms referer=None
[W 11:09:11.696 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:09:41.650 NotebookApp] Forbidden
[W 11:09:41.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.110000ms referer=None
[W 11:09:41.692 NotebookApp] 401 POST /login (127.0.0.1) 1.430000ms referer=None
[W 11:10:11.650 NotebookApp] Forbidden
[W 11:10:11.650 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.040000ms referer=None
[W 11:10:11.691 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:10:41.653 NotebookApp] Forbidden
[W 11:10:41.653 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:10:41.695 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:11:11.653 NotebookApp] Forbidden
[W 11:11:11.653 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.040000ms referer=None
[W 11:11:11.697 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:11:41.654 NotebookApp] Forbidden
[W 11:11:41.655 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 11:11:41.698 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:12:11.660 NotebookApp] Forbidden
[W 11:12:11.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:12:11.701 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:12:41.657 NotebookApp] Forbidden
[W 11:12:41.657 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.790000ms referer=None
[W 11:12:41.699 NotebookApp] 401 POST /login (127.0.0.1) 1.250000ms referer=None
[W 11:13:11.653 NotebookApp] Forbidden
[W 11:13:11.654 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.910000ms referer=None
[W 11:13:11.693 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:13:41.656 NotebookApp] Forbidden
[W 11:13:41.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:13:41.698 NotebookApp] 401 POST /login (127.0.0.1) 1.480000ms referer=None
[W 11:14:11.654 NotebookApp] Forbidden
[W 11:14:11.654 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:14:11.694 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:14:41.656 NotebookApp] Forbidden
[W 11:14:41.657 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 11:14:41.701 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:15:11.656 NotebookApp] Forbidden
[W 11:15:11.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:15:11.700 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:15:41.656 NotebookApp] Forbidden
[W 11:15:41.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.070000ms referer=None
[W 11:15:41.700 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:16:11.655 NotebookApp] Forbidden
[W 11:16:11.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.800000ms referer=None
[W 11:16:11.690 NotebookApp] 401 POST /login (127.0.0.1) 0.820000ms referer=None
[W 11:16:41.656 NotebookApp] Forbidden
[W 11:16:41.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.830000ms referer=None
[W 11:16:41.697 NotebookApp] 401 POST /login (127.0.0.1) 0.850000ms referer=None
[W 11:17:11.656 NotebookApp] Forbidden
[W 11:17:11.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.750000ms referer=None
[W 11:17:11.694 NotebookApp] 401 POST /login (127.0.0.1) 0.880000ms referer=None
[W 11:17:41.660 NotebookApp] Forbidden
[W 11:17:41.660 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 11:17:41.704 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:18:11.656 NotebookApp] Forbidden
[W 11:18:11.656 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.780000ms referer=None
[W 11:18:11.694 NotebookApp] 401 POST /login (127.0.0.1) 0.780000ms referer=None
[W 11:18:41.657 NotebookApp] Forbidden
[W 11:18:41.657 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.710000ms referer=None
[W 11:18:41.700 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:19:11.658 NotebookApp] Forbidden
[W 11:19:11.658 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:19:11.697 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:19:41.658 NotebookApp] Forbidden
[W 11:19:41.659 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 11:19:41.699 NotebookApp] 401 POST /login (127.0.0.1) 1.030000ms referer=None
[W 11:20:11.667 NotebookApp] Forbidden
[W 11:20:11.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.760000ms referer=None
[W 11:20:11.707 NotebookApp] 401 POST /login (127.0.0.1) 0.740000ms referer=None
[W 11:20:41.658 NotebookApp] Forbidden
[W 11:20:41.658 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.920000ms referer=None
[W 11:20:41.699 NotebookApp] 401 POST /login (127.0.0.1) 0.970000ms referer=None
[W 11:21:11.661 NotebookApp] Forbidden
[W 11:21:11.662 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:21:11.701 NotebookApp] 401 POST /login (127.0.0.1) 1.030000ms referer=None
[W 11:21:41.663 NotebookApp] Forbidden
[W 11:21:41.663 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:21:41.700 NotebookApp] 401 POST /login (127.0.0.1) 1.030000ms referer=None
[W 11:22:11.661 NotebookApp] Forbidden
[W 11:22:11.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:22:11.699 NotebookApp] 401 POST /login (127.0.0.1) 0.970000ms referer=None
[W 11:22:41.659 NotebookApp] Forbidden
[W 11:22:41.659 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.840000ms referer=None
[W 11:22:41.708 NotebookApp] 401 POST /login (127.0.0.1) 1.160000ms referer=None
[W 11:23:11.661 NotebookApp] Forbidden
[W 11:23:11.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:23:11.706 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:23:41.660 NotebookApp] Forbidden
[W 11:23:41.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:23:41.701 NotebookApp] 401 POST /login (127.0.0.1) 1.050000ms referer=None
[W 11:24:11.663 NotebookApp] Forbidden
[W 11:24:11.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.910000ms referer=None
[W 11:24:11.705 NotebookApp] 401 POST /login (127.0.0.1) 1.040000ms referer=None
[W 11:24:41.664 NotebookApp] Forbidden
[W 11:24:41.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:24:41.703 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:25:11.664 NotebookApp] Forbidden
[W 11:25:11.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:25:11.707 NotebookApp] 401 POST /login (127.0.0.1) 2.110000ms referer=None
[W 11:25:41.664 NotebookApp] Forbidden
[W 11:25:41.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:25:41.707 NotebookApp] 401 POST /login (127.0.0.1) 1.130000ms referer=None
[W 11:26:11.661 NotebookApp] Forbidden
[W 11:26:11.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.650000ms referer=None
[W 11:26:11.699 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:26:41.661 NotebookApp] Forbidden
[W 11:26:41.661 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.670000ms referer=None
[W 11:26:41.705 NotebookApp] 401 POST /login (127.0.0.1) 0.940000ms referer=None
[W 11:27:11.666 NotebookApp] Forbidden
[W 11:27:11.667 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.900000ms referer=None
[W 11:27:11.708 NotebookApp] 401 POST /login (127.0.0.1) 1.160000ms referer=None
[W 11:27:41.662 NotebookApp] Forbidden
[W 11:27:41.663 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.070000ms referer=None
[W 11:27:41.747 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:28:11.663 NotebookApp] Forbidden
[W 11:28:11.663 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.950000ms referer=None
[W 11:28:11.703 NotebookApp] 401 POST /login (127.0.0.1) 1.100000ms referer=None
[W 11:28:41.664 NotebookApp] Forbidden
[W 11:28:41.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 11:28:41.709 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:29:11.664 NotebookApp] Forbidden
[W 11:29:11.664 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.130000ms referer=None
[W 11:29:11.705 NotebookApp] 401 POST /login (127.0.0.1) 1.550000ms referer=None
[W 11:29:41.665 NotebookApp] Forbidden
[W 11:29:41.665 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:29:41.743 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:30:11.663 NotebookApp] Forbidden
[W 11:30:11.663 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:30:11.704 NotebookApp] 401 POST /login (127.0.0.1) 1.170000ms referer=None
[W 11:30:41.666 NotebookApp] Forbidden
[W 11:30:41.667 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.840000ms referer=None
[W 11:30:41.708 NotebookApp] 401 POST /login (127.0.0.1) 1.190000ms referer=None
[W 11:31:11.666 NotebookApp] Forbidden
[W 11:31:11.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 11:31:11.708 NotebookApp] 401 POST /login (127.0.0.1) 1.120000ms referer=None
[W 11:31:41.665 NotebookApp] Forbidden
[W 11:31:41.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:31:41.704 NotebookApp] 401 POST /login (127.0.0.1) 1.130000ms referer=None
[W 11:32:11.665 NotebookApp] Forbidden
[W 11:32:11.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.190000ms referer=None
[W 11:32:11.708 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:32:41.666 NotebookApp] Forbidden
[W 11:32:41.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.910000ms referer=None
[W 11:32:41.708 NotebookApp] 401 POST /login (127.0.0.1) 1.440000ms referer=None
[W 11:33:11.666 NotebookApp] Forbidden
[W 11:33:11.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:33:11.705 NotebookApp] 401 POST /login (127.0.0.1) 1.200000ms referer=None
[W 11:33:41.668 NotebookApp] Forbidden
[W 11:33:41.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:33:41.714 NotebookApp] 401 POST /login (127.0.0.1) 1.520000ms referer=None
[W 11:34:11.666 NotebookApp] Forbidden
[W 11:34:11.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 11:34:11.705 NotebookApp] 401 POST /login (127.0.0.1) 1.280000ms referer=None
[W 11:34:41.665 NotebookApp] Forbidden
[W 11:34:41.666 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.900000ms referer=None
[W 11:34:41.711 NotebookApp] 401 POST /login (127.0.0.1) 1.060000ms referer=None
[W 11:35:11.668 NotebookApp] Forbidden
[W 11:35:11.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.720000ms referer=None
[W 11:35:11.707 NotebookApp] 401 POST /login (127.0.0.1) 0.860000ms referer=None
[W 11:35:41.667 NotebookApp] Forbidden
[W 11:35:41.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.730000ms referer=None
[W 11:35:41.707 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:36:11.668 NotebookApp] Forbidden
[W 11:36:11.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.660000ms referer=None
[W 11:36:11.712 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:36:41.668 NotebookApp] Forbidden
[W 11:36:41.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.710000ms referer=None
[W 11:36:41.719 NotebookApp] 401 POST /login (127.0.0.1) 0.690000ms referer=None
[W 11:37:11.667 NotebookApp] Forbidden
[W 11:37:11.667 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.680000ms referer=None
[W 11:37:11.708 NotebookApp] 401 POST /login (127.0.0.1) 0.690000ms referer=None
[W 11:37:41.668 NotebookApp] Forbidden
[W 11:37:41.668 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.710000ms referer=None
[W 11:37:41.711 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:38:11.670 NotebookApp] Forbidden
[W 11:38:11.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.720000ms referer=None
[W 11:38:11.709 NotebookApp] 401 POST /login (127.0.0.1) 0.690000ms referer=None
[W 11:38:41.670 NotebookApp] Forbidden
[W 11:38:41.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.720000ms referer=None
[W 11:38:41.712 NotebookApp] 401 POST /login (127.0.0.1) 0.680000ms referer=None
[W 11:39:11.670 NotebookApp] Forbidden
[W 11:39:11.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.660000ms referer=None
[W 11:39:11.709 NotebookApp] 401 POST /login (127.0.0.1) 0.700000ms referer=None
[W 11:39:41.670 NotebookApp] Forbidden
[W 11:39:41.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.630000ms referer=None
[W 11:39:41.712 NotebookApp] 401 POST /login (127.0.0.1) 0.660000ms referer=None
[W 11:40:11.669 NotebookApp] Forbidden
[W 11:40:11.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.670000ms referer=None
[W 11:40:11.711 NotebookApp] 401 POST /login (127.0.0.1) 0.680000ms referer=None
[W 11:40:41.673 NotebookApp] Forbidden
[W 11:40:41.673 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.680000ms referer=None
[W 11:40:41.715 NotebookApp] 401 POST /login (127.0.0.1) 0.660000ms referer=None
[W 11:41:11.670 NotebookApp] Forbidden
[W 11:41:11.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.670000ms referer=None
[W 11:41:11.708 NotebookApp] 401 POST /login (127.0.0.1) 0.660000ms referer=None
[W 11:41:41.670 NotebookApp] Forbidden
[W 11:41:41.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.660000ms referer=None
[W 11:41:41.711 NotebookApp] 401 POST /login (127.0.0.1) 0.670000ms referer=None
[W 11:42:11.670 NotebookApp] Forbidden
[W 11:42:11.670 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.710000ms referer=None
[W 11:42:11.712 NotebookApp] 401 POST /login (127.0.0.1) 0.670000ms referer=None
[W 11:42:41.673 NotebookApp] Forbidden
[W 11:42:41.674 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.680000ms referer=None
[W 11:42:41.714 NotebookApp] 401 POST /login (127.0.0.1) 0.650000ms referer=None
[W 11:43:11.673 NotebookApp] Forbidden
[W 11:43:11.673 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 11:43:11.714 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:43:41.673 NotebookApp] Forbidden
[W 11:43:41.673 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:43:41.717 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 11:44:11.673 NotebookApp] Forbidden
[W 11:44:11.674 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:44:11.715 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:44:41.672 NotebookApp] Forbidden
[W 11:44:41.673 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.040000ms referer=None
[W 11:44:41.710 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:45:11.675 NotebookApp] Forbidden
[W 11:45:11.675 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:45:11.715 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:45:41.675 NotebookApp] Forbidden
[W 11:45:41.676 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:45:41.716 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:46:11.675 NotebookApp] Forbidden
[W 11:46:11.676 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.110000ms referer=None
[W 11:46:11.721 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:46:41.676 NotebookApp] Forbidden
[W 11:46:41.677 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.080000ms referer=None
[W 11:46:41.716 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:47:11.676 NotebookApp] Forbidden
[W 11:47:11.676 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.100000ms referer=None
[W 11:47:11.717 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:47:41.676 NotebookApp] Forbidden
[W 11:47:41.676 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.090000ms referer=None
[W 11:47:41.717 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:48:11.676 NotebookApp] Forbidden
[W 11:48:11.677 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 11:48:11.717 NotebookApp] 401 POST /login (127.0.0.1) 1.360000ms referer=None
[W 11:48:41.677 NotebookApp] Forbidden
[W 11:48:41.677 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 11:48:41.718 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:49:11.678 NotebookApp] Forbidden
[W 11:49:11.679 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 11:49:11.718 NotebookApp] 401 POST /login (127.0.0.1) 1.360000ms referer=None
[W 11:49:41.681 NotebookApp] Forbidden
[W 11:49:41.681 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 11:49:41.727 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:50:11.681 NotebookApp] Forbidden
[W 11:50:11.682 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.070000ms referer=None
[W 11:50:11.723 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:50:41.679 NotebookApp] Forbidden
[W 11:50:41.680 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.100000ms referer=None
[W 11:50:41.722 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:51:11.680 NotebookApp] Forbidden
[W 11:51:11.681 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.070000ms referer=None
[W 11:51:11.722 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:51:41.680 NotebookApp] Forbidden
[W 11:51:41.681 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 11:51:41.723 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:52:11.681 NotebookApp] Forbidden
[W 11:52:11.682 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:52:11.723 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 11:52:41.684 NotebookApp] Forbidden
[W 11:52:41.684 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 11:52:41.726 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:53:11.685 NotebookApp] Forbidden
[W 11:53:11.686 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:53:11.725 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:53:41.682 NotebookApp] Forbidden
[W 11:53:41.683 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 11:53:41.722 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:54:11.683 NotebookApp] Forbidden
[W 11:54:11.683 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:54:11.726 NotebookApp] 401 POST /login (127.0.0.1) 1.470000ms referer=None
[W 11:54:41.686 NotebookApp] Forbidden
[W 11:54:41.686 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:54:41.725 NotebookApp] 401 POST /login (127.0.0.1) 1.500000ms referer=None
[W 11:55:11.684 NotebookApp] Forbidden
[W 11:55:11.685 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:55:11.720 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:55:41.684 NotebookApp] Forbidden
[W 11:55:41.685 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:55:41.727 NotebookApp] 401 POST /login (127.0.0.1) 1.420000ms referer=None
[W 11:56:11.685 NotebookApp] Forbidden
[W 11:56:11.685 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 11:56:11.727 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 11:56:41.688 NotebookApp] Forbidden
[W 11:56:41.688 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 11:56:41.730 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:57:11.685 NotebookApp] Forbidden
[W 11:57:11.685 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:57:11.734 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:57:41.686 NotebookApp] Forbidden
[W 11:57:41.687 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:57:41.769 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 11:58:11.687 NotebookApp] Forbidden
[W 11:58:11.687 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 11:58:11.726 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:58:41.688 NotebookApp] Forbidden
[W 11:58:41.688 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 11:58:41.728 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 11:59:11.689 NotebookApp] Forbidden
[W 11:59:11.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 11:59:11.721 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 11:59:41.689 NotebookApp] Forbidden
[W 11:59:41.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 11:59:41.733 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:00:11.688 NotebookApp] Forbidden
[W 12:00:11.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 12:00:11.731 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:00:41.688 NotebookApp] Forbidden
[W 12:00:41.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.930000ms referer=None
[W 12:00:41.728 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 12:01:11.689 NotebookApp] Forbidden
[W 12:01:11.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:01:11.722 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:01:41.695 NotebookApp] Forbidden
[W 12:01:41.695 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 12:01:41.740 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 12:02:11.689 NotebookApp] Forbidden
[W 12:02:11.689 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:02:11.724 NotebookApp] 401 POST /login (127.0.0.1) 1.460000ms referer=None
[W 12:02:41.695 NotebookApp] Forbidden
[W 12:02:41.695 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 12:02:41.744 NotebookApp] 401 POST /login (127.0.0.1) 1.510000ms referer=None
[W 12:03:11.692 NotebookApp] Forbidden
[W 12:03:11.692 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 12:03:11.737 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:03:41.697 NotebookApp] Forbidden
[W 12:03:41.697 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.180000ms referer=None
[W 12:03:41.737 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 12:04:11.695 NotebookApp] Forbidden
[W 12:04:11.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 12:04:11.739 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:04:41.699 NotebookApp] Forbidden
[W 12:04:41.699 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.080000ms referer=None
[W 12:04:41.741 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 12:05:11.693 NotebookApp] Forbidden
[W 12:05:11.693 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.790000ms referer=None
[W 12:05:11.733 NotebookApp] 401 POST /login (127.0.0.1) 0.550000ms referer=None
[W 12:05:41.695 NotebookApp] Forbidden
[W 12:05:41.695 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 12:05:41.740 NotebookApp] 401 POST /login (127.0.0.1) 1.260000ms referer=None
[W 12:06:11.699 NotebookApp] Forbidden
[W 12:06:11.699 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.040000ms referer=None
[W 12:06:11.741 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 12:06:41.692 NotebookApp] Forbidden
[W 12:06:41.693 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 12:06:41.732 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:07:11.693 NotebookApp] Forbidden
[W 12:07:11.694 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:07:11.734 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 12:07:41.700 NotebookApp] Forbidden
[W 12:07:41.701 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 12:07:41.748 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:08:11.696 NotebookApp] Forbidden
[W 12:08:11.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 12:08:11.738 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 12:08:41.696 NotebookApp] Forbidden
[W 12:08:41.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.030000ms referer=None
[W 12:08:41.741 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:09:11.702 NotebookApp] Forbidden
[W 12:09:11.702 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:09:11.799 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:09:41.702 NotebookApp] Forbidden
[W 12:09:41.703 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 12:09:41.795 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:10:11.697 NotebookApp] Forbidden
[W 12:10:11.698 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.060000ms referer=None
[W 12:10:11.735 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:10:41.698 NotebookApp] Forbidden
[W 12:10:41.699 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.920000ms referer=None
[W 12:10:41.741 NotebookApp] 401 POST /login (127.0.0.1) 1.360000ms referer=None
[W 12:11:11.696 NotebookApp] Forbidden
[W 12:11:11.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.940000ms referer=None
[W 12:11:11.732 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:11:41.695 NotebookApp] Forbidden
[W 12:11:41.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:11:41.731 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:12:11.700 NotebookApp] Forbidden
[W 12:12:11.701 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.050000ms referer=None
[W 12:12:11.744 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:12:41.698 NotebookApp] Forbidden
[W 12:12:41.698 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.930000ms referer=None
[W 12:12:41.738 NotebookApp] 401 POST /login (127.0.0.1) 1.210000ms referer=None
[W 12:13:11.696 NotebookApp] Forbidden
[W 12:13:11.697 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.040000ms referer=None
[W 12:13:11.727 NotebookApp] 401 POST /login (127.0.0.1) 1.080000ms referer=None
[W 12:13:41.696 NotebookApp] Forbidden
[W 12:13:41.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.880000ms referer=None
[W 12:13:41.738 NotebookApp] 401 POST /login (127.0.0.1) 1.090000ms referer=None
[W 12:14:11.700 NotebookApp] Forbidden
[W 12:14:11.700 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.900000ms referer=None
[W 12:14:11.736 NotebookApp] 401 POST /login (127.0.0.1) 1.040000ms referer=None
[W 12:14:41.709 NotebookApp] Forbidden
[W 12:14:41.709 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 12:14:41.752 NotebookApp] 401 POST /login (127.0.0.1) 1.380000ms referer=None
[W 12:15:11.697 NotebookApp] Forbidden
[W 12:15:11.697 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.000000ms referer=None
[W 12:15:11.735 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:15:41.701 NotebookApp] Forbidden
[W 12:15:41.701 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.920000ms referer=None
[W 12:15:41.744 NotebookApp] 401 POST /login (127.0.0.1) 1.390000ms referer=None
[W 12:16:11.703 NotebookApp] Forbidden
[W 12:16:11.704 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.940000ms referer=None
[W 12:16:11.743 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:16:41.700 NotebookApp] Forbidden
[W 12:16:41.701 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.970000ms referer=None
[W 12:16:41.744 NotebookApp] 401 POST /login (127.0.0.1) 1.400000ms referer=None
[W 12:17:11.703 NotebookApp] Forbidden
[W 12:17:11.703 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.940000ms referer=None
[W 12:17:11.745 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:17:41.702 NotebookApp] Forbidden
[W 12:17:41.702 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.960000ms referer=None
[W 12:17:41.745 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:18:11.704 NotebookApp] Forbidden
[W 12:18:11.704 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 12:18:11.741 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:18:41.699 NotebookApp] Forbidden
[W 12:18:41.699 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 12:18:41.744 NotebookApp] 401 POST /login (127.0.0.1) 1.410000ms referer=None
[W 12:19:11.702 NotebookApp] Forbidden
[W 12:19:11.702 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.010000ms referer=None
[W 12:19:11.741 NotebookApp] 401 POST /login (127.0.0.1) 1.370000ms referer=None
[W 12:19:41.702 NotebookApp] Forbidden
[W 12:19:41.703 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.980000ms referer=None
[W 12:19:41.747 NotebookApp] 401 POST /login (127.0.0.1) 1.480000ms referer=None
[W 12:20:11.696 NotebookApp] Forbidden
[W 12:20:11.696 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.990000ms referer=None
[W 12:20:11.735 NotebookApp] 401 POST /login (127.0.0.1) 1.020000ms referer=None
[W 12:20:41.701 NotebookApp] Forbidden
[W 12:20:41.701 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.930000ms referer=None
[W 12:20:41.744 NotebookApp] 401 POST /login (127.0.0.1) 1.500000ms referer=None
[W 12:21:11.698 NotebookApp] Forbidden
[W 12:21:11.699 NotebookApp] 403 GET /api/sessions (127.0.0.1) 1.020000ms referer=None
[W 12:21:11.738 NotebookApp] 401 POST /login (127.0.0.1) 1.100000ms referer=None
[W 12:21:41.699 NotebookApp] Forbidden
[W 12:21:41.700 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.900000ms referer=None
[W 12:21:41.742 NotebookApp] 401 POST /login (127.0.0.1) 1.130000ms referer=None
[I 12:22:11.564 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:b1b582091e2c47f69f14c8f8a7095444
[W 12:22:11.694 NotebookApp] Forbidden
[W 12:22:11.695 NotebookApp] 403 GET /api/sessions (127.0.0.1) 0.910000ms referer=None
[W 12:22:11.740 NotebookApp] 401 POST /login (127.0.0.1) 1.240000ms referer=None
[W 19:21:59.516 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.430000ms referer=None
[W 19:22:00.566 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.400000ms referer=None
[W 19:22:04.103 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.430000ms referer=None
[W 19:22:04.278 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 19:22:05.137 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.490000ms referer=None
[W 19:22:06.201 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.380000ms referer=None
[W 20:19:35.250 NotebookApp] WebSocket ping timeout after 119975 ms.
[I 20:19:40.251 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:c0de59fe808940daa335a7b4dceebcc3
[W 21:06:11.550 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 21:06:12.055 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.500000ms referer=None
[W 21:06:13.633 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.340000ms referer=None
[W 21:06:34.821 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.020000ms referer=None
[W 21:06:49.123 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[W 21:06:58.847 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.530000ms referer=None
[W 21:07:07.923 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.410000ms referer=None
[I 21:08:13.361 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 21:08:13.362 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 21:08:13.675 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[I 21:10:13.299 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 21:10:13.300 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 21:10:13.662 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.200000ms referer=None
[W 21:12:13.154 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.470000ms referer=None
[I 21:12:13.998 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 21:12:13.999 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 21:12:14.405 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.330000ms referer=None
[W 21:50:42.688 NotebookApp] WebSocket ping timeout after 119983 ms.
[I 21:50:47.691 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:82e18012a9dc4a1983762b6a9ef16f66
[I 07:12:58.594 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:12:58.595 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:12:58.935 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.360000ms referer=None
[W 07:13:04.827 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:13:05.289 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.280000ms referer=None
[W 07:13:06.652 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.360000ms referer=None
[W 07:13:12.547 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.310000ms referer=None
[W 07:13:28.463 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.350000ms referer=None
[W 07:13:29.947 NotebookApp] Notebook attention.ipynb is not trusted
[I 07:13:30.275 NotebookApp] Kernel started: 550ba8ee-abe9-4a89-863d-f5143971dcc1, name: lena
[W 07:13:30.387 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.340000ms referer=None
[W 07:13:31.815 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.350000ms referer=None
[I 07:13:35.556 NotebookApp] Starting buffering for 550ba8ee-abe9-4a89-863d-f5143971dcc1:d9e20e1f273244d78d1fde7fda9d80f3
[I 07:15:06.319 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:15:06.321 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:15:06.685 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.400000ms referer=None
[I 07:25:06.329 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:25:06.331 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:25:06.693 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.280000ms referer=None
[I 07:27:06.569 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:27:06.570 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:27:06.914 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.360000ms referer=None
[W 07:28:27.748 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[I 07:31:06.567 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:31:06.569 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:31:06.927 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.530000ms referer=None
[I 07:33:06.579 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 07:33:06.581 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 07:33:07.032 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.360000ms referer=None
[W 07:41:35.709 NotebookApp] WebSocket ping timeout after 119981 ms.
[I 07:41:40.711 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:bdf3f9a5ffea4f8c83a14ee54dcdc149
[I 18:21:35.973 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:21:35.974 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:21:36.290 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.480000ms referer=None
[I 18:22:18.626 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:22:18.627 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:22:18.976 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.240000ms referer=None
[W 18:22:19.171 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:22:20.017 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.250000ms referer=None
[W 18:22:21.269 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.340000ms referer=None
[W 18:22:35.849 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.510000ms referer=None
[W 18:22:48.404 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[W 18:24:14.412 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.700000ms referer=None
[I 18:24:21.127 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:24:21.129 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:24:21.272 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.460000ms referer=None
[W 18:38:56.699 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.550000ms referer=None
[W 18:39:05.753 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.590000ms referer=None
[W 18:39:17.337 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.690000ms referer=None
[W 18:39:35.168 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.640000ms referer=None
[W 18:40:05.128 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.630000ms referer=None
[I 18:40:21.296 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:40:21.297 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:40:21.636 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[W 18:40:42.537 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.560000ms referer=None
[W 18:41:08.618 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[W 18:41:33.314 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.620000ms referer=None
[I 18:42:21.346 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:42:21.348 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:42:21.665 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.240000ms referer=None
[W 18:45:08.832 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.580000ms referer=None
[W 18:45:58.285 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.570000ms referer=None
[I 18:46:21.259 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:46:21.261 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:46:21.640 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.300000ms referer=None
[W 18:46:30.972 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 0.870000ms referer=None
[W 18:46:43.243 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.540000ms referer=None
[W 18:46:44.243 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.370000ms referer=None
[W 18:47:51.556 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.590000ms referer=None
[I 18:48:21.255 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 18:48:21.257 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 18:48:21.637 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.200000ms referer=None
[W 19:02:39.445 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.600000ms referer=None
[I 19:04:21.778 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 19:04:21.779 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 19:04:22.209 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.420000ms referer=None
[I 19:06:21.865 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 19:06:21.866 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 19:06:22.255 NotebookApp] 404 GET /js/app/service-worker.js (127.0.0.1) 1.520000ms referer=None
[W 19:44:50.310 NotebookApp] WebSocket ping timeout after 119985 ms.
[I 19:44:55.312 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:684c8b39ba3b463eacc07b3067a0a828
[I 10:13:15.906 NotebookApp] 302 GET /?token=20a2040e67f3d4d2e5e24307baec456ab126e0814069cc8a (127.0.0.1) 0.590000ms
[W 10:13:23.165 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:35:25.650 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:35:25.652 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:37:25.630 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:37:25.631 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:39:25.627 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:39:25.628 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:41:25.632 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:41:25.633 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:43:25.637 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:43:25.638 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:47:25.640 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:47:25.642 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:51:26.493 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:51:26.494 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 10:53:26.540 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 10:53:26.541 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 11:19:27.215 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 11:19:27.216 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 11:21:27.273 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 11:21:27.275 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:05:27.224 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:05:27.225 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:07:27.251 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:07:27.252 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:19:27.246 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:19:27.248 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:25:27.424 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:25:27.425 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:27:27.221 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:27:27.223 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:29:27.394 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:29:27.395 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:31:27.238 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:31:27.240 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:33:27.228 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:33:27.230 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[I 12:43:27.264 NotebookApp] Saving file at /Attention vs. no attention.ipynb
[W 12:43:27.265 NotebookApp] Notebook Attention vs. no attention.ipynb is not trusted
[W 13:28:54.899 NotebookApp] WebSocket ping timeout after 118463 ms.
[I 13:28:59.900 NotebookApp] Starting buffering for 3010a91d-2db2-4408-83b8-66780ca0384f:2fac3c4a25184600a08fa131b6fa1671
[W 09:36:38.467 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[W 09:36:38.481 NotebookApp] Clearing invalid/expired login cookie username-localhost-8888
[W 09:36:38.488 NotebookApp] Forbidden
[W 09:36:38.496 NotebookApp] 403 GET /api/sessions?_=1690212374592 (127.0.0.1) 89.690000ms referer=http://localhost:8888/tree
[W 09:36:38.504 NotebookApp] Forbidden
[W 09:36:38.504 NotebookApp] 403 GET /api/terminals?_=1690212374593 (127.0.0.1) 23.150000ms referer=http://localhost:8888/tree
[W 11:44:27.157 NotebookApp] Forbidden
[W 11:44:27.158 NotebookApp] 403 POST /api/kernels/3f2a67db-184d-4d6f-9f27-324889914266/restart (127.0.0.1) 7.940000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:27.168 NotebookApp] Forbidden
[W 11:44:27.168 NotebookApp] 403 DELETE /api/sessions/c309a599-da96-4c1c-a78a-898fb5a69eda (127.0.0.1) 1.820000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:27.176 NotebookApp] Forbidden
[W 11:44:27.177 NotebookApp] 403 POST /api/sessions (127.0.0.1) 1.150000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:38.876 NotebookApp] Forbidden
[W 11:44:38.877 NotebookApp] 403 POST /api/kernels/3f2a67db-184d-4d6f-9f27-324889914266/restart (127.0.0.1) 1.760000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:38.886 NotebookApp] Forbidden
[W 11:44:38.887 NotebookApp] 403 DELETE /api/sessions/c309a599-da96-4c1c-a78a-898fb5a69eda (127.0.0.1) 0.850000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:38.892 NotebookApp] Forbidden
[W 11:44:38.892 NotebookApp] 403 POST /api/sessions (127.0.0.1) 0.910000ms referer=http://localhost:8888/notebooks/Example.ipynb
[W 11:44:44.079 NotebookApp] Forbidden
[W 11:44:44.080 NotebookApp] 403 GET /api/sessions?_=1690212374594 (127.0.0.1) 1.530000ms referer=http://localhost:8888/tree
[W 11:44:44.089 NotebookApp] Forbidden
[W 11:44:44.089 NotebookApp] 403 GET /api/terminals?_=1690212374595 (127.0.0.1) 0.770000ms referer=http://localhost:8888/tree
[W 11:44:46.260 NotebookApp] Forbidden
[W 11:44:46.260 NotebookApp] 403 GET /api/contents/Example.ipynb?content=0&_=1690212388785 (127.0.0.1) 1.750000ms referer=http://localhost:8888/notebooks/Example.ipynb
[I 11:44:48.088 NotebookApp] 302 GET /notebooks/Example.ipynb (127.0.0.1) 3.010000ms
[I 11:45:16.260 NotebookApp] 302 GET /tree?token=4ade503cb3a7bed9ee27b4732321be0372cfe1233e04ea33 (127.0.0.1) 2.640000ms
[I 11:45:29.540 NotebookApp] 302 GET /?token=4ade503cb3a7bed9ee27b4732321be0372cfe1233e04ea33 (127.0.0.1) 1.810000ms
[I 11:45:29.545 NotebookApp] 302 GET /tree?token=4ade503cb3a7bed9ee27b4732321be0372cfe1233e04ea33 (127.0.0.1) 0.600000ms
[W 11:45:56.812 NotebookApp] 401 POST /login?next=%2Ftree%3Ftoken%3D4ade503cb3a7bed9ee27b4732321be0372cfe1233e04ea33 (127.0.0.1) 3.970000ms referer=http://localhost:8888/login?next=%2Ftree%3Ftoken%3D4ade503cb3a7bed9ee27b4732321be0372cfe1233e04ea33
[I 11:46:13.549 NotebookApp] 302 GET /tree?token=005c043d17e66b9ac86364a7649f9c3ff8d451193fd14247 (127.0.0.1) 0.880000ms
[I 11:46:37.242 NotebookApp] 302 GET /?token=005c043d17e66b9ac86364a7649f9c3ff8d451193fd14247 (127.0.0.1) 0.630000ms
[I 11:46:37.248 NotebookApp] 302 GET /tree?token=005c043d17e66b9ac86364a7649f9c3ff8d451193fd14247 (127.0.0.1) 0.710000ms
[I 11:47:11.598 NotebookApp] 302 GET /tree?token=bedd91e979ed205841aaacc876cdeedaa8ef822e422ec287 (127.0.0.1) 0.890000ms
[I 11:47:31.275 NotebookApp] 302 GET /?token=bedd91e979ed205841aaacc876cdeedaa8ef822e422ec287 (127.0.0.1) 0.610000ms
[I 11:47:31.281 NotebookApp] 302 GET /tree?token=bedd91e979ed205841aaacc876cdeedaa8ef822e422ec287 (127.0.0.1) 0.730000ms
[I 11:48:22.287 NotebookApp] 302 GET /tree?token=150dcde8309070b5a6589424c6a103f71297463e8271c41e (127.0.0.1) 0.910000ms
[W 11:48:37.237 NotebookApp] 401 POST /login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e (127.0.0.1) 2.520000ms referer=http://localhost:8888/login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e
[W 11:48:37.907 NotebookApp] 401 POST /login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e (127.0.0.1) 1.600000ms referer=http://localhost:8888/login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e
[W 11:48:38.433 NotebookApp] 401 POST /login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e (127.0.0.1) 1.590000ms referer=http://localhost:8888/login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e
[W 11:48:38.768 NotebookApp] 401 POST /login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e (127.0.0.1) 1.510000ms referer=http://localhost:8888/login?next=%2Ftree%3Ftoken%3D150dcde8309070b5a6589424c6a103f71297463e8271c41e
[I 11:54:08.537 NotebookApp] 302 GET /tree?token=05620ee0d6e29caf0f359c352beb8161b5d732c22599da86 (127.0.0.1) 0.840000ms
[I 11:56:57.013 NotebookApp] 302 GET /tree (127.0.0.1) 0.840000ms
[W 11:56:59.230 NotebookApp] 401 POST /login?next=%2Ftree (127.0.0.1) 1.660000ms referer=http://localhost:8888/login?next=%2Ftree
[W 11:57:00.843 NotebookApp] 401 POST /login?next=%2Ftree (127.0.0.1) 1.630000ms referer=http://localhost:8888/login?next=%2Ftree
[I 11:57:17.190 NotebookApp] 302 GET / (127.0.0.1) 1.190000ms
[I 11:57:17.196 NotebookApp] 302 GET /tree? (127.0.0.1) 0.700000ms
[W 11:57:20.391 NotebookApp] 401 POST /login?next=%2Ftree%3F (127.0.0.1) 1.690000ms referer=http://localhost:8888/login?next=%2Ftree%3F
[I 11:57:35.445 NotebookApp] 302 GET /tree (127.0.0.1) 0.830000ms
[W 11:57:36.917 NotebookApp] 401 POST /login?next=%2Ftree (127.0.0.1) 1.620000ms referer=http://localhost:8888/login?next=%2Ftree
[W 11:57:37.958 NotebookApp] 401 POST /login?next=%2Ftree (127.0.0.1) 1.600000ms referer=http://localhost:8888/login?next=%2Ftree
[I 13:10:11.368 NotebookApp] 302 GET /?token=1350ebdf10a08f148d5e46c1d30abf6cb63b8490576e51ba (127.0.0.1) 0.580000ms
[I 13:10:11.377 NotebookApp] 302 GET /tree?token=1350ebdf10a08f148d5e46c1d30abf6cb63b8490576e51ba (127.0.0.1) 2.490000ms
