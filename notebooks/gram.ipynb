{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09d90ef2e2544a65949a5382aa665e8a895142ccb15d506742792c571feba52d3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "from src.features.sequences import SequenceHandler\n",
    "from src.features.knowledge import HierarchyKnowledge\n",
    "from src.models import GramEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Transforming splitted sequences to tensors: 100%|██████████| 3/3 [00:00<00:00, 15.51it/s]\n",
      "Transforming splitted sequences to tensors: 100%|██████████| 1/1 [00:00<?, ?it/s](4, 2, 4)\n",
      "(4, 1, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_df = pd.DataFrame(data={\n",
    "    'sequence': [\n",
    "        [ # sequence1\n",
    "            ['a', 'b'], # visit1\n",
    "            ['a', 'c'], # visit2\n",
    "        ], \n",
    "        [ # sequence2\n",
    "            ['a', 'b', 'c'],\n",
    "            ['a'],\n",
    "            ['d'],\n",
    "        ],\n",
    "        [ # sequence3\n",
    "            ['a', 'b'], \n",
    "            ['a', 'd'], \n",
    "        ], \n",
    "    ]\n",
    "})\n",
    "handler = SequenceHandler(flatten=True)\n",
    "split = handler.transform_train_test_split(sequence_df, 'sequence')\n",
    "combined_x = tf.concat([split.train_x, split.test_x], axis=0)\n",
    "combined_y = tf.concat([split.train_y, split.test_y], axis=0)\n",
    "\n",
    "print(combined_x.shape) # (dataset_size, max_length, feature_size)\n",
    "print(combined_y.shape) # (dataset_size, 1, feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building Hierarchy from df: 8it [00:00, 8013.96it/s]{'a': 0, 'd': 1, 'b': 2, 'c': 3, 'ab2': 4, 'b1': 5, 'a1': 6, 'cd1': 7, 'abcd3': 8}\n",
      "Node for idx 0 (label: a)\n",
      "<-Parent nodes: 6(a1)\n",
      "->Child nodes: \n",
      "Node for idx 1 (label: d)\n",
      "<-Parent nodes: 7(cd1)\n",
      "->Child nodes: \n",
      "Node for idx 2 (label: b)\n",
      "<-Parent nodes: 5(b1)\n",
      "->Child nodes: \n",
      "Node for idx 3 (label: c)\n",
      "<-Parent nodes: 7(cd1)\n",
      "->Child nodes: \n",
      "Node for idx 4 (label: ab2)\n",
      "<-Parent nodes: 8(abcd3)\n",
      "->Child nodes: 6(a1),5(b1)\n",
      "Node for idx 5 (label: b1)\n",
      "<-Parent nodes: 4(ab2)\n",
      "->Child nodes: 2(b)\n",
      "Node for idx 6 (label: a1)\n",
      "<-Parent nodes: 4(ab2)\n",
      "->Child nodes: 0(a)\n",
      "Node for idx 7 (label: cd1)\n",
      "<-Parent nodes: 8(abcd3)\n",
      "->Child nodes: 3(c),1(d)\n",
      "Node for idx 8 (label: abcd3)\n",
      "<-Parent nodes: \n",
      "->Child nodes: 7(cd1),4(ab2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hierarchy_df = pd.DataFrame(\n",
    "    data={\n",
    "        'parent': ['a1', 'b1', 'cd1', 'cd1', 'ab2', 'ab2', 'abcd3', 'abcd3'],\n",
    "        'child': ['a', 'b', 'c', 'd', 'a1', 'b1', 'cd1', 'ab2']\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge = HierarchyKnowledge()\n",
    "knowledge.build_hierarchy_from_df(hierarchy_df, split.vocab)\n",
    "\n",
    "print(knowledge.extended_vocab)\n",
    "print('\\n'.join([str(node) for node in knowledge.nodes.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([4, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "embeddings = {}\n",
    "embedding_size = 8\n",
    "for name, idx in knowledge.extended_vocab.items():\n",
    "    embeddings[idx] = tf.Variable(\n",
    "        initial_value=tf.random.normal(shape=(1,embedding_size)),\n",
    "        trainable=True,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "all_embeddings = [embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()]\n",
    "concatenated_embeddings = tf.concat(all_embeddings, axis=0)\n",
    "concatenated_embeddings.shape # (num_leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([4, 9, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "ancestor_embeddings = {}\n",
    "for idx, node in knowledge.nodes.items():\n",
    "    if not node.is_leaf(): continue\n",
    "    ancestor_idxs = set(node.get_ancestor_label_idxs() + [idx])\n",
    "    id_ancestor_embeddings = [\n",
    "        embeddings[x]  if (x in ancestor_idxs) \n",
    "        else tf.constant(0, shape=(embeddings[0].shape), dtype='float32')\n",
    "        for x in range(len(knowledge.extended_vocab))\n",
    "    ]\n",
    "    ancestor_embeddings[idx] = tf.concat(id_ancestor_embeddings, axis=0)\n",
    "\n",
    "print(ancestor_embeddings[0].shape) # shape: (num_nodes, embedding_size)\n",
    "all_ancestor_embeddings = [\n",
    "    ancestor_embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()\n",
    "]\n",
    "concatenated_ancestor_embeddings = tf.concat([all_ancestor_embeddings], axis=1)\n",
    "concatenated_ancestor_embeddings.shape # (num_leaf_nodes, num_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.keras.layers.Dense(units=16)\n",
    "w2 = tf.keras.layers.Dense(units=16)\n",
    "u = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 9, 1)\n",
      "(4, 9, 1)\n",
      "(4, 9, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[ 0.4391212 , -0.69954044, -0.69012654,  0.166058  ,  0.5658248 ,\n",
       "         0.1925041 ,  0.28310868,  0.47520086],\n",
       "       [ 0.15381241, -0.22646004,  0.2454637 ,  0.12253262, -0.3956595 ,\n",
       "         0.08820544, -0.09927468,  0.55573636],\n",
       "       [ 0.3088606 , -0.7868706 , -0.0760816 ,  0.47396648,  0.77842563,\n",
       "         0.29273698,  0.7843944 ,  0.32635233],\n",
       "       [-0.30848473, -0.15757278,  0.33354178, -0.14685214, -0.33262885,\n",
       "         0.20864192, -0.01028858,  0.7099187 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "con2 = tf.expand_dims(concatenated_embeddings, 1)\n",
    "score = u(tf.nn.tanh(\n",
    "    w1(con2) + w2(concatenated_ancestor_embeddings)\n",
    "))\n",
    "print(score.shape)\n",
    "attention_weights = tf.nn.softmax(score, axis=0)\n",
    "print(attention_weights.shape) # (leaf_nodes, all_nodes, 1)\n",
    "context_vector = attention_weights * concatenated_ancestor_embeddings\n",
    "print(context_vector.shape) # (leaf_nodes, all_nodes, embedding_size)\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1) \n",
    "context_vector # shape: (leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.7479818 , -1.4864111 , -0.7662082 ,  0.6400245 ,  1.3442504 ,\n",
       "        0.48524106,  1.0675031 ,  0.8015532 ], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "combined_x[0]\n",
    "context_vector[0] + context_vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 2, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2, 8), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.43949705, -1.6439838 , -0.4326664 ,  0.49317235,\n",
       "          1.0116216 ,  0.69388294,  1.0572145 ,  1.5114719 ]],\n",
       "\n",
       "       [[ 0.43949705, -1.6439838 , -0.4326664 ,  0.49317235,\n",
       "          1.0116216 ,  0.69388294,  1.0572145 ,  1.5114719 ],\n",
       "        [ 0.4391212 , -0.69954044, -0.69012654,  0.166058  ,\n",
       "          0.5658248 ,  0.1925041 ,  0.28310868,  0.47520086]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.7479818 , -1.4864111 , -0.7662082 ,  0.6400245 ,\n",
       "          1.3442504 ,  0.48524106,  1.0675031 ,  0.8015532 ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.7479818 , -1.4864111 , -0.7662082 ,  0.6400245 ,\n",
       "          1.3442504 ,  0.48524106,  1.0675031 ,  0.8015532 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\n",
    "print(combined_x.shape)\n",
    "tf.linalg.matmul(combined_x, context_vector) # shape: (dataset_size, max_length, embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2\n",
    "vocab_size = len(split.vocab)\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(max_length, vocab_size))\n",
    "embedding_layer = GramEmbedding(knowledge)\n",
    "prediction_model = tf.keras.models.Sequential([\n",
    "    input_layer,\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='relu'),\n",
    "])\n",
    "prediction_model.compile(\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=tf.optimizers.Adam(), \n",
    "            metrics=['CategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(embedding_layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 16), dtype=float32, numpy=\n",
       "array([[[ 0.45860285, -0.8094061 , -0.8881423 ,  0.6915797 ,\n",
       "          0.7778867 , -0.16019487, -0.42384362,  0.9732113 ,\n",
       "         -1.0849925 ,  0.12832978, -0.16205223, -0.05826806,\n",
       "         -0.6269017 ,  0.6797151 ,  0.4429526 ,  0.88718   ]],\n",
       "\n",
       "       [[ 1.742705  , -0.33816293, -0.32940295, -0.20686728,\n",
       "         -0.33488658,  1.2455566 ,  0.3894918 , -0.06009046,\n",
       "         -0.5491302 , -0.2999603 ,  1.2351984 , -0.0372693 ,\n",
       "         -0.26207778, -0.768544  ,  0.18959118, -0.55703205]],\n",
       "\n",
       "       [[ 0.23887655, -1.1413323 ,  0.34748358,  0.83838624,\n",
       "          0.93078667, -0.51384854, -1.3149151 ,  0.7438372 ,\n",
       "         -0.73259443,  0.32347718, -0.5855996 ,  0.34120414,\n",
       "          1.5915494 , -0.46074736, -2.0714567 , -0.37715694]],\n",
       "\n",
       "       [[ 0.38439468, -0.12188402,  0.43615142, -2.144266  ,\n",
       "         -0.26360708, -0.0507897 , -1.078655  , -0.08635159,\n",
       "         -1.0205619 , -0.20950972, -1.3936907 ,  0.69263345,\n",
       "         -1.3156145 ,  0.85807097, -1.1938369 ,  0.52976817]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "(old_ctx, old_weights) = embedding_layer._calculate_attention_embeddings()\n",
    "old_embs = tf.constant(embedding_layer.concatenated_embeddings.value())\n",
    "old_anc_embs = tf.constant(embedding_layer.concatenated_ancestor_embeddings.value())\n",
    "old_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1566 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 5.1476 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1428 - categorical_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1416 - categorical_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1416 - categorical_accuracy: 0.6667\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d509057c10>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "prediction_model.fit(x=split.train_x, y=split.train_y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 16), dtype=float32, numpy=\n",
       "array([[[ 0.467861  , -0.81769806, -0.87941426,  0.6844128 ,\n",
       "          0.77731776, -0.15368856, -0.43322623,  0.96499074,\n",
       "         -1.0764097 ,  0.1366386 , -0.152081  , -0.05109737,\n",
       "         -0.6203225 ,  0.6825094 ,  0.4504309 ,  0.8964409 ]],\n",
       "\n",
       "       [[ 1.73377   , -0.32968634, -0.3297837 , -0.19798316,\n",
       "         -0.3440358 ,  1.2542542 ,  0.3801561 , -0.06910255,\n",
       "         -0.540053  , -0.30874735,  1.2443237 , -0.04612953,\n",
       "         -0.27087656, -0.77742785,  0.19920804, -0.5474403 ]],\n",
       "\n",
       "       [[ 0.23195578, -1.1435264 ,  0.33953387,  0.84111685,\n",
       "          0.93766993, -0.506261  , -1.3061062 ,  0.75275457,\n",
       "         -0.7328707 ,  0.3138227 , -0.5791674 ,  0.33276343,\n",
       "          1.5857468 , -0.46848828, -2.06588   , -0.38590994]],\n",
       "\n",
       "       [[ 0.39466083, -0.13193208,  0.42709947, -2.1541717 ,\n",
       "         -0.2734999 , -0.06069435, -1.0889127 , -0.07704251,\n",
       "         -1.0301846 , -0.19982052, -1.4033588 ,  0.7023139 ,\n",
       "         -1.305849  ,  0.867909  , -1.2040755 ,  0.53984773]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "(new_ctx, new_weights) = embedding_layer._calculate_attention_embeddings()\n",
    "new_embs = tf.constant(embedding_layer.concatenated_embeddings.value())\n",
    "new_anc_embs = tf.constant(embedding_layer.concatenated_ancestor_embeddings.value())\n",
    "new_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 16), dtype=float32, numpy=\n",
       "array([[[-0.00925815,  0.00829196, -0.00872803,  0.00716692,\n",
       "          0.00056893, -0.00650631,  0.00938261,  0.00822055,\n",
       "         -0.00858283, -0.00830881, -0.00997123, -0.00717069,\n",
       "         -0.00657916, -0.00279433, -0.0074783 , -0.00926095]],\n",
       "\n",
       "       [[ 0.00893497, -0.00847659,  0.00038075, -0.00888412,\n",
       "          0.00914922, -0.00869763,  0.0093357 ,  0.00901208,\n",
       "         -0.00907719,  0.00878707, -0.00912535,  0.00886023,\n",
       "          0.00879878,  0.00888383, -0.00961685, -0.00959176]],\n",
       "\n",
       "       [[ 0.00692077,  0.00219417,  0.00794971, -0.00273061,\n",
       "         -0.00688326, -0.00758755, -0.00880885, -0.00891739,\n",
       "          0.00027627,  0.00965449, -0.00643218,  0.0084407 ,\n",
       "          0.00580263,  0.00774091, -0.00557661,  0.008753  ]],\n",
       "\n",
       "       [[-0.01026616,  0.01004806,  0.00905195,  0.00990582,\n",
       "          0.00989282,  0.00990465,  0.01025772, -0.00930908,\n",
       "          0.00962269, -0.0096892 ,  0.00966811, -0.00968045,\n",
       "         -0.00976551, -0.00983804,  0.01023853, -0.01007956]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "old_embs - new_embs"
   ]
  }
 ]
}