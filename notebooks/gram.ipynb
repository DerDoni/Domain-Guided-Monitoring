{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09d90ef2e2544a65949a5382aa665e8a895142ccb15d506742792c571feba52d3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "from src.features.sequences import SequenceHandler\n",
    "from src.features.knowledge import HierarchyKnowledge\n",
    "from src.models import GramEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Transforming splitted sequences to tensors: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "Transforming splitted sequences to tensors: 100%|██████████| 2/2 [00:00<00:00, 1000.43it/s](3, 2, 4)\n",
      "(3, 1, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_df = pd.DataFrame(data={\n",
    "    'sequence': [\n",
    "        [ # sequence1\n",
    "            ['a', 'b'], # visit1\n",
    "            ['a', 'c'], # visit2\n",
    "        ], \n",
    "        [ # sequence2\n",
    "            ['a', 'b', 'c'],\n",
    "            ['a'],\n",
    "            ['d'],\n",
    "        ],\n",
    "        [ # sequence3\n",
    "            ['a', 'b'], \n",
    "            ['a', 'd'], \n",
    "        ], \n",
    "    ]\n",
    "})\n",
    "handler = SequenceHandler(flatten=True)\n",
    "split = handler.transform_train_test_split(sequence_df, 'sequence')\n",
    "combined_x = tf.concat([split.train_x, split.test_x], axis=0)\n",
    "combined_y = tf.concat([split.train_y, split.test_y], axis=0)\n",
    "\n",
    "print(combined_x.shape) # (dataset_size, max_length, feature_size)\n",
    "print(combined_y.shape) # (dataset_size, 1, feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building Hierarchy from df: 8it [00:00, 2673.66it/s]{'a': 0, 'd': 1, 'b': 2, 'c': 3, 'a1': 4, 'cd1': 5, 'ab2': 6, 'b1': 7, 'abcd3': 8}\n",
      "Node for idx 0 (label: a)\n",
      "<-Parent nodes: 4(a1)\n",
      "->Child nodes: \n",
      "Node for idx 1 (label: d)\n",
      "<-Parent nodes: 5(cd1)\n",
      "->Child nodes: \n",
      "Node for idx 2 (label: b)\n",
      "<-Parent nodes: 7(b1)\n",
      "->Child nodes: \n",
      "Node for idx 3 (label: c)\n",
      "<-Parent nodes: 5(cd1)\n",
      "->Child nodes: \n",
      "Node for idx 4 (label: a1)\n",
      "<-Parent nodes: 6(ab2)\n",
      "->Child nodes: 0(a)\n",
      "Node for idx 5 (label: cd1)\n",
      "<-Parent nodes: 8(abcd3)\n",
      "->Child nodes: 3(c),1(d)\n",
      "Node for idx 6 (label: ab2)\n",
      "<-Parent nodes: 8(abcd3)\n",
      "->Child nodes: 4(a1),7(b1)\n",
      "Node for idx 7 (label: b1)\n",
      "<-Parent nodes: 6(ab2)\n",
      "->Child nodes: 2(b)\n",
      "Node for idx 8 (label: abcd3)\n",
      "<-Parent nodes: \n",
      "->Child nodes: 5(cd1),6(ab2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hierarchy_df = pd.DataFrame(\n",
    "    data={\n",
    "        'parent': ['a1', 'b1', 'cd1', 'cd1', 'ab2', 'ab2', 'abcd3', 'abcd3'],\n",
    "        'child': ['a', 'b', 'c', 'd', 'a1', 'b1', 'cd1', 'ab2']\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge = HierarchyKnowledge()\n",
    "knowledge.build_hierarchy_from_df(hierarchy_df, split.vocab)\n",
    "\n",
    "print(knowledge.extended_vocab)\n",
    "print('\\n'.join([str(node) for node in knowledge.nodes.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([4, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "embeddings = {}\n",
    "embedding_size = 8\n",
    "for name, idx in knowledge.extended_vocab.items():\n",
    "    embeddings[idx] = tf.Variable(\n",
    "        initial_value=tf.random.normal(shape=(1,embedding_size)),\n",
    "        trainable=True,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "all_embeddings = [embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()]\n",
    "concatenated_embeddings = tf.concat(all_embeddings, axis=0)\n",
    "concatenated_embeddings.shape # (num_leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([4, 9, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "ancestor_embeddings = {}\n",
    "for idx, node in knowledge.nodes.items():\n",
    "    if not node.is_leaf(): continue\n",
    "    ancestor_idxs = set(node.get_ancestor_label_idxs() + [idx])\n",
    "    id_ancestor_embeddings = [\n",
    "        embeddings[x]  if (x in ancestor_idxs) \n",
    "        else tf.constant(0, shape=(embeddings[0].shape), dtype='float32')\n",
    "        for x in range(len(knowledge.extended_vocab))\n",
    "    ]\n",
    "    ancestor_embeddings[idx] = tf.concat(id_ancestor_embeddings, axis=0)\n",
    "\n",
    "print(ancestor_embeddings[0].shape) # shape: (num_nodes, embedding_size)\n",
    "all_ancestor_embeddings = [\n",
    "    ancestor_embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()\n",
    "]\n",
    "concatenated_ancestor_embeddings = tf.concat([all_ancestor_embeddings], axis=1)\n",
    "concatenated_ancestor_embeddings.shape # (num_leaf_nodes, num_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.keras.layers.Dense(units=16)\n",
    "w2 = tf.keras.layers.Dense(units=16)\n",
    "u = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 9, 1)\n",
      "(4, 9, 1)\n",
      "(4, 9, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[ 0.13523413, -0.26464623, -0.68057   , -0.20489092, -0.13474315,\n",
       "         0.08108522, -0.2112375 ,  0.10981014],\n",
       "       [-0.04848791, -0.31979886,  0.27716798,  0.16883737,  0.3178332 ,\n",
       "        -0.49723762,  0.4665865 ,  0.8277112 ],\n",
       "       [-0.11086635, -0.27435493, -0.29858112,  1.2453539 ,  0.11035765,\n",
       "        -0.1973583 ,  0.25268143, -0.83086956],\n",
       "       [-0.4768219 , -0.7192046 ,  0.5580113 ,  0.27178335,  0.2834713 ,\n",
       "        -1.1895331 ,  0.38526332,  0.662086  ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "con2 = tf.expand_dims(concatenated_embeddings, 1)\n",
    "score = u(tf.nn.tanh(\n",
    "    w1(con2) + w2(concatenated_ancestor_embeddings)\n",
    "))\n",
    "print(score.shape)\n",
    "attention_weights = tf.nn.softmax(score, axis=0)\n",
    "print(attention_weights.shape) # (leaf_nodes, all_nodes, 1)\n",
    "context_vector = attention_weights * concatenated_ancestor_embeddings\n",
    "print(context_vector.shape) # (leaf_nodes, all_nodes, embedding_size)\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1) \n",
    "context_vector # shape: (leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.02436779, -0.53900117, -0.9791511 ,  1.040463  , -0.0243855 ,\n",
       "       -0.11627308,  0.04144393, -0.72105944], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "combined_x[0]\n",
    "context_vector[0] + context_vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 2, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 8), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.02436779, -0.53900117, -0.9791511 ,  1.040463  ,\n",
       "         -0.0243855 , -0.11627308,  0.04144393, -0.72105944]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.45245412, -1.2582058 , -0.42113984,  1.3122463 ,\n",
       "          0.25908577, -1.3058062 ,  0.42670727, -0.05897343]],\n",
       "\n",
       "       [[-0.45245412, -1.2582058 , -0.42113984,  1.3122463 ,\n",
       "          0.25908577, -1.3058062 ,  0.42670727, -0.05897343],\n",
       "        [ 0.13523413, -0.26464623, -0.68057   , -0.20489092,\n",
       "         -0.13474315,  0.08108522, -0.2112375 ,  0.10981014]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\n",
    "print(combined_x.shape)\n",
    "tf.linalg.matmul(combined_x, context_vector) # shape: (dataset_size, max_length, embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2\n",
    "vocab_size = len(split.vocab)\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(max_length, vocab_size))\n",
    "embedding_layer = GramEmbedding(knowledge)\n",
    "prediction_model = tf.keras.models.Sequential([\n",
    "    input_layer,\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='relu'),\n",
    "])\n",
    "prediction_model.compile(\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=tf.optimizers.Adam(), \n",
    "            metrics=['CategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4621 - categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.3675 - categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3003 - categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.2485 - categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.2065 - categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.1713 - categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.1409 - categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.1142 - categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0905 - categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0690 - categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0495 - categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0316 - categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.0150 - categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9996 - categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9852 - categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9716 - categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9588 - categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9467 - categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9353 - categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9243 - categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9139 - categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9039 - categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8943 - categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8851 - categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8762 - categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8677 - categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8594 - categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8562 - categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8562 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x221c25dd4c0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "prediction_model.fit(x=split.train_x, y=split.train_y, epochs=100)"
   ]
  }
 ]
}