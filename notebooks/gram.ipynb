{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09d90ef2e2544a65949a5382aa665e8a895142ccb15d506742792c571feba52d3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "from src.features.sequences import SequenceHandler\n",
    "from src.features.knowledge import HierarchyKnowledge\n",
    "from src.models import GramEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df = pd.DataFrame(data={\n",
    "    'sequence': [\n",
    "        [ # sequence1\n",
    "            ['a', 'b'], # visit1\n",
    "            ['a', 'c'], # visit2\n",
    "        ], \n",
    "        [ # sequence2\n",
    "            ['a', 'b', 'c'],\n",
    "            ['a'],\n",
    "            ['d'],\n",
    "        ],\n",
    "        [ # sequence3\n",
    "            ['a', 'b'], \n",
    "            ['a', 'd'], \n",
    "        ], \n",
    "    ]\n",
    "})\n",
    "handler = SequenceHandler(flatten=True)\n",
    "split = handler.transform_train_test_split(sequence_df, 'sequence')\n",
    "combined_x = tf.concat([split.train_x, split.test_x], axis=0)\n",
    "combined_y = tf.concat([split.train_y, split.test_y], axis=0)\n",
    "\n",
    "print(combined_x.shape) # (dataset_size, max_length, feature_size)\n",
    "print(combined_y.shape) # (dataset_size, 1, feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_df = pd.DataFrame(\n",
    "    data={\n",
    "        'parent': ['a1', 'b1', 'cd1', 'cd1', 'ab2', 'ab2', 'abcd3', 'abcd3'],\n",
    "        'child': ['a', 'b', 'c', 'd', 'a1', 'b1', 'cd1', 'ab2']\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge = HierarchyKnowledge()\n",
    "knowledge.build_hierarchy_from_df(hierarchy_df, split.vocab)\n",
    "\n",
    "print(knowledge.extended_vocab)\n",
    "print('\\n'.join([str(node) for node in knowledge.nodes.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "embedding_size = 8\n",
    "for name, idx in knowledge.extended_vocab.items():\n",
    "    embeddings[idx] = tf.Variable(\n",
    "        initial_value=tf.random.normal(shape=(1,embedding_size)),\n",
    "        trainable=True,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "all_embeddings = [embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()]\n",
    "concatenated_embeddings = tf.concat(all_embeddings, axis=0)\n",
    "concatenated_embeddings.shape # (num_leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestor_embeddings = {}\n",
    "for idx, node in knowledge.nodes.items():\n",
    "    if not node.is_leaf(): continue\n",
    "    ancestor_idxs = set(node.get_ancestor_label_idxs() + [idx])\n",
    "    id_ancestor_embeddings = [\n",
    "        embeddings[x]  if (x in ancestor_idxs) \n",
    "        else tf.constant(0, shape=(embeddings[0].shape), dtype='float32')\n",
    "        for x in range(len(knowledge.extended_vocab))\n",
    "    ]\n",
    "    ancestor_embeddings[idx] = tf.concat(id_ancestor_embeddings, axis=0)\n",
    "\n",
    "print(ancestor_embeddings[0].shape) # shape: (num_nodes, embedding_size)\n",
    "all_ancestor_embeddings = [\n",
    "    ancestor_embeddings[node.label_idx] for node in knowledge.nodes.values() if node.is_leaf()\n",
    "]\n",
    "concatenated_ancestor_embeddings = tf.concat([all_ancestor_embeddings], axis=1)\n",
    "concatenated_ancestor_embeddings.shape # (num_leaf_nodes, num_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.keras.layers.Dense(units=16)\n",
    "w2 = tf.keras.layers.Dense(units=16)\n",
    "u = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2 = tf.expand_dims(concatenated_embeddings, 1)\n",
    "score = u(tf.nn.tanh(\n",
    "    w1(con2) + w2(concatenated_ancestor_embeddings)\n",
    "))\n",
    "print(score.shape)\n",
    "attention_weights = tf.nn.softmax(score, axis=0)\n",
    "print(attention_weights.shape) # (leaf_nodes, all_nodes, 1)\n",
    "context_vector = attention_weights * concatenated_ancestor_embeddings\n",
    "print(context_vector.shape) # (leaf_nodes, all_nodes, embedding_size)\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1) \n",
    "context_vector # shape: (leaf_nodes, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_x[0]\n",
    "context_vector[0] + context_vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(combined_x.shape)\n",
    "tf.linalg.matmul(combined_x, context_vector) # shape: (dataset_size, max_length, embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2\n",
    "vocab_size = len(split.vocab)\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(max_length, vocab_size))\n",
    "embedding_layer = GramEmbedding(knowledge)\n",
    "prediction_model = tf.keras.models.Sequential([\n",
    "    input_layer,\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='relu'),\n",
    "])\n",
    "prediction_model.compile(\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=tf.optimizers.Adam(), \n",
    "            metrics=['CategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(old_ctx, old_weights) = embedding_layer._calculate_attention_embeddings()\n",
    "old_embs = tf.constant(embedding_layer.concatenated_embeddings.value())\n",
    "old_anc_embs = tf.constant(embedding_layer.concatenated_ancestor_embeddings.value())\n",
    "old_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model.fit(x=split.train_x, y=split.train_y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_ctx, new_weights) = embedding_layer._calculate_attention_embeddings()\n",
    "new_embs = tf.constant(embedding_layer.concatenated_embeddings.value())\n",
    "new_anc_embs = tf.constant(embedding_layer.concatenated_ancestor_embeddings.value())\n",
    "new_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_embs - new_embs"
   ]
  }
 ]
}