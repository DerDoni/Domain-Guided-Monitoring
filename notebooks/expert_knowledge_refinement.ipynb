{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 15:36:41.258623: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 15:36:41.749589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-07 15:36:41.749642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-07 15:36:41.749646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.refinement import knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/attention_graph.py\n",
    "%run utils/mlflow_query.py\n",
    "%run utils/percentiles.py\n",
    "%run utils/loading.py\n",
    "%run utils/comparison.py\n",
    "%run utils/refinement.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized with 86 MLFlow runs from pkl\n"
     ]
    }
   ],
   "source": [
    "mlflow_helper = MlflowHelper(pkl_file=Path(\"mlflow_run_df.pkl\"))\n",
    "#mlflow_helper.query_all_runs(query_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_mimic_ref_df = mlflow_helper.mimic_run_df(include_noise=False, include_refinements=True)\n",
    "relevant_mimic_ref_df = relevant_mimic_ref_df[\n",
    "        relevant_mimic_ref_df[\"data_tags_refinement_type\"].fillna(\"\").astype(str).apply(len) > 0\n",
    "].copy()\n",
    "relevant_mimic_ref_df['refinement_run'] = relevant_mimic_ref_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "relevant_mimic_ref_df['refinement_type'] = relevant_mimic_ref_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "relevant_mimic_ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_accuracy_df = mlflow_helper.load_best_metrics_for_ids(run_ids=set(relevant_mimic_ref_df['info_run_id']))\n",
    "mimic_accuracy_df['refinement_run'] = mimic_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "mimic_accuracy_df['refinement_type'] = mimic_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "mimic_accuracy_df['refinement_type_order'] = mimic_accuracy_df['refinement_type'].replace({\n",
    "    'reference':0, \n",
    "    'original':1, \n",
    "    'refinement_0':2,\n",
    "    'refinement_1':3,\n",
    "    'refinement_2':4,})\n",
    "\n",
    "mimic_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=mimic_accuracy_df[\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(0.0).astype(float) == 0.0) &\n",
    "        (mimic_accuracy_df['val_top_20_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_20_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=mimic_accuracy_df[\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) &\n",
    "        (mimic_accuracy_df['val_top_20_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_20_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_accuracy_df_p = calculate_accuracies_per_percentiles(\n",
    "    relevant_run_df=relevant_mimic_ref_df, \n",
    "    k=20, num_percentiles=10, num_input_percentiles=10,\n",
    "    percentile_names=[\n",
    "        'avg_input_frequencies_percentile', \n",
    "        'median_input_frequencies_percentile', \n",
    "        'min_input_frequencies_percentile', \n",
    "        'p10_input_frequencies_percentile', \n",
    "        'unknown_inputs_percentile', \n",
    "        'output_frequency_percentile',\n",
    "        'avg_input_frequencies_range', \n",
    "        'median_input_frequencies_range', \n",
    "        'min_input_frequencies_range', \n",
    "        'p10_input_frequencies_range', \n",
    "        'unknown_inputs_range', \n",
    "    ],\n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir)\n",
    "mimic_accuracy_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=mimic_accuracy_df_p,\n",
    "    refinement_df=relevant_mimic_ref_df[relevant_mimic_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.0\"],\n",
    "    reference_refinement_type=\"original\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=mimic_accuracy_df_p,\n",
    "    refinement_df=relevant_mimic_ref_df[relevant_mimic_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.1\"],\n",
    "    reference_refinement_type=\"reference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAM without unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icd9_text():\n",
    "    icd9_df = pd.read_csv(\"../data/icd9.csv\")\n",
    "    return (\n",
    "        icd9_df[[\"child_name\", \"child_code\"]]\n",
    "        .drop_duplicates()\n",
    "        .rename(columns={\"child_name\": \"description\", \"child_code\": \"code\",})\n",
    "        .set_index(\"code\")\n",
    "        .to_dict(\"index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_df = mlflow_helper.mimic_run_df(include_noise=False, include_refinements=False)\n",
    "\n",
    "mimic_gram_run_id = mimic_df[\n",
    "    (mimic_df['data_tags_noise_type'].fillna('').apply(len) == 0) &   \n",
    "    (mimic_df['data_params_ModelConfigbase_hidden_embeddings_trainable'] == 'False') &\n",
    "    (mimic_df['data_tags_model_type'] == 'gram')\n",
    "].iloc[0].get('info_run_id')\n",
    "\n",
    "texts = load_icd9_text()\n",
    "unknowns = set([x for x,y in texts.items() if \n",
    "    (y[\"description\"].lower().startswith(\"other\")\n",
    "    or y[\"description\"].lower().startswith(\"unspecified\")\n",
    "    or y[\"description\"].lower().endswith(\"unspecified\")\n",
    "    or y[\"description\"].lower().endswith(\"unspecified type\")\n",
    "    or y[\"description\"].lower().endswith(\"not elsewhere classified\"))])\n",
    "\n",
    "attentions = load_attention_weights(\n",
    "    mimic_gram_run_id, \n",
    "    mlflow_helper.local_mlflow_dir\n",
    ")\n",
    "print(sum([len(x) for x in attentions.values()]))\n",
    "attentions_without_unknowns = {\n",
    "    x:[y for y in ys if y not in unknowns or x == y] for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns.values()]))\n",
    "with open('gram_without_unknowns.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns, f)\n",
    "\n",
    "unknowns2 = set([\n",
    "    x for x,y in texts.items() \n",
    "    if any(z in y[\"description\"].lower() for z in [\"other\", \"unspecified\", \"elsewhere\"])\n",
    "])\n",
    "\n",
    "attentions_without_unknowns2 = {\n",
    "    x:[y for y in ys if y not in unknowns2 or x == y] for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns2.values()]))\n",
    "with open('gram_without_unknowns2.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns2, f)\n",
    "\n",
    "attentions_without_unknowns3 = {\n",
    "    x:(\n",
    "        [y for y in ys if y not in unknowns2 or x == y] if x not in unknowns2\n",
    "        else [x]\n",
    "     ) for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns3.values()]))\n",
    "with open('gram_without_unknowns3.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huawei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data_tags_refinement_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_tags_refinement_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m relevant_huawei_ref_df \u001b[38;5;241m=\u001b[39m mlflow_helper\u001b[38;5;241m.\u001b[39mhuawei_run_df(include_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, include_refinements\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m relevant_huawei_ref_df \u001b[38;5;241m=\u001b[39m relevant_huawei_ref_df[\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mrelevant_huawei_ref_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_tags_refinement_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m relevant_huawei_ref_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefinement_run\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relevant_huawei_ref_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_tags_refinement_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m relevant_huawei_ref_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefinement_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relevant_huawei_ref_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_tags_refinement_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]))\n",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_tags_refinement_type'"
     ]
    }
   ],
   "source": [
    "relevant_huawei_ref_df = mlflow_helper.huawei_run_df(include_noise=False, include_refinements=True)\n",
    "relevant_huawei_ref_df = relevant_huawei_ref_df[\n",
    "        relevant_huawei_ref_df[\"data_tags_refinement_type\"].fillna(\"\").astype(str).apply(len) > 0\n",
    "].copy()\n",
    "relevant_huawei_ref_df['refinement_run'] = relevant_huawei_ref_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "relevant_huawei_ref_df['refinement_type'] = relevant_huawei_ref_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "relevant_huawei_ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_accuracy_df = mlflow_helper.load_best_metrics_for_ids(run_ids=set(relevant_huawei_ref_df['info_run_id']))\n",
    "huawei_accuracy_df['refinement_run'] = huawei_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "huawei_accuracy_df['refinement_type'] = huawei_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "huawei_accuracy_df['refinement_type_order'] = huawei_accuracy_df['refinement_type'].replace({\n",
    "    'reference':0, \n",
    "    'original':1, \n",
    "    'refinement_0':2,\n",
    "    'refinement_1':3,\n",
    "    'refinement_2':4,})\n",
    "huawei_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=huawei_accuracy_df[\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) &\n",
    "        (huawei_accuracy_df['val_top_5_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_5_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=huawei_accuracy_df[\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) &\n",
    "        (huawei_accuracy_df['val_top_5_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_5_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_accuracy_df_p = calculate_accuracies_per_percentiles(\n",
    "    relevant_run_df=relevant_huawei_ref_df, \n",
    "    k=20, num_percentiles=10, num_input_percentiles=10,\n",
    "    percentile_names=[\n",
    "        'avg_input_frequencies_percentile', \n",
    "        'median_input_frequencies_percentile', \n",
    "        'min_input_frequencies_percentile', \n",
    "        'p10_input_frequencies_percentile', \n",
    "        'unknown_inputs_percentile', \n",
    "        'output_frequency_percentile',\n",
    "        'avg_input_frequencies_range', \n",
    "        'median_input_frequencies_range', \n",
    "        'min_input_frequencies_range', \n",
    "        'p10_input_frequencies_range', \n",
    "        'unknown_inputs_range', \n",
    "    ],\n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir)\n",
    "huawei_accuracy_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=huawei_accuracy_df_p,\n",
    "    refinement_df=relevant_huawei_ref_df[relevant_huawei_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.0\"],\n",
    "    reference_refinement_type=\"original\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=huawei_accuracy_df_p,\n",
    "    refinement_df=relevant_huawei_ref_df[relevant_huawei_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.1\"],\n",
    "    reference_refinement_type=\"reference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_example_runs = {\n",
    "    'edges_added': {\n",
    "        'gram': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/gram_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/text_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/causal_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "    'edges_removed': {\n",
    "        'gram': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/gram_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/text_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/causal_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "}\n",
    "\n",
    "mimic_example_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_example_runs = {\n",
    "    'edges_added': {\n",
    "        'gram': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_gram_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_text_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_causal_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "    'edges_removed': {\n",
    "        'gram': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_gram_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "        'text': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_text_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "        'causal': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_causal_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "    },\n",
    "}\n",
    "\n",
    "huawei_example_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinementConfig:\n",
    "    min_edge_weight: float = 0.8\n",
    "    max_train_examples: int = 100\n",
    "    refinement_metric: str = \"mean_outlier_score\"\n",
    "    refinement_metric_maxrank: int = 100\n",
    "    max_edges_to_remove: int = 100\n",
    "    max_refinement_metric: int = -1\n",
    "    mlflow_dir: str = \"../gsim01/mlruns/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_removed_edges(original_run_id, reference_run_id, local_mlflow_dir, use_node_mapping=False):\n",
    "    original_attention = load_attention_weights(original_run_id, local_mlflow_dir)\n",
    "    frequencies = load_input_frequency_dict(original_run_id, local_mlflow_dir)\n",
    "\n",
    "    config = RefinementConfig()\n",
    "    config.min_edge_weight = 0.5\n",
    "    config.max_train_examples = 50\n",
    "    config.max_refinement_metric = -2\n",
    "    refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "    \n",
    "    feature_node_mapping = convert_to_node_mapping(\n",
    "        [x for x in original_attention], use_node_mapping\n",
    "    )\n",
    "    colored_connections = calculate_colored_connections(\n",
    "        reference_connections=set(\n",
    "            [(c,p) for c,ps in refined_knowledge.items() for p in ps]\n",
    "        ),\n",
    "        attention_weights=original_attention,\n",
    "        feature_node_mapping=feature_node_mapping,\n",
    "    )\n",
    "    print(\"Removed\", len(colored_connections), \"edges\")\n",
    "    node_mapping = _create_graph_visualization(\n",
    "        attention_weights=original_attention, \n",
    "        threshold=0.25, \n",
    "        run_name=\"refinement_edges_removed\", \n",
    "        node_mapping=feature_node_mapping,\n",
    "        colored_connections=colored_connections)\n",
    "    return node_mapping, frequencies\n",
    "\n",
    "def plot_for_added_edges(original_run_id, reference_run_id, local_mlflow_dir, use_node_mapping=False):\n",
    "    original_attention = load_attention_weights(original_run_id, local_mlflow_dir)\n",
    "    reference_attention = load_attention_weights(reference_run_id, local_mlflow_dir)\n",
    "    frequencies = load_input_frequency_dict(original_run_id, local_mlflow_dir)\n",
    "\n",
    "    config = RefinementConfig()\n",
    "    config.min_edge_weight = 0.5\n",
    "    config.max_train_examples = 50\n",
    "    config.max_edges_to_remove = 1000\n",
    "    config.max_refinement_metric = 2\n",
    "    refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "    \n",
    "    refined_attention = {c:{} for c in refined_knowledge}\n",
    "    for child in original_attention:\n",
    "        for parent in original_attention[child]:\n",
    "            if parent in refined_knowledge.get(child, {}):\n",
    "                refined_attention[child][parent] = original_attention[child][parent]\n",
    "\n",
    "    feature_node_mapping = convert_to_node_mapping(\n",
    "        [x for x in original_attention], use_node_mapping\n",
    "    )\n",
    "    colored_connections = calculate_colored_connections(\n",
    "        reference_connections=set(\n",
    "            [(c,p) for c,ps in reference_attention.items() for p in ps]\n",
    "        ),\n",
    "        attention_weights=refined_attention,\n",
    "        feature_node_mapping=feature_node_mapping,\n",
    "    )\n",
    "    print(\"Added\", len(colored_connections), \"edges\")\n",
    "    node_mapping = _create_graph_visualization(\n",
    "        attention_weights=refined_attention, \n",
    "        threshold=0.25, \n",
    "        run_name=\"refinement_edges_removed\", \n",
    "        node_mapping=feature_node_mapping,\n",
    "        colored_connections=colored_connections)\n",
    "    return node_mapping, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, frequencies = plot_for_removed_edges(\n",
    "    original_run_id=relevant_mimic_ref_df[\n",
    "        (relevant_mimic_ref_df['refinement_run'] == mimic_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_mimic_ref_df['refinement_type'] == \"original\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    reference_run_id=relevant_mimic_ref_df[\n",
    "        (relevant_mimic_ref_df['refinement_run'] == mimic_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_mimic_ref_df['refinement_type'] == \"reference\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir, \n",
    "    use_node_mapping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, frequencies = plot_for_removed_edges(\n",
    "    original_run_id=relevant_huawei_ref_df[\n",
    "        (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_huawei_ref_df['refinement_type'] == \"original\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    reference_run_id=relevant_huawei_ref_df[\n",
    "        (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_huawei_ref_df['refinement_type'] == \"reference\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir, \n",
    "    use_node_mapping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_run_id = relevant_huawei_ref_df[\n",
    "    (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "    (relevant_huawei_ref_df['refinement_type'] == \"original\")\n",
    "][\"info_run_id\"].iloc[0]\n",
    "reference_run_id = relevant_huawei_ref_df[\n",
    "    (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "    (relevant_huawei_ref_df['refinement_type'] == \"reference\")\n",
    "][\"info_run_id\"].iloc[0]\n",
    "\n",
    "original_attention = load_attention_weights(original_run_id, mlflow_helper.local_mlflow_dir)\n",
    "frequencies = load_input_frequency_dict(original_run_id, mlflow_helper.local_mlflow_dir)\n",
    "\n",
    "config = RefinementConfig()\n",
    "config.min_edge_weight = 0.5\n",
    "config.max_train_examples = 1000\n",
    "config.max_refinement_metric = 0\n",
    "refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "\n",
    "feature_node_mapping = convert_to_node_mapping(\n",
    "    [x for x in original_attention], False,\n",
    ")\n",
    "colored_connections = calculate_colored_connections(\n",
    "    reference_connections=set(\n",
    "        [(c,p) for c,ps in refined_knowledge.items() for p in ps]\n",
    "    ),\n",
    "    attention_weights=original_attention,\n",
    "    feature_node_mapping=feature_node_mapping,\n",
    ")\n",
    "print(\"Removed\", len(colored_connections), \"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([str((x, frequencies[x[0]]['absolute_frequency'])) for x in colored_connections if x[1] == \"server\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"asldkfj.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join([x for x, ys in original_attention.items() if \"server\" in ys and float(ys.get(\"server\", -1)) > 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mapping = _create_graph_visualization(\n",
    "    attention_weights=original_attention, \n",
    "    threshold=0.25, \n",
    "    run_name=\"refinement_edges_removed_gram\", \n",
    "    node_mapping=feature_node_mapping,\n",
    "    colored_connections=colored_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_knowledge_text = refined_knowledge"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b5e93e154d2b3bebada531bd37ae367fe461e3b71c186231ccdab3aa47e3f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('healthcare-aiops': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
