{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.refinement import knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/attention_graph.py\n",
    "%run utils/mlflow_query.py\n",
    "%run utils/percentiles.py\n",
    "%run utils/loading.py\n",
    "%run utils/comparison.py\n",
    "%run utils/refinement.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_helper = MlflowHelper(pkl_file=Path(\"mlflow_run_df.pkl\"))\n",
    "#mlflow_helper.query_all_runs(query_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_mimic_ref_df = mlflow_helper.mimic_run_df(include_noise=False, include_refinements=True)\n",
    "relevant_mimic_ref_df = relevant_mimic_ref_df[\n",
    "        relevant_mimic_ref_df[\"data_tags_refinement_type\"].fillna(\"\").astype(str).apply(len) > 0\n",
    "].copy()\n",
    "relevant_mimic_ref_df['refinement_run'] = relevant_mimic_ref_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "relevant_mimic_ref_df['refinement_type'] = relevant_mimic_ref_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "relevant_mimic_ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_accuracy_df = mlflow_helper.load_best_metrics_for_ids(run_ids=set(relevant_mimic_ref_df['info_run_id']))\n",
    "mimic_accuracy_df['refinement_run'] = mimic_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "mimic_accuracy_df['refinement_type'] = mimic_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "mimic_accuracy_df['refinement_type_order'] = mimic_accuracy_df['refinement_type'].replace({\n",
    "    'reference':0, \n",
    "    'original':1, \n",
    "    'refinement_0':2,\n",
    "    'refinement_1':3,\n",
    "    'refinement_2':4,})\n",
    "\n",
    "mimic_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=mimic_accuracy_df[\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(0.0).astype(float) == 0.0) &\n",
    "        (mimic_accuracy_df['val_top_20_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_20_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=mimic_accuracy_df[\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (mimic_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) &\n",
    "        (mimic_accuracy_df['val_top_20_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_20_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_accuracy_df_p = calculate_accuracies_per_percentiles(\n",
    "    relevant_run_df=relevant_mimic_ref_df, \n",
    "    k=20, num_percentiles=10, num_input_percentiles=10,\n",
    "    percentile_names=[\n",
    "        'avg_input_frequencies_percentile', \n",
    "        'median_input_frequencies_percentile', \n",
    "        'min_input_frequencies_percentile', \n",
    "        'p10_input_frequencies_percentile', \n",
    "        'unknown_inputs_percentile', \n",
    "        'output_frequency_percentile',\n",
    "        'avg_input_frequencies_range', \n",
    "        'median_input_frequencies_range', \n",
    "        'min_input_frequencies_range', \n",
    "        'p10_input_frequencies_range', \n",
    "        'unknown_inputs_range', \n",
    "    ],\n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir)\n",
    "mimic_accuracy_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=mimic_accuracy_df_p,\n",
    "    refinement_df=relevant_mimic_ref_df[relevant_mimic_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.0\"],\n",
    "    reference_refinement_type=\"original\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=mimic_accuracy_df_p,\n",
    "    refinement_df=relevant_mimic_ref_df[relevant_mimic_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.1\"],\n",
    "    reference_refinement_type=\"reference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAM without unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icd9_text():\n",
    "    icd9_df = pd.read_csv(\"../data/icd9.csv\")\n",
    "    return (\n",
    "        icd9_df[[\"child_name\", \"child_code\"]]\n",
    "        .drop_duplicates()\n",
    "        .rename(columns={\"child_name\": \"description\", \"child_code\": \"code\",})\n",
    "        .set_index(\"code\")\n",
    "        .to_dict(\"index\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_df = mlflow_helper.mimic_run_df(include_noise=False, include_refinements=False)\n",
    "\n",
    "mimic_gram_run_id = mimic_df[\n",
    "    (mimic_df['data_tags_noise_type'].fillna('').apply(len) == 0) &   \n",
    "    (mimic_df['data_params_ModelConfigbase_hidden_embeddings_trainable'] == 'False') &\n",
    "    (mimic_df['data_tags_model_type'] == 'gram')\n",
    "].iloc[0].get('info_run_id')\n",
    "\n",
    "texts = load_icd9_text()\n",
    "unknowns = set([x for x,y in texts.items() if \n",
    "    (y[\"description\"].lower().startswith(\"other\")\n",
    "    or y[\"description\"].lower().startswith(\"unspecified\")\n",
    "    or y[\"description\"].lower().endswith(\"unspecified\")\n",
    "    or y[\"description\"].lower().endswith(\"unspecified type\")\n",
    "    or y[\"description\"].lower().endswith(\"not elsewhere classified\"))])\n",
    "\n",
    "attentions = load_attention_weights(\n",
    "    mimic_gram_run_id, \n",
    "    mlflow_helper.local_mlflow_dir\n",
    ")\n",
    "print(sum([len(x) for x in attentions.values()]))\n",
    "attentions_without_unknowns = {\n",
    "    x:[y for y in ys if y not in unknowns or x == y] for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns.values()]))\n",
    "with open('gram_without_unknowns.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns, f)\n",
    "\n",
    "unknowns2 = set([\n",
    "    x for x,y in texts.items() \n",
    "    if any(z in y[\"description\"].lower() for z in [\"other\", \"unspecified\", \"elsewhere\"])\n",
    "])\n",
    "\n",
    "attentions_without_unknowns2 = {\n",
    "    x:[y for y in ys if y not in unknowns2 or x == y] for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns2.values()]))\n",
    "with open('gram_without_unknowns2.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns2, f)\n",
    "\n",
    "attentions_without_unknowns3 = {\n",
    "    x:(\n",
    "        [y for y in ys if y not in unknowns2 or x == y] if x not in unknowns2\n",
    "        else [x]\n",
    "     ) for x,ys in attentions.items()\n",
    "}\n",
    "print(sum([len(x) for x in attentions_without_unknowns3.values()]))\n",
    "with open('gram_without_unknowns3.json', 'w') as f:\n",
    "    json.dump(attentions_without_unknowns3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huawei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_huawei_ref_df = mlflow_helper.huawei_run_df(include_noise=False, include_refinements=True)\n",
    "relevant_huawei_ref_df = relevant_huawei_ref_df[\n",
    "        relevant_huawei_ref_df[\"data_tags_refinement_type\"].fillna(\"\").astype(str).apply(len) > 0\n",
    "].copy()\n",
    "relevant_huawei_ref_df['refinement_run'] = relevant_huawei_ref_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "relevant_huawei_ref_df['refinement_type'] = relevant_huawei_ref_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "relevant_huawei_ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_accuracy_df = mlflow_helper.load_best_metrics_for_ids(run_ids=set(relevant_huawei_ref_df['info_run_id']))\n",
    "huawei_accuracy_df['refinement_run'] = huawei_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "huawei_accuracy_df['refinement_type'] = huawei_accuracy_df[\"data_tags_refinement_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))\n",
    "huawei_accuracy_df['refinement_type_order'] = huawei_accuracy_df['refinement_type'].replace({\n",
    "    'reference':0, \n",
    "    'original':1, \n",
    "    'refinement_0':2,\n",
    "    'refinement_1':3,\n",
    "    'refinement_2':4,})\n",
    "huawei_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=huawei_accuracy_df[\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) &\n",
    "        (huawei_accuracy_df['val_top_5_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_5_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=huawei_accuracy_df[\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigreference_file_knowledge'].fillna('').apply(len) > 0) &\n",
    "        (huawei_accuracy_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) &\n",
    "        (huawei_accuracy_df['val_top_5_categorical_accuracy_history_best'].fillna(-1) > 0)\n",
    "    ].sort_values(by=\"refinement_type_order\"), \n",
    "    x=\"refinement_type\", \n",
    "    y=\"val_top_5_categorical_accuracy_history_best\", \n",
    "    hue=\"data_params_RefinementConfigoriginal_file_knowledge\",\n",
    "    estimator=None,\n",
    "    units=\"refinement_run\",\n",
    "    sort=False,\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_accuracy_df_p = calculate_accuracies_per_percentiles(\n",
    "    relevant_run_df=relevant_huawei_ref_df, \n",
    "    k=20, num_percentiles=10, num_input_percentiles=10,\n",
    "    percentile_names=[\n",
    "        'avg_input_frequencies_percentile', \n",
    "        'median_input_frequencies_percentile', \n",
    "        'min_input_frequencies_percentile', \n",
    "        'p10_input_frequencies_percentile', \n",
    "        'unknown_inputs_percentile', \n",
    "        'output_frequency_percentile',\n",
    "        'avg_input_frequencies_range', \n",
    "        'median_input_frequencies_range', \n",
    "        'min_input_frequencies_range', \n",
    "        'p10_input_frequencies_range', \n",
    "        'unknown_inputs_range', \n",
    "    ],\n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir)\n",
    "huawei_accuracy_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=huawei_accuracy_df_p,\n",
    "    refinement_df=relevant_huawei_ref_df[relevant_huawei_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.0\"],\n",
    "    reference_refinement_type=\"original\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_refinement_improvement(\n",
    "    accuracy_df=huawei_accuracy_df_p,\n",
    "    refinement_df=relevant_huawei_ref_df[relevant_huawei_ref_df[\"data_params_RefinementConfigedges_to_add\"].fillna(\"0.0\") == \"0.1\"],\n",
    "    reference_refinement_type=\"reference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_example_runs = {\n",
    "    'edges_added': {\n",
    "        'gram': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/gram_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/text_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/causal_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.1') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "    'edges_removed': {\n",
    "        'gram': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/gram_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/text_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_mimic_ref_df[\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/causal_original_file_knowledge.json') &\n",
    "            (relevant_mimic_ref_df['data_params_RefinementConfigedges_to_add'].fillna('0.0') == '0.0') \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "}\n",
    "\n",
    "mimic_example_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_example_runs = {\n",
    "    'edges_added': {\n",
    "        'gram': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_gram_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'text': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_text_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "        'causal': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_causal_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) == 0.1) \n",
    "        ]['refinement_run'].iloc[0],\n",
    "    },\n",
    "    'edges_removed': {\n",
    "        'gram': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_gram_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "        'text': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_text_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "        'causal': relevant_huawei_ref_df[\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigoriginal_file_knowledge'] == 'data/huawei_causal_original_file_knowledge.json') &\n",
    "            (relevant_huawei_ref_df['data_params_RefinementConfigedges_to_add'].fillna(-1).astype(float) <= 0) \n",
    "        ].sort_values(by=\"info_start_time\")['refinement_run'].iloc[0],\n",
    "    },\n",
    "}\n",
    "\n",
    "huawei_example_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinementConfig:\n",
    "    min_edge_weight: float = 0.8\n",
    "    max_train_examples: int = 100\n",
    "    refinement_metric: str = \"mean_outlier_score\"\n",
    "    refinement_metric_maxrank: int = 100\n",
    "    max_edges_to_remove: int = 100\n",
    "    max_refinement_metric: int = -1\n",
    "    mlflow_dir: str = \"../gsim01/mlruns/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_removed_edges(original_run_id, reference_run_id, local_mlflow_dir, use_node_mapping=False):\n",
    "    original_attention = load_attention_weights(original_run_id, local_mlflow_dir)\n",
    "    frequencies = load_input_frequency_dict(original_run_id, local_mlflow_dir)\n",
    "\n",
    "    config = RefinementConfig()\n",
    "    config.min_edge_weight = 0.5\n",
    "    config.max_train_examples = 50\n",
    "    config.max_refinement_metric = -2\n",
    "    refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "    \n",
    "    feature_node_mapping = convert_to_node_mapping(\n",
    "        [x for x in original_attention], use_node_mapping\n",
    "    )\n",
    "    colored_connections = calculate_colored_connections(\n",
    "        reference_connections=set(\n",
    "            [(c,p) for c,ps in refined_knowledge.items() for p in ps]\n",
    "        ),\n",
    "        attention_weights=original_attention,\n",
    "        feature_node_mapping=feature_node_mapping,\n",
    "    )\n",
    "    print(\"Removed\", len(colored_connections), \"edges\")\n",
    "    node_mapping = _create_graph_visualization(\n",
    "        attention_weights=original_attention, \n",
    "        threshold=0.25, \n",
    "        run_name=\"refinement_edges_removed\", \n",
    "        node_mapping=feature_node_mapping,\n",
    "        colored_connections=colored_connections)\n",
    "    return node_mapping, frequencies\n",
    "\n",
    "def plot_for_added_edges(original_run_id, reference_run_id, local_mlflow_dir, use_node_mapping=False):\n",
    "    original_attention = load_attention_weights(original_run_id, local_mlflow_dir)\n",
    "    reference_attention = load_attention_weights(reference_run_id, local_mlflow_dir)\n",
    "    frequencies = load_input_frequency_dict(original_run_id, local_mlflow_dir)\n",
    "\n",
    "    config = RefinementConfig()\n",
    "    config.min_edge_weight = 0.5\n",
    "    config.max_train_examples = 50\n",
    "    config.max_edges_to_remove = 1000\n",
    "    config.max_refinement_metric = 2\n",
    "    refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "    \n",
    "    refined_attention = {c:{} for c in refined_knowledge}\n",
    "    for child in original_attention:\n",
    "        for parent in original_attention[child]:\n",
    "            if parent in refined_knowledge.get(child, {}):\n",
    "                refined_attention[child][parent] = original_attention[child][parent]\n",
    "\n",
    "    feature_node_mapping = convert_to_node_mapping(\n",
    "        [x for x in original_attention], use_node_mapping\n",
    "    )\n",
    "    colored_connections = calculate_colored_connections(\n",
    "        reference_connections=set(\n",
    "            [(c,p) for c,ps in reference_attention.items() for p in ps]\n",
    "        ),\n",
    "        attention_weights=refined_attention,\n",
    "        feature_node_mapping=feature_node_mapping,\n",
    "    )\n",
    "    print(\"Added\", len(colored_connections), \"edges\")\n",
    "    node_mapping = _create_graph_visualization(\n",
    "        attention_weights=refined_attention, \n",
    "        threshold=0.25, \n",
    "        run_name=\"refinement_edges_removed\", \n",
    "        node_mapping=feature_node_mapping,\n",
    "        colored_connections=colored_connections)\n",
    "    return node_mapping, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, frequencies = plot_for_removed_edges(\n",
    "    original_run_id=relevant_mimic_ref_df[\n",
    "        (relevant_mimic_ref_df['refinement_run'] == mimic_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_mimic_ref_df['refinement_type'] == \"original\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    reference_run_id=relevant_mimic_ref_df[\n",
    "        (relevant_mimic_ref_df['refinement_run'] == mimic_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_mimic_ref_df['refinement_type'] == \"reference\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir, \n",
    "    use_node_mapping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, frequencies = plot_for_removed_edges(\n",
    "    original_run_id=relevant_huawei_ref_df[\n",
    "        (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_huawei_ref_df['refinement_type'] == \"original\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    reference_run_id=relevant_huawei_ref_df[\n",
    "        (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "        (relevant_huawei_ref_df['refinement_type'] == \"reference\")\n",
    "    ][\"info_run_id\"].iloc[0], \n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir, \n",
    "    use_node_mapping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_run_id = relevant_huawei_ref_df[\n",
    "    (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "    (relevant_huawei_ref_df['refinement_type'] == \"original\")\n",
    "][\"info_run_id\"].iloc[0]\n",
    "reference_run_id = relevant_huawei_ref_df[\n",
    "    (relevant_huawei_ref_df['refinement_run'] == huawei_example_runs['edges_removed']['gram']) &\n",
    "    (relevant_huawei_ref_df['refinement_type'] == \"reference\")\n",
    "][\"info_run_id\"].iloc[0]\n",
    "\n",
    "original_attention = load_attention_weights(original_run_id, mlflow_helper.local_mlflow_dir)\n",
    "frequencies = load_input_frequency_dict(original_run_id, mlflow_helper.local_mlflow_dir)\n",
    "\n",
    "config = RefinementConfig()\n",
    "config.min_edge_weight = 0.5\n",
    "config.max_train_examples = 1000\n",
    "config.max_refinement_metric = 0\n",
    "refined_knowledge = knowledge.KnowledgeProcessor(config).load_refined_knowledge(refinement_run_id=original_run_id, reference_run_id=reference_run_id)\n",
    "\n",
    "feature_node_mapping = convert_to_node_mapping(\n",
    "    [x for x in original_attention], False,\n",
    ")\n",
    "colored_connections = calculate_colored_connections(\n",
    "    reference_connections=set(\n",
    "        [(c,p) for c,ps in refined_knowledge.items() for p in ps]\n",
    "    ),\n",
    "    attention_weights=original_attention,\n",
    "    feature_node_mapping=feature_node_mapping,\n",
    ")\n",
    "print(\"Removed\", len(colored_connections), \"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([str((x, frequencies[x[0]]['absolute_frequency'])) for x in colored_connections if x[1] == \"server\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"asldkfj.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join([x for x, ys in original_attention.items() if \"server\" in ys and float(ys.get(\"server\", -1)) > 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mapping = _create_graph_visualization(\n",
    "    attention_weights=original_attention, \n",
    "    threshold=0.25, \n",
    "    run_name=\"refinement_edges_removed_gram\", \n",
    "    node_mapping=feature_node_mapping,\n",
    "    colored_connections=colored_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_knowledge_text = refined_knowledge"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b5e93e154d2b3bebada531bd37ae367fe461e3b71c186231ccdab3aa47e3f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('healthcare-aiops': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
