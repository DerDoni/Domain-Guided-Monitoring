{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.features import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/base.py\n",
    "%run utils/loading.py\n",
    "%run utils/attention_graph.py\n",
    "%run utils/mlflow_query.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_helper = MlflowHelper(pkl_file=Path(\"mlflow_run_df.pkl\"))\n",
    "#mlflow_helper.query_all_runs(pkl_file=Path(\"mlflow_run_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_df = mlflow_helper.huawei_run_df(\n",
    "    valid_x_columns=[\"log_cluster_template\", \"fine_log_cluster_template\", \"coarse_log_cluster_template\", \"attention_log_cluster_template_90\"],\n",
    "    valid_y_columns=[\"attributes\", \"coarse_log_cluster_template\"],\n",
    "    include_drain_hierarchy=True,\n",
    ")\n",
    "huawei_df = huawei_df[\n",
    "    huawei_df[\"data_params_ModelConfigbase_feature_embeddings_trainable\"].astype(str) == \"False\"\n",
    "]\n",
    "\n",
    "huawei_df.groupby(by=[\n",
    "    \"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    \"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    \"data_tags_model_type\",\n",
    "]).agg({\n",
    "    \"info_run_id\": len\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drain Hierarchy - Suggested Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = huawei_df[\n",
    "    (huawei_df[\"data_params_SequenceConfigx_sequence_column_name\"] == \"fine_log_cluster_template\")\n",
    "    & (huawei_df[\"data_params_SequenceConfigy_sequence_column_name\"] == \"attributes\")\n",
    "    & (huawei_df[\"data_tags_model_type\"] == \"gram_logs\")\n",
    "][\"info_run_id\"].iloc[0]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_node_mapping = create_graph_visualization(\n",
    "    run_id=run_id, \n",
    "    local_mlflow_dir=mlflow_helper.local_mlflow_dir,\n",
    "    threshold=0.2, \n",
    "    run_name='drain_hierarchy', \n",
    "    use_node_mapping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logs = df = pd.DataFrame(\n",
    "    pd.read_csv('../data/logs_aggregated_concurrent.csv')[\"Payload\"].fillna(\"\").astype(str).replace(np.nan, \"\", regex=True).dropna().drop_duplicates().reset_index(drop=True)\n",
    ")\n",
    "drain = preprocessing.Drain(\n",
    "    preprocessing.DrainParameters(\n",
    "        depth=huawei_df[\n",
    "            huawei_df[\"info_run_id\"] == run_id\n",
    "        ][\"data_params_HuaweiPreprocessorConfigfine_drain_log_depth\"].astype(int).iloc[0],\n",
    "        st=huawei_df[\n",
    "            huawei_df[\"info_run_id\"] == run_id\n",
    "        ][\"data_params_HuaweiPreprocessorConfigfine_drain_log_st\"].astype(float).iloc[0],\n",
    "        rex=[\n",
    "            (\"(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)\", \"\"),\n",
    "            (\"[^a-zA-Z0-9\\-\\.]\", \" \"),\n",
    "            (\"[^a-zA-Z\\d\\s:]\", \"\"),\n",
    "        ],\n",
    "    ),\n",
    "    data_df=original_logs,\n",
    "    data_df_column_name=\"Payload\",\n",
    ")\n",
    "drain_result = drain.load_data().drop_duplicates().set_index(\"log_idx\")\n",
    "log_result_df = pd.merge(\n",
    "    original_logs, \n",
    "    drain_result, \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how=\"left\"\n",
    ").rename(columns={\n",
    "    \"cluster_template\": \"fine_log_cluster_template\"\n",
    "})[[\"Payload\", \"fine_log_cluster_template\"]]\n",
    "\n",
    "log_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = load_attention_weights(run_id=run_id, local_mlflow_dir=mlflow_helper.local_mlflow_dir)\n",
    "attention_representations = []\n",
    "\n",
    "for fine_template in attention_weights:\n",
    "    best_representation = sorted([(k,float(v)) for k,v in attention_weights[fine_template].items()], key=lambda x: x[1], reverse=True)[0]\n",
    "    attention_representation = {\n",
    "        \"attention_representation_\" + str(x): (best_representation[0] if float(best_representation[1]) > x else fine_template)\n",
    "        for x in [0.5, 0.9]\n",
    "    }\n",
    "    attention_representation[\"fine_log_cluster_template\"] = fine_template[len(\"fine_log_cluster_template#\"):]\n",
    "    attention_representation[\"attention_representation\"] = best_representation[0]\n",
    "    attention_representations.append(attention_representation)\n",
    "\n",
    "pd.DataFrame.from_records(attention_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_type_template(attention_representation: str):\n",
    "    if \"_log_cluster_template#\" in attention_representation:\n",
    "        splitted = attention_representation.split(\"#\")\n",
    "        return (splitted[0], \" \".join(splitted[1:]))\n",
    "    elif attention_representation.startswith(\"coarse_log_cluster_path#\"):\n",
    "        splitted = attention_representation.split(\"#\")\n",
    "        return (splitted[0], \" \".join(splitted[1:]) + \" ***\")\n",
    "    elif attention_representation.startswith(\"coarse_log_cluster_path->\"):\n",
    "        splitted = attention_representation.split(\"->\")\n",
    "        return (splitted[0] + \"_\" + str(len(splitted)-2), \" \".join(splitted[2:]) + \" ***\")\n",
    "    else:\n",
    "        return (\"???\", attention_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_df = pd.merge(\n",
    "    log_result_df, \n",
    "    pd.DataFrame.from_records(attention_representations),\n",
    "    how=\"left\",\n",
    "    on=\"fine_log_cluster_template\").fillna(\"\")\n",
    "for column in [x for x in drain_df.columns if x.startswith(\"attention_representation\")]:\n",
    "    drain_df[column + \"_type\"] = drain_df[column].apply(lambda x: extract_type_template(str(x))[0])\n",
    "    drain_df[column + \"_template\"] = drain_df[column].apply(lambda x: extract_type_template(str(x))[1])\n",
    "\n",
    "drain_df[[\"attention_representation\", \"attention_representation_type\", \"attention_representation_template\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_grouped = drain_df.groupby(by=[\"attention_representation_type\"]).agg({\n",
    "    \"Payload\": lambda x: len(set(x)),\n",
    "    \"fine_log_cluster_template\": lambda x: len(set(x)), \n",
    "    \"attention_representation_template\": lambda x: len(set(x)),\n",
    "})\n",
    "drain_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df = drain_grouped.reset_index(drop=False).melt(\n",
    "    id_vars=[\"attention_representation_type\"],\n",
    "    value_vars=[\"Payload\"],# \"fine_log_cluster_template\", \"attention_representation_template\"],\n",
    "    value_name=\"num_examples\",\n",
    "    var_name=\"type\")\n",
    "g = sns.catplot(data=melt_df,\n",
    "    x=\"attention_representation_type\", \n",
    "    y=\"num_examples\",\n",
    "    hue=\"type\",\n",
    "    order=[\n",
    "        \"fine_log_cluster_template\", \"0_log_cluster_template\", \"1_log_cluster_template\", \"2_log_cluster_template\", \n",
    "        \"coarse_log_cluster_template\", \"coarse_log_cluster_path\"\n",
    "    ] + [\"coarse_log_cluster_path_\" + str(x) for x in reversed(range(\n",
    "        max([int(x.split(\"_\")[-1]) for x in drain_grouped.index if x.startswith(\"coarse_log_cluster_path_\")]) + 1\n",
    "    ))],\n",
    "    #col=\"type\",\n",
    "    kind=\"bar\",\n",
    "    sharey=False,\n",
    "    palette=\"Set2\",\n",
    "    legend=False,\n",
    ").set_xticklabels(rotation=90).set_axis_labels(\"\", \"number of log lines\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"drain_distribution.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_df[\n",
    "    drain_df[\"attention_representation_type\"] == \"coarse_log_cluster_path_0\"\n",
    "][[\"Payload\", \"attention_representation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_df[\"attention_log_cluster_template_50\"] = drain_df[\"attention_representation_0.5\"]\n",
    "drain_df[\"attention_log_cluster_template_90\"] = drain_df[\"attention_representation_0.9\"]\n",
    "drain_df[\n",
    "    [\"Payload\", \"attention_log_cluster_template_50\", \"attention_log_cluster_template_90\"]\n",
    "].to_csv(\"drain_attention_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"drain_attention_clusters.csv\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_importances = calculate_attention_importances(attention_weights)\n",
    "examples_extensions = [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->9->extension\"] if x[1] > 0.9]\n",
    "examples_instance = [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->7->instance\"] if x[1] > 0.9]\n",
    "examples_instance2 = [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->9->instance->*\"] if x[1] > 0.9]\n",
    "examples_automatically = [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->10->automatically\"] if x[1] > 0.9]\n",
    "examples_cleaning= [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->4->cleaning->stale\"] if x[1] > 0.9]\n",
    "examples_date = [x[0].split(\"#\")[1] for x in attention_importances[\"coarse_log_cluster_path->17\"] if x[1] > 0.9]\n",
    "\n",
    "examples_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights[\"fine_log_cluster_template#25 nov 2019 19 * * 0100 get v3 auth tokens http 11 200 * * pythonkeystoneclient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights[[x for x in attention_importances[\"coarse_log_cluster_path->9->extension\"] if x[1] < 0.9][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (x, ys) for x,ys in attention_importances.items() if \n",
    "    \"either ensure your deployment is ready\" in x \n",
    "    and x.startswith(\"coarse_log_cluster_template\") \n",
    "    and \"* * * * * * * * * * * *\" in x\n",
    "    and len([y for y in ys if y[1] > 0.2]) == 3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_metrics_df = mlflow_helper.load_best_metrics_for_ids(set(huawei_df[\"info_run_id\"]))\n",
    "huawei_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=huawei_metrics_df[\n",
    "        (huawei_metrics_df[\"data_params_SequenceConfigx_sequence_column_name\"].apply(lambda x: x != \"log_cluster_template\"))\n",
    "        #& (huawei_metrics_df[\"data_params_SequenceConfigy_sequence_column_name\"].apply(lambda x: x == \"attributes\"))\n",
    "        #& (huawei_metrics_df[\"data_tags_model_type\"].apply(lambda x: x == \"simple\"))\n",
    "    ],\n",
    "    hue=\"data_tags_model_type\", \n",
    "    x=\"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    y=\"val_top_5_categorical_accuracy_history_best\",\n",
    "    row=\"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    order=[\"fine_log_cluster_template\", \"coarse_log_cluster_template\", \"attention_log_cluster_template_90\"],\n",
    "    kind=\"box\",\n",
    "    sharey=\"row\",\n",
    ").set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = huawei_metrics_df.copy()\n",
    "df[\"data_tags_model_type\"] = df[\"data_tags_model_type\"].apply(lambda x: {\n",
    "    \"gram\": \"hierarchy\",\n",
    "}.get(x, x))\n",
    "df[\"data_params_SequenceConfigx_sequence_column_name\"] = df[\"data_params_SequenceConfigx_sequence_column_name\"].apply(lambda x: {\n",
    "    \"log_cluster_template\": \"fine_log_cluster_template\",\n",
    "    \"attention_log_cluster_template_90\": \"attention_log_cluster_template\",\n",
    "}.get(x, x))\n",
    "df[\"Log Template\"] = df[\"data_params_SequenceConfigx_sequence_column_name\"].apply(lambda x: \"attention\" if \"attention\" in x else \"drain\")\n",
    "g = sns.catplot(\n",
    "    data=df[\n",
    "        df[\"data_params_SequenceConfigy_sequence_column_name\"].apply(lambda x: x == \"attributes\")\n",
    "        & df[\"data_tags_model_type\"].apply(lambda x: x == \"simple\")\n",
    "        &  df[\"data_params_ModelConfigbase_hidden_embeddings_trainable\"].apply(lambda x: x == \"False\")\n",
    "    ],\n",
    "    hue=\"Log Template\", \n",
    "    x=\"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    y=\"val_top_5_categorical_accuracy_history_best\",\n",
    "    row=\"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    order=[\"fine_log_cluster_template\", \"coarse_log_cluster_template\", \"attention_log_cluster_template\"],\n",
    "    kind=\"box\",\n",
    "    palette=\"Set2\",\n",
    "    dodge=False,\n",
    ").set_xticklabels(rotation=45).set_titles(\"\").set_axis_labels('', \"val_top_5_categorical_accuracy\")\n",
    "plt.savefig(\"drain_results.png\", dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MIMIC Clusters as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy = pd.read_csv('../data/hierarchy_icd9.csv')\n",
    "hierarchy[hierarchy[\"level_0\"] == \"976.1\"].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_df = mlflow_helper.mimic_run_df()\n",
    "example_mimic_run_id = mimic_df[\n",
    "    (mimic_df[\"data_params_ModelConfigbase_feature_embeddings_trainable\"] == \"False\")\n",
    "    & (mimic_df[\"data_tags_model_type\"] == \"gram\")\n",
    "    & (mimic_df[\"data_params_SequenceConfigx_sequence_column_name\"] == \"level_0\")\n",
    "][\"info_run_id\"].iloc[2]\n",
    "\n",
    "attention_weights = load_attention_weights(example_mimic_run_id, mlflow_helper.local_mlflow_dir)\n",
    "frequencies = load_input_frequency_dict(example_mimic_run_id, mlflow_helper.local_mlflow_dir)\n",
    "hierarchy = pd.read_csv('../data/hierarchy_icd9.csv')\n",
    "\n",
    "attention_representations = []\n",
    "diff_09 = []\n",
    "diff_05 = []\n",
    "for input in attention_weights:\n",
    "    levels = hierarchy[hierarchy[\"level_0\"] == input].iloc[0].to_dict()\n",
    "    best_representation = sorted([(k,float(v)) for k,v in attention_weights[input].items()], key=lambda x: x[1], reverse=True)[0]\n",
    "    attention_representation = {\n",
    "        \"attention_representation_\" + str(x): (best_representation[0] if float(best_representation[1]) > x else input)\n",
    "        for x in [0.5, 0.9]\n",
    "    }\n",
    "    attention_representation[\"original_level_cluster\"] = input\n",
    "    attention_representation[\"attention_representation\"] = best_representation[0]\n",
    "    for key in set(attention_representation.keys()):\n",
    "        attention_representation[key + \"_level\"] = sorted([\n",
    "            x for x in levels if levels[x] == attention_representation[key]\n",
    "        ])[0]\n",
    "\n",
    "    if attention_representation[\"attention_representation\"] != attention_representation[\"attention_representation_0.9\"]:\n",
    "        diff_09.append(input)\n",
    "        \n",
    "    if attention_representation[\"attention_representation\"] != attention_representation[\"attention_representation_0.5\"]:\n",
    "        diff_05.append(input)\n",
    "        \n",
    "    attention_representations.append(attention_representation)\n",
    "\n",
    "print(len(diff_05))\n",
    "print(len(diff_09))\n",
    "pd.DataFrame.from_records(attention_representations).to_csv(\"gram_attention_levels2.csv\", index=False)\n",
    "icd_df = pd.read_csv(\"gram_attention_levels2.csv\")\n",
    "icd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df_grouped = icd_df.groupby(by=[\"attention_representation_level\"]).agg({\n",
    "    \"original_level_cluster\": lambda x: len(set(x)),\n",
    "})\n",
    "icd_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df = icd_df_grouped.reset_index(drop=False).melt(\n",
    "    id_vars=[\"attention_representation_level\"],\n",
    "    value_vars=[\"original_level_cluster\"],# \"fine_log_cluster_template\", \"attention_representation_template\"],\n",
    "    value_name=\"num_examples\",\n",
    "    var_name=\"type\")\n",
    "g = sns.catplot(data=melt_df,\n",
    "    x=\"attention_representation_level\", \n",
    "    y=\"num_examples\",\n",
    "    hue=\"type\",\n",
    "    order=[\n",
    "        \"level_0\", \"level_1\", \"level_2\", 'level_3', \"level_4\"\n",
    "    ],\n",
    "    #col=\"type\",\n",
    "    kind=\"bar\",\n",
    "    sharey=False,\n",
    "    palette=\"Set2\",\n",
    "    legend=False,\n",
    ").set_xticklabels(rotation=90).set_axis_labels(\"\", \"number of level_0 features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"icd_distribution.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_df = mlflow_helper.mimic_run_df(    \n",
    "    valid_x_columns=[\"level_0\", \"level_1\", \"level_2\", \"level_3\", \"attention_representation\", \"attention_representation_0.5\", \"attention_representation_0.9\"],\n",
    ")\n",
    "mimic_df = mimic_df[\n",
    "    mimic_df[\"data_params_ModelConfigbase_feature_embeddings_trainable\"].astype(str) == \"False\"\n",
    "]\n",
    "mimic_df = mlflow_helper.load_best_metrics_for_ids(set(mimic_df[\"info_run_id\"]))\n",
    "mimic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=mimic_df,\n",
    "    hue=\"data_tags_model_type\", \n",
    "    x=\"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    y=\"val_top_20_categorical_accuracy_history_best\",\n",
    "    #row=\"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    order=[\"level_0\", \"level_1\", \"level_2\", \"attention_representation\", \"attention_representation_0.9\", \"attention_representation_0.5\"],\n",
    "    kind=\"box\",\n",
    "    sharey=\"row\",\n",
    ").set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=mimic_df[\n",
    "        mimic_df[\"data_tags_model_type\"] == \"simple\"\n",
    "    ],\n",
    "    #hue=\"data_tags_model_type\", \n",
    "    x=\"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    y=\"val_top_20_categorical_accuracy_history_best\",\n",
    "    #row=\"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    order=[\"level_0\", \"level_1\", \"attention_representation\"],\n",
    "    kind=\"box\",\n",
    "    sharey=\"row\",\n",
    ").set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mimic_df.copy()\n",
    "df[\"Input Feature\"] = df[\"data_params_SequenceConfigx_sequence_column_name\"].apply(lambda x: \"ICD9\" if \"attention\" not in x else \"attention\")\n",
    "g = sns.catplot(\n",
    "    data=df[\n",
    "        df[\"data_params_SequenceConfigy_sequence_column_name\"].apply(lambda x: x == \"level_3\")\n",
    "        & df[\"data_tags_model_type\"].apply(lambda x: x == \"simple\")\n",
    "        &  df[\"data_params_ModelConfigbase_hidden_embeddings_trainable\"].apply(lambda x: x == \"False\")\n",
    "    ],\n",
    "    hue=\"Input Feature\", \n",
    "    x=\"data_params_SequenceConfigx_sequence_column_name\",\n",
    "    y=\"val_top_20_categorical_accuracy_history_best\",\n",
    "    #row=\"data_params_SequenceConfigy_sequence_column_name\",\n",
    "    order=[\"level_0\", \"level_1\", \"level_2\", \"attention_representation\"],\n",
    "    hue_order=[\"ICD9\", \"attention\"],\n",
    "    kind=\"box\",\n",
    "    palette=\"Set2\",\n",
    "    dodge=False,\n",
    ").set_xticklabels(rotation=45).set_titles(\"\").set_axis_labels('', \"val_top_20_categorical_accuracy\")\n",
    "plt.savefig(\"mimic_results.png\", dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b5e93e154d2b3bebada531bd37ae367fe461e3b71c186231ccdab3aa47e3f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('healthcare-aiops': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
