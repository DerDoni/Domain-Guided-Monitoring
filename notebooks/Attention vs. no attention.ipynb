{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cfc4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 20:32:57.303605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 20:32:57.797261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-13 20:32:57.797317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-13 20:32:57.797321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.features import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3dd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass issues with invoking notebook with server arguments\n",
    "sys.argv.clear()\n",
    "sys.argv.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b242b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/attention_graph.py\n",
    "%run utils/mlflow_query.py\n",
    "%run utils/loading.py\n",
    "%run utils/comparison.py\n",
    "%run utils/ranks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_helper = MlflowHelper(pkl_file=Path(\"mlflow_run_df.pkl\"))\n",
    "#mlflow_helper.query_runs(pkl_file=Path(\"mlflow_run_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pd.read_pickle(\"../data/sequences_df.pkl\")\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc61a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_config = preprocessing.HuaweiPreprocessorConfig()\n",
    "huawei_config.aggregated_log_file = Path(\"../data/logs_aggregated_concurrent.csv\")\n",
    "huawei_config.traces_root_directory = Path(\"../data/concurrent_data/traces/\")\n",
    "huawei_config.final_log_file = Path(\"../data/huawei.pkl\")\n",
    "huawei_config.remove_dates_from_payload = True\n",
    "\n",
    "sequence_preprocessor = preprocessing.ConcurrentAggregatedLogsPreprocessor(huawei_config)\n",
    "#huawei_full_data = sequence_preprocessor.load_full_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_full_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d559bf",
   "metadata": {},
   "source": [
    "# Manually step through program flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de701ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_df = sequence_preprocessor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_df[\"url_cluster_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5923ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF settings\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "tensorflow_seed = 7796\n",
    "random_seed = 82379498237\n",
    "\n",
    "tf.random.set_seed(tensorflow_seed)\n",
    "random.seed(random_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd0bf2",
   "metadata": {},
   "source": [
    "# Collect sequence metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67652cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import sequences\n",
    "from src.features.sequences import transformer\n",
    "\n",
    "sequence_column_name = sequence_preprocessor.sequence_column_name\n",
    "\n",
    "transformer_config = sequences.SequenceConfig()\n",
    "transformer_config.x_sequence_column_name = \"fine_log_cluster_template\"\n",
    "transformer_config.y_sequence_column_name = \"attributes\"\n",
    "transformer_config.predict_full_y_sequence_wide = True\n",
    "\n",
    "transformer = transformer.NextPartialSequenceTransformerFromDataframe(transformer_config)\n",
    "\n",
    "metadata = transformer.collect_metadata(sequences_df, sequence_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75e080",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2316e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_842114/1652825543.py:1: DtypeWarning: Columns (23,24,25,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset_df = pd.read_csv(Path(\"../data/logs_aggregated_concurrent.csv\")).fillna(\"\").astype(str).replace(np.nan, \"\", regex=True)\n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(Path(\"../data/logs_aggregated_concurrent.csv\")).fillna(\"\").astype(str).replace(np.nan, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40634c",
   "metadata": {},
   "source": [
    "# Drain URL cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_only_data = sequence_preprocessor._load_log_only_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_only_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_only_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e94096",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = sequence_preprocessor._read_log_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43abc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce741e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df_url = sequence_preprocessor._add_url_drain_clusters(log_df)\n",
    "log_df_url.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fa815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.preprocessing import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1278fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mspell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:72\u001b[0m, in \u001b[0;36mLogParser.__init__\u001b[0;34m(self, indir, outdir, log_format, tau, keep_para, text_max_length, logmain)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrootNode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogCluL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_logformat_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m rootNodePath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavePath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrootNode.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     75\u001b[0m logCluLPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavePath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogCluL.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Domain-Guided-Monitoring/src/features/preprocessing/spell.py:229\u001b[0m, in \u001b[0;36mLogParser.generate_logformat_regex\u001b[0;34m(self, logformat)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\" Function to generate regular expression to split log messages\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m headers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 229\u001b[0m splitters \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(<[^<>]+>)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(splitters)):\n",
      "File \u001b[0;32m~/miniconda3/envs/lena/lib/python3.9/re.py:231\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(pattern, string, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;124;03m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    of the list.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxsplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "parser = spell.LogParser(indir=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(logs_aggregated_concurrent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfe21fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lena",
   "language": "python",
   "name": "lena"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
